:::MLL 1560873514.700728431 submission_org: {"value": "Intel_Corp", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560873514.702179292 submission_platform: {"value": "32xCLX-8260L_CPUs", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560873514.703434067 submission_division: {"value": "closed", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560873514.704750902 submission_status: {"value": "onprem", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560873514.706088809 submission_benchmark: {"value": "minigo", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560873514.707364391 submission_poc_name: {"value": "Guokai Ma, Letian Kang, Christine Cheng, Mingxiao Huang", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560873514.708642355 submission_poc_email: {"value": "guokai.ma@intel.com, letian.kang@intel.com, christine.cheng@intel.com, mingxiao.huang@intel.com", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560873514.709947026 submission_entry: {"value": {"framework": "TensorFlow 1.13.1", "power": "none", "notes": "none", "interconnect": "OPA", "os": "Oracle Linux Server 7.6", "libraries": "MKLDNN (v0.18), MKL (v2019.0.3.20190220), IntelMPI (2018.1.163)", "compilers": "GCC6.3", "nodes": [{"num_nodes": 32, "cpu": "Intel(R) Xeon(R) Platinum 8260L CPU @ 2.40GHz", "num_cores": 48, "num_vcpus": "NA", "accelerator": "NA", "num_accelerators": 0, "sys_mem_size": "192G", "sys_storage_type": "SSD", "sys_storage_size": "800G", "cpu_accel_interconnect": "100Gb OPA", "network_card": "100Gb OPA", "num_network_cards": 1, "notes": "NA"}]}, "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560873515.984077135 cache_clear: {value: true, metadata: {lineno: 0, file: manual}}
~/submission/benchmarks/minigo/implementations/tensorflow ~/submission/benchmarks/minigo/clx-8260l-2s-x32
Physical cores = 48
Virtual cores = 96
NUMA cores = 24
KMP_HW_SUBSET = 2T
Output to /lfs/lfs12/gma_akey
./run_mn.sh: line 20: ulimit: max user processes: cannot modify limit: Operation not permitted
Wiping dir /lfs/lfs12/gma_akey/results/epb312
:::MLL 1560873523.355233 init_start: {"value": null, "metadata": {'lineno': 742, 'file': 'ml_perf/reference_implementation.py'}}
Making dir /lfs/lfs12/gma_akey/results/epb312/models
Making dir /lfs/lfs12/gma_akey/results/epb312/data/selfplay
Making dir /lfs/lfs12/gma_akey/results/epb312/data/holdout
Making dir /lfs/lfs12/gma_akey/results/epb312/sgf/eval
Making dir /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks
Making dir /lfs/lfs12/gma_akey/results/epb312/work_dir
Making dir /lfs/lfs12/gma_akey/results/epb312/mpi
[2019-06-18 09:58:51] Selfplay nodes = ['epb312', 'epb318', 'epb352', 'epb339', 'epb305', 'epb212', 'epb315', 'epb338', 'epb336', 'epb335', 'epb330', 'epb294', 'epb319', 'epb317', 'epb314', 'epb316', 'epb313', 'epb309', 'epb306', 'epb304', 'epb303', 'epb301', 'epb300', 'epb001', 'epb331', 'epb052']
[2019-06-18 09:58:51] Train nodes = ['epb332', 'epb051', 'epb333', 'epb139', 'epb334', 'epb138']
[2019-06-18 09:58:51] Eval nodes = ['epb312', 'epb318', 'epb352', 'epb339', 'epb305', 'epb212', 'epb315', 'epb338', 'epb336', 'epb335', 'epb330', 'epb294', 'epb319', 'epb317', 'epb314', 'epb316', 'epb313', 'epb309', 'epb306', 'epb304', 'epb303', 'epb301', 'epb300', 'epb001', 'epb331', 'epb052']
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.51s/it]
[2019-06-18 10:01:45] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/tools/strip_unused_lib.py:86: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
[2019-06-18 10:01:45] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/tools/optimize_for_inference_lib.py:113: remove_training_nodes (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.remove_training_nodes`
2019-06-18 10:01:45.770430: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX512F
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2019-06-18 10:01:45.783618: I tensorflow/core/common_runtime/process_util.cc:113] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
[2019-06-18 10:01:45] From ./quantize_graph.py:351: quantize_v2 (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.
Instructions for updating:
`tf.quantize_v2` is deprecated, please use `tf.quantization.quantize` instead.
2019-06-18 10:01:46.122473: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
[2019-06-18 10:01:46] From ./dual_net.py:679: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.gfile.GFile.
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_99']
Reading tf_records from 1 inputs
[2019-06-18 10:01:50] minmax time: 3.881 seconds
2019-06-18 10:01:50.014235: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:01:50.019535: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:01:50.024261: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560873710.140646 init_stop: {"value": null, "metadata": {'lineno': 614, 'file': 'ml_perf/reference_implementation.py'}}
:::MLL 1560873710.141025 run_start: {"value": null, "metadata": {'lineno': 615, 'file': 'ml_perf/reference_implementation.py'}}
:::MLL 1560873710.141438 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 0}}
[2019-06-18 10:01:50] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir 
[2019-06-18 10:01:50] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-2-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000001-000000 --seed=2 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000001-000000 --seed=1023779833 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000001-000000 --seed=2047559664 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000001-000000 --seed=3071339495 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000001-000000 --seed=4095119326 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000001-000000 --seed=5118899157 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000001-000000 --seed=6142678988 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000001-000000 --seed=7166458819 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000001-000000 --seed=8190238650 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000001-000000 --seed=9214018481 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000001-000000 --seed=10237798312 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000001-000000 --seed=11261578143 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000001-000000 --seed=12285357974 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000001-000000 --seed=13309137805 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000001-000000 --seed=14332917636 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000001-000000 --seed=15356697467 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000001-000000 --seed=16380477298 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000001-000000 --seed=17404257129 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000001-000000 --seed=18428036960 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000001-000000 --seed=19451816791 : \
-host epb3
[2019-06-18 10:02:24] selfplay finished: 34.417 seconds
[2019-06-18 10:02:24] selfplay mn: 34.439 seconds
[2019-06-18 10:02:24] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-2-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779833 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559664 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339495 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119326 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899157 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142678988 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458819 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238650 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018481 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798312 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578143 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285357974 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137805 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917636 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697467 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477298 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257129 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036960 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816791 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596622 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376453 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156284 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_
[2019-06-18 10:02:41] divide_golden_chunk finished: 17.300 seconds
[2019-06-18 10:02:41] generate golden chunk: 17.317 seconds
[2019-06-18 10:02:47] train finished: 56.942 seconds
:::MLL 1560873726.608857 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873726.609735 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873726.610589 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:07.192103 47174591869824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560873726.680556 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873726.680930 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873726.681255 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:07.193013 47206704022400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560873726.674926 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873726.675389 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873726.675789 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:07.193147 47145756373888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560873726.614860 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873726.615638 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873726.616309 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:07.193179 47578542158720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 10:02:07.193592 47174591869824 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpjzt8jxxq
I0618 10:02:07.194661 47174591869824 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpjzt8jxxq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae7f960ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:07.195088 47174591869824 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:02:07.194655 47206704022400 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp3pq4pncl
I0618 10:02:07.195781 47206704022400 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp3pq4pncl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aef73694e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:02:07.195270 47578542158720 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpo_4aia7q
W0618 10:02:07.195260 47145756373888 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp36u5lazg
I0618 10:02:07.196240 47206704022400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:02:07.196306 47578542158720 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpo_4aia7q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4606b10e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:07.196365 47145756373888 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp36u5lazg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae142a60e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:07.196726 47578542158720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:02:07.196801 47145756373888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560873726.620548 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873726.621470 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873726.622361 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:07.197587 47233881707392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560873726.620537 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873726.621484 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873726.622349 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:07.197627 47188459164544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560873726.687189 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873726.687613 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873726.687972 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:07.197649 47819691787136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560873726.685336 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873726.685744 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873726.686142 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:07.197692 47294198907776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 10:02:07.199138 47233881707392 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp02jnsulh
I0618 10:02:07.200257 47233881707392 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp02jnsulh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af5c753ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:02:07.199663 47188459164544 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpr9fa4oou
I0618 10:02:07.200727 47233881707392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:02:07.200790 47188459164544 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpr9fa4oou', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeb33eeee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:02:07.200060 47819691787136 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpkb2_9jb6
W0618 10:02:07.200087 47294198907776 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpern3iqme
I0618 10:02:07.201105 47819691787136 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpkb2_9jb6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7e2c545e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:07.201137 47294198907776 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpern3iqme', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b03d2835e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:07.201228 47188459164544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:02:07.201529 47819691787136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:02:07.201562 47294198907776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:02:07.203882 47578542158720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:07.203899 47174591869824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:07.203952 47206704022400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:07.204017 47145756373888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:07.209311 47294198907776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:07.209387 47819691787136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:07.209487 47188459164544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:07.209540 47233881707392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:07.223865 47174591869824 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:07.223863 47578542158720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:07.223995 47206704022400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:07.223999 47145756373888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:07.229243 47819691787136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:07.229334 47294198907776 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:07.231004 47188459164544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:07.231169 47233881707392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560873726.548568 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873726.549466 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873726.550266 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:07.249016 47833330242432 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560873726.559041 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873726.559790 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873726.560494 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:07.249044 47307258872704 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560873726.649836 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873726.650322 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873726.650752 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:07.249189 47008264995712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560873726.640326 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873726.640865 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873726.641346 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:07.249193 47693940302720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 10:02:07.250050 47833330242432 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp46fadjav
I0618 10:02:07.250746 47833330242432 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp46fadjav', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b81593eadd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:02:07.250514 47307258872704 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpcp5p3dgw
I0618 10:02:07.251079 47833330242432 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:02:07.251194 47307258872704 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpcp5p3dgw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b06dcf28dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:07.251505 47307258872704 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:02:07.250929 47008264995712 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp4xf9g9oo
W0618 10:02:07.250903 47693940302720 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp8abclcnw
I0618 10:02:07.251934 47693940302720 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp8abclcnw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b60e4f4fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:07.251956 47008264995712 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp4xf9g9oo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac13f85fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:07.252361 47693940302720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:02:07.252375 47008264995712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:02:07.258527 47833330242432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:07.258480 47307258872704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:07.258768 47693940302720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:07.258883 47008264995712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:07.277795 47307258872704 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:07.277996 47833330242432 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:07.278868 47693940302720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:07.279055 47008264995712 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:07.280912 47206704022400 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:02:07.280988 47145756373888 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:02:07.281486 47578542158720 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:02:07.284963 47188459164544 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:02:07.285284 47206704022400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:02:07.285133 47233881707392 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:02:07.285326 47145756373888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:02:07.285849 47174591869824 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:02:07.285850 47578542158720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:02:07.289497 47188459164544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:02:07.289693 47233881707392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:02:07.290161 47174591869824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:02:07.290407 47206704022400 estimator.py:1111] Calling model_fn.
I0618 10:02:07.290457 47145756373888 estimator.py:1111] Calling model_fn.
W0618 10:02:07.290518 47206704022400 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:02:07.290564 47145756373888 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:02:07.290966 47578542158720 estimator.py:1111] Calling model_fn.
W0618 10:02:07.291084 47578542158720 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:02:07.291934 47206704022400 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:02:07.291976 47145756373888 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:02:07.292504 47578542158720 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:02:07.293090 47819691787136 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:02:07.294592 47188459164544 estimator.py:1111] Calling model_fn.
W0618 10:02:07.294702 47188459164544 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:02:07.294862 47233881707392 estimator.py:1111] Calling model_fn.
W0618 10:02:07.294975 47233881707392 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:02:07.295211 47174591869824 estimator.py:1111] Calling model_fn.
W0618 10:02:07.295319 47174591869824 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:02:07.295150 47294198907776 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:02:07.296108 47188459164544 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:02:07.296423 47233881707392 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:02:07.296733 47174591869824 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:02:07.297395 47819691787136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:02:07.299504 47294198907776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:02:07.302429 47819691787136 estimator.py:1111] Calling model_fn.
W0618 10:02:07.302536 47819691787136 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:02:07.303932 47819691787136 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:02:07.304599 47294198907776 estimator.py:1111] Calling model_fn.
W0618 10:02:07.304715 47294198907776 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:02:07.306115 47294198907776 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560873726.627601 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873726.628003 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873726.628385 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:07.325932 47939552654208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560873726.627902 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873726.628338 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873726.628674 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:07.325975 47287617459072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560873726.565474 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873726.566375 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873726.567259 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:07.326004 47198943638400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560873726.565479 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873726.566367 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873726.567266 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:07.326083 47664810099584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 10:02:07.327515 47939552654208 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpk3_q_dxo
I0618 10:02:07.328581 47939552654208 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpk3_q_dxo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9a14980e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:02:07.328005 47287617459072 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpmfl0r7jn
I0618 10:02:07.329026 47939552654208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:02:07.329061 47287617459072 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpmfl0r7jn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b024a3a6e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:02:07.328441 47664810099584 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpn6tvlcbg
W0618 10:02:07.328417 47198943638400 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpa04fhm96
I0618 10:02:07.329466 47664810099584 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpn6tvlcbg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5a1ca95e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:07.329470 47198943638400 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpa04fhm96', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeda4db4e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:07.329493 47287617459072 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:02:07.329882 47664810099584 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:02:07.329896 47198943638400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:02:07.335176 47307258872704 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:02:07.335304 47833330242432 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:02:07.337769 47664810099584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:07.337854 47939552654208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:07.337907 47287617459072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:07.337928 47198943638400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:07.338795 47008264995712 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:02:07.339417 47307258872704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:02:07.339633 47833330242432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:02:07.340739 47693940302720 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:02:07.343089 47008264995712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:02:07.344409 47307258872704 estimator.py:1111] Calling model_fn.
W0618 10:02:07.344502 47307258872704 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:02:07.344701 47833330242432 estimator.py:1111] Calling model_fn.
W0618 10:02:07.344795 47833330242432 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:02:07.345046 47693940302720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:02:07.345729 47307258872704 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:02:07.346052 47833330242432 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:02:07.348098 47008264995712 estimator.py:1111] Calling model_fn.
W0618 10:02:07.348206 47008264995712 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:02:07.349590 47008264995712 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:02:07.350107 47693940302720 estimator.py:1111] Calling model_fn.
W0618 10:02:07.350210 47693940302720 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:02:07.351614 47693940302720 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:02:07.358786 47939552654208 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:07.358874 47664810099584 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:07.358895 47287617459072 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:07.359162 47198943638400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560873726.636453 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873726.637163 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 15608[2019-06-18 10:02:47] iteration time 0: 56.971 seconds
2019-06-18 10:02:47.492121: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560873767.113049 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 1}}
[2019-06-18 10:02:50] minmax time: 3.232 seconds
2019-06-18 10:02:50.733970: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:02:50.739198: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:02:50.743898: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560873770.754794 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 0}}
[2019-06-18 10:02:50] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir 
[2019-06-18 10:02:50] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-2-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000001-000001 --seed=2 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000001-000001 --seed=1023779833 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000001-000001 --seed=2047559664 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000001-000001 --seed=3071339495 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000001-000001 --seed=4095119326 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000001-000001 --seed=5118899157 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000001-000001 --seed=6142678988 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000001-000001 --seed=7166458819 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000001-000001 --seed=8190238650 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000001-000001 --seed=9214018481 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000001-000001 --seed=10237798312 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000001-000001 --seed=11261578143 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000001-000001 --seed=12285357974 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000001-000001 --seed=13309137805 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000001-000001 --seed=14332917636 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000001-000001 --seed=15356697467 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000001-000001 --seed=16380477298 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000001-000001 --seed=17404257129 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000001-000001 --seed=18428036960 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000001-000001 --seed=19451816791 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000001-000001 --seed=20475596622 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_
[2019-06-18 10:03:01] eval finished: 10.768 seconds
[2019-06-18 10:03:01] Win rate 000001-000001 vs checkpoint: 0.830
:::MLL 1560873781.587719 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 0}}
[2019-06-18 10:03:01] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-3-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000002-000000 --seed=3 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000002-000000 --seed=1023779834 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000002-000000 --seed=2047559665 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000002-000000 --seed=3071339496 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000002-000000 --seed=4095119327 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000002-000000 --seed=5118899158 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000002-000000 --seed=6142678989 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000002-000000 --seed=7166458820 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000002-000000 --seed=8190238651 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000002-000000 --seed=9214018482 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000002-000000 --seed=10237798313 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000002-000000 --seed=11261578144 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000002-000000 --seed=12285357975 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000002-000000 --seed=13309137806 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000002-000000 --seed=14332917637 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000002-000000 --seed=15356697468 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000002-000000 --seed=16380477299 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000002-000000 --seed=17404257130 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000002-000000 --seed=18428036961 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/
[2019-06-18 10:03:31] selfplay finished: 30.152 seconds
[2019-06-18 10:03:31] selfplay mn: 30.172 seconds
[2019-06-18 10:03:31] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-3-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779834 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559665 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339496 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119327 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899158 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142678989 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458820 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238651 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018482 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798313 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578144 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285357975 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137806 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917637 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697468 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477299 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257130 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036961 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816792 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596623 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376454 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156285 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_
[2019-06-18 10:03:34] train finished: 44.196 seconds
:::MLL 1560873775.993555 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873775.994265 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873775.994925 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:56.060411 47417156825984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560873775.989219 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873775.990142 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873775.990952 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:56.060599 47164039660416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 10:02:56.061430 47417156825984 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpgp4ue_up
W0618 10:02:56.061577 47164039660416 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpn1nq_6bx
I0618 10:02:56.062442 47417156825984 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpgp4ue_up', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2073604e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:56.062592 47164039660416 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpn1nq_6bx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae5846ace80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:56.062860 47417156825984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:02:56.063008 47164039660416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:02:56.068202 47417156825984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:56.068258 47164039660416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560873775.998784 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873775.999578 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873776.000286 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:56.069948 47209987359616 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560873775.997477 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873775.998319 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873775.999129 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:56.070039 47102277358464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560873775.996901 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873775.997736 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873775.998528 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:56.070300 47412609045376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560873775.997305 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873775.998163 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873775.998924 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:56.070379 46938762118016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 10:02:56.070950 47209987359616 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp1kvhgay_
W0618 10:02:56.071010 47102277358464 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpmp80jcp7
I0618 10:02:56.072007 47209987359616 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp1kvhgay_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af0371d1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:56.072048 47102277358464 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpmp80jcp7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad72318ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:02:56.071312 47412609045376 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpi_uiietp
W0618 10:02:56.071398 46938762118016 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp886oohhy
I0618 10:02:56.072354 47412609045376 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpi_uiietp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1f644eae80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:56.072429 47209987359616 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:02:56.072455 47102277358464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:02:56.072428 46938762118016 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp886oohhy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab110d45e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:56.072770 47412609045376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:02:56.072838 46938762118016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:02:56.077457 47102277358464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:56.077457 47209987359616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:56.077686 46938762118016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:56.077690 47412609045376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560873776.017349 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873776.018220 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873776.019006 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:56.088139 46962946044800 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560873776.018532 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873776.019351 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873776.020051 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:56.088208 47989495628672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 10:02:56.090796 47164039660416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:56.090931 47417156825984 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:56.089242 46962946044800 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpsqkj1enf
W0618 10:02:56.089270 47989495628672 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp74hii4oq
I0618 10:02:56.090327 46962946044800 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpsqkj1enf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab6b24dce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:56.090381 47989495628672 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp74hii4oq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba5b56d5e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560873776.059995 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873776.060403 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873776.060736 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:56.091603 47318318183296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560873776.059720 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873776.060110 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873776.060466 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:56.091678 47940099175296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000001.tfrecord.zz_0
I0618 10:02:56.090767 46962946044800 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:02:56.090823 47989495628672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:02:56.092634 47318318183296 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpruxeswap
:::MLL 1560873776.064785 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873776.065196 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873776.065578 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:56.093998 47814179615616 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 10:02:56.092690 47940099175296 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpzqf8z0jn
:::MLL 1560873776.065755 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873776.066154 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873776.066474 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:56.094166 47522648617856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000001.tfrecord.zz_0
I0618 10:02:56.093668 47318318183296 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpruxeswap', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0970224e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:56.093702 47940099175296 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpzqf8z0jn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9a352b4e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:56.094080 47318318183296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:02:56.094116 47940099175296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:02:56.095028 47814179615616 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp8lqakfw2
I0618 10:02:56.095179 47522648617856 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b39032d3d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:56.096041 47814179615616 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp8lqakfw2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7ce3c74e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:56.096346 47522648617856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:02:56.096463 47814179615616 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:02:56.097232 47102277358464 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:56.097379 47209987359616 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:56.097733 46938762118016 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:56.097837 47412609045376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:56.096266 46962946044800 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:56.096294 47989495628672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560873776.039490 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873776.040312 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873776.041068 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:56.096302 47551689737088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560873776.026773 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873776.027719 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873776.028593 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:56.096455 47753368351616 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 10:02:56.099022 47940099175296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:56.099030 47318318183296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:56.097298 47551689737088 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpe31bqf6a
W0618 10:02:56.097408 47753368351616 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpsd0y7a54
I0618 10:02:56.098299 47551689737088 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpe31bqf6a', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3fc6299e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:56.098380 47753368351616 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpsd0y7a54', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6ebb250e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:56.098696 47551689737088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:02:56.098762 47753368351616 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:02:56.101170 47522648617856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:56.101218 47814179615616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:56.103845 47753368351616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:56.103894 47551689737088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560873776.087006 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873776.087478 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873776.087903 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:56.113356 47617961845632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 10:02:56.114385 47617961845632 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp3ypew73z
I0618 10:02:56.115390 47617961845632 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp3ypew73z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4f3449ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:56.115797 47617961845632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560873776.096023 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873776.096441 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873776.096803 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:56.118881 47484697052032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 10:02:56.118723 47940099175296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:56.118820 47318318183296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:56.118291 46962946044800 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:56.119837 47484697052032 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpa_eax8b3
W0618 10:02:56.120569 47617961845632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:56.118603 47989495628672 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:02:56.120795 47484697052032 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpa_eax8b3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b302d165e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:02:56.120863 47522648617856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:02:56.121191 47484697052032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:02:56.121178 47814179615616 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560873776.055294 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873776.056190 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873776.057019 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:56.122258 47524556596096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560873776.068299 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873776.069052 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873776.069852 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:56.122217 46955087172480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 10:02:56.123250 47524556596096 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp8svcmjxw
W0618 10:02:56.123226 46955087172480 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpsmzpz_ea
I0618 10:02:56.124236 46955087172480 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpsmzpz_ea', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab4dde0cdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:56.124246 47524556596096 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp8svcmjxw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3974e6be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:56.124637 47524556596096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:02:56.124635 46955087172480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:02:56.125828 47484697052032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:56.123802 47753368351616 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:56.123908 47551689737088 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560873776.096661 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873776.097088 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873776.097485 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:56.125358 48005699978112 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560873776.096642 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873776.097063 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873776.097447 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:56.125443 47024648807296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 10:02:56.126761 47024648807296 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp6_jg7amt
W0618 10:02:56.126734 48005699978112 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpj12rqu9_
I0618 10:02:56.127729 47024648807296 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp6_jg7amt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac510133e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:56.127730 48005699978112 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpj12rqu9_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba97b481e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:56.128128 47024648807296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:02:56.128126 48005699978112 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:02:56.129747 47524556596096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:56.129771 46955087172480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:56.132900 47024648807296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:56.132898 48005699978112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:56.140231 47617961845632 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:56.140220 47164039660416 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:02:56.140574 47417156825984 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560873776.112913 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873776.113323 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873776.113669 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:56.141969 46988132062080 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 10:02:56.145085 47102277358464 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560873776.114429 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873776.114875 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873776.115259 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:02:56.142861 47707705566080 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 10:02:56.144505 47164039660416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:02:56.145503 47209987359616 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:02:56.144870 47417156825984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:02:56.145612 47484697052032 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:56.146019 46938762118016 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:02:56.145987 47412609045376 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:02:56.143685 46988132062080 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpds4ac6ik
W0618 10:02:56.143821 47707705566080 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpsjx5m0ju
I0618 10:02:56.144735 46988132062080 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpds4ac6ik', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abc8f81de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:56.144822 47707705566080 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpsjx5m0ju', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b64196e3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:02:56.145198 46988132062080 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:02:56.145271 47707705566080 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:02:56.149388 47102277358464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:02:56.149816 47209987359616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:02:56.149552 47164039660416 estimator.py:1111] Calling model_fn.
W0618 10:02:56.149665 47164039660416 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:02:56.150346 46938762118016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:02:56.149391 47524556596096 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:56.149485 46955087172480 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:56.150302 47412609045376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:02:56.149923 47417156825984 estimator.py:1111] Calling model_fn.
W0618 10:02:56.150031 47417156825984 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:02:56.151026 47164039660416 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:02:56.151404 47417156825984 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:02:56.150175 47707705566080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:02:56.150178 46988132062080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:02:56.154435 47102277358464 estimator.py:1111] Calling model_fn.
W0618 10:02:56.154543 47102277358464 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:02:56.152573 47024648807296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:02:56.152662 48005699978112 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:02:56.154914 47209987359616 estimator.py:1111] Calling model_fn.
W0618 10:02:56.155021 47209987359616 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:02:56.155358 47412609045376 estimator.py:1111] Calling model_fn.
I0618 10:02:56.155427 46938762118016 estimator.py:1111] Calling model_fn.
W0618 10:02:56.155468 47412609045376 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:02:56.155533 46938762118016 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:02:56.155911 47102277358464 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:02:56.156409 47209987359616 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in[2019-06-18 10:03:35] divide_golden_chunk finished: 3.527 seconds
[2019-06-18 10:03:35] generate golden chunk: 3.542 seconds
[2019-06-18 10:03:35] moving /lfs/lfs12/gma_akey/results/epb312/models/000002-000001.meta --> /lfs/lfs12/gma_akey/results/epb312/models/000002-000002.meta
[2019-06-18 10:03:35] moving /lfs/lfs12/gma_akey/results/epb312/models/000002-000001.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb312/models/000002-000002.data-00000-of-00001
[2019-06-18 10:03:35] moving /lfs/lfs12/gma_akey/results/epb312/models/000002-000001.index --> /lfs/lfs12/gma_akey/results/epb312/models/000002-000002.index
[2019-06-18 10:03:35] moving /lfs/lfs12/gma_akey/results/epb312/models/000002-000001.pb --> /lfs/lfs12/gma_akey/results/epb312/models/000002-000002.pb
[2019-06-18 10:03:35] iteration time 1: 48.230 seconds
2019-06-18 10:03:35.746181: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560873815.342723 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 2}}
[2019-06-18 10:03:38] minmax time: 3.214 seconds
2019-06-18 10:03:38.969891: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:03:38.975381: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:03:38.979918: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560873818.989817 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 1}}
[2019-06-18 10:03:39] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir 
[2019-06-18 10:03:39] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-3-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000002-000002 --seed=3 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000002-000002 --seed=1023779834 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000002-000002 --seed=2047559665 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000002-000002 --seed=3071339496 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000002-000002 --seed=4095119327 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000002-000002 --seed=5118899158 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000002-000002 --seed=6142678989 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000002-000002 --seed=7166458820 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000002-000002 --seed=8190238651 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000002-000002 --seed=9214018482 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000002-000002 --seed=10237798313 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000002-000002 --seed=11261578144 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000002-000002 --seed=12285357975 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000002-000002 --seed=13309137806 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000002-000002 --seed=14332917637 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000002-000002 --seed=15356697468 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000002-000002 --seed=16380477299 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000002-000002 --seed=17404257130 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000002-000002 --seed=18428036961 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000002-000002 --seed=19451816792 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000002-000002 --seed=20475596623 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 10:03:49] eval finished: 10.193 seconds
[2019-06-18 10:03:49] Win rate 000002-000002 vs 000001-000001: 0.340
:::MLL 1560873829.245575 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 1}}
[2019-06-18 10:03:49] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-4-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000003-000001 --seed=4 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000003-000001 --seed=1023779835 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000003-000001 --seed=2047559666 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000003-000001 --seed=3071339497 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000003-000001 --seed=4095119328 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000003-000001 --seed=5118899159 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000003-000001 --seed=6142678990 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000003-000001 --seed=7166458821 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000003-000001 --seed=8190238652 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000003-000001 --seed=9214018483 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000003-000001 --seed=10237798314 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000003-000001 --seed=11261578145 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000003-000001 --seed=12285357976 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000003-000001 --seed=13309137807 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000003-000001 --seed=14332917638 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000003-000001 --seed=15356697469 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000003-000001 --seed=16380477300 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000003-000001 --seed=17404257131 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000003-000001 --seed=18428036962 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/
[2019-06-18 10:04:19] selfplay finished: 29.889 seconds
[2019-06-18 10:04:19] selfplay mn: 29.906 seconds
[2019-06-18 10:04:19] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-4-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779835 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559666 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339497 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119328 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899159 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142678990 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458821 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238652 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018483 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798314 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578145 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285357976 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137807 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917638 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697469 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477300 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257131 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036962 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816793 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596624 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376455 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156286 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_
[2019-06-18 10:04:22] divide_golden_chunk finished: 3.410 seconds
[2019-06-18 10:04:22] generate golden chunk: 3.424 seconds
[2019-06-18 10:04:23] train finished: 44.559 seconds
:::MLL 1560873824.246276 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873824.247178 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873824.248022 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:03:44.318407 47938721686400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560873824.254680 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873824.255379 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873824.256098 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:03:44.318497 47542226523008 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 10:03:44.319426 47938721686400 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp7g426ak0
I0618 10:03:44.320425 47938721686400 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp7g426ak0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b99e3107e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:03:44.319797 47542226523008 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpjd874zle
I0618 10:03:44.320821 47938721686400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:03:44.320872 47542226523008 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpjd874zle', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3d921c5dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:03:44.321285 47542226523008 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:03:44.325827 47938721686400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:03:44.326241 47542226523008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560873824.255500 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873824.256403 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873824.257277 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:03:44.333308 47453803377536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560873824.267581 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873824.268306 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873824.268997 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:03:44.333328 47704400057216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 10:03:44.334616 47453803377536 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp3i4fc20b
W0618 10:03:44.334648 47704400057216 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpehrgag36
I0618 10:03:44.335633 47453803377536 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp3i4fc20b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b28fbae4e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:03:44.335645 47704400057216 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpehrgag36', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6354681e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:03:44.336036 47453803377536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:03:44.336044 47704400057216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560873824.259951 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873824.260712 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873824.261414 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:03:44.336201 47456160646016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560873824.258132 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873824.258917 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873824.259742 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:03:44.336321 46999234159488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 10:03:44.337263 47456160646016 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmphca3hgre
W0618 10:03:44.337424 46999234159488 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp6pc0b02e
I0618 10:03:44.338383 47456160646016 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmphca3hgre', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b29882f5e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:03:44.338516 46999234159488 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp6pc0b02e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abf253e7e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:03:44.338838 47456160646016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:03:44.338955 46999234159488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:03:44.341049 47453803377536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:03:44.341059 47704400057216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:03:44.344093 47456160646016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:03:44.344166 46999234159488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:03:44.345777 47938721686400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:03:44.346136 47542226523008 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:03:44.360748 47704400057216 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:03:44.360744 47453803377536 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560873824.286741 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873824.287603 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873824.288309 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:03:44.361054 47586947789696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560873824.285576 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873824.286439 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873824.287252 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:03:44.361321 47132230546304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560873824.329241 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873824.329701 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873824.330161 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:03:44.362911 47335721681792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 10:03:44.362146 47586947789696 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp23p307np
W0618 10:03:44.362381 47132230546304 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpdpsazzsh
I0618 10:03:44.363244 47586947789696 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp23p307np', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b47fbb4bda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:03:44.363502 47132230546304 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpdpsazzsh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ade1c723e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:03:44.363986 47335721681792 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpfbdjgr0h
I0618 10:03:44.363676 47586947789696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:03:44.365071 47335721681792 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpfbdjgr0h', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0d7d767e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:03:44.363957 47132230546304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560873824.332896 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873824.333336 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873824.333702 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:03:44.365237 47976932987776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000002.tfrecord.zz_0
I0618 10:03:44.365482 47335721681792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:03:44.366624 46999234159488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:03:44.366636 47456160646016 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:03:44.366228 47976932987776 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpb4r34lry
I0618 10:03:44.367362 47976932987776 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpb4r34lry', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba2c8a29e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:03:44.367783 47976932987776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560873824.287241 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873824.288061 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873824.288758 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:03:44.368400 47453712155520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560873824.290542 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873824.291290 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873824.291977 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:03:44.368431 47420913951616 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560873824.288849 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873824.289584 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873824.290335 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:03:44.368357 47052004565888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560873824.291146 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873824.291902 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873824.292591 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:03:44.368463 47858709922688 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 10:03:44.368924 47586947789696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:03:44.370313 47335721681792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:03:44.369389 47420913951616 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpkthvh0ll
W0618 10:03:44.369418 47453712155520 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpo7t6wr_s
I0618 10:03:44.370378 47420913951616 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpkthvh0ll', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2153516e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:03:44.369271 47132230546304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:03:44.370391 47453712155520 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpo7t6wr_s', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b28f63e5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:03:44.370783 47420913951616 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:03:44.370789 47453712155520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:03:44.369343 47052004565888 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpbfd4dkh9
W0618 10:03:44.369406 47858709922688 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpdktr70cx
I0618 10:03:44.370311 47052004565888 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpbfd4dkh9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acb6e9afe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:03:44.370363 47858709922688 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpdktr70cx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8741fdde10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:03:44.370692 47052004565888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:03:44.370752 47858709922688 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:03:44.372352 47976932987776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560873824.343384 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873824.343761 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873824.344105 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:03:44.376505 47092628218752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 10:03:44.375804 47420913951616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:03:44.375781 47453712155520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560873824.344477 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873824.344848 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873824.345207 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:03:44.376768 47947256566656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 10:03:44.375768 47052004565888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:03:44.375776 47858709922688 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:03:44.377619 47092628218752 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpqu67ga77
I0618 10:03:44.377866 47947256566656 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9bdfc86d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:03:44.378689 47092628218752 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpqu67ga77', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad4e3f6be80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:03:44.379069 47947256566656 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:03:44.379109 47092628218752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560873824.348180 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873824.348621 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873824.349034 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:03:44.382189 47120508793728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560873824.348132 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873824.348576 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873824.348992 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:03:44.382143 47288292131712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 10:03:44.383933 47092628218752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:03:44.383941 47947256566656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:03:44.383183 47288292131712 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmptse30hb9
W0618 10:03:44.383246 47120508793728 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpu23mh44i
I0618 10:03:44.384268 47288292131712 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmptse30hb9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0272711e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:03:44.384320 47120508793728 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpu23mh44i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adb61c68e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:03:44.384674 47288292131712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:03:44.384725 47120508793728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560873824.348204 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873824.348597 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873824.348927 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:03:44.383945 47442881409920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560873824.344063 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873824.344637 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873824.345092 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:03:44.384165 47147039343488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 10:03:44.384893 47442881409920 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp8w1gfhmo
W0618 10:03:44.385107 47147039343488 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp792_85m9
I0618 10:03:44.385974 47442881409920 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp8w1gfhmo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2670ae3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:03:44.386214 47147039343488 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp792_85m9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae18f1e8e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:03:44.386433 47442881409920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:03:44.386642 47147039343488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:03:44.389324 47120508793728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:03:44.389313 47288292131712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:03:44.390465 47335721681792 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:03:44.390981 47442881409920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:03:44.392363 47976932987776 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:03:44.391236 47586947789696 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:03:44.391283 47147039343488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:03:44.391798 47132230546304 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:03:44.393778 47938721686400 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:03:44.393863 47542226523008 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:03:44.395630 47453712155520 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:03:44.395672 47420913951616 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:03:44.395722 47052004565888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:03:44.398093 47938721686400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:03:44.398153 47542226523008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:03:44.396178 47858709922688 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:03:44.403213 47542226523008 estimator.py:1111] Calling model_fn.
I0618 10:03:44.403176 47938721686400 estimator.py:1111] Calling model_fn.
W0618 10:03:44.403281 47938721686400 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:03:44.403318 47542226523008 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:03:44.403573 47092628218752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:03:44.403695 47947256566656 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560873824.369100 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873824.369510 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873824.369876 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:03:44.402758 47166469579648 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560873824.370355 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873824.370780 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873824.371218 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:03:44.403445 47391094477696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 10:03:44.404630 47938721686400 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:03:44.404681 47542226523008 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:03:44.403834 47166469579648 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp03l3n9xl
I0618 10:03:44.404859 47166469579648 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp03l3n9xl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae615407e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:03:44.404449 47391094477696 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpcy9w3cw2
I0618 10:03:44.405251 47166469579648 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:03:44.405405 47391094477696 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpcy9w3cw2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1a61f05e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:03:44.405792 47391094477696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560873824.371502 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873824.371988 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873824.372380 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:03:44.405725 47990109832064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560873824.372330 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873824.372786 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873824.373216 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:03:44.405784 47230393279360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 10:03:44.408786 47453803377536 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:03:44.409152 47704400057216 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:03:44.409167 47120508793728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:03:44.409124 47288292131712 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:03:44.406695 47990109832064 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpsycbgutq
W0618 10:03:44.406747 47230393279360 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp1816psmq
I0618 10:03:44.407659 47990109832064 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpsycbgutq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba5da094da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:03:44.407722 47230393279360 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp1816psmq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af4f766be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:03:44.408055 47990109832064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:03:44.408115 47230393279360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:03:44.409983 47166469579648 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:03:44.410410 47391094477696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:03:44.410458 47442881409920 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:03:44.410854 47147039343488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:03:44.413087 47453803377536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:03:44.413470 47704400057216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:03:44.412676 47990109832064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:03:44.412701 47230393279360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:03:44.414955 46999234159488 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions [2019-06-18 10:04:23] iteration time 2: 48.228 seconds
2019-06-18 10:04:24.009980: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560873863.570792 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 3}}
[2019-06-18 10:04:27] minmax time: 3.231 seconds
2019-06-18 10:04:27.250906: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:04:27.256314: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:04:27.260815: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560873867.272519 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 2}}
[2019-06-18 10:04:27] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir 
[2019-06-18 10:04:27] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-4-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000003-000002 --seed=4 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000003-000002 --seed=1023779835 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000003-000002 --seed=2047559666 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000003-000002 --seed=3071339497 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000003-000002 --seed=4095119328 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000003-000002 --seed=5118899159 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000003-000002 --seed=6142678990 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000003-000002 --seed=7166458821 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000003-000002 --seed=8190238652 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000003-000002 --seed=9214018483 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000003-000002 --seed=10237798314 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000003-000002 --seed=11261578145 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000003-000002 --seed=12285357976 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000003-000002 --seed=13309137807 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000003-000002 --seed=14332917638 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000003-000002 --seed=15356697469 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000003-000002 --seed=16380477300 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000003-000002 --seed=17404257131 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000003-000002 --seed=18428036962 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000003-000002 --seed=19451816793 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000003-000002 --seed=20475596624 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 10:04:38] eval finished: 10.846 seconds
[2019-06-18 10:04:38] Win rate 000003-000002 vs 000001-000001: 0.740
:::MLL 1560873878.178183 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 2}}
[2019-06-18 10:04:38] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-5-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000004-000001 --seed=5 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000004-000001 --seed=1023779836 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000004-000001 --seed=2047559667 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000004-000001 --seed=3071339498 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000004-000001 --seed=4095119329 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000004-000001 --seed=5118899160 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000004-000001 --seed=6142678991 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000004-000001 --seed=7166458822 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000004-000001 --seed=8190238653 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000004-000001 --seed=9214018484 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000004-000001 --seed=10237798315 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000004-000001 --seed=11261578146 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000004-000001 --seed=12285357977 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000004-000001 --seed=13309137808 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000004-000001 --seed=14332917639 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000004-000001 --seed=15356697470 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000004-000001 --seed=16380477301 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000004-000001 --seed=17404257132 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000004-000001 --seed=18428036963 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/
[2019-06-18 10:05:08] selfplay finished: 30.435 seconds
[2019-06-18 10:05:08] selfplay mn: 30.452 seconds
[2019-06-18 10:05:08] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-5-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779836 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559667 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339498 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119329 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899160 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142678991 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458822 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238653 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018484 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798315 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578146 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285357977 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137808 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917639 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697470 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477301 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257132 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036963 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816794 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596625 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376456 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156287 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_
[2019-06-18 10:05:11] train finished: 43.937 seconds
:::MLL 1560873872.530464 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873872.531215 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873872.531868 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:04:32.594942 47174830687104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560873872.525682 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873872.526571 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873872.527400 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:04:32.595016 47660024587136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 10:04:32.595980 47174830687104 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpo3mdabcu
W0618 10:04:32.596007 47660024587136 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpurjqqh6s
I0618 10:04:32.596973 47660024587136 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpurjqqh6s', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b58ff6c2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:04:32.596973 47174830687104 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpo3mdabcu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae8079cde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:04:32.597363 47660024587136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:04:32.597371 47174830687104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:04:32.602501 47174830687104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:04:32.602507 47660024587136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560873872.537921 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873872.538667 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873872.539348 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:04:32.605623 47259155833728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560873872.536631 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873872.537316 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873872.538064 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:04:32.605690 47703352673152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 10:04:32.606710 47703352673152 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpgy4dv_bt
W0618 10:04:32.606677 47259155833728 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpvupt7jzt
I0618 10:04:32.607764 47259155833728 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpvupt7jzt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afba9c87e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:04:32.607772 47703352673152 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpgy4dv_bt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6315fa5e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:04:32.608205 47703352673152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:04:32.608205 47259155833728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:04:32.613428 47703352673152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:04:32.613429 47259155833728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:04:32.622118 47660024587136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:04:32.622182 47174830687104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:04:32.633501 47703352673152 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:04:32.633520 47259155833728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560873872.569593 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873872.570380 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873872.571070 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:04:32.635548 46936160781184 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560873872.563760 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873872.564689 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873872.565549 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:04:32.635685 47077405553536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560873872.558407 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873872.559299 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873872.560154 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:04:32.638406 47843542074240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 10:04:32.636590 46936160781184 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmptlrn499q
W0618 10:04:32.636726 47077405553536 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp8h_vye5g
:::MLL 1560873872.566567 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873872.567292 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873872.567912 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:04:32.638675 47973353722752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000003.tfrecord.zz_0
I0618 10:04:32.637645 46936160781184 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmptlrn499q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab075c71da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:04:32.637755 47077405553536 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp8h_vye5g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad1589f4e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:04:32.638051 46936160781184 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:04:32.638159 47077405553536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:04:32.639471 47843542074240 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpy8syenxk
W0618 10:04:32.639738 47973353722752 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp28375w7q
I0618 10:04:32.640553 47843542074240 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpy8syenxk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b83b9eade80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:04:32.640846 47973353722752 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp28375w7q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba1f34b5e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:04:32.640996 47843542074240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:04:32.641302 47973353722752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560873872.609160 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873872.609587 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873872.610017 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:04:32.644703 47320436007808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560873872.610052 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873872.610484 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873872.610939 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:04:32.644728 47819719426944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 10:04:32.642950 46936160781184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:04:32.642984 47077405553536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:04:32.645759 47819719426944 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7e2dfa0d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:04:32.645754 47320436007808 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp2w0r2t0h
I0618 10:04:32.646723 47320436007808 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp2w0r2t0h', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b09ee5dae80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:04:32.646850 47819719426944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:04:32.646251 47843542074240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:04:32.647114 47320436007808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560873872.613865 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873872.614317 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873872.614689 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:04:32.646923 47069455905664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 10:04:32.646689 47973353722752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:04:32.647985 47069455905664 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpmo86iklu
I0618 10:04:32.649042 47069455905664 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpmo86iklu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acf7ec94e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:04:32.649475 47069455905664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:04:32.651487 47819719426944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:04:32.651652 47320436007808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:04:32.654609 47069455905664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560873872.619253 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873872.619697 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873872.620086 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:04:32.654875 46942293382016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 10:04:32.655923 46942293382016 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpdtkmtxrg
I0618 10:04:32.656932 46942293382016 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpdtkmtxrg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab1e34f2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:04:32.657320 46942293382016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:04:32.661813 46942293382016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560873872.628443 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873872.628834 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873872.629158 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:04:32.662989 47131233653632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560873872.630697 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873872.631109 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873872.631514 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:04:32.664099 47486963921792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 10:04:32.664101 47131233653632 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmptmdm62ew
I0618 10:04:32.665174 47131233653632 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmptmdm62ew', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adde106be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:04:32.665562 47131233653632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:04:32.665155 47486963921792 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpsrqbreo7
I0618 10:04:32.666122 47486963921792 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpsrqbreo7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b30b433fe80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:04:32.665041 47077405553536 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:04:32.666510 47486963921792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:04:32.665527 46936160781184 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:04:32.668624 47843542074240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560873872.598050 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873872.598771 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873872.599406 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:04:32.667408 47798329512832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560873872.600844 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873872.601612 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873872.602314 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:04:32.667509 47228402783104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 10:04:32.669401 47973353722752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:04:32.670156 47660024587136 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:04:32.670633 47174830687104 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:04:32.670266 47131233653632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:04:32.671009 47819719426944 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:04:32.671190 47320436007808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:04:32.668453 47798329512832 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpp9egz2nh
W0618 10:04:32.668512 47228402783104 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpgv4vi928
I0618 10:04:32.669497 47798329512832 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpp9egz2nh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b793309ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:04:32.669549 47228402783104 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpgv4vi928', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af480c21e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:04:32.671088 47486963921792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:04:32.669951 47798329512832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:04:32.670011 47228402783104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:04:32.674461 47069455905664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:04:32.674483 47660024587136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:04:32.674984 47174830687104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:04:32.675215 47798329512832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:04:32.675239 47228402783104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:04:32.679539 47660024587136 estimator.py:1111] Calling model_fn.
W0618 10:04:32.679644 47660024587136 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:04:32.680060 47174830687104 estimator.py:1111] Calling model_fn.
W0618 10:04:32.680169 47174830687104 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:04:32.681006 47660024587136 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560873872.644307 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873872.644693 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873872.645028 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:04:32.679102 47840042025856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 10:04:32.681548 46942293382016 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:04:32.681546 47174830687104 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:04:32.681711 47703352673152 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:04:32.681802 47259155833728 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560873872.646014 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873872.646400 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873872.646763 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:04:32.679883 47891813725056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 10:04:32.680164 47840042025856 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpljff05gx
I0618 10:04:32.681163 47840042025856 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpljff05gx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b82e94c5e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:04:32.681547 47840042025856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:04:32.680892 47891813725056 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp0ngjac1b
I0618 10:04:32.681855 47891813725056 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp0ngjac1b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8ef721be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:04:32.682242 47891813725056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560873872.616017 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873872.616930 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873872.617776 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:04:32.684945 47110628373376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 10:04:32.686042 47703352673152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560873872.616158 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873872.617053 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873872.617916 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:04:32.684978 47918148928384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 10:04:32.686108 47259155833728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:04:32.686047 47918148928384 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp7kl309ym
W0618 10:04:32.686016 47110628373376 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp6duod7c7
I0618 10:04:32.687034 47110628373376 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp6duod7c7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad914db4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:04:32.687038 47918148928384 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp7kl309ym', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9518d51e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:04:32.686114 47840042025856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:04:32.687452 47918148928384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:04:32.687453 47110628373376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:04:32.686667 47891813725056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:04:32.689878 47131233653632 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:04:32.691082 47703352673152 estimator.py:1111] Calling model_fn.
W0618 10:04:32.691190 47703352673152 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:04:32.691215 47259155833728 estimator.py:1111] Calling model_fn.
W0618 10:04:32.691324 47259155833728 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:04:32.690729 47486963921792 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:04:32.692537 47703352673152 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:04:32.692697 47259155833728 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:04:32.692291 47110628373376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:04:32.692325 47918148928384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:04:32.695137 47798329512832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:04:32.695126 47228402783104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:04:32.705972 47840042025856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:04:32.706335 47891813725056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:04:32.712182 47110628373376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:04:32.713021 47918148928384 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:04:32.716705 47843542074240 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:04:32.716901 47973353722752 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:04:32.718403 47819719426944 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:04:32.718879 47320436007808 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:04:32.717222 47077405553536 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:04:32.717625 46936160781184 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560873872.682664 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873872.683116 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873872.683506 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:04:32.718548 47671326032768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560873872.682743 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873872.683190 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873872.683574 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:04:32.718573 47573307020160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 10:04:32.721571 47069455905664 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:04:32.721024 47843542074240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:04:32.721243 47973353722752 deprecatio[2019-06-18 10:05:12] divide_golden_chunk finished: 3.526 seconds
[2019-06-18 10:05:12] generate golden chunk: 3.540 seconds
[2019-06-18 10:05:12] moving /lfs/lfs12/gma_akey/results/epb312/models/000004-000002.pb --> /lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb
[2019-06-18 10:05:12] moving /lfs/lfs12/gma_akey/results/epb312/models/000004-000002.index --> /lfs/lfs12/gma_akey/results/epb312/models/000004-000003.index
[2019-06-18 10:05:12] moving /lfs/lfs12/gma_akey/results/epb312/models/000004-000002.meta --> /lfs/lfs12/gma_akey/results/epb312/models/000004-000003.meta
[2019-06-18 10:05:12] moving /lfs/lfs12/gma_akey/results/epb312/models/000004-000002.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb312/models/000004-000003.data-00000-of-00001
[2019-06-18 10:05:12] iteration time 3: 48.643 seconds
2019-06-18 10:05:12.693296: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560873912.213573 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 4}}
[2019-06-18 10:05:15] minmax time: 3.220 seconds
2019-06-18 10:05:15.923570: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:05:15.930570: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:05:15.934942: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560873915.945359 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 3}}
[2019-06-18 10:05:15] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir 
[2019-06-18 10:05:15] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-5-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000004-000003 --seed=5 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000004-000003 --seed=1023779836 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000004-000003 --seed=2047559667 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000004-000003 --seed=3071339498 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000004-000003 --seed=4095119329 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000004-000003 --seed=5118899160 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000004-000003 --seed=6142678991 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000004-000003 --seed=7166458822 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000004-000003 --seed=8190238653 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000004-000003 --seed=9214018484 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000004-000003 --seed=10237798315 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000004-000003 --seed=11261578146 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000004-000003 --seed=12285357977 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000004-000003 --seed=13309137808 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000004-000003 --seed=14332917639 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000004-000003 --seed=15356697470 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000004-000003 --seed=16380477301 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000004-000003 --seed=17404257132 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000004-000003 --seed=18428036963 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000004-000003 --seed=19451816794 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000004-000003 --seed=20475596625 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 10:05:26] eval finished: 10.897 seconds
[2019-06-18 10:05:26] Win rate 000004-000003 vs 000003-000002: 0.590
:::MLL 1560873926.904223 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 3}}
[2019-06-18 10:05:26] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-6-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000005-000002 --seed=6 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000005-000002 --seed=1023779837 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000005-000002 --seed=2047559668 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000005-000002 --seed=3071339499 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000005-000002 --seed=4095119330 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000005-000002 --seed=5118899161 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000005-000002 --seed=6142678992 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000005-000002 --seed=7166458823 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000005-000002 --seed=8190238654 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000005-000002 --seed=9214018485 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000005-000002 --seed=10237798316 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000005-000002 --seed=11261578147 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000005-000002 --seed=12285357978 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000005-000002 --seed=13309137809 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000005-000002 --seed=14332917640 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000005-000002 --seed=15356697471 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000005-000002 --seed=16380477302 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000005-000002 --seed=17404257133 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000005-000002 --seed=18428036964 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/
[2019-06-18 10:05:56] selfplay finished: 29.105 seconds
[2019-06-18 10:05:56] selfplay mn: 29.122 seconds
[2019-06-18 10:05:56] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-6-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779837 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559668 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339499 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119330 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899161 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142678992 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458823 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238654 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018485 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798316 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578147 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285357978 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137809 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917640 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697471 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477302 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257133 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036964 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816795 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596626 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376457 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156288 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_
[2019-06-18 10:05:59] divide_golden_chunk finished: 3.317 seconds
[2019-06-18 10:05:59] generate golden chunk: 3.331 seconds
[2019-06-18 10:05:59] train finished: 43.869 seconds
:::MLL 1560873921.229151 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873921.229848 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873921.230519 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:05:21.298768 47329237947264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560873921.217588 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873921.218447 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873921.219242 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:05:21.298850 47733497942912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 10:05:21.299848 47329237947264 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmphfavz2m6
W0618 10:05:21.299878 47733497942912 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpl4cooecj
I0618 10:05:21.300927 47329237947264 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmphfavz2m6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0bfb009e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:05:21.300929 47733497942912 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpl4cooecj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6a1ac69e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:05:21.301364 47329237947264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:05:21.301364 47733497942912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560873921.224773 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873921.225490 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873921.226138 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:05:21.306232 47108243424128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560873921.218501 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873921.219373 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873921.220220 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:05:21.306230 47921627259776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 10:05:21.306719 47329237947264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:05:21.306713 47733497942912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:05:21.307265 47921627259776 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpury_gakl
W0618 10:05:21.307317 47108243424128 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpocp9wh8z
I0618 10:05:21.308291 47921627259776 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpury_gakl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b95e8283dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:05:21.308366 47108243424128 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpocp9wh8z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad886b3ddd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:05:21.308717 47921627259776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:05:21.308785 47108243424128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:05:21.314100 47921627259776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:05:21.314135 47108243424128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560873921.247739 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873921.248576 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873921.249410 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:05:21.319921 47924843733888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560873921.248554 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873921.249436 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873921.250109 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:05:21.320036 47327099990912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 10:05:21.321008 47924843733888 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmppga7d7uu
W0618 10:05:21.321095 47327099990912 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmprdv955d9
I0618 10:05:21.322075 47924843733888 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmppga7d7uu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b96a7dfada0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:05:21.322203 47327099990912 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmprdv955d9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0b7b91fda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:05:21.322518 47924843733888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:05:21.322657 47327099990912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:05:21.326558 47733497942912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:05:21.327209 47329237947264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:05:21.327794 47924843733888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:05:21.327887 47327099990912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:05:21.334053 47921627259776 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:05:21.334176 47108243424128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560873921.264711 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873921.265440 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873921.266109 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:05:21.337951 47771641607040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560873921.280058 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873921.280874 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873921.281615 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:05:21.338308 47192510559104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560873921.263173 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873921.263929 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873921.264721 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:05:21.338018 47996549682048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560873921.258421 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873921.259347 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873921.260217 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:05:21.338381 47917943362432 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 10:05:21.338953 47771641607040 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp5fpmxian
W0618 10:05:21.339008 47996549682048 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpv2ruej_g
I0618 10:05:21.339922 47771641607040 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp5fpmxian', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b72fc50ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:05:21.339970 47996549682048 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpv2ruej_g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba759e1ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:05:21.339449 47917943362432 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpr0v08jnh
W0618 10:05:21.339421 47192510559104 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpe3c6m5n9
I0618 10:05:21.340541 47917943362432 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpr0v08jnh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b950c946e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:05:21.340321 47771641607040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:05:21.340550 47192510559104 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpe3c6m5n9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aec256a3e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:05:21.340366 47996549682048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:05:21.340981 47917943362432 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:05:21.341016 47192510559104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560873921.307231 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873921.307636 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873921.307959 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:05:21.345966 47882850382720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 10:05:21.345490 47996549682048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:05:21.345489 47771641607040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560873921.308697 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873921.309072 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873921.309397 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:05:21.346722 46965783663488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 10:05:21.346305 47917943362432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:05:21.346369 47192510559104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:05:21.347030 47882850382720 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmplgwhxi3i
I0618 10:05:21.348055 47882850382720 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmplgwhxi3i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8ce0dffe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:05:21.348483 47882850382720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:05:21.347747 46965783663488 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab75b705d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:05:21.348923 46965783663488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:05:21.350272 47327099990912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:05:21.350347 47924843733888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:05:21.353462 47882850382720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:05:21.353928 46965783663488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560873921.314423 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873921.314824 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873921.315150 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:05:21.354054 47228488532864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560873921.317209 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873921.317665 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873921.318063 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:05:21.354902 47400286139264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 10:05:21.355070 47228488532864 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp6dgiu71b
I0618 10:05:21.356074 47228488532864 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp6dgiu71b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af485de9dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:05:21.356491 47228488532864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:05:21.355829 47400286139264 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpvulpzrcb
I0618 10:05:21.356875 47400286139264 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpvulpzrcb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1c85cdfe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:05:21.357290 47400286139264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560873921.317794 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873921.318207 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873921.318557 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:05:21.356567 47583684879232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560873921.318964 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873921.319342 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873921.319662 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:05:21.356618 47190446535552 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 10:05:21.357655 47583684879232 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpm1t6q8rd
W0618 10:05:21.357693 47190446535552 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpv2hixrts
I0618 10:05:21.358745 47583684879232 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpm1t6q8rd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b473938be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:05:21.358776 47190446535552 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpv2hixrts', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aebaa63ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:05:21.359136 47583684879232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:05:21.359177 47190446535552 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:05:21.361366 47228488532864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:05:21.361955 47400286139264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560873921.301973 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873921.302802 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873921.303544 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:05:21.361607 47109398180736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560873921.289885 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873921.290796 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873921.291656 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:05:21.361671 47889023509376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 10:05:21.362697 47889023509376 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpnhz_jwbh
W0618 10:05:21.362666 47109398180736 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp98s1any3
W0618 10:05:21.363792 47583684879232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:05:21.363869 47190446535552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:05:21.363767 47889023509376 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpnhz_jwbh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8e50d27e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:05:21.365058 47996549682048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:05:21.363742 47109398180736 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp98s1any3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad8cb880da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:05:21.365133 47771641607040 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:05:21.364226 47889023509376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:05:21.364228 47109398180736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:05:21.368927 47917943362432 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:05:21.369032 47192510559104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:05:21.369424 47889023509376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:05:21.369446 47109398180736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560873921.334172 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873921.334558 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873921.334888 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:05:21.371615 47616586003328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 10:05:21.374105 47882850382720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:05:21.372713 47616586003328 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpvzgj5dq_
I0618 10:05:21.373794 47616586003328 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpvzgj5dq_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4ee2480e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:05:21.374573 46965783663488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560873921.336802 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873921.337282 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873921.337685 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:05:21.373794 47548535616384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000004.tfrecord.zz_0
I0618 10:05:21.374235 47616586003328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:05:21.374865 47733497942912 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:05:21.375221 47329237947264 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:05:21.374823 47548535616384 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpcy0dplwa
I0618 10:05:21.375844 47548535616384 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpcy0dplwa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3f0a298e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:05:21.376259 47548535616384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:05:21.379183 47733497942912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:05:21.379552 47329237947264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:05:21.379257 47616586003328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:05:21.381142 47228488532864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:05:21.381688 47400286139264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:05:21.381198 47548535616384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:05:21.381859 47921627259776 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:05:21.381927 47108243424128 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:05:21.384242 47733497942912 estimator.py:1111] Calling model_fn.
W0618 10:05:21.384350 47733497942912 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:05:21.384651 47329237947264 estimator.py:1111] Calling model_fn.
W0618 10:05:21.384761 47329237947264 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:05:21.383463 47583684879232 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:05:21.385710 47733497942912 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:05:21.383751 47190446535552 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:05:21.386127 47329237947264 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:05:21.386146 47921627259776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:05:21.386228 47108243424128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560873921.349668 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873921.350054 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873921.350385 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:05:21.388358 47111486788480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560873921.351068 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873921.351440 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873921.351779 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:05:21.388419 47458870379392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 10:05:21.389351 47111486788480 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpszyazrvs
W0618 10:05:21.389380 47458870379392 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpnoa4k0h1
I0618 10:05:21.391162 47921627259776 estimator.py:1111] Calling model_fn.
W0618 10:05:21.391268 47921627259776 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:05:21.390336 47458870379392 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpnoa4k0h1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2a29b28e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:05:21.391284 47108243424128 estimator.py:1111] Calling model_fn.
I0618 10:05:21.390335 47111486788480 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpszyazrvs', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad94805ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:05:21.391388 47108243424128 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:05:21.389349 47889023509376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:05:21.390722 47458870379392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:05:21.390736 47111486788480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:05:21.389486 47109398180736 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:05:21.392605 47921627259776 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:05:21.392724 47108243424128 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:05:21.395527 47111486788480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:05:21.395488 47458870379392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:05:21.399160 47616586003328 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:05:21.400962 47548535616384 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:05:21.401572 47327099990912 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:05:21.402108 47924843733888 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:05:21.406198 47327099990912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:05:21.406747 47924843733888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:05:21.411619 47327099990912 estimator.py:1111] Calling model_fn.
W0618 10:05:21.411734 47327099990912 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:05:21.412216 47924843733888 estimator.py:1111] Calling model_fn.
W0618 10:05:21.412327 47924843733888 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layer[2019-06-18 10:05:59] moving /lfs/lfs12/gma_akey/results/epb312/models/000005-000003.meta --> /lfs/lfs12/gma_akey/results/epb312/models/000005-000004.meta
[2019-06-18 10:05:59] moving /lfs/lfs12/gma_akey/results/epb312/models/000005-000003.index --> /lfs/lfs12/gma_akey/results/epb312/models/000005-000004.index
[2019-06-18 10:05:59] moving /lfs/lfs12/gma_akey/results/epb312/models/000005-000003.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb312/models/000005-000004.data-00000-of-00001
[2019-06-18 10:05:59] moving /lfs/lfs12/gma_akey/results/epb312/models/000005-000003.pb --> /lfs/lfs12/gma_akey/results/epb312/models/000005-000004.pb
[2019-06-18 10:05:59] iteration time 4: 47.668 seconds
2019-06-18 10:06:00.521988: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560873959.882027 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 5}}
[2019-06-18 10:06:03] minmax time: 3.233 seconds
2019-06-18 10:06:03.765162: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:06:03.770616: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:06:03.775173: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560873963.786004 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 4}}
[2019-06-18 10:06:03] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000006-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000006-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000006-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000006-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000006-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000006-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000006-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000006-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000006-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000006-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000006-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir 
[2019-06-18 10:06:03] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-6-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000005-000004 --seed=6 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000005-000004 --seed=1023779837 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000005-000004 --seed=2047559668 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000005-000004 --seed=3071339499 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000005-000004 --seed=4095119330 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000005-000004 --seed=5118899161 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000005-000004 --seed=6142678992 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000005-000004 --seed=7166458823 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000005-000004 --seed=8190238654 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000005-000004 --seed=9214018485 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000005-000004 --seed=10237798316 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000005-000004 --seed=11261578147 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000005-000004 --seed=12285357978 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000005-000004 --seed=13309137809 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000005-000004 --seed=14332917640 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000005-000004 --seed=15356697471 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000005-000004 --seed=16380477302 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000005-000004 --seed=17404257133 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000005-000004 --seed=18428036964 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000005-000004 --seed=19451816795 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000005-000004 --seed=20475596626 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 10:06:15] eval finished: 11.310 seconds
[2019-06-18 10:06:15] Win rate 000005-000004 vs 000004-000003: 0.290
:::MLL 1560873975.158424 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 4}}
[2019-06-18 10:06:15] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-7-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000006-000003 --seed=7 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000006-000003 --seed=1023779838 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000006-000003 --seed=2047559669 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000006-000003 --seed=3071339500 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000006-000003 --seed=4095119331 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000006-000003 --seed=5118899162 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000006-000003 --seed=6142678993 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000006-000003 --seed=7166458824 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000006-000003 --seed=8190238655 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000006-000003 --seed=9214018486 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000006-000003 --seed=10237798317 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000006-000003 --seed=11261578148 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000006-000003 --seed=12285357979 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000006-000003 --seed=13309137810 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000006-000003 --seed=14332917641 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000006-000003 --seed=15356697472 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000006-000003 --seed=16380477303 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000006-000003 --seed=17404257134 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000006-000003 --seed=18428036965 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/
[2019-06-18 10:06:44] selfplay finished: 29.437 seconds
[2019-06-18 10:06:44] selfplay mn: 29.454 seconds
[2019-06-18 10:06:44] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-7-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779838 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559669 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339500 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119331 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899162 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142678993 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458824 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238655 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018486 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798317 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578148 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285357979 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137810 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917641 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697472 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477303 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257134 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036965 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816796 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596627 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376458 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156289 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_
[2019-06-18 10:06:47] train finished: 43.693 seconds
:::MLL 1560873969.034585 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873969.035346 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873969.036047 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:09.102307 47278903092096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560873969.028998 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873969.029856 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873969.030699 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:09.102328 47204358509440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 10:06:09.103253 47278903092096 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpoic6c007
W0618 10:06:09.103282 47204358509440 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp9r8r0uk9
I0618 10:06:09.104230 47278903092096 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpoic6c007', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0042cfae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:09.104250 47204358509440 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp9r8r0uk9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeee79bae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:09.104624 47278903092096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:06:09.104635 47204358509440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:06:09.109653 47204358509440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:09.109698 47278903092096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560873969.052698 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873969.053593 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873969.054406 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:09.125566 48010709533568 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560873969.059855 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873969.060615 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873969.061272 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:09.125945 47074305315712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 10:06:09.126604 48010709533568 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpp336oa1u
I0618 10:06:09.127679 48010709533568 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpp336oa1u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2baaa5dfce80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:06:09.126950 47074305315712 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpizrpim0j
I0618 10:06:09.127992 47074305315712 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpizrpim0j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad09fd55e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:09.128084 48010709533568 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:06:09.128392 47074305315712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:06:09.129101 47204358509440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:06:09.129498 47278903092096 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:06:09.132989 48010709533568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:09.133222 47074305315712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560873969.085384 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873969.086239 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873969.087065 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:09.139356 46983659795328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560873969.063903 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873969.064820 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873969.065654 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:09.139457 46991814341504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 10:06:09.140406 46983659795328 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpx2pu7r53
W0618 10:06:09.140462 46991814341504 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpwhp3zg6k
I0618 10:06:09.141528 46983659795328 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpx2pu7r53', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abb84f07e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:09.141538 46991814341504 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpwhp3zg6k', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abd6afcfe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:09.141986 46991814341504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:06:09.142002 46983659795328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:06:09.147269 46991814341504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:09.147481 46983659795328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:09.153364 48010709533568 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:06:09.153694 47074305315712 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560873969.119367 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873969.119778 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873969.120106 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:09.158505 47950031897472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 10:06:09.159588 47950031897472 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpl2z_x7uz
I0618 10:06:09.160655 47950031897472 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpl2z_x7uz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9c85349e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:09.161087 47950031897472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560873969.120874 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873969.121281 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873969.121637 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:09.164060 47163998761856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 10:06:09.165068 47163998761856 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp2olehbvl
I0618 10:06:09.166084 47163998761856 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp2olehbvl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae581face48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:06:09.166187 47950031897472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:06:09.166496 47163998761856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:06:09.169824 46991814341504 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:06:09.171347 47163998761856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:09.170725 46983659795328 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560873969.108793 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873969.109560 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873969.110353 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:09.172759 48008241042304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560873969.098731 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873969.099647 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873969.100523 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:09.172897 47636735251328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560873969.131703 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873969.132181 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873969.132540 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:09.175402 47488159474560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560873969.134755 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873969.135171 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873969.135526 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:09.175480 47689458996096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 10:06:09.173809 48008241042304 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpb6w8h22p
W0618 10:06:09.173902 47636735251328 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmppav3f__s
I0618 10:06:09.174863 48008241042304 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpb6w8h22p', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2baa12bd9e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:09.174946 47636735251328 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmppav3f__s', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5393452e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:09.175291 48008241042304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:06:09.176497 47488159474560 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp_sim_vqh
I0618 10:06:09.175371 47636735251328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:06:09.176595 47689458996096 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5fd9d97d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:09.177526 47488159474560 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp_sim_vqh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b30fb76be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:06:09.177561 47204358509440 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:06:09.177777 47689458996096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:06:09.177823 47278903092096 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:06:09.177940 47488159474560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560873969.138190 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873969.138581 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873969.138954 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:09.177835 47133893432192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560873969.138479 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873969.138914 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873969.139242 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:09.177875 47561613886336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 10:06:09.178821 47561613886336 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp7bgedsp7
W0618 10:06:09.178790 47133893432192 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp77hztf5z
I0618 10:06:09.179753 47133893432192 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp77hztf5z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ade7f8fee80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:09.179790 47561613886336 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp7bgedsp7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4215b01e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:09.180146 47133893432192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:06:09.180178 47561613886336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:06:09.181864 47204358509440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:06:09.182145 47278903092096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:06:09.180760 48008241042304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:09.180760 47636735251328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:09.182898 47689458996096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:09.182960 47488159474560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:09.184777 47133893432192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:09.184797 47561613886336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:06:09.186883 47204358509440 estimator.py:1111] Calling model_fn.
W0618 10:06:09.186987 47204358509440 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:06:09.187068 47950031897472 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:06:09.187205 47278903092096 estimator.py:1111] Calling model_fn.
W0618 10:06:09.187312 47278903092096 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:06:09.188329 47204358509440 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:06:09.188657 47278903092096 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:06:09.192083 47163998761856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560873969.118592 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873969.119452 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873969.120166 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:09.190931 47702296687488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560873969.117637 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873969.118474 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873969.119264 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:09.191027 47465111409536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 10:06:09.191961 47702296687488 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmprlwm0wmr
W0618 10:06:09.192001 47465111409536 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp9h8wsq5n
I0618 10:06:09.193029 47702296687488 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmprlwm0wmr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b62d7094e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:09.193056 47465111409536 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp9h8wsq5n', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2b9db11e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:09.193442 47702296687488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:06:09.193478 47465111409536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:06:09.198458 47702296687488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:09.198465 47465111409536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560873969.133965 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873969.134677 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873969.135411 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:09.199967 47844259042176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560873969.124511 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873969.125400 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873969.126274 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:09.199959 47836691600256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 10:06:09.201763 48010709533568 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:06:09.202221 47074305315712 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:06:09.201041 47836691600256 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp5fppjf_g
W0618 10:06:09.201073 47844259042176 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpf6wm4w_7
I0618 10:06:09.202092 47836691600256 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp5fppjf_g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b822198ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:09.202137 47844259042176 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpf6wm4w_7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b83e4a6ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:09.202516 47836691600256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:06:09.202559 47844259042176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:06:09.204016 47488159474560 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:06:09.204118 47689458996096 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:06:09.202714 48008241042304 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:06:09.202788 47636735251328 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:06:09.204346 47561613886336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:06:09.204360 47133893432192 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:06:09.206049 48010709533568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:06:09.206533 47074305315712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:06:09.207496 47836691600256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:09.207509 47844259042176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:06:09.211091 48010709533568 estimator.py:1111] Calling model_fn.
W0618 10:06:09.211202 48010709533568 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:06:09.211625 47074305315712 estimator.py:1111] Calling model_fn.
W0618 10:06:09.211733 47074305315712 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:06:09.212548 48010709533568 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:06:09.213109 47074305315712 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:06:09.218784 46983659795328 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:06:09.218766 46991814341504 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:06:09.218441 47465111409536 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:06:09.218687 47702296687488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:06:09.223082 46983659795328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:06:09.223091 46991814341504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560873969.186148 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873969.186541 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873969.186901 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:09.226016 47126650250112 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560873969.187035 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873969.187416 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873969.187741 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:09.226311 47855545729920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 10:06:09.227475 47836691600256 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:06:09.227591 47844259042176 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:06:09.228149 46983659795328 estimator.py:1111] Calling model_fn.
I0618 10:06:09.228179 46991814341504 estimator.py:1111] Calling model_fn.
W0618 10:06:09.228257 46983659795328 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:06:09.228285 46991814341504 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:06:09.227066 47126650250112 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpynzsdxd9
W0618 10:06:09.227357 47855545729920 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp62joxq99
I0618 10:06:09.228153 47126650250112 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpynzsdxd9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adccfd5be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:06:09.229616 46983659795328 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:06:09.229657 46991814341504 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:06:09.228455 47855545729920 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp62joxq99', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8685641e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:09.228591 47126650250112 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:06:09.228850 47855545729920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:06:09.234668 47950031897472 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:06:09.233319 47126650250112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:09.233522 47855545729920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560873969.195889 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873969.196377 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873969.196733 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:09.236376 46963745534848 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560873969.197001 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873969.197410 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873969.197778 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:09.236532 47636632068992 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 10:06:09.239085 47950031897472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:06:09.239625 47163998761856 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:06:09.237412 46963745534848 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpk_36lwoo
W0618 10:06:09.237534 47636632068992 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmprpq0fchi
I0618 10:06:09.238438 46963745534848 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpk_36lwoo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab6e1f50e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:09.238572 47636632068992 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmprpq0fchi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b538d1ebe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:09.238858 46963745534848 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:06:09.238992 47636632068992 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:06:09.244057 47163998761856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:06:09.244279 47950031897472 estimator.py:1111] Calling model_fn.
W0618 10:06:09.244394 47950031897472 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:06:09.245805 47950031897472 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:06:09.243765 46963745534848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:09.243832 47636632068992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560873969.205811 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873969.206243 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873969.206639 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:09.245887 47195698619264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560873969.206818 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560873969.207220 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560873969.207565 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:09.245985 47864078607232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 10:06:09.246914 47195698619264 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpyh2qhf_h
W0618 10:06:09.247005 47864078607232 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp8akkqvff
I0618 10:06:09.247945 47195698619264 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpyh2qhf_h', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aece3702e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:09.248011 47864078607232 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp8akkqvff', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8881fd7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:09.248365 47195698619264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:06:09.248417 47864078607232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:06:09.249471 47163998761856 estimator.py:1111] Calling model_fn.
W0618 10:06:09.249580 47163998761856 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:06:09.251042 47163998761856 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:06:09.251830 47133893432192 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecat[2019-06-18 10:06:47] divide_golden_chunk finished: 3.301 seconds
[2019-06-18 10:06:47] generate golden chunk: 3.316 seconds
[2019-06-18 10:06:47] iteration time 5: 48.048 seconds
2019-06-18 10:06:48.488122: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874007.930106 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 6}}
[2019-06-18 10:06:51] minmax time: 3.258 seconds
2019-06-18 10:06:51.756230: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:06:51.761613: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:06:51.766137: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874011.777932 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 5}}
[2019-06-18 10:06:51] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir 
[2019-06-18 10:06:51] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-7-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000006-000004 --seed=7 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000006-000004 --seed=1023779838 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000006-000004 --seed=2047559669 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000006-000004 --seed=3071339500 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000006-000004 --seed=4095119331 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000006-000004 --seed=5118899162 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000006-000004 --seed=6142678993 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000006-000004 --seed=7166458824 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000006-000004 --seed=8190238655 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000006-000004 --seed=9214018486 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000006-000004 --seed=10237798317 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000006-000004 --seed=11261578148 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000006-000004 --seed=12285357979 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000006-000004 --seed=13309137810 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000006-000004 --seed=14332917641 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000006-000004 --seed=15356697472 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000006-000004 --seed=16380477303 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000006-000004 --seed=17404257134 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000006-000004 --seed=18428036965 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000006-000004 --seed=19451816796 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000006-000004 --seed=20475596627 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 10:07:04] eval finished: 12.364 seconds
[2019-06-18 10:07:04] Win rate 000006-000004 vs 000004-000003: 0.620
:::MLL 1560874024.204975 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 5}}
[2019-06-18 10:07:04] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-8-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000007-000003 --seed=8 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000007-000003 --seed=1023779839 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000007-000003 --seed=2047559670 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000007-000003 --seed=3071339501 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000007-000003 --seed=4095119332 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000007-000003 --seed=5118899163 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000007-000003 --seed=6142678994 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000007-000003 --seed=7166458825 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000007-000003 --seed=8190238656 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000007-000003 --seed=9214018487 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000007-000003 --seed=10237798318 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000007-000003 --seed=11261578149 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000007-000003 --seed=12285357980 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000007-000003 --seed=13309137811 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000007-000003 --seed=14332917642 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000007-000003 --seed=15356697473 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000007-000003 --seed=16380477304 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000007-000003 --seed=17404257135 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000007-000003 --seed=18428036966 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/
[2019-06-18 10:07:32] selfplay finished: 28.736 seconds
[2019-06-18 10:07:32] selfplay mn: 28.754 seconds
[2019-06-18 10:07:32] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-8-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779839 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559670 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339501 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119332 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899163 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142678994 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458825 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238656 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018487 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798318 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578149 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285357980 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137811 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917642 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697473 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477304 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257135 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036966 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816797 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596628 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376459 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156290 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_
[2019-06-18 10:07:35] train finished: 43.612 seconds
:::MLL 1560874017.024773 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874017.025557 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874017.026232 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:57.100347 47235281343360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560874017.027660 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874017.028386 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874017.029061 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:57.100364 47741063041920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 10:06:57.101427 47235281343360 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpagme6ctx
W0618 10:06:57.101387 47741063041920 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmprriuhiuo
I0618 10:06:57.102465 47741063041920 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmprriuhiuo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6bddb0de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:57.102495 47235281343360 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpagme6ctx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af61ac0add8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:57.102892 47741063041920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:06:57.102916 47235281343360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:06:57.108131 47235281343360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:57.108127 47741063041920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874017.036164 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874017.036948 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874017.037649 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:57.108590 47896699343744 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560874017.028514 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874017.029404 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874017.030240 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:57.108969 47807365399424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560874017.024146 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874017.025083 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874017.025945 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:57.109008 47730972824448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560874017.053931 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874017.054808 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874017.055621 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:57.109124 46987602432896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 10:06:57.109666 47896699343744 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpabnh2znx
I0618 10:06:57.110727 47896699343744 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpabnh2znx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b901a565e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:06:57.110004 47807365399424 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp6617a2z4
I0618 10:06:57.111049 47807365399424 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp6617a2z4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7b4d9e9e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:57.111229 47896699343744 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:06:57.111519 47807365399424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:06:57.110121 47730972824448 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpwws14pq3
W0618 10:06:57.110191 46987602432896 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpraie1d3i
I0618 10:06:57.111209 47730972824448 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpwws14pq3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6984445e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:57.111304 46987602432896 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpraie1d3i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abc6ff03e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:57.111675 47730972824448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:06:57.111814 46987602432896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:06:57.116407 47896699343744 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:57.116508 47807365399424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:57.117028 47730972824448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:57.117105 46987602432896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:57.128221 47235281343360 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:06:57.128257 47741063041920 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874017.057024 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874017.057750 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874017.058441 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:57.129137 47118090322816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560874017.054527 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874017.055260 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874017.055985 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:57.129213 47887110095744 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 10:06:57.130226 47118090322816 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpmykciwae
W0618 10:06:57.130295 47887110095744 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp7gne5osb
I0618 10:06:57.131279 47118090322816 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpmykciwae', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adad19f8dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:57.131347 47887110095744 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp7gne5osb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8ddec60e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:57.131697 47118090322816 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:06:57.131779 47887110095744 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:06:57.136594 47807365399424 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:06:57.136677 47896699343744 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:06:57.137110 47118090322816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:57.137127 47887110095744 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:57.139740 47730972824448 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:06:57.140076 46987602432896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874017.100462 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874017.100898 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874017.101277 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:57.144112 47224402121600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 10:06:57.145164 47224402121600 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpvq0_hlh7
I0618 10:06:57.146222 47224402121600 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpvq0_hlh7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af3924cde80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:57.146660 47224402121600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:06:57.151814 47224402121600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874017.110816 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874017.111288 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874017.111701 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:57.154504 47377074193280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 10:06:57.155568 47377074193280 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpwfgcrb2x
I0618 10:06:57.156655 47377074193280 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpwfgcrb2x', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b171e43de80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:57.157093 47377074193280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:06:57.157419 47887110095744 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:06:57.157439 47118090322816 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874017.115755 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874017.116184 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874017.116543 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:57.161113 46965232743296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560874017.116457 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874017.116843 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874017.117203 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:57.161075 48003170182016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560874017.115344 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874017.115815 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874017.116217 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:57.161948 47078803592064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 10:06:57.161907 47377074193280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:57.162175 48003170182016 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpnki2gcqg
I0618 10:06:57.162220 46965232743296 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab73a9a0cf8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:57.163252 48003170182016 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpnki2gcqg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba8e47e5e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:57.163435 46965232743296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:06:57.163689 48003170182016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:06:57.163023 47078803592064 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp9791oxw8
I0618 10:06:57.164084 47078803592064 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp9791oxw8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad1abf39e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:57.164519 47078803592064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874017.124403 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874017.124853 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874017.125245 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:57.165730 47545932342144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560874017.090313 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874017.091251 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874017.092103 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:57.164391 47109494133632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560874017.096306 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874017.097015 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874017.097687 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:57.164402 47022324872064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 10:06:57.166753 47545932342144 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpys8ha2br
I0618 10:06:57.167826 47545932342144 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpys8ha2br', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3e6efeae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:57.168271 47545932342144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:06:57.165520 47022324872064 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpwmuwv63t
W0618 10:06:57.165548 47109494133632 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpd5uwvpwv
W0618 10:06:57.168621 46965232743296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:06:57.166598 47109494133632 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpd5uwvpwv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad8d1402e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:57.166597 47022324872064 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpwmuwv63t', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac4858ebe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:06:57.168812 48003170182016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:06:57.167003 47109494133632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:06:57.167011 47022324872064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:06:57.169529 47078803592064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:57.172947 47545932342144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:57.173086 47224402121600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:06:57.172060 47022324872064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:57.172061 47109494133632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:57.176650 47235281343360 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:06:57.177066 47741063041920 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:06:57.180930 47235281343360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:06:57.181405 47741063041920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560874017.107589 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874017.108515 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874017.109214 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:57.181004 47431856276352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560874017.106736 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874017.107616 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874017.108490 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:57.181111 47528776233856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 10:06:57.182966 47377074193280 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874017.140356 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874017.140762 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874017.141104 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:57.183377 47604093379456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560874017.140226 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874017.140638 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874017.140998 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:57.183413 47765771338624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 10:06:57.182150 47431856276352 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp19honcej
W0618 10:06:57.182261 47528776233856 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp4ah7_u28
W0618 10:06:57.185113 47807365399424 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:06:57.183265 47431856276352 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp19honcej', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b23df881e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:06:57.185232 47896699343744 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:06:57.183362 47528776233856 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp4ah7_u28', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3a70694e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:57.183704 47431856276352 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:06:57.183798 47528776233856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:06:57.185995 47235281343360 estimator.py:1111] Calling model_fn.
W0618 10:06:57.184447 47604093379456 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp8gu4y74d
W0618 10:06:57.186105 47235281343360 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:06:57.184474 47765771338624 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp5ue62kob
I0618 10:06:57.185479 47604093379456 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp8gu4y74d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4bf9a9bdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:57.185489 47765771338624 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp5ue62kob', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b719e6b8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:06:57.186487 47741063041920 estimator.py:1111] Calling model_fn.
W0618 10:06:57.186596 47741063041920 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:06:57.185879 47604093379456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:06:57.185878 47765771338624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:06:57.187457 47235281343360 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:06:57.187966 47741063041920 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:06:57.188434 46965232743296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:06:57.188565 48003170182016 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:06:57.189220 47078803592064 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:06:57.189399 47807365399424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:06:57.189535 47896699343744 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:06:57.189584 46987602432896 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:06:57.189664 47730972824448 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:06:57.189037 47431856276352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:57.189073 47528776233856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:57.190672 47604093379456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:57.190685 47765771338624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:06:57.192675 47545932342144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:06:57.191994 47109494133632 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:06:57.192191 47022324872064 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:06:57.194448 47807365399424 estimator.py:1111] Calling model_fn.
W0618 10:06:57.194555 47807365399424 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:06:57.194615 47896699343744 estimator.py:1111] Calling model_fn.
W0618 10:06:57.193922 46987602432896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:06:57.194722 47896699343744 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:06:57.194008 47730972824448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:06:57.195925 47807365399424 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:06:57.196102 47896699343744 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:06:57.199016 46987602432896 estimator.py:1111] Calling model_fn.
I0618 10:06:57.199078 47730972824448 estimator.py:1111] Calling model_fn.
W0618 10:06:57.199127 46987602432896 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:06:57.199188 47730972824448 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:06:57.200486 46987602432896 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:06:57.200544 47730972824448 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:06:57.205928 47118090322816 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:06:57.206399 47887110095744 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:06:57.210144 47604093379456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:06:57.210230 47765771338624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:06:57.210243 47118090322816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:06:57.210696 47887110095744 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560874017.167129 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874017.167735 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874017.168168 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:06:57.210747 47092599178112 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 10:06:57.211850 47528776233856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:06:57.211887 47431856276352 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data[2019-06-18 10:07:36] divide_golden_chunk finished: 3.346 seconds
[2019-06-18 10:07:36] generate golden chunk: 3.360 seconds
[2019-06-18 10:07:36] moving /lfs/lfs12/gma_akey/results/epb312/models/000007-000004.index --> /lfs/lfs12/gma_akey/results/epb312/models/000007-000005.index
[2019-06-18 10:07:36] moving /lfs/lfs12/gma_akey/results/epb312/models/000007-000004.meta --> /lfs/lfs12/gma_akey/results/epb312/models/000007-000005.meta
[2019-06-18 10:07:36] moving /lfs/lfs12/gma_akey/results/epb312/models/000007-000004.pb --> /lfs/lfs12/gma_akey/results/epb312/models/000007-000005.pb
[2019-06-18 10:07:36] moving /lfs/lfs12/gma_akey/results/epb312/models/000007-000004.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb312/models/000007-000005.data-00000-of-00001
[2019-06-18 10:07:36] iteration time 6: 48.433 seconds
2019-06-18 10:07:36.962002: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874056.362973 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 7}}
[2019-06-18 10:07:40] minmax time: 3.174 seconds
2019-06-18 10:07:40.146407: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:07:40.151814: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:07:40.156346: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874060.166935 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 6}}
[2019-06-18 10:07:40] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir 
[2019-06-18 10:07:40] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-8-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000007-000005 --seed=8 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000007-000005 --seed=1023779839 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000007-000005 --seed=2047559670 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000007-000005 --seed=3071339501 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000007-000005 --seed=4095119332 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000007-000005 --seed=5118899163 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000007-000005 --seed=6142678994 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000007-000005 --seed=7166458825 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000007-000005 --seed=8190238656 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000007-000005 --seed=9214018487 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000007-000005 --seed=10237798318 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000007-000005 --seed=11261578149 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000007-000005 --seed=12285357980 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000007-000005 --seed=13309137811 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000007-000005 --seed=14332917642 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000007-000005 --seed=15356697473 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000007-000005 --seed=16380477304 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000007-000005 --seed=17404257135 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000007-000005 --seed=18428036966 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000007-000005 --seed=19451816797 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000007-000005 --seed=20475596628 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 10:07:51] eval finished: 11.724 seconds
[2019-06-18 10:07:51] Win rate 000007-000005 vs 000006-000004: 0.400
:::MLL 1560874071.950868 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 6}}
[2019-06-18 10:07:51] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-9-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000008-000004 --seed=9 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000008-000004 --seed=1023779840 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000008-000004 --seed=2047559671 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000008-000004 --seed=3071339502 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000008-000004 --seed=4095119333 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000008-000004 --seed=5118899164 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000008-000004 --seed=6142678995 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000008-000004 --seed=7166458826 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000008-000004 --seed=8190238657 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000008-000004 --seed=9214018488 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000008-000004 --seed=10237798319 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000008-000004 --seed=11261578150 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000008-000004 --seed=12285357981 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000008-000004 --seed=13309137812 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000008-000004 --seed=14332917643 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000008-000004 --seed=15356697474 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000008-000004 --seed=16380477305 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000008-000004 --seed=17404257136 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000008-000004 --seed=18428036967 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/
[2019-06-18 10:08:21] selfplay finished: 29.569 seconds
[2019-06-18 10:08:21] selfplay mn: 29.586 seconds
[2019-06-18 10:08:21] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-9-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779840 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559671 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339502 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119333 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899164 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142678995 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458826 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238657 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018488 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798319 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578150 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285357981 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137812 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917643 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697474 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477305 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257136 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036967 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816798 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596629 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376460 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156291 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_
[2019-06-18 10:08:23] train finished: 43.356 seconds
:::MLL 1560874065.381609 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874065.382436 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874065.383231 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:07:45.459283 47860870030208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560874065.381921 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874065.382770 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874065.383540 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:07:45.459288 47908822889344 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 10:07:45.460340 47860870030208 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp_wq4ca5_
W0618 10:07:45.460371 47908822889344 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpu7p8rrqq
I0618 10:07:45.461344 47860870030208 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp_wq4ca5_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b87c2be7e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:07:45.461368 47908822889344 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpu7p8rrqq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b92ecf50e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:07:45.461737 47860870030208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:07:45.461764 47908822889344 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:07:45.466655 47860870030208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:07:45.466669 47908822889344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874065.407347 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874065.408055 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874065.408726 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:07:45.479854 47002225501056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560874065.402465 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874065.403384 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874065.404212 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:07:45.479897 47725375959936 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 10:07:45.480919 47002225501056 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp_cwn23kf
W0618 10:07:45.480943 47725375959936 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp8bvvab93
I0618 10:07:45.481991 47002225501056 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp_cwn23kf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abfd78aae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:07:45.481997 47725375959936 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp8bvvab93', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6836ab0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:07:45.482408 47002225501056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:07:45.482437 47725375959936 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:07:45.486530 47860870030208 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:07:45.487383 47908822889344 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:07:45.487597 47002225501056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:07:45.487585 47725375959936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874065.409650 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874065.410464 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874065.411297 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:07:45.488484 47360828699520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560874065.410162 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874065.411016 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874065.411739 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:07:45.488464 47928765170560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 10:07:45.489547 47928765170560 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpocfsi78o
W0618 10:07:45.489580 47360828699520 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpb8enhzd2
I0618 10:07:45.490593 47928765170560 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpocfsi78o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b97919c0e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:07:45.490641 47360828699520 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpb8enhzd2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1355f54da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:07:45.491014 47928765170560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:07:45.491056 47360828699520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:07:45.496223 47928765170560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:07:45.496224 47360828699520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874065.420167 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874065.421029 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874065.421781 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:07:45.498056 46919296504704 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560874065.419276 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874065.420108 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874065.420925 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:07:45.498154 47709110956928 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 10:07:45.499114 46919296504704 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp7y6kgo35
W0618 10:07:45.499174 47709110956928 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpfdazwi00
I0618 10:07:45.500181 46919296504704 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp7y6kgo35', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aac88969e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:07:45.500232 47709110956928 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpfdazwi00', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b646d32ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:07:45.500605 46919296504704 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:07:45.500658 47709110956928 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:07:45.507738 47002225501056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:07:45.507792 47725375959936 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:07:45.505970 47709110956928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:07:45.505993 46919296504704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874065.463889 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874065.464452 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874065.464791 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:07:45.510687 47007212475264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560874065.462125 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874065.462537 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874065.462890 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:07:45.510731 47128774722432 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000007.tfrecord.zz_0
I0618 10:07:45.511816 47007212475264 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac100c9ed68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:07:45.511782 47128774722432 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpqqaqoyzd
I0618 10:07:45.512822 47128774722432 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpqqaqoyzd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2add4e769e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:07:45.513008 47007212475264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:07:45.513240 47128774722432 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:07:45.517993 47007212475264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:07:45.518124 47128774722432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:07:45.517416 47360828699520 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:07:45.517416 47928765170560 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874065.441311 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874065.442100 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874065.442791 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:07:45.525924 47670277911424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560874065.439766 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874065.440533 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874065.441326 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:07:45.525993 47710500516736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 10:07:45.526993 47670277911424 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmprwcry4vq
:::MLL 1560874065.486446 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874065.486954 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874065.487349 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:07:45.528307 47776683365248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 10:07:45.527075 47710500516736 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp0r6axbwk
I0618 10:07:45.528092 47670277911424 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmprwcry4vq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5b62917e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:07:45.528153 47710500516736 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp0r6axbwk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b64c005be80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:07:45.528540 47670277911424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:07:45.528589 47710500516736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:07:45.527858 47709110956928 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:07:45.528015 46919296504704 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:07:45.529399 47776683365248 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpac9zbcus
I0618 10:07:45.530472 47776683365248 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpac9zbcus', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7428d3edd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:07:45.530919 47776683365248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874065.455655 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874065.456511 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874065.457304 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:07:45.529860 47611250000768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560874065.455418 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874065.456228 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874065.457078 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:07:45.529861 47749541258112 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 10:07:45.530890 47611250000768 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpf48y6bde
W0618 10:07:45.530920 47749541258112 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpcjtr68i_
I0618 10:07:45.531883 47611250000768 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpf48y6bde', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4da43b1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:07:45.531897 47749541258112 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpcjtr68i_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6dd7082e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:07:45.532278 47611250000768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:07:45.532290 47749541258112 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:07:45.533841 47670277911424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:07:45.533856 47710500516736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:07:45.534741 47860870030208 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:07:45.535771 47908822889344 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:07:45.536099 47776683365248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:07:45.537485 47749541258112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:07:45.537497 47611250000768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:07:45.539072 47860870030208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:07:45.539121 47128774722432 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:07:45.539240 47007212475264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:07:45.540129 47908822889344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560874065.500412 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874065.500881 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874065.501273 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:07:45.540224 46963435180928 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560874065.494352 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874065.494739 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874065.495071 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:07:45.539323 47499892155264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560874065.493197 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874065.493722 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874065.494158 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:07:45.539554 47813557420928 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 10:07:45.541240 46963435180928 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpzc_j0j8v
I0618 10:07:45.542267 46963435180928 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpzc_j0j8v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab6cf756e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:07:45.542690 46963435180928 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:07:45.540368 47499892155264 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp0m4za5jw
W0618 10:07:45.540558 47813557420928 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpze2box_0
I0618 10:07:45.541421 47499892155264 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp0m4za5jw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b33b6c92e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:07:45.541703 47813557420928 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpze2box_0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7cbeb15e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:07:45.541861 47499892155264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:07:45.544139 47860870030208 estimator.py:1111] Calling model_fn.
I0618 10:07:45.542163 47813557420928 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:07:45.544245 47860870030208 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:07:45.545243 47908822889344 estimator.py:1111] Calling model_fn.
W0618 10:07:45.545352 47908822889344 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:07:45.545619 47860870030208 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:07:45.546725 47908822889344 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:07:45.547533 46963435180928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:07:45.546504 47499892155264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:07:45.546704 47813557420928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874065.485781 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874065.486235 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874065.486608 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:07:45.552463 48006377567104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560874065.488958 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874065.489372 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874065.489732 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:07:45.552577 47912709276544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 10:07:45.553426 48006377567104 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp31lkmwwg
W0618 10:07:45.553542 47912709276544 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp3lyfoala
I0618 10:07:45.554384 48006377567104 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp31lkmwwg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba9a3ab4e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:07:45.554514 47912709276544 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp3lyfoala', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b93d49a9e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:07:45.554783 48006377567104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:07:45.554908 47912709276544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874065.509511 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874065.509918 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874065.510252 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:07:45.554289 47533681808256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560874065.509276 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874065.509665 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874065.510014 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:07:45.554402 47855132783488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 10:07:45.555895 47710500516736 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:07:45.556562 47002225501056 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:07:45.555930 47670277911424 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:07:45.556962 47725375959936 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:07:45.557308 47776683365248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:07:45.555321 47533681808256 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp9b9dmiqi
W0618 10:07:45.555432 47855132783488 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpcsqa49pp
W0618 10:07:45.557238 47749541258112 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:07:45.556403 47533681808256 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp9b9dmiqi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3b94ce5e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:07:45.557527 47611250000768 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:07:45.556515 47855132783488 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpcsqa49pp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b866cc70e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:07:45.556851 47533681808256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:07:45.556941 47855132783488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:07:45.559372 48006377567104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:07:45.559455 47912709276544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:07:45.560880 47002225501056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:07:45.561324 47725375959936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:07:45.561550 47533681808256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:07:45.561594 47855132783488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:07:45.565934 47002225501056 estimator.py:1111] Calling model_fn.
W0618 10:07:45.566039 47002225501056 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:07:45.566438 47725375959936 estimator.py:1111] Calling model_fn.
W0618 10:07:45.566548 47725375959936 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:07:45.567389 47002225501056 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:07:45.567916 47725375959936 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:07:45.566111 47499892155264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:07:45.566327 47813557420928 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:07:45.568699 46963435180928 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:07:45.568594 47360828699520 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:07:45.568819 47928765170560 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:07:45.573238 47360828699520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:07:45.573442 47928765170560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:07:45.578912 48006377567104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:07:45.579046 47912709276544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:07:45.578715 47360828699520 estimator.py:1111] Calling model_fn.
W0618 10:07:45.578830 47360828699520 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:07:45.578874 47928765170560 estimator.py:1111] Calling model_fn.
W0618 10:07:45.578987 47928765170560 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layer[2019-06-18 10:08:24] divide_golden_chunk finished: 3.323 seconds
[2019-06-18 10:08:24] generate golden chunk: 3.337 seconds
[2019-06-18 10:08:24] iteration time 7: 48.514 seconds
2019-06-18 10:08:25.523468: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874104.876709 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 8}}
[2019-06-18 10:08:28] minmax time: 3.224 seconds
2019-06-18 10:08:28.757584: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:08:28.762899: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:08:28.767392: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874108.779351 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 7}}
[2019-06-18 10:08:28] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000009-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000009-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000009-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000009-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000009-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000009-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000009-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000009-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000009-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000009-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000009-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:08:28] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-9-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000008-000005 --seed=9 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000008-000005 --seed=1023779840 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000008-000005 --seed=2047559671 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000008-000005 --seed=3071339502 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000008-000005 --seed=4095119333 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000008-000005 --seed=5118899164 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000008-000005 --seed=6142678995 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000008-000005 --seed=7166458826 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000008-000005 --seed=8190238657 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000008-000005 --seed=9214018488 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000008-000005 --seed=10237798319 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000008-000005 --seed=11261578150 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000008-000005 --seed=12285357981 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000008-000005 --seed=13309137812 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000008-000005 --seed=14332917643 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000008-000005 --seed=15356697474 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000008-000005 --seed=16380477305 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000008-000005 --seed=17404257136 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000008-000005 --seed=18428036967 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000008-000005 --seed=19451816798 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000008-000005 --seed=20475596629 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 10:08:40] eval finished: 11.570 seconds
[2019-06-18 10:08:40] Win rate 000008-000005 vs 000006-000004: 0.450
:::MLL 1560874120.410709 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 7}}
[2019-06-18 10:08:40] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-10-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000009-000004 --seed=10 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000009-000004 --seed=1023779841 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000009-000004 --seed=2047559672 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000009-000004 --seed=3071339503 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000009-000004 --seed=4095119334 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000009-000004 --seed=5118899165 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000009-000004 --seed=6142678996 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000009-000004 --seed=7166458827 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000009-000004 --seed=8190238658 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000009-000004 --seed=9214018489 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000009-000004 --seed=10237798320 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000009-000004 --seed=11261578151 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000009-000004 --seed=12285357982 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000009-000004 --seed=13309137813 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000009-000004 --seed=14332917644 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000009-000004 --seed=15356697475 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000009-000004 --seed=16380477306 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000009-000004 --seed=17404257137 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000009-000004 --seed=18428036968 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:09:09] selfplay finished: 29.454 seconds
[2019-06-18 10:09:09] selfplay mn: 29.471 seconds
[2019-06-18 10:09:09] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-10-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779841 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559672 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339503 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119334 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899165 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142678996 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458827 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238658 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018489 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798320 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578151 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285357982 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137813 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917644 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697475 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477306 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257137 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036968 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816799 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596630 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376461 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156292 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golde
[2019-06-18 10:09:12] train finished: 44.015 seconds
:::MLL 1560874114.071819 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874114.072567 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874114.073203 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:08:34.147086 47462670365568 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560874114.070111 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874114.070848 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874114.071650 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:08:34.147128 47506657842048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 10:08:34.148054 47462670365568 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpaf5qt4he
W0618 10:08:34.148083 47506657842048 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpwm0m9bln
I0618 10:08:34.149034 47462670365568 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpaf5qt4he', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2b0c31ce80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:08:34.149044 47506657842048 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpwm0m9bln', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b354a0d6e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:08:34.149431 47462670365568 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:08:34.149436 47506657842048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:08:34.154418 47506657842048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:08:34.154515 47462670365568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874114.071210 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874114.072103 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874114.072908 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:08:34.164082 47719520592768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560874114.082312 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874114.083046 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874114.083694 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:08:34.164229 47950465840000 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 10:08:34.165072 47719520592768 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpyf6u93_v
W0618 10:08:34.165156 47950465840000 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp8ivxge9i
I0618 10:08:34.166044 47719520592768 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpyf6u93_v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b66d9a92e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:08:34.166124 47950465840000 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp8ivxge9i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9c9f120e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:08:34.166449 47719520592768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:08:34.166512 47950465840000 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:08:34.171424 47950465840000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:08:34.171453 47719520592768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:08:34.174262 47506657842048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:08:34.174826 47462670365568 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874114.097505 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874114.098373 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874114.099102 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:08:34.177481 47529914774400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560874114.097003 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874114.097813 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874114.098617 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:08:34.177757 47129246442368 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 10:08:34.178608 47529914774400 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmplliy1e43
W0618 10:08:34.178819 47129246442368 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpeh80hbu2
I0618 10:08:34.179743 47529914774400 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmplliy1e43', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3ab4460e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:08:34.179938 47129246442368 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpeh80hbu2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2add6a947e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:08:34.180184 47529914774400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:08:34.180376 47129246442368 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:08:34.185490 47529914774400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:08:34.185625 47129246442368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:08:34.191340 47719520592768 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:08:34.191386 47950465840000 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874114.146702 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874114.147115 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874114.147475 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:08:34.195991 47508497040256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560874114.147913 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874114.148326 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874114.148677 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:08:34.196126 47527118373760 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560874114.109948 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874114.110886 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874114.111771 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:08:34.194801 47711863280512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560874114.114627 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874114.115319 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874114.116070 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:08:34.194814 47550178075520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 10:08:34.196961 47508497040256 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpfazjrsmp
I0618 10:08:34.197117 47527118373760 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3a0d985d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:08:34.198069 47508497040256 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpfazjrsmp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b35b7ad5e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:08:34.198456 47527118373760 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:08:34.198511 47508497040256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:08:34.195887 47550178075520 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpdy6kk6ti
W0618 10:08:34.195919 47711863280512 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp7nksi1ev
I0618 10:08:34.197001 47550178075520 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpdy6kk6ti', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3f6c0f7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:08:34.197011 47711863280512 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp7nksi1ev', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b65113fdda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:08:34.197463 47711863280512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:08:34.197463 47550178075520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:08:34.203161 47527118373760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:08:34.203202 47508497040256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:08:34.202832 47711863280512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:08:34.202838 47550178075520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874114.128371 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874114.129105 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874114.129811 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:08:34.204516 47948071674752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560874114.125675 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874114.126421 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874114.127099 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:08:34.204582 46913606710144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 10:08:34.207526 47529914774400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:08:34.205525 47948071674752 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpr_wqwnma
W0618 10:08:34.205558 46913606710144 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpakw9lpp9
I0618 10:08:34.206535 47948071674752 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpr_wqwnma', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9c105dfda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:08:34.206550 46913606710144 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpakw9lpp9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aab35732e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:08:34.208110 47129246442368 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:08:34.206968 47948071674752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:08:34.206972 46913606710144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874114.160177 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874114.160627 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874114.161005 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:08:34.211508 47130813420416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560874114.160072 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874114.160520 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874114.160912 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:08:34.211688 47319512224640 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560874114.164986 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874114.165416 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874114.165783 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:08:34.213467 47421744636800 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560874114.138647 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874114.139408 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874114.140085 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:08:34.212522 47190476841856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560874114.136576 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874114.137312 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874114.138025 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:08:34.212637 47140465365888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 10:08:34.212578 47130813420416 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpci91gygr
W0618 10:08:34.211939 47948071674752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:08:34.211939 46913606710144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:08:34.212744 47319512224640 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp0nc3tzk6
I0618 10:08:34.213621 47130813420416 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpci91gygr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2addc7faae80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:08:34.213769 47319512224640 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp0nc3tzk6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b09b74dde80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:08:34.214029 47130813420416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:08:34.214162 47319512224640 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:08:34.213564 47190476841856 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp1lxejx5i
W0618 10:08:34.214519 47421744636800 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpqy03puim
W0618 10:08:34.213798 47140465365888 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp1_nougl_
I0618 10:08:34.214630 47190476841856 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp1lxejx5i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aebac322e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:08:34.215606 47421744636800 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpqy03puim', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2184d4be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:08:34.214838 47140465365888 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp1_nougl_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae00747add8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:08:34.215063 47190476841856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:08:34.216052 47421744636800 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:08:34.215255 47140465365888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:08:34.218629 47130813420416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:08:34.218719 47319512224640 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874114.169153 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874114.169615 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874114.170027 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:08:34.219355 47222805042048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 10:08:34.220803 47421744636800 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:08:34.220045 47190476841856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:08:34.220335 47222805042048 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp8ov0ejge
W0618 10:08:34.220141 47140465365888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:08:34.221436 47222805042048 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp8ov0ejge', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af3331b6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:08:34.221966 47222805042048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:08:34.222160 47506657842048 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:08:34.222450 47462670365568 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:08:34.222662 47527118373760 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:08:34.222665 47508497040256 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874114.176939 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874114.177420 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874114.177792 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:08:34.222534 47812680389504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 10:08:34.223590 47812680389504 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp458076tb
W0618 10:08:34.226479 47506657842048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:08:34.224653 47812680389504 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp458076tb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7c8a6adda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:08:34.226749 47462670365568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:08:34.225091 47812680389504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:08:34.227139 47222805042048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:08:34.225183 47711863280512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:08:34.225221 47550178075520 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:08:34.231532 47506657842048 estimator.py:1111] Calling model_fn.
W0618 10:08:34.231637 47506657842048 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:08:34.231811 47462670365568 estimator.py:1111] Calling model_fn.
W0618 10:08:34.231919 47462670365568 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560874114.185898 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874114.186349 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874114.186735 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:08:34.229877 47582961382272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 10:08:34.230021 47812680389504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:08:34.232982 47506657842048 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:08:34.233272 47462670365568 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:08:34.230848 47582961382272 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpjvuz6ds3
I0618 10:08:34.231884 47582961382272 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpjvuz6ds3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b470e190e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:08:34.231727 46913606710144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:08:34.231778 47948071674752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:08:34.232320 47582961382272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:08:34.238059 47130813420416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:08:34.236934 47582961382272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:08:34.238344 47319512224640 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:08:34.239718 47950465840000 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:08:34.239729 47719520592768 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:08:34.240296 47421744636800 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:08:34.239866 47190476841856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:08:34.239888 47140465365888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:08:34.244023 47950465840000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:08:34.244063 47719520592768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:08:34.249074 47950465840000 estimator.py:1111] Calling model_fn.
I0618 10:08:34.249121 47719520592768 estimator.py:1111] Calling model_fn.
W0618 10:08:34.249183 47950465840000 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:08:34.249224 47719520592768 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:08:34.250538 47950465840000 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:08:34.250568 47719520592768 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:08:34.251356 47222805042048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:08:34.249758 47812680389504 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:08:34.255514 47529914774400 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:08:34.256158 47129246442368 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560874114.206166 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874114.206643 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874114.207093 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:08:34.255506 47566986933120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560874114.207300 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874114.207797 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874114.208174 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:08:34.255715 46991302009728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 10:08:34.256311 47582961382272 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:08:34.256521 47566986933120 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp6k0la2j7
:::MLL 1560874114.210108 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874114.210592 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874114.211005 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:08:34.258442 47314563498880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560874114.209662 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874114.210140 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874114.210559 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:08:34.258452 47259310797696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 10:08:34.256735 46991302009728 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpjslhe4ih
I0618 10:08:34.257566 47566986933120 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp6k0la2j7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4355f24e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:08:34.257762 46991302009728 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpjslhe4ih', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abd4c735e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:08:34.257989 47566986933120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:08:34.258188 46991302009728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:08:34.259795 47529914774400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:08:34.260507 47129246442368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:08:34.259585 47314563498880 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpp2_dunhg
W0618 10:08:34.259618 47259310797696 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpnbx751j8
I0618 10:08:34.260664 47314563498880 estimator.py:201] Using co[2019-06-18 10:09:13] divide_golden_chunk finished: 3.318 seconds
[2019-06-18 10:09:13] generate golden chunk: 3.332 seconds
[2019-06-18 10:09:13] iteration time 8: 48.339 seconds
2019-06-18 10:09:13.906872: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874153.215588 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 9}}
[2019-06-18 10:09:17] minmax time: 3.249 seconds
2019-06-18 10:09:17.166007: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:09:17.176842: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:09:17.181303: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874157.193514 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 8}}
[2019-06-18 10:09:17] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000010-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000010-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000010-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000010-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000010-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000010-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000010-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000010-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000010-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000010-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000010-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:09:17] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-10-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000009-000005 --seed=10 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000009-000005 --seed=1023779841 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000009-000005 --seed=2047559672 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000009-000005 --seed=3071339503 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000009-000005 --seed=4095119334 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000009-000005 --seed=5118899165 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000009-000005 --seed=6142678996 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000009-000005 --seed=7166458827 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000009-000005 --seed=8190238658 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000009-000005 --seed=9214018489 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000009-000005 --seed=10237798320 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000009-000005 --seed=11261578151 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000009-000005 --seed=12285357982 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000009-000005 --seed=13309137813 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000009-000005 --seed=14332917644 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000009-000005 --seed=15356697475 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000009-000005 --seed=16380477306 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000009-000005 --seed=17404257137 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000009-000005 --seed=18428036968 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000009-000005 --seed=19451816799 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000009-000005 --seed=20475596630 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:09:30] eval finished: 13.269 seconds
[2019-06-18 10:09:30] Win rate 000009-000005 vs 000006-000004: 0.540
:::MLL 1560874170.526000 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 8}}
[2019-06-18 10:09:30] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-11-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000010-000004 --seed=11 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000010-000004 --seed=1023779842 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000010-000004 --seed=2047559673 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000010-000004 --seed=3071339504 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000010-000004 --seed=4095119335 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000010-000004 --seed=5118899166 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000010-000004 --seed=6142678997 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000010-000004 --seed=7166458828 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000010-000004 --seed=8190238659 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000010-000004 --seed=9214018490 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000010-000004 --seed=10237798321 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000010-000004 --seed=11261578152 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000010-000004 --seed=12285357983 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000010-000004 --seed=13309137814 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000010-000004 --seed=14332917645 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000010-000004 --seed=15356697476 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000010-000004 --seed=16380477307 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000010-000004 --seed=17404257138 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000010-000004 --seed=18428036969 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:09:59] selfplay finished: 29.196 seconds
[2019-06-18 10:09:59] selfplay mn: 29.213 seconds
[2019-06-18 10:09:59] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-11-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779842 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559673 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339504 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119335 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899166 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142678997 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458828 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238659 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018490 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798321 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578152 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285357983 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137814 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917645 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697476 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477307 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257138 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036969 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816800 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596631 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376462 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156293 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golde
[2019-06-18 10:10:01] train finished: 43.831 seconds
:::MLL 1560874162.435816 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874162.436557 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874162.437305 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:09:22.501057 47539794928512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560874162.423852 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874162.424720 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874162.425567 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:09:22.501143 47671129502592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 10:09:22.502011 47539794928512 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpwvcdj83m
W0618 10:09:22.502104 47671129502592 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp04ddkq3_
I0618 10:09:22.502996 47539794928512 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpwvcdj83m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3d012d0dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:09:22.503083 47671129502592 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp04ddkq3_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5b9553ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:09:22.503402 47539794928512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:09:22.503475 47671129502592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:09:22.508434 47671129502592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:09:22.508444 47539794928512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:09:22.528226 47671129502592 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:09:22.528228 47539794928512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874162.471007 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874162.471956 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874162.472640 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:09:22.552765 47553316983680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560874162.474690 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874162.475438 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874162.476134 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:09:22.552985 47156150322048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 10:09:22.553897 47553316983680 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmph_5iqn4u
W0618 10:09:22.554074 47156150322048 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpxbebldn2
I0618 10:09:22.554986 47553316983680 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmph_5iqn4u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4027276da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:09:22.555156 47156150322048 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpxbebldn2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae3ae2cfe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:09:22.555435 47553316983680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:09:22.555594 47156150322048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:09:22.560670 47553316983680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:09:22.560791 47156150322048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874162.483285 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874162.484188 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874162.485017 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:09:22.563725 47307713471360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560874162.493519 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874162.494242 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874162.494888 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:09:22.563766 47915901891456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 10:09:22.564795 47307713471360 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpgq9zblz0
W0618 10:09:22.564825 47915901891456 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp7bfjdf5v
I0618 10:09:22.565929 47307713471360 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpgq9zblz0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b06f80b3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:09:22.565939 47915901891456 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp7bfjdf5v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9492e5fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:09:22.566363 47307713471360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:09:22.566370 47915901891456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:09:22.571361 47307713471360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:09:22.571372 47915901891456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874162.495712 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874162.496454 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874162.497151 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:09:22.574062 47806148141952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560874162.490085 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874162.491032 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874162.491883 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:09:22.574038 47430901896064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560874162.522974 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874162.523372 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874162.523701 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:09:22.574976 47424256586624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560874162.522741 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874162.523142 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874162.523481 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:09:22.575125 47671688221568 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 10:09:22.575081 47806148141952 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpf_kswpi5
W0618 10:09:22.575108 47430901896064 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpwv1qf2ps
I0618 10:09:22.576085 47806148141952 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpf_kswpi5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7b0510ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:09:22.576104 47430901896064 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpwv1qf2ps', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b23a6a56e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:09:22.576481 47806148141952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:09:22.576496 47430901896064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:09:22.576573 47539794928512 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:09:22.576002 47424256586624 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpn2d2onq4
W0618 10:09:22.576128 47671688221568 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp2ltwguee
I0618 10:09:22.576979 47424256586624 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpn2d2onq4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b221a8e0dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:09:22.576944 47671129502592 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:09:22.577113 47671688221568 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp2ltwguee', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5bb6a12dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:09:22.577372 47424256586624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:09:22.577507 47671688221568 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:09:22.581022 47539794928512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:09:22.581317 47806148141952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:09:22.581325 47430901896064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:09:22.581370 47671129502592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:09:22.581913 47424256586624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:09:22.582114 47671688221568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:09:22.582949 47553316983680 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:09:22.583368 47156150322048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:09:22.586114 47539794928512 estimator.py:1111] Calling model_fn.
W0618 10:09:22.586223 47539794928512 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:09:22.586405 47671129502592 estimator.py:1111] Calling model_fn.
W0618 10:09:22.586510 47671129502592 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:09:22.587577 47539794928512 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:09:22.587848 47671129502592 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:09:22.591491 47307713471360 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:09:22.591472 47915901891456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:09:22.601299 47806148141952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:09:22.601401 47424256586624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:09:22.601335 47430901896064 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:09:22.601672 47671688221568 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874162.495270 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874162.496092 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874162.496917 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:09:22.601360 47467420484480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560874162.495731 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874162.496625 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874162.497391 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:09:22.601550 47486612648832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560874162.550325 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874162.550789 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874162.551219 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:09:22.601640 47987075224448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560874162.550335 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874162.550792 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874162.551219 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:09:22.601722 47629980480384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 10:09:22.602476 47467420484480 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp_2mfaams
W0618 10:09:22.602602 47486612648832 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpt6nvtp53
I0618 10:09:22.603580 47467420484480 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp_2mfaams', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2c2752ce80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:09:22.603683 47486612648832 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpt6nvtp53', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b309f440e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:09:22.604035 47467420484480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:09:22.604124 47486612648832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:09:22.602656 47987075224448 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp_a16n4ao
:::MLL 1560874162.525416 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874162.526336 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874162.527210 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:09:22.604283 47418866033536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 10:09:22.602693 47629980480384 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpjhcr37ln
:::MLL 1560874162.533772 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874162.534509 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874162.535213 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:09:22.604271 47223957791616 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_0
I0618 10:09:22.603638 47987075224448 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp_a16n4ao', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba52528ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:09:22.603667 47629980480384 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpjhcr37ln', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5200a77e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:09:22.604037 47987075224448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:09:22.604055 47629980480384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:09:22.605338 47418866033536 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpjqqmenlq
W0618 10:09:22.605309 47223957791616 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpc9nw7ix4
I0618 10:09:22.606325 47223957791616 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpc9nw7ix4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af377d0ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:09:22.606348 47418866033536 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpjqqmenlq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b20d940be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:09:22.606730 47223957791616 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:09:22.606750 47418866033536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:09:22.609253 47467420484480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:09:22.609376 47486612648832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:09:22.608622 47987075224448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:09:22.608654 47629980480384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:09:22.612042 47418866033536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:09:22.612043 47223957791616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874162.567108 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874162.567552 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874162.567921 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:09:22.617523 47355765363584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560874162.568075 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874162.568552 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874162.569185 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:09:22.615622 47675109766016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560874162.570039 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874162.570478 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874162.570860 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:09:22.618405 47799906050944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 10:09:22.618520 47355765363584 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpnsljwupa
I0618 10:09:22.619547 47355765363584 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpnsljwupa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b122828ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:09:22.616672 47675109766016 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmptkcfrhxh
I0618 10:09:22.617772 47675109766016 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmptkcfrhxh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5c8291ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:09:22.619968 47355765363584 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:09:22.619456 47799906050944 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b799101fd68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:09:22.618214 47675109766016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:09:22.620627 47799906050944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:09:22.624632 47355765363584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:09:22.625143 47799906050944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:09:22.623323 47675109766016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874162.578395 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874162.578856 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874162.579252 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:09:22.623592 47580663350144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 10:09:22.624595 47580663350144 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpjyzv5nhd
I0618 10:09:22.625638 47580663350144 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpjyzv5nhd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b46851fce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:09:22.626063 47580663350144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874162.550420 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874162.550897 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874162.551283 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:09:22.628208 47950914179968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 10:09:22.628041 47987075224448 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:09:22.628194 47629980480384 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:09:22.629217 47950914179968 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpz62rkfui
I0618 10:09:22.630257 47950914179968 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpz62rkfui', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9cb9cb2e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560874162.553684 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874162.554102 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874162.554466 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:09:22.630264 47908102083456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz_0
I0618 10:09:22.630674 47950914179968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:09:22.631476 47467420484480 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:09:22.631813 47486612648832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:09:22.631707 47223957791616 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:09:22.631776 47418866033536 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:09:22.630821 47580663350144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:09:22.631390 47908102083456 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpk8aiepnm
I0618 10:09:22.632533 47908102083456 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpk8aiepnm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b92c1fe6e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:09:22.632980 47908102083456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:09:22.632829 47553316983680 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:09:22.633293 47156150322048 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:09:22.635398 47950914179968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:09:22.638081 47908102083456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:09:22.637290 47553316983680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:09:22.637762 47156150322048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:09:22.639495 47307713471360 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:09:22.639651 47915901891456 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:09:22.644218 47355765363584 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:09:22.642477 47553316983680 estimator.py:1111] Calling model_fn.
W0618 10:09:22.642605 47553316983680 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:09:22.644736 47799906050944 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:09:22.642984 47156150322048 estimator.py:1111] Calling model_fn.
W0618 10:09:22.643103 47156150322048 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:09:22.643413 47675109766016 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:09:22.643792 47307713471360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:09:22.644035 47553316983680 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:09:22.643951 47915901891456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:09:22.644547 47156150322048 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:09:22.648545 47671688221568 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:09:22.648615 47424256586624 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    [2019-06-18 10:10:03] divide_golden_chunk finished: 3.305 seconds
[2019-06-18 10:10:03] generate golden chunk: 3.319 seconds
[2019-06-18 10:10:03] moving /lfs/lfs12/gma_akey/results/epb312/models/000010-000005.meta --> /lfs/lfs12/gma_akey/results/epb312/models/000010-000006.meta
[2019-06-18 10:10:03] moving /lfs/lfs12/gma_akey/results/epb312/models/000010-000005.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb312/models/000010-000006.data-00000-of-00001
[2019-06-18 10:10:03] moving /lfs/lfs12/gma_akey/results/epb312/models/000010-000005.index --> /lfs/lfs12/gma_akey/results/epb312/models/000010-000006.index
[2019-06-18 10:10:03] moving /lfs/lfs12/gma_akey/results/epb312/models/000010-000005.pb --> /lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb
[2019-06-18 10:10:03] iteration time 9: 49.885 seconds
2019-06-18 10:10:03.819558: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874203.100381 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 10}}
[2019-06-18 10:10:07] minmax time: 3.182 seconds
2019-06-18 10:10:07.011092: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:10:07.016397: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:10:07.020878: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874207.031843 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 9}}
[2019-06-18 10:10:07] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:10:07] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-11-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000010-000006 --seed=11 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000010-000006 --seed=1023779842 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000010-000006 --seed=2047559673 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000010-000006 --seed=3071339504 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000010-000006 --seed=4095119335 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000010-000006 --seed=5118899166 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000010-000006 --seed=6142678997 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000010-000006 --seed=7166458828 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000010-000006 --seed=8190238659 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000010-000006 --seed=9214018490 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000010-000006 --seed=10237798321 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000010-000006 --seed=11261578152 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000010-000006 --seed=12285357983 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000010-000006 --seed=13309137814 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000010-000006 --seed=14332917645 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000010-000006 --seed=15356697476 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000010-000006 --seed=16380477307 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000010-000006 --seed=17404257138 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000010-000006 --seed=18428036969 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000010-000006 --seed=19451816800 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000010-000006 --seed=20475596631 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:10:17] eval finished: 10.239 seconds
[2019-06-18 10:10:17] Win rate 000010-000006 vs 000009-000005: 0.620
:::MLL 1560874217.333593 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 9}}
[2019-06-18 10:10:17] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-12-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000011-000005 --seed=12 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000011-000005 --seed=1023779843 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000011-000005 --seed=2047559674 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000011-000005 --seed=3071339505 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000011-000005 --seed=4095119336 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000011-000005 --seed=5118899167 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000011-000005 --seed=6142678998 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000011-000005 --seed=7166458829 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000011-000005 --seed=8190238660 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000011-000005 --seed=9214018491 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000011-000005 --seed=10237798322 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000011-000005 --seed=11261578153 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000011-000005 --seed=12285357984 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000011-000005 --seed=13309137815 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000011-000005 --seed=14332917646 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000011-000005 --seed=15356697477 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000011-000005 --seed=16380477308 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000011-000005 --seed=17404257139 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000011-000005 --seed=18428036970 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:10:47] selfplay finished: 30.144 seconds
[2019-06-18 10:10:47] selfplay mn: 30.165 seconds
[2019-06-18 10:10:47] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-12-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779843 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559674 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339505 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119336 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899167 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142678998 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458829 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238660 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018491 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798322 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578153 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285357984 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137815 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917646 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697477 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477308 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257139 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036970 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816801 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596632 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376463 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156294 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golde
[2019-06-18 10:10:50] train finished: 43.518 seconds
:::MLL 1560874212.352921 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874212.353794 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874212.354635 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:10:12.441066 47841772635008 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560874212.355685 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874212.356602 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874212.357434 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:10:12.439388 47385222480768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560874212.362205 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874212.362929 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874212.363607 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:10:12.439437 47287342502784 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560874212.366588 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874212.367341 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874212.368073 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:10:12.441487 46988733027200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560874212.364364 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874212.365110 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874212.365811 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:10:12.442028 47733579645824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560874212.359748 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874212.360667 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874212.361524 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:10:12.442155 47146950734720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 10:10:12.442065 47841772635008 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmprs13gigh
W0618 10:10:12.440368 47385222480768 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpw9j7amum
I0618 10:10:12.443067 47841772635008 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmprs13gigh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8350735e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:10:12.440411 47287342502784 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmplj0v9z4n
I0618 10:10:12.441371 47385222480768 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpw9j7amum', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1903f0dda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:10:12.442490 46988733027200 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpfpfmocd_
I0618 10:10:12.441383 47287342502784 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmplj0v9z4n', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0239d6ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:10:12.443463 47841772635008 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:10:12.443595 46988733027200 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpfpfmocd_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abcb353ddd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:10:12.441771 47385222480768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:10:12.441775 47287342502784 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:10:12.443038 47733579645824 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp42v70wmp
W0618 10:10:12.443139 47146950734720 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpofjrtjfg
I0618 10:10:12.444003 46988733027200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:10:12.444056 47733579645824 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp42v70wmp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6a1fa54e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:10:12.444122 47146950734720 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpofjrtjfg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae189d67e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:10:12.444457 47733579645824 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:10:12.444511 47146950734720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:10:12.448316 47841772635008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:10:12.446529 47385222480768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:10:12.446538 47287342502784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:10:12.448950 46988733027200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:10:12.449186 47733579645824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:10:12.449206 47146950734720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874212.380188 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874212.380992 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874212.381676 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:10:12.462296 48000548782976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560874212.378692 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874212.379449 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874212.380274 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:10:12.462482 47906131448704 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 10:10:12.463421 48000548782976 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpgv3h260v
W0618 10:10:12.463554 47906131448704 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpl02jlfmz
I0618 10:10:12.464520 48000548782976 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpgv3h260v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba8483f1e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:10:12.464676 47906131448704 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpl02jlfmz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b924c88ee80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:10:12.464967 48000548782976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:10:12.465115 47906131448704 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:10:12.468114 47841772635008 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:10:12.468930 47733579645824 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:10:12.468968 47146950734720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:10:12.469310 46988733027200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:10:12.468725 47385222480768 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:10:12.468838 47287342502784 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:10:12.470175 48000548782976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:10:12.470194 47906131448704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:10:12.492448 47906131448704 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:10:12.492501 48000548782976 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874212.438768 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874212.439244 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874212.439655 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:10:12.498136 47694645969792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560874212.435112 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874212.435579 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874212.436017 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:10:12.498175 47329121010560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560874212.418214 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874212.419082 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874212.419935 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:10:12.497956 47014375310208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560874212.431612 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874212.432390 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874212.433078 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:10:12.497948 47702659224448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560874212.445588 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874212.445959 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874212.446400 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:10:12.499195 47072297505664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560874212.443814 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874212.444213 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874212.444541 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:10:12.499158 47196363002752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560874212.446162 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874212.446686 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874212.447103 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:10:12.499334 47071096128384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560874212.442785 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874212.443169 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874212.443496 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:10:12.498036 47653840601984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560874212.444743 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874212.445127 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874212.445460 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:10:12.498465 47646322578304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 10:10:12.499186 47694645969792 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp8wu_rc8a
W0618 10:10:12.498984 47702659224448 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpfv3utw0i
W0618 10:10:12.499212 47329121010560 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp0a2dw13o
W0618 10:10:12.499017 47014375310208 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpg1w8qk6z
I0618 10:10:12.500172 47694645969792 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp8wu_rc8a', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b610f049e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:10:12.500174 47329121010560 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp0a2dw13o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0bf4085e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:10:12.500193 47072297505664 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad028289d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:10:12.500050 47702659224448 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpfv3utw0i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b62eca51e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:10:12.500165 47196363002752 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp2gh3yl0w
I0618 10:10:12.500080 47014375310208 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpg1w8qk6z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac2abba1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:10:12.500361 47071096128384 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpwr_bc42e
I0618 10:10:12.501138 47196363002752 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp2gh3yl0w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aed0b09de80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:10:12.500565 47694645969792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:10:12.500572 47329121010560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:10:12.501323 47072297505664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:10:12.500451 47702659224448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:10:12.500475 47014375310208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:10:12.501397 47071096128384 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpwr_bc42e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acfe08d1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:10:12.501585 47196363002752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:10:12.499032 47653840601984 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpgbp0_wan
I0618 10:10:12.501822 47071096128384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:10:12.499997 47653840601984 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpgbp0_wan', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b578ed41da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:10:12.499452 47646322578304 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpvaka50l8
I0618 10:10:12.500394 47653840601984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:10:12.500423 47646322578304 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpvaka50l8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b55ceb82e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:10:12.500821 47646322578304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874212.453243 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874212.453694 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874212.454095 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:10:12.503086 47322061316992 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 10:10:12.504096 47322061316992 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpby_ha6n0
I0618 10:10:12.505142 47322061316992 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpby_ha6n0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0a4f3dee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:10:12.505534 47322061316992 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:10:12.505209 47694645969792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:10:12.505983 47072297505664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:10:12.505207 47329121010560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:10:12.506155 47196363002752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:10:12.505383 47014375310208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:10:12.505387 47702659224448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:10:12.506510 47071096128384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:10:12.504959 47653840601984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:10:12.505324 47646322578304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:10:12.510039 47322061316992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874212.435346 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874212.436246 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874212.436964 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:10:12.512480 47926125282176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560874212.434459 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874212.435327 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874212.436186 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:10:12.512488 47204003201920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 10:10:12.516034 47841772635008 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:10:12.513533 47204003201920 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpqf5fouvd
W0618 10:10:12.513562 47926125282176 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpbfo_k03n
I0618 10:10:12.514559 47204003201920 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpqf5fouvd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeed26e1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:10:12.514591 47926125282176 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpbfo_k03n', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b96f4428da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:10:12.514955 47204003201920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:10:12.514987 47926125282176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:10:12.517506 47733579645824 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:10:12.517895 47146950734720 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:10:12.518030 46988733027200 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:10:12.520346 47841772635008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:10:12.521830 47733579645824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:10:12.519827 47204003201920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:10:12.519835 47926125282176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:10:12.522236 47146950734720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:10:12.522516 46988733027200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:10:12.521270 47385222480768 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:10:12.521260 47287342502784 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:10:12.524614 47694645969792 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:10:12.525384 47072297505664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:10:12.525393 47841772635008 estimator.py:1111] Calling model_fn.
W0618 10:10:12.525475 47196363002752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:10:12.524853 47329121010560 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:10:12.525503 47841772635008 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:10:12.526012 47071096128384 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:10:12.524385 47653840601984 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:10:12.525502 47702659224448 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:10:12.525548 47014375310208 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:10:12.524734 47646322578304 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:10:12.526859 47841772635008 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:10:12.526908 47733579645824 estimator.py:1111] Calling model_fn.
W0618 10:10:12.527019 47733579645824 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:10:12.527339 47146950734720 estimator.py:1111] Calling model_fn.
W0618 10:10:12.527448 47146950734720 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:10:12.527779 46988733027200 estimator.py:1111] Calling model_fn.
W0618 10:10:12.525856 47385222480768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:10:12.527895 46988733027200 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:10:12.525868 47287342502784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:10:12.528380 47733579645824 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:10:12.528816 47146950734720 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:10:12.529406 47322061316992 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:10:12.529453 46988733027200 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:10:12.531144 47385222480768 estimator.py:1111] Calling model_fn.
I0618 10:10:12.531160 47287342502784 estimator.py:1111] Calling model_fn.
W0618 10:10:12.531286 47385222480768 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:10:12.531298 47287342502784 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:10:12.532760 47385222480768 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:10:12.532756 47287342502784 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:10:12.541033 47906131448704 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:10:12.539661 47204003201920 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:10:12.539748 47926125282176 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:10:12.541435 48000548782976 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:10:12.545656 47906131448704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:10:12.546073 48000548782976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:10:12.551090 47906131448704 estimator.py:1111] Calling model_fn.
W0618 10:10:12.551202 47906131448704 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:10:12.551538 48000548782976 estimator.py:1111] Calling[2019-06-18 10:10:50] divide_golden_chunk finished: 3.314 seconds
[2019-06-18 10:10:50] generate golden chunk: 3.328 seconds
[2019-06-18 10:10:50] moving /lfs/lfs12/gma_akey/results/epb312/models/000011-000006.meta --> /lfs/lfs12/gma_akey/results/epb312/models/000011-000007.meta
[2019-06-18 10:10:50] moving /lfs/lfs12/gma_akey/results/epb312/models/000011-000006.pb --> /lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb
[2019-06-18 10:10:50] moving /lfs/lfs12/gma_akey/results/epb312/models/000011-000006.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb312/models/000011-000007.data-00000-of-00001
[2019-06-18 10:10:50] moving /lfs/lfs12/gma_akey/results/epb312/models/000011-000006.index --> /lfs/lfs12/gma_akey/results/epb312/models/000011-000007.index
[2019-06-18 10:10:50] iteration time 10: 47.769 seconds
2019-06-18 10:10:51.629449: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874250.869774 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 11}}
[2019-06-18 10:10:54] minmax time: 3.296 seconds
2019-06-18 10:10:54.934988: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:10:54.940444: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:10:54.945063: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874254.956174 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 10}}
[2019-06-18 10:10:54] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:10:55] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-12-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000011-000007 --seed=12 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000011-000007 --seed=1023779843 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000011-000007 --seed=2047559674 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000011-000007 --seed=3071339505 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000011-000007 --seed=4095119336 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000011-000007 --seed=5118899167 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000011-000007 --seed=6142678998 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000011-000007 --seed=7166458829 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000011-000007 --seed=8190238660 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000011-000007 --seed=9214018491 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000011-000007 --seed=10237798322 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000011-000007 --seed=11261578153 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000011-000007 --seed=12285357984 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000011-000007 --seed=13309137815 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000011-000007 --seed=14332917646 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000011-000007 --seed=15356697477 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000011-000007 --seed=16380477308 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000011-000007 --seed=17404257139 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000011-000007 --seed=18428036970 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000011-000007 --seed=19451816801 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000011-000007 --seed=20475596632 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:11:07] eval finished: 12.198 seconds
[2019-06-18 10:11:07] Win rate 000011-000007 vs 000010-000006: 0.570
:::MLL 1560874267.215968 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 10}}
[2019-06-18 10:11:07] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-13-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000012-000006 --seed=13 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000012-000006 --seed=1023779844 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000012-000006 --seed=2047559675 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000012-000006 --seed=3071339506 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000012-000006 --seed=4095119337 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000012-000006 --seed=5118899168 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000012-000006 --seed=6142678999 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000012-000006 --seed=7166458830 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000012-000006 --seed=8190238661 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000012-000006 --seed=9214018492 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000012-000006 --seed=10237798323 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000012-000006 --seed=11261578154 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000012-000006 --seed=12285357985 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000012-000006 --seed=13309137816 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000012-000006 --seed=14332917647 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000012-000006 --seed=15356697478 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000012-000006 --seed=16380477309 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000012-000006 --seed=17404257140 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000012-000006 --seed=18428036971 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:11:37] selfplay finished: 30.504 seconds
[2019-06-18 10:11:37] selfplay mn: 30.524 seconds
[2019-06-18 10:11:37] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-13-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779844 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559675 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339506 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119337 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899168 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142678999 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458830 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238661 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018492 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798323 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578154 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285357985 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137816 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917647 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697478 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477309 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257140 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036971 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816802 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596633 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376464 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156295 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golde
[2019-06-18 10:11:38] train finished: 43.878 seconds
:::MLL 1560874260.282742 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874260.283496 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874260.284180 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:00.364156 47915153994624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 10:11:00.365129 47915153994624 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpk8gkxomt
I0618 10:11:00.366137 47915153994624 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpk8gkxomt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9466520e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:00.366542 47915153994624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874260.280706 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874260.281454 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874260.282174 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:00.367078 47614077985664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 10:11:00.368049 47614077985664 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpn79tpfkw
I0618 10:11:00.369064 47614077985664 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpn79tpfkw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4e4ccabe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:00.369480 47614077985664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:11:00.371486 47915153994624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874260.294809 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874260.295527 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874260.296222 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:00.372922 47940613436288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560874260.285370 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874260.286288 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874260.287143 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:00.372916 47961845564288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 10:11:00.374349 47614077985664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:00.373898 47940613436288 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmplvtepz4l
W0618 10:11:00.373932 47961845564288 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp5bbw_0ju
I0618 10:11:00.374886 47940613436288 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmplvtepz4l', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9a53d23e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:00.374919 47961845564288 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp5bbw_0ju', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9f455ade10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:00.375289 47940613436288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:11:00.375333 47961845564288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:11:00.380177 47940613436288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:00.380227 47961845564288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874260.304869 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874260.305777 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874260.306606 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:00.387697 47762997724032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560874260.310015 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874260.310746 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874260.311432 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:00.387821 47693098369920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 10:11:00.391013 47915153994624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:11:00.388780 47762997724032 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpivbmuvv3
W0618 10:11:00.388877 47693098369920 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpzxtzx8dn
I0618 10:11:00.389839 47762997724032 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpivbmuvv3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b70f9198da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:00.389934 47693098369920 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpzxtzx8dn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b60b2c61e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:00.390269 47762997724032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:11:00.390365 47693098369920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:11:00.393694 47614077985664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:11:00.395512 47762997724032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:00.395701 47693098369920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:00.399821 47940613436288 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:11:00.400184 47961845564288 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874260.324344 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874260.325282 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874260.326183 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:00.407278 47780306297728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560874260.335895 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874260.336648 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874260.337353 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:00.407400 47042231382912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 10:11:00.408368 47780306297728 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp5f83mexm
W0618 10:11:00.408437 47042231382912 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpp64xvou5
I0618 10:11:00.409428 47780306297728 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp5f83mexm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7500c55dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:00.409476 47042231382912 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpp64xvou5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac92813fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:00.409839 47780306297728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:11:00.409877 47042231382912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:11:00.415021 47780306297728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:00.415044 47042231382912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:00.417519 47762997724032 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:11:00.418083 47693098369920 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874260.368133 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874260.368579 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874260.368974 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:00.422828 47133621986176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560874260.369041 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874260.369480 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874260.369852 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:00.422876 47875662906240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_0_0
I0618 10:11:00.423848 47133621986176 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ade6f61fcf8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:11:00.423871 47875662906240 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpq5gdhj18
I0618 10:11:00.424827 47875662906240 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpq5gdhj18', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8b3477ce80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:00.424956 47133621986176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:11:00.425235 47875662906240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874260.371142 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874260.371654 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874260.372188 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:00.425851 47966219154304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 10:11:00.426838 47966219154304 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpfqysiop1
I0618 10:11:00.427807 47966219154304 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpfqysiop1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba04a0a8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:00.428208 47966219154304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:11:00.429629 47133621986176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:00.429810 47875662906240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874260.377188 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874260.377636 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874260.378031 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:00.429701 47467821470592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 10:11:00.430680 47467821470592 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpj8zxwq_o
I0618 10:11:00.431644 47467821470592 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpj8zxwq_o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2c3f396e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:00.432103 47467821470592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:11:00.432979 47966219154304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:00.434405 47042231382912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:11:00.434481 47780306297728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874260.332213 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874260.333100 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874260.333858 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:00.435095 47978950263680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560874260.332569 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874260.333423 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874260.334233 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:00.435147 47116105950080 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 10:11:00.436725 47467821470592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:00.436225 47978950263680 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpw31i1_rx
W0618 10:11:00.436257 47116105950080 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp_7tis56z
I0618 10:11:00.437349 47116105950080 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp_7tis56z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ada5b586e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:00.437352 47978950263680 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpw31i1_rx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba340dfce80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:00.437788 47116105950080 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:11:00.437800 47978950263680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:11:00.439398 47915153994624 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:11:00.441158 47614077985664 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:11:00.443763 47915153994624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:11:00.443057 47116105950080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:00.443103 47978950263680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:00.445474 47614077985664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560874260.353005 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874260.353958 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874260.354837 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:00.444178 47572882875264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560874260.383479 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874260.383885 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874260.384248 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:00.444419 47888298263424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560874260.361602 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874260.362379 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874260.363092 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:00.444189 46916151944064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560874260.383743 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874260.384144 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874260.384470 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:00.444437 47074562773888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 10:11:00.445454 47888298263424 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmptesjsl0_
W0618 10:11:00.445428 47074562773888 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpkt1vst_0
W0618 10:11:00.448019 47940613436288 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:11:00.445278 47572882875264 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpg_l3ktsc
W0618 10:11:00.445246 46916151944064 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp9xegyasj
I0618 10:11:00.446425 47074562773888 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpkt1vst_0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad0af2dee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:00.446441 47888298263424 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmptesjsl0_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8e25981e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:00.446346 46916151944064 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp9xegyasj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aabcd286e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:00.446375 47572882875264 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpg_l3ktsc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b44b55f3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:00.446826 47074562773888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:11:00.446839 47888298263424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:11:00.446738 46916151944064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:11:00.448781 47961845564288 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:11:00.446788 47572882875264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:11:00.448898 47915153994624 estimator.py:1111] Calling model_fn.
W0618 10:11:00.448913 47133621986176 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:11:00.449004 47915153994624 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:11:00.449181 47875662906240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:11:00.450363 47915153994624 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:11:00.450578 47614077985664 estimator.py:1111] Calling model_fn.
W0618 10:11:00.450684 47614077985664 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:11:00.452030 47614077985664 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:11:00.452309 47940613436288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:11:00.452363 47966219154304 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:11:00.453123 47961845564288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:11:00.451484 47888298263424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:00.451475 47074562773888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:00.451534 47572882875264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:00.451551 46916151944064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:00.456144 47467821470592 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:11:00.457404 47940613436288 estimator.py:1111] Calling model_fn.
W0618 10:11:00.457513 47940613436288 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:11:00.458240 47961845564288 estimator.py:1111] Calling model_fn.
W0618 10:11:00.458353 47961845564288 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:11:00.458863 47940613436288 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:11:00.459714 47961845564288 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560874260.382169 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874260.382561 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874260.382918 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:00.464043 47454077191040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560874260.380521 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874260.380926 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874260.381273 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:00.464138 47891738731392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 10:11:00.464783 47116105950080 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:11:00.464947 47978950263680 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:11:00.465055 47454077191040 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp4i8lq8tc
W0618 10:11:00.465114 47891738731392 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpdyghvqdq
I0618 10:11:00.466073 47454077191040 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp4i8lq8tc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b290c004e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:00.466111 47891738731392 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpdyghvqdq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8ef2a97e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:00.466488 47454077191040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:11:00.466528 47891738731392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:11:00.466683 47762997724032 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:11:00.467394 47693098369920 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:11:00.471242 47454077191040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:00.471253 47891738731392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:00.470712 47888298263424 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:11:00.470951 47762997724032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:11:00.470952 47074562773888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:11:00.471362 47572882875264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:11:00.471355 46916151944064 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:11:00.471709 47693098369920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:11:00.475981 47762997724032 estimator.py:1111] Calling model_fn.
W0618 10:11:00.476091 47762997724032 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:11:00.476850 47693098369920 estimator.py:1111] Calling model_fn.
W0618 10:11:00.476959 47693098369920 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:11:00.477426 47762997724032 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:11:00.478340 47693098369920 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560874260.424809 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874260.425215 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874260.425563 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:00.479351 47665859355520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560874260.426728 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874260.427135 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874260.427500 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:00.480191 47870871016320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 10:11:00.480366 47665859355520 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp40y9y13e
I0618 10:11:00.481345 47665859355520 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp40y9y13e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5a5b33be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:00.481751 47665859355520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:11:00.481165 47870871016320 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpb3v36azm
I0618 10:11:00.482130 47870871016320 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpb3v36azm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8a16d96e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:00.482523 47870871016320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:11:00.482725 47042231382912 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It[2019-06-18 10:11:41] divide_golden_chunk finished: 3.280 seconds
[2019-06-18 10:11:41] generate golden chunk: 3.294 seconds
[2019-06-18 10:11:41] moving /lfs/lfs12/gma_akey/results/epb312/models/000012-000007.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb312/models/000012-000008.data-00000-of-00001
[2019-06-18 10:11:41] moving /lfs/lfs12/gma_akey/results/epb312/models/000012-000007.meta --> /lfs/lfs12/gma_akey/results/epb312/models/000012-000008.meta
[2019-06-18 10:11:41] moving /lfs/lfs12/gma_akey/results/epb312/models/000012-000007.index --> /lfs/lfs12/gma_akey/results/epb312/models/000012-000008.index
[2019-06-18 10:11:41] moving /lfs/lfs12/gma_akey/results/epb312/models/000012-000007.pb --> /lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb
[2019-06-18 10:11:41] iteration time 11: 50.209 seconds
2019-06-18 10:11:41.881745: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874301.079151 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 12}}
[2019-06-18 10:11:45] minmax time: 3.333 seconds
2019-06-18 10:11:45.224746: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:11:45.230170: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:11:45.234860: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874305.245852 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 11}}
[2019-06-18 10:11:45] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000013-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000013-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000013-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000013-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000013-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000013-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000013-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000013-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000013-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000013-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000013-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:11:45] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-13-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000012-000008 --seed=13 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000012-000008 --seed=1023779844 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000012-000008 --seed=2047559675 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000012-000008 --seed=3071339506 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000012-000008 --seed=4095119337 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000012-000008 --seed=5118899168 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000012-000008 --seed=6142678999 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000012-000008 --seed=7166458830 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000012-000008 --seed=8190238661 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000012-000008 --seed=9214018492 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000012-000008 --seed=10237798323 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000012-000008 --seed=11261578154 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000012-000008 --seed=12285357985 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000012-000008 --seed=13309137816 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000012-000008 --seed=14332917647 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000012-000008 --seed=15356697478 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000012-000008 --seed=16380477309 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000012-000008 --seed=17404257140 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000012-000008 --seed=18428036971 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000012-000008 --seed=19451816802 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000012-000008 --seed=20475596633 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:11:57] eval finished: 12.288 seconds
[2019-06-18 10:11:57] Win rate 000012-000008 vs 000011-000007: 0.610
:::MLL 1560874317.597066 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 11}}
[2019-06-18 10:11:57] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-14-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000013-000007 --seed=14 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000013-000007 --seed=1023779845 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000013-000007 --seed=2047559676 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000013-000007 --seed=3071339507 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000013-000007 --seed=4095119338 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000013-000007 --seed=5118899169 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000013-000007 --seed=6142679000 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000013-000007 --seed=7166458831 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000013-000007 --seed=8190238662 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000013-000007 --seed=9214018493 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000013-000007 --seed=10237798324 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000013-000007 --seed=11261578155 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000013-000007 --seed=12285357986 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000013-000007 --seed=13309137817 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000013-000007 --seed=14332917648 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000013-000007 --seed=15356697479 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000013-000007 --seed=16380477310 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000013-000007 --seed=17404257141 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000013-000007 --seed=18428036972 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:12:27] selfplay finished: 29.888 seconds
[2019-06-18 10:12:27] selfplay mn: 29.905 seconds
[2019-06-18 10:12:27] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-14-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779845 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559676 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339507 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119338 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899169 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142679000 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458831 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238662 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018493 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798324 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578155 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285357986 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137817 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917648 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697479 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477310 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257141 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036972 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816803 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596634 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376465 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156296 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golde
[2019-06-18 10:12:28] train finished: 43.722 seconds
:::MLL 1560874310.512779 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874310.513537 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874310.514246 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:50.585366 47729673073536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560874310.500247 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874310.501094 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874310.501896 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:50.586502 47932191490944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 10:11:50.586421 47729673073536 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmppp1iarcz
I0618 10:11:50.587438 47729673073536 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmppp1iarcz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6936cbce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:50.587842 47729673073536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:11:50.587471 47932191490944 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp15xt0tfv
I0618 10:11:50.588479 47932191490944 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp15xt0tfv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b985dd59e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:50.588874 47932191490944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:11:50.592893 47729673073536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:50.594064 47932191490944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:50.612353 47729673073536 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:11:50.614770 47932191490944 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874310.534885 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874310.535685 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874310.536419 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:50.619703 47175489090432 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560874310.536310 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874310.537063 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874310.537767 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:50.619762 47868861916032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 10:11:50.620783 47175489090432 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpvng31kne
W0618 10:11:50.620810 47868861916032 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpc2xudlk3
I0618 10:11:50.621848 47175489090432 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpvng31kne', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae82edb3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:50.621879 47868861916032 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpc2xudlk3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b899f18fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:50.622283 47175489090432 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:11:50.622300 47868861916032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:11:50.627508 47175489090432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:50.627524 47868861916032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874310.538692 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874310.539447 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874310.540110 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:50.631494 46919046964096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560874310.541743 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874310.542471 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874310.543161 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:50.631760 47163620733824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 10:11:50.632529 46919046964096 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp0gs7t_2e
W0618 10:11:50.632703 47163620733824 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpzti3wcp9
I0618 10:11:50.633511 46919046964096 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp0gs7t_2e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aac79b6fe80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:50.633684 47163620733824 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpzti3wcp9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae56b727e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:50.633901 46919046964096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:11:50.634081 47163620733824 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:11:50.638756 46919046964096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:50.638841 47163620733824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874310.562900 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874310.563626 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874310.564369 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:50.645480 47810873967488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560874310.558448 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874310.559375 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874310.560175 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:50.645519 47044149928832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 10:11:50.646490 47044149928832 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpvt_8nse7
W0618 10:11:50.646521 47810873967488 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpp_0slpu1
I0618 10:11:50.647501 47044149928832 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpvt_8nse7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac99a6eae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:50.647516 47810873967488 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpp_0slpu1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7c1ebf1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:50.647902 47044149928832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:11:50.647929 47810873967488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:11:50.649588 47175489090432 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:11:50.649774 47868861916032 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:11:50.652879 47044149928832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:50.652902 47810873967488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:50.658570 47163620733824 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:11:50.658654 46919046964096 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874310.603005 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874310.603439 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874310.603823 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:50.659987 47004547031936 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 10:11:50.660353 47729673073536 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:11:50.661073 47004547031936 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpz15mv9bb
I0618 10:11:50.662180 47004547031936 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpz15mv9bb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac061ea7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560874310.580529 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874310.581275 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874310.581969 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:50.660201 47653035275136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560874310.578773 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874310.579556 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874310.580369 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:50.660182 47133684757376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_0_0
I0618 10:11:50.662616 47004547031936 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874310.609039 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874310.609475 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874310.609872 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:50.663749 47752984769408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 10:11:50.661268 47133684757376 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp7trqbel1
W0618 10:11:50.661299 47653035275136 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmptrdjquyu
I0618 10:11:50.662392 47653035275136 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmptrdjquyu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b575ed3be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:50.662387 47133684757376 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp7trqbel1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ade731f9e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:11:50.664683 47729673073536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:11:50.662829 47653035275136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:11:50.662831 47133684757376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:11:50.664711 47752984769408 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpt22av41e
W0618 10:11:50.665481 47932191490944 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:11:50.665678 47752984769408 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpt22av41e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6ea447fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:50.666074 47752984769408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:11:50.667379 47004547031936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:11:50.669806 47729673073536 estimator.py:1111] Calling model_fn.
W0618 10:11:50.667849 47653035275136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:50.667837 47133684757376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:50.669922 47729673073536 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:11:50.670075 47932191490944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:11:50.670614 47752984769408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:50.671282 47729673073536 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560874310.562515 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874310.563415 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874310.564267 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:50.670806 47923552764800 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560874310.570542 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874310.571320 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874310.572027 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:50.670876 47909376590720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 10:11:50.671905 47923552764800 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp4feizrl2
W0618 10:11:50.671950 47909376590720 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpw8ynuedf
W0618 10:11:50.672548 47810873967488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:11:50.672991 47923552764800 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp4feizrl2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b965aed1e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:50.673043 47909376590720 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpw8ynuedf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b930df5de80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:11:50.672807 47044149928832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:11:50.673438 47923552764800 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:11:50.673498 47909376590720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:11:50.675615 47932191490944 estimator.py:1111] Calling model_fn.
W0618 10:11:50.675734 47932191490944 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:11:50.677352 47932191490944 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560874310.621987 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874310.622494 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874310.622865 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:50.679255 47386389955456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 10:11:50.678805 47909376590720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:50.678815 47923552764800 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874310.623674 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874310.624088 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874310.624441 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:50.679439 47949495034752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 10:11:50.680267 47386389955456 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp8dd70sc3
I0618 10:11:50.680466 47949495034752 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9c6534bd68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:50.681222 47386389955456 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp8dd70sc3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1949871e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:50.681582 47949495034752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:11:50.681617 47386389955456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874310.627236 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874310.627620 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874310.627943 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:50.684074 47099742643072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 10:11:50.686394 47949495034752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:50.686396 47386389955456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:50.686774 47004547031936 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:11:50.685077 47099742643072 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp7t1lwnka
I0618 10:11:50.686052 47099742643072 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp7t1lwnka', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad68c042e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560874310.628552 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874310.628935 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874310.629342 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:50.686289 47282906534784 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_0_0
I0618 10:11:50.686448 47099742643072 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:11:50.687577 47653035275136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:11:50.687630 47133684757376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:11:50.687220 47282906534784 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpihs837zp
I0618 10:11:50.688228 47282906534784 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpihs837zp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b01316f6e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:11:50.690061 47752984769408 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:11:50.688670 47282906534784 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:11:50.691244 47099742643072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:50.693717 47282906534784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:50.700917 47909376590720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:11:50.700938 47923552764800 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:11:50.701460 47175489090432 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560874310.616272 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874310.616773 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874310.617213 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:50.702684 47332588565376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560874310.620388 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874310.620834 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874310.621201 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:50.702987 47918545662848 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 10:11:50.701986 47868861916032 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:11:50.703672 47332588565376 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp_hlgtzpq
W0618 10:11:50.703945 47918545662848 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpl7a683_r
I0618 10:11:50.704636 47332588565376 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp_hlgtzpq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0cc2b70e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:50.704908 47918545662848 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpl7a683_r', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b95307ace10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:50.705037 47332588565376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:11:50.705741 47386389955456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:11:50.705797 47949495034752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:11:50.705303 47918545662848 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:11:50.706444 46919046964096 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:11:50.706927 47163620733824 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560874310.647823 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874310.648234 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874310.648583 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:50.705053 47629656728448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560874310.647001 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874310.647422 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874310.647828 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:50.705227 47129185997696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 10:11:50.705728 47175489090432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:11:50.706301 47868861916032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:11:50.706062 47629656728448 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpp9j4fgiw
W0618 10:11:50.706213 47129185997696 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp6_n8bv0s
I0618 10:11:50.707045 47629656728448 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpp9j4fgiw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b51ed5b7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:11:50.707180 47129185997696 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp6_n8bv0s', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2add66fa2e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560874310.651368 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874310.651881 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874310.652263 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:50.708330 47424826819456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_0_0
I0618 10:11:50.707447 47629656728448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:11:50.707568 47129185997696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:11:50.709656 47332588565376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:50.709937 47918545662848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:11:50.710752 46919046964096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560874310.654587 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874310.655031 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874310.655426 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:11:50.709755 47513953067904 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 10:11:50.709308 47424826819456 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpszfq90wo
I0618 10:11:50.710283 47424826819456 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpszfq90wo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b223c8b0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:11:50.711262 47163620733824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:11:50.710683 47424826819456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:11:50.710728 47513953067904 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmppbeokm2t
I0618 10:11:50.711679 47513953067904 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmppbeokm2t', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b36fce1ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:11:50.710648 47099742643072 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:11:50.710810 47175489090432 estimator.py:1111] Calling model_fn.
W0618 10:11:50.710923 47175489090432 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:11:50.712079 47513953067904 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:11:50.711361 47868861916032 estimator.py:1111] Calling model_fn.
W0618 10:11:50.711470 47868861916032 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:11:50.712279 47175489090432 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a[2019-06-18 10:12:30] divide_golden_chunk finished: 3.410 seconds
[2019-06-18 10:12:30] generate golden chunk: 3.424 seconds
[2019-06-18 10:12:30] moving /lfs/lfs12/gma_akey/results/epb312/models/000013-000008.index --> /lfs/lfs12/gma_akey/results/epb312/models/000013-000009.index
[2019-06-18 10:12:30] moving /lfs/lfs12/gma_akey/results/epb312/models/000013-000008.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb312/models/000013-000009.data-00000-of-00001
[2019-06-18 10:12:30] moving /lfs/lfs12/gma_akey/results/epb312/models/000013-000008.pb --> /lfs/lfs12/gma_akey/results/epb312/models/000013-000009.pb
[2019-06-18 10:12:30] moving /lfs/lfs12/gma_akey/results/epb312/models/000013-000008.meta --> /lfs/lfs12/gma_akey/results/epb312/models/000013-000009.meta
[2019-06-18 10:12:30] iteration time 12: 49.889 seconds
2019-06-18 10:12:31.811119: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874350.968190 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 13}}
[2019-06-18 10:12:35] minmax time: 3.238 seconds
2019-06-18 10:12:35.058905: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:12:35.064161: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:12:35.068719: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874355.079872 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 12}}
[2019-06-18 10:12:35] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000014-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000014-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000014-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000014-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000014-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000014-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000014-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000014-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000014-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000014-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000014-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:12:35] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-14-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000013-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000013-000009 --seed=14 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000013-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000013-000009 --seed=1023779845 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000013-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000013-000009 --seed=2047559676 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000013-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000013-000009 --seed=3071339507 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000013-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000013-000009 --seed=4095119338 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000013-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000013-000009 --seed=5118899169 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000013-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000013-000009 --seed=6142679000 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000013-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000013-000009 --seed=7166458831 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000013-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000013-000009 --seed=8190238662 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000013-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000013-000009 --seed=9214018493 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000013-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000013-000009 --seed=10237798324 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000013-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000013-000009 --seed=11261578155 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000013-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000013-000009 --seed=12285357986 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000013-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000013-000009 --seed=13309137817 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000013-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000013-000009 --seed=14332917648 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000013-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000013-000009 --seed=15356697479 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000013-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000013-000009 --seed=16380477310 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000013-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000013-000009 --seed=17404257141 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000013-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000013-000009 --seed=18428036972 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000013-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000013-000009 --seed=19451816803 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000013-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000013-000009 --seed=20475596634 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:12:47] eval finished: 12.464 seconds
[2019-06-18 10:12:47] Win rate 000013-000009 vs 000012-000008: 0.390
:::MLL 1560874367.601814 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 12}}
[2019-06-18 10:12:47] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-15-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000014-000008 --seed=15 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000014-000008 --seed=1023779846 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000014-000008 --seed=2047559677 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000014-000008 --seed=3071339508 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000014-000008 --seed=4095119339 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000014-000008 --seed=5118899170 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000014-000008 --seed=6142679001 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000014-000008 --seed=7166458832 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000014-000008 --seed=8190238663 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000014-000008 --seed=9214018494 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000014-000008 --seed=10237798325 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000014-000008 --seed=11261578156 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000014-000008 --seed=12285357987 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000014-000008 --seed=13309137818 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000014-000008 --seed=14332917649 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000014-000008 --seed=15356697480 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000014-000008 --seed=16380477311 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000014-000008 --seed=17404257142 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000014-000008 --seed=18428036973 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:13:18] selfplay finished: 30.447 seconds
[2019-06-18 10:13:18] selfplay mn: 30.467 seconds
[2019-06-18 10:13:18] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-15-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779846 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559677 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339508 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119339 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899170 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142679001 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458832 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238663 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018494 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798325 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578156 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285357987 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137818 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917649 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697480 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477311 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257142 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036973 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816804 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596635 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376466 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156297 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000014-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golde
[2019-06-18 10:13:18] train finished: 43.645 seconds
:::MLL 1560874360.296751 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874360.297525 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874360.298202 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:40.384008 47223653450624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560874360.295446 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874360.296274 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874360.297058 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:40.384252 47499522290560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 10:12:40.385015 47223653450624 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpz3ksau9y
W0618 10:12:40.385246 47499522290560 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpqbzx68ht
I0618 10:12:40.386012 47223653450624 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpz3ksau9y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af365ad1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:40.386255 47499522290560 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpqbzx68ht', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b33a0bd8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:40.386408 47223653450624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:12:40.386658 47499522290560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:12:40.391387 47223653450624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:40.391562 47499522290560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:40.410674 47223653450624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:40.411150 47499522290560 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874360.329298 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874360.330062 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874360.330715 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:40.415286 47974000698240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560874360.331609 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874360.332355 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874360.333053 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:40.415304 47707777614720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 10:12:40.416478 47974000698240 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp5wo7t_k7
W0618 10:12:40.416455 47707777614720 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpzseytlos
I0618 10:12:40.417458 47707777614720 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpzseytlos', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b641db98e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:40.417471 47974000698240 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp5wo7t_k7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba219db6e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:40.417855 47707777614720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:12:40.417865 47974000698240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:12:40.422813 47974000698240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:40.422809 47707777614720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874360.356350 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874360.357007 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874360.357637 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:40.438527 47943609045888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560874360.348833 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874360.349752 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874360.350568 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:40.438797 47570952844160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 10:12:40.439550 47943609045888 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpkf_cyr6c
W0618 10:12:40.442355 47707777614720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:40.439778 47570952844160 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpurq5f9qg
W0618 10:12:40.442468 47974000698240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:12:40.440552 47943609045888 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpkf_cyr6c', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9b065fae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:40.440764 47570952844160 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpurq5f9qg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4442554da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:40.440952 47943609045888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:12:40.441159 47570952844160 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:12:40.445805 47943609045888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:40.445814 47570952844160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874360.350065 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874360.350830 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874360.351617 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:40.449949 47138071704448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560874360.351482 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874360.352210 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874360.352890 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:40.450110 47100060902272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 10:12:40.451072 47138071704448 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpz341itm8
W0618 10:12:40.451208 47100060902272 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpjniahqe3
I0618 10:12:40.452161 47138071704448 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpz341itm8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adf789b4e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:40.452296 47100060902272 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpjniahqe3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad69efc7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:40.452604 47138071704448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:12:40.452741 47100060902272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874360.398387 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874360.398823 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874360.399213 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:40.455234 47734416720768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 10:12:40.456332 47734416720768 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp97nmzmns
I0618 10:12:40.457436 47734416720768 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp97nmzmns', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6a518a1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:40.457879 47734416720768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:12:40.458986 47223653450624 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:12:40.459820 47499522290560 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:12:40.457942 47138071704448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:40.458008 47100060902272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:40.462598 47734416720768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:40.463319 47223653450624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560874360.401878 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874360.402327 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874360.402707 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:40.463513 47619060425600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 10:12:40.464152 47499522290560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:12:40.464499 47619060425600 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpwpewrt3b
I0618 10:12:40.465465 47619060425600 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpwpewrt3b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4f75c4be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:40.465860 47619060425600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:12:40.465579 47943609045888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:40.465558 47570952844160 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874360.405782 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874360.406251 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874360.406643 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:40.467728 47331277321088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_0_0
I0618 10:12:40.468393 47223653450624 estimator.py:1111] Calling model_fn.
W0618 10:12:40.468501 47223653450624 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:12:40.469190 47499522290560 estimator.py:1111] Calling model_fn.
W0618 10:12:40.469297 47499522290560 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:12:40.468822 47331277321088 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0c748f0d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:12:40.469924 47223653450624 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:12:40.470014 47331277321088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:12:40.470387 47619060425600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:40.470649 47499522290560 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:12:40.474742 47331277321088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874360.405560 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874360.406018 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874360.406436 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:40.475486 47495068763008 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 10:12:40.476485 47495068763008 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpe2qygowk
I0618 10:12:40.477447 47495068763008 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpe2qygowk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b32974a1e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:40.477841 47495068763008 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:12:40.480155 47138071704448 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:40.482022 47734416720768 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:40.480506 47100060902272 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:40.482415 47495068763008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:40.489742 47619060425600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874360.409574 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874360.410355 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874360.411078 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:40.489474 47949636916096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560874360.399890 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874360.400858 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874360.401775 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:40.489664 47180420219776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 10:12:40.490454 47974000698240 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:12:40.490542 47707777614720 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560874360.430620 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874360.431116 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874360.431573 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:40.489739 46954961855360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 10:12:40.490633 47949636916096 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp92z0mojc
W0618 10:12:40.490746 47180420219776 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp4yahe375
I0618 10:12:40.491749 47949636916096 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp92z0mojc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9c6da9ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:40.491866 47180420219776 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp4yahe375', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae954c65e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:40.492239 47949636916096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:12:40.492306 47180420219776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:12:40.490720 46954961855360 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp6gyr92j8
I0618 10:12:40.491684 46954961855360 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp6gyr92j8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab4d668be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:40.492082 46954961855360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:12:40.494342 47331277321088 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:40.494760 47974000698240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:12:40.494857 47707777614720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560874360.438702 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874360.439161 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874360.439549 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:40.493633 47956951827328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 10:12:40.494589 47956951827328 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp_4akkplp
:::MLL 1560874360.404084 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874360.404944 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874360.405827 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:40.495975 47677598946176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560874360.410868 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874360.411623 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874360.412323 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:40.496084 47188345668480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_0_0
I0618 10:12:40.495553 47956951827328 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp_4akkplp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9e21aa5da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:40.495948 47956951827328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:12:40.497664 47949636916096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:40.497659 47180420219776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:40.496702 46954961855360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:40.496970 47677598946176 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp35r7k4q3
W0618 10:12:40.497059 47188345668480 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmprvhli77x
I0618 10:12:40.497963 47677598946176 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp35r7k4q3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5d16efadd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:40.498046 47188345668480 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmprvhli77x', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeb2d2b1dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:40.498360 47677598946176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:12:40.498444 47188345668480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:12:40.499803 47974000698240 estimator.py:1111] Calling model_fn.
W0618 10:12:40.499912 47974000698240 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:12:40.499936 47707777614720 estimator.py:1111] Calling model_fn.
W0618 10:12:40.500046 47707777614720 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:12:40.501276 47974000698240 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:12:40.501399 47707777614720 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:12:40.501663 47495068763008 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:40.500474 47956951827328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874360.441767 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874360.442222 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874360.442608 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:40.501024 47875212395392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 10:12:40.503183 47677598946176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:40.503283 47188345668480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:40.502037 47875212395392 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpsx6mc0p2
I0618 10:12:40.503017 47875212395392 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpsx6mc0p2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8b199d9da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560874360.445295 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874360.445730 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874360.446127 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:40.503241 47533180777344 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_0_0
I0618 10:12:40.503412 47875212395392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:12:40.504193 47533180777344 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpde0vhqyu
I0618 10:12:40.505157 47533180777344 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpde0vhqyu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3b76f14e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:40.505546 47533180777344 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:12:40.508174 47875212395392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:40.510109 47533180777344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:40.514269 47943609045888 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:12:40.514225 47570952844160 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:12:40.516098 46954961855360 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:40.519708 47949636916096 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:40.519740 47180420219776 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:40.518561 47570952844160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:12:40.518617 47943609045888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:12:40.519864 47956951827328 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:40.523096 47677598946176 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:40.523153 47188345668480 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:12:40.523628 47570952844160 estimator.py:1111] Calling model_fn.
I0618 10:12:40.523720 47943609045888 estimator.py:1111] Calling model_fn.
W0618 10:12:40.523746 47570952844160 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:12:40.523832 47943609045888 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:12:40.525099 47570952844160 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:12:40.525199 47943609045888 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:12:40.529221 47734416720768 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:12:40.527723 47875212395392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874360.463667 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874360.464073 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874360.464432 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:40.529444 47964804387712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560874360.461040 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874360.461468 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874360.461834 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:40.529652 47898376999808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 10:12:40.528591 47100060902272 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:12:40.528739 47138071704448 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful arg[2019-06-18 10:13:21] divide_golden_chunk finished: 3.339 seconds
[2019-06-18 10:13:21] generate golden chunk: 3.354 seconds
[2019-06-18 10:13:21] iteration time 13: 50.456 seconds
2019-06-18 10:13:22.305802: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874401.424477 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 14}}
[2019-06-18 10:13:25] minmax time: 3.304 seconds
2019-06-18 10:13:25.620120: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:13:25.625478: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:13:25.629900: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874405.642538 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 13}}
[2019-06-18 10:13:25] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000015-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000015-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000015-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000015-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000015-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000015-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000015-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000015-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000015-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000015-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000015-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:13:25] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-15-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000014-000009 --seed=15 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000014-000009 --seed=1023779846 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000014-000009 --seed=2047559677 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000014-000009 --seed=3071339508 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000014-000009 --seed=4095119339 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000014-000009 --seed=5118899170 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000014-000009 --seed=6142679001 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000014-000009 --seed=7166458832 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000014-000009 --seed=8190238663 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000014-000009 --seed=9214018494 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000014-000009 --seed=10237798325 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000014-000009 --seed=11261578156 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000014-000009 --seed=12285357987 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000014-000009 --seed=13309137818 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000014-000009 --seed=14332917649 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000014-000009 --seed=15356697480 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000014-000009 --seed=16380477311 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000014-000009 --seed=17404257142 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000014-000009 --seed=18428036973 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000014-000009 --seed=19451816804 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000014-000009 --seed=20475596635 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:13:38] eval finished: 12.584 seconds
[2019-06-18 10:13:38] Win rate 000014-000009 vs 000012-000008: 0.350
:::MLL 1560874418.288819 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 13}}
[2019-06-18 10:13:38] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-16-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000015-000008 --seed=16 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000015-000008 --seed=1023779847 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000015-000008 --seed=2047559678 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000015-000008 --seed=3071339509 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000015-000008 --seed=4095119340 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000015-000008 --seed=5118899171 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000015-000008 --seed=6142679002 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000015-000008 --seed=7166458833 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000015-000008 --seed=8190238664 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000015-000008 --seed=9214018495 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000015-000008 --seed=10237798326 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000015-000008 --seed=11261578157 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000015-000008 --seed=12285357988 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000015-000008 --seed=13309137819 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000015-000008 --seed=14332917650 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000015-000008 --seed=15356697481 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000015-000008 --seed=16380477312 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000015-000008 --seed=17404257143 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000015-000008 --seed=18428036974 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:14:08] selfplay finished: 30.272 seconds
[2019-06-18 10:14:08] selfplay mn: 30.292 seconds
[2019-06-18 10:14:08] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-16-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779847 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559678 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339509 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119340 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899171 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142679002 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458833 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238664 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018495 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798326 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578157 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285357988 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137819 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917650 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697481 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477312 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257143 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036974 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816805 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596636 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376467 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156298 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golde
[2019-06-18 10:14:09] train finished: 43.542 seconds
:::MLL 1560874410.847198 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874410.848071 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874410.848859 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:30.934438 47117072823168 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560874410.857947 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874410.858634 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874410.859287 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:30.934475 47910844679040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 10:13:30.935469 47117072823168 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpxfju7yhv
W0618 10:13:30.935498 47910844679040 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpfeofzub3
I0618 10:13:30.936516 47117072823168 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpxfju7yhv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ada94f9ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:30.936527 47910844679040 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpfeofzub3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9365771e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:30.936932 47910844679040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:13:30.936937 47117072823168 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:13:30.941934 47117072823168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:30.941989 47910844679040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:30.961165 47117072823168 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:13:30.961482 47910844679040 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874410.902882 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874410.903640 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874410.904306 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:30.988814 47651498853248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560874410.906056 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874410.906776 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874410.907454 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:30.988863 47098233353088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 10:13:30.989976 47098233353088 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpoiz2fv27
W0618 10:13:30.989942 47651498853248 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpg7ogpwjs
I0618 10:13:30.991006 47651498853248 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpg7ogpwjs', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b57033fde80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:30.991021 47098233353088 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpoiz2fv27', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad6320e3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:30.991405 47651498853248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:13:30.991440 47098233353088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:13:30.996292 47651498853248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:30.996302 47098233353088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:31.008389 47117072823168 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:13:31.010609 47910844679040 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:13:31.012650 47117072823168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:13:31.014964 47910844679040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:13:31.015961 47098233353088 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:13:31.016020 47651498853248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:13:31.017700 47117072823168 estimator.py:1111] Calling model_fn.
W0618 10:13:31.017807 47117072823168 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560874410.926460 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874410.927406 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874410.928264 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:31.016208 47415012643712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560874410.931100 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874410.931864 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874410.932544 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:31.016482 47118034686848 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560874410.954785 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874410.955174 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874410.955522 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:31.019057 47529896309632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 10:13:31.019165 47117072823168 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560874410.955642 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874410.956032 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874410.956354 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:31.019096 47154911466368 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 10:13:31.017313 47415012643712 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp2odfq6lg
I0618 10:13:31.020062 47910844679040 estimator.py:1111] Calling model_fn.
W0618 10:13:31.017525 47118034686848 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmprq9oswvc
W0618 10:13:31.020172 47910844679040 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:13:31.018404 47415012643712 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp2odfq6lg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1ff392ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:31.018611 47118034686848 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmprq9oswvc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adace4e9e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:31.018845 47415012643712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:13:31.020087 47154911466368 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp5845hc3o
I0618 10:13:31.019058 47118034686848 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:13:31.020048 47529896309632 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp9mfpwsio
I0618 10:13:31.021064 47529896309632 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp9mfpwsio', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3ab32c3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:31.021093 47154911466368 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp5845hc3o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae364559dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:31.021491 47529896309632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:13:31.021520 47154911466368 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:13:31.021533 47910844679040 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:13:31.024161 47415012643712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:31.024200 47118034686848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:31.026219 47154911466368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:31.026242 47529896309632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874410.943001 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874410.943764 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874410.944427 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:31.028940 47085251670912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560874410.939229 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874410.940108 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874410.940786 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:31.029005 47519145354112 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 10:13:31.029949 47085251670912 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmporqx0bh0
W0618 10:13:31.029993 47519145354112 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp8sfqi0hb
I0618 10:13:31.030947 47085251670912 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmporqx0bh0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad32c496e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:31.030981 47519145354112 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp8sfqi0hb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b38325dbe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:31.031346 47085251670912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:13:31.031377 47519145354112 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:13:31.036289 47085251670912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:31.036333 47519145354112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874410.977658 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874410.978117 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874410.978498 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:31.039776 47469316129664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560874410.977584 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874410.978040 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874410.978426 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:31.039974 47293355840384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_0_0
I0618 10:13:31.040781 47469316129664 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2c98501d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:13:31.040958 47293355840384 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmps92d4a6w
I0618 10:13:31.041895 47469316129664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:13:31.041937 47293355840384 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmps92d4a6w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b03a0432e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:31.042332 47293355840384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:13:31.045381 47154911466368 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:13:31.045641 47529896309632 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:13:31.046577 47469316129664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:31.046934 47293355840384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:31.046375 47415012643712 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:13:31.046388 47118034686848 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874410.959266 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874410.960084 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874410.960844 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:31.047259 47103300395904 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560874410.961364 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874410.962059 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874410.962806 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:31.047372 47943995888512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 10:13:31.048326 47943995888512 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpdi9pov87
W0618 10:13:31.048297 47103300395904 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp932_8vr6
:::MLL 1560874410.968222 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874410.969018 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874410.969682 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:31.049276 46935668966272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560874410.958763 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874410.959708 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874410.960575 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:31.049325 47283776193408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_0_0
I0618 10:13:31.049358 47103300395904 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp932_8vr6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad760133e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:31.049383 47943995888512 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpdi9pov87', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9b1d6e5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:31.049787 47103300395904 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:13:31.049823 47943995888512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:13:31.050378 46935668966272 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpv4yuphnq
W0618 10:13:31.050409 47283776193408 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmptuhn9bkn
I0618 10:13:31.051481 46935668966272 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpv4yuphnq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab058769e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:31.051516 47283776193408 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmptuhn9bkn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0165455e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:31.051951 46935668966272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:13:31.051985 47283776193408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:13:31.054702 47103300395904 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:31.054717 47943995888512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:31.055584 47085251670912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:13:31.055858 47519145354112 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:13:31.057270 47283776193408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:31.057283 46935668966272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:31.064307 47651498853248 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:13:31.064399 47098233353088 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:13:31.065763 47469316129664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:13:31.066224 47293355840384 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:13:31.068608 47651498853248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:13:31.068703 47098233353088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560874411.005889 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874411.006352 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874411.006676 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:31.066823 47852540478336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 10:13:31.067869 47852540478336 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpt4ukf7ua
:::MLL 1560874411.008864 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874411.009341 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874411.009717 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:31.068468 47583328539520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_0_0
I0618 10:13:31.068867 47852540478336 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpt4ukf7ua', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b85d2439e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:31.069275 47852540478336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:13:31.069446 47583328539520 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpe1xxsedo
I0618 10:13:31.070413 47583328539520 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpe1xxsedo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4723fb5e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:31.070808 47583328539520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:13:31.073662 47651498853248 estimator.py:1111] Calling model_fn.
W0618 10:13:31.073771 47651498853248 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:13:31.073786 47098233353088 estimator.py:1111] Calling model_fn.
W0618 10:13:31.073897 47098233353088 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:13:31.075134 47651498853248 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:13:31.075282 47098233353088 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:13:31.074364 47943995888512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:13:31.074366 47103300395904 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:13:31.073942 47852540478336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:31.075360 47583328539520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:31.079460 47283776193408 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:13:31.079509 46935668966272 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874411.019841 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874411.020298 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874411.020697 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:31.081761 47624805647232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560874411.019932 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874411.020389 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874411.020795 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:31.081988 47714559468416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 10:13:31.082824 47624805647232 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp_rvr9v1x
W0618 10:13:31.083023 47714559468416 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmprhlfh5p6
I0618 10:13:31.083856 47624805647232 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp_rvr9v1x', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b50cc35de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:31.084033 47714559468416 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmprhlfh5p6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b65b1f47da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:31.084254 47624805647232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:13:31.084428 47714559468416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874411.018007 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874411.018415 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874411.018778 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:31.089327 47797913846656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560874411.014938 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874411.015432 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874411.015773 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:31.089357 47196478587776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 10:13:31.088903 47624805647232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:31.089035 47714559468416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:31.090398 47797913846656 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpseto2971
W0618 10:13:31.090370 47196478587776 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpjj0eia40
I0618 10:13:31.091347 47196478587776 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpjj0eia40', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aed11ed8e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:31.091375 47797913846656 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpseto2971', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b791a435e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:31.091743 47196478587776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:13:31.091776 47797913846656 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:13:31.092558 47154911466368 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:13:31.093447 47529896309632 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:13:31.093290 47852540478336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:13:31.094570 47583328539520 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:13:31.096831 47154911466368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:13:31.096436 47196478587776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:31.096445 47797913846656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:31.095716 47415012643712 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:13:31.095904 47118034686848 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:13:31.097802 47529896309632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using [2019-06-18 10:14:11] divide_golden_chunk finished: 3.343 seconds
[2019-06-18 10:14:11] generate golden chunk: 3.357 seconds
[2019-06-18 10:14:11] iteration time 14: 50.515 seconds
2019-06-18 10:14:12.875836: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874451.939949 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 15}}
[2019-06-18 10:14:16] minmax time: 3.247 seconds
2019-06-18 10:14:16.132503: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:14:16.138162: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:14:16.142848: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874456.155488 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 14}}
[2019-06-18 10:14:16] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:14:16] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-16-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000015-000009 --seed=16 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000015-000009 --seed=1023779847 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000015-000009 --seed=2047559678 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000015-000009 --seed=3071339509 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000015-000009 --seed=4095119340 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000015-000009 --seed=5118899171 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000015-000009 --seed=6142679002 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000015-000009 --seed=7166458833 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000015-000009 --seed=8190238664 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000015-000009 --seed=9214018495 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000015-000009 --seed=10237798326 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000015-000009 --seed=11261578157 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000015-000009 --seed=12285357988 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000015-000009 --seed=13309137819 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000015-000009 --seed=14332917650 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000015-000009 --seed=15356697481 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000015-000009 --seed=16380477312 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000015-000009 --seed=17404257143 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000015-000009 --seed=18428036974 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000015-000009 --seed=19451816805 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000015-000009 --seed=20475596636 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:14:27] eval finished: 11.468 seconds
[2019-06-18 10:14:27] Win rate 000015-000009 vs 000012-000008: 0.830
:::MLL 1560874467.686068 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 14}}
[2019-06-18 10:14:27] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-17-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000016-000008 --seed=17 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000016-000008 --seed=1023779848 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000016-000008 --seed=2047559679 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000016-000008 --seed=3071339510 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000016-000008 --seed=4095119341 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000016-000008 --seed=5118899172 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000016-000008 --seed=6142679003 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000016-000008 --seed=7166458834 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000016-000008 --seed=8190238665 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000016-000008 --seed=9214018496 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000016-000008 --seed=10237798327 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000016-000008 --seed=11261578158 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000016-000008 --seed=12285357989 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000016-000008 --seed=13309137820 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000016-000008 --seed=14332917651 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000016-000008 --seed=15356697482 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000016-000008 --seed=16380477313 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000016-000008 --seed=17404257144 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000016-000008 --seed=18428036975 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:14:57] selfplay finished: 29.593 seconds
[2019-06-18 10:14:57] selfplay mn: 29.613 seconds
[2019-06-18 10:14:57] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-17-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779848 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559679 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339510 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119341 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899172 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142679003 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458834 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238665 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018496 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798327 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578158 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285357989 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137820 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917651 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697482 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477313 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257144 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036975 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816806 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596637 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376468 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156299 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golde
[2019-06-18 10:14:59] train finished: 43.507 seconds
:::MLL 1560874461.430283 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874461.431000 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874461.431665 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:21.518147 46915160097664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_0_0
:::MLL 1560874461.426946 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874461.427780 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874461.428447 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:21.518139 47702164628352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_0_0
W0618 10:14:21.519195 46915160097664 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpzf8wrawl
W0618 10:14:21.519165 47702164628352 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp4fzfj01r
I0618 10:14:21.520141 47702164628352 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp4fzfj01r', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b62cf2a3dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:21.520155 46915160097664 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpzf8wrawl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aab920a1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:21.520533 47702164628352 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:14:21.520550 46915160097664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:14:21.525347 46915160097664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:21.525358 47702164628352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:21.544759 46915160097664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:14:21.544839 47702164628352 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874461.463762 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874461.464509 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874461.465155 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:21.552467 47917980795776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_0_0
:::MLL 1560874461.460200 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874461.461095 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874461.461767 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:21.552717 47720749736832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_0_0
W0618 10:14:21.553559 47917980795776 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpggpqpbtx
W0618 10:14:21.553774 47720749736832 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpycodalw0
I0618 10:14:21.554652 47917980795776 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpggpqpbtx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b950ecf9da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:21.554917 47720749736832 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpycodalw0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6722ec7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:21.555109 47917980795776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:14:21.555363 47720749736832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:14:21.560301 47917980795776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:21.560470 47720749736832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874461.472795 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874461.473522 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874461.474235 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:21.563541 47716125246336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_0_0
:::MLL 1560874461.469889 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874461.470653 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874461.471346 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:21.563882 47078435734400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_0_0
W0618 10:14:21.564568 47716125246336 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpaeqrwt9h
W0618 10:14:21.564854 47078435734400 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp5142rfr7
I0618 10:14:21.565587 47716125246336 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpaeqrwt9h', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b660f485e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:21.565834 47078435734400 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp5142rfr7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad196069e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:21.565989 47716125246336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:14:21.566226 47078435734400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:14:21.570863 47716125246336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:21.571078 47078435734400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874461.480258 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874461.481087 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874461.481923 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:21.578447 47751972270976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_0_0
:::MLL 1560874461.480585 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874461.481451 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874461.482230 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:21.578389 47764768658304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_0_0
W0618 10:14:21.579537 47751972270976 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp32j1n6lc
W0618 10:14:21.579504 47764768658304 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpu8nkb4_8
I0618 10:14:21.580486 47764768658304 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpu8nkb4_8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7162a7ee80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:21.580500 47751972270976 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp32j1n6lc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6e67ee8e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:21.580890 47751972270976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:14:21.580888 47764768658304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:14:21.582447 47917980795776 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:14:21.582540 47720749736832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:14:21.585670 47764768658304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:21.585740 47751972270976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:21.590076 47716125246336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:14:21.590258 47078435734400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874461.519225 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874461.519652 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874461.519977 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:21.592669 47659652027264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_0_0
:::MLL 1560874461.522058 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874461.522478 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874461.522829 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:21.592835 47586720707456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_0_0
W0618 10:14:21.593235 46915160097664 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:14:21.593526 47702164628352 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:14:21.593682 47659652027264 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpaj558aom
W0618 10:14:21.593810 47586720707456 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpw0rt89wn
I0618 10:14:21.594658 47659652027264 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpaj558aom', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b58e9375e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:21.594794 47586720707456 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpw0rt89wn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b47ee2bce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:21.595060 47659652027264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:14:21.595189 47586720707456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874461.516510 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874461.517223 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874461.517902 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:21.594705 47505098105728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_0_0
:::MLL 1560874461.505493 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874461.506411 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874461.507279 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:21.594814 47477815321472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_0_0
W0618 10:14:21.595708 47505098105728 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp_1h92vbr
W0618 10:14:21.595823 47477815321472 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp36muveth
I0618 10:14:21.596712 47505098105728 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp_1h92vbr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b34ed15be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:21.596840 47477815321472 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp36muveth', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2e92e77e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:14:21.597672 46915160097664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:14:21.597964 47702164628352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:14:21.597118 47505098105728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:14:21.597240 47477815321472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:14:21.599670 47659652027264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:21.599705 47586720707456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:14:21.602730 46915160097664 estimator.py:1111] Calling model_fn.
W0618 10:14:21.602837 46915160097664 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:14:21.602092 47505098105728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:21.602162 47477815321472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:14:21.603057 47702164628352 estimator.py:1111] Calling model_fn.
W0618 10:14:21.603165 47702164628352 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:14:21.604198 46915160097664 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:14:21.604521 47702164628352 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:14:21.605048 47764768658304 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:14:21.605340 47751972270976 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874461.543238 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874461.543616 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874461.543942 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:21.606782 47200900621184 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_0_0
:::MLL 1560874461.542348 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874461.542730 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874461.543101 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:21.606743 47465175360384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_0_0
W0618 10:14:21.607840 47200900621184 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp0aaef4_a
W0618 10:14:21.607811 47465175360384 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp0u2ubcwt
I0618 10:14:21.608800 47465175360384 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp0u2ubcwt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2ba180fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:21.608827 47200900621184 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp0aaef4_a', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aee19807e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:21.609206 47465175360384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:14:21.609228 47200900621184 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874461.548609 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874461.549107 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874461.549551 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:21.609665 47728096965504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_0_0
W0618 10:14:21.610731 47728096965504 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpiozjvvx0
I0618 10:14:21.611779 47728096965504 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpiozjvvx0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b68d8da4e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:21.612211 47728096965504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:14:21.613865 47200900621184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:21.613888 47465175360384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874461.556695 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874461.557138 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874461.557530 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:21.615858 47747215451008 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_0_0
W0618 10:14:21.617022 47728096965504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:21.619015 47586720707456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:14:21.619022 47659652027264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:14:21.616850 47747215451008 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpxu80v9i8
I0618 10:14:21.617839 47747215451008 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpxu80v9i8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6d4c672e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:21.618231 47747215451008 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:14:21.621322 47505098105728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:14:21.621740 47477815321472 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874461.549435 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874461.549984 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874461.550463 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:21.623950 47381868798848 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_0_0
:::MLL 1560874461.556250 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874461.556747 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874461.557197 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:21.624392 47994416149376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_0_0
W0618 10:14:21.622772 47747215451008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:21.624948 47381868798848 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpd8gecnpp
I0618 10:14:21.625930 47381868798848 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpd8gecnpp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b183c0bbe80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:21.625389 47994416149376 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba6dab66d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:21.626338 47381868798848 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:14:21.626520 47994416149376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:14:21.630958 47381868798848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:21.631139 47994416149376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:21.632030 47917980795776 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:14:21.631982 47720749736832 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:14:21.633195 47465175360384 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:14:21.633225 47200900621184 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:14:21.636302 47917980795776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:14:21.636263 47720749736832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:14:21.636404 47728096965504 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:14:21.637650 47078435734400 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:14:21.637666 47716125246336 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:14:21.641320 47720749736832 estimator.py:1111] Calling model_fn.
I0618 10:14:21.641370 47917980795776 estimator.py:1111] Calling model_fn.
W0618 10:14:21.641430 47720749736832 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:14:21.641476 47917980795776 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:14:21.641949 47716125246336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:14:21.641924 47078435734400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:14:21.642271 47747215451008 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:14:21.642798 47720749736832 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:14:21.642854 47917980795776 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560874461.517305 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874461.518235 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874461.519054 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:21.647896 47079370957696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_0_0
:::MLL 1560874461.517160 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874461.518073 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874461.518890 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:21.647927 47086631494528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000006-000003.tfrecord.zz_0_0
I0618 10:14:21.646998 47716125246336 estimator.py:1111] Calling model_fn.
I0618 10:14:21.646986 47078435734400 estimator.py:1111] Calling model_fn.
W0618 10:14:21.647096 47078435734400 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:14:21.647104 47716125246336 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:14:21.650206 47381868798848 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:14:21.650488 47994416149376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:14:21.649026 47079370957696 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp7v11w4e5
W0618 10:14:21.648464 47716125246336 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:14:21.649050 47086631494528 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpedloju_5
W0618 10:14:21.648451 47078435734400 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:14:21.650148 47079370957696 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp7v11w4e5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad1cdc4ee80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:21.650171 47086631494528 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpedloju_5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad37e87ee80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:21.650613 47079370957696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:14:21.650634 47086631494528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:14:21.652910 47764768658304 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:14:21.653589 47751972270976 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:14:21.656067 47086631494528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:21.656111 47079370957696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:21.657171 47764768658304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:14:21.657912 47751972270976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:14:21.662207 47764768658304 estimator.py:1111] Calling model_fn.
W0618 10:14:21.662316 47764768658304 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:14:21.662986 47751972270976 estimator.py:1111] Calling model_fn.
W0618 10:14:21.663098 47751972270976 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:14:21.663661 47764768658304 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:14:21.664435 47751972270976 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops[2019-06-18 10:15:00] divide_golden_chunk finished: 3.270 seconds
[2019-06-18 10:15:00] generate golden chunk: 3.284 seconds
[2019-06-18 10:15:00] moving /lfs/lfs12/gma_akey/results/epb312/models/000016-000009.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb312/models/000016-000010.data-00000-of-00001
[2019-06-18 10:15:00] moving /lfs/lfs12/gma_akey/results/epb312/models/000016-000009.meta --> /lfs/lfs12/gma_akey/results/epb312/models/000016-000010.meta
[2019-06-18 10:15:00] moving /lfs/lfs12/gma_akey/results/epb312/models/000016-000009.index --> /lfs/lfs12/gma_akey/results/epb312/models/000016-000010.index
[2019-06-18 10:15:00] moving /lfs/lfs12/gma_akey/results/epb312/models/000016-000009.pb --> /lfs/lfs12/gma_akey/results/epb312/models/000016-000010.pb
[2019-06-18 10:15:00] iteration time 15: 48.686 seconds
2019-06-18 10:15:01.563055: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874500.625807 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 16}}
[2019-06-18 10:15:04] minmax time: 3.274 seconds
2019-06-18 10:15:04.846782: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:15:04.860363: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:15:04.864729: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874504.875941 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 15}}
[2019-06-18 10:15:04] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:15:04] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-17-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000016-000010 --seed=17 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000016-000010 --seed=1023779848 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000016-000010 --seed=2047559679 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000016-000010 --seed=3071339510 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000016-000010 --seed=4095119341 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000016-000010 --seed=5118899172 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000016-000010 --seed=6142679003 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000016-000010 --seed=7166458834 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000016-000010 --seed=8190238665 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000016-000010 --seed=9214018496 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000016-000010 --seed=10237798327 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000016-000010 --seed=11261578158 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000016-000010 --seed=12285357989 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000016-000010 --seed=13309137820 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000016-000010 --seed=14332917651 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000016-000010 --seed=15356697482 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000016-000010 --seed=16380477313 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000016-000010 --seed=17404257144 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000016-000010 --seed=18428036975 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000016-000010 --seed=19451816806 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000016-000010 --seed=20475596637 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:15:15] eval finished: 11.074 seconds
[2019-06-18 10:15:16] Win rate 000016-000010 vs 000015-000009: 0.300
:::MLL 1560874516.013224 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 15}}
[2019-06-18 10:15:16] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-18-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000017-000009 --seed=18 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000017-000009 --seed=1023779849 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000017-000009 --seed=2047559680 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000017-000009 --seed=3071339511 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000017-000009 --seed=4095119342 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000017-000009 --seed=5118899173 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000017-000009 --seed=6142679004 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000017-000009 --seed=7166458835 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000017-000009 --seed=8190238666 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000017-000009 --seed=9214018497 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000017-000009 --seed=10237798328 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000017-000009 --seed=11261578159 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000017-000009 --seed=12285357990 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000017-000009 --seed=13309137821 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000017-000009 --seed=14332917652 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000017-000009 --seed=15356697483 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000017-000009 --seed=16380477314 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000017-000009 --seed=17404257145 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000017-000009 --seed=18428036976 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:15:45] selfplay finished: 29.190 seconds
[2019-06-18 10:15:45] selfplay mn: 29.208 seconds
[2019-06-18 10:15:45] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-18-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779849 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559680 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339511 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119342 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899173 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142679004 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458835 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238666 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018497 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798328 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578159 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285357990 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137821 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917652 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697483 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477314 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257145 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036976 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816807 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596638 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376469 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156300 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golde
[2019-06-18 10:15:48] divide_golden_chunk finished: 3.340 seconds
[2019-06-18 10:15:48] generate golden chunk: 3.355 seconds
[2019-06-18 10:15:48] train finished: 43.775 seconds
:::MLL 1560874510.111638 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874510.112511 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874510.113320 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:10.204090 47184071132032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560874510.125043 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874510.125763 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874510.126413 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:10.204052 46951320703872 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 10:15:10.205101 47184071132032 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp0_ru61_k
W0618 10:15:10.205075 46951320703872 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpe1h5vtyn
I0618 10:15:10.206103 47184071132032 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp0_ru61_k', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aea2e62de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:10.206097 46951320703872 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpe1h5vtyn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab3fd611e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:10.206501 47184071132032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:10.206499 46951320703872 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:10.211546 47184071132032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:10.211526 46951320703872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:10.230863 47184071132032 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:10.230939 46951320703872 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874510.164862 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874510.165790 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874510.166656 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:10.256666 47500222358400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560874510.180264 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874510.181026 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874510.181859 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:10.256738 47721858491264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 10:15:10.257717 47500222358400 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpaj33w090
W0618 10:15:10.257748 47721858491264 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmptb9agcc2
I0618 10:15:10.258694 47500222358400 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpaj33w090', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b33ca77be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:10.258725 47721858491264 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmptb9agcc2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b676502ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:10.259134 47500222358400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:10.259170 47721858491264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:10.264420 47721858491264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:10.264441 47500222358400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:10.279653 47184071132032 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:15:10.280898 46951320703872 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:15:10.284137 47184071132032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:15:10.285326 46951320703872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:15:10.286351 47721858491264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:10.286436 47500222358400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:15:10.289222 47184071132032 estimator.py:1111] Calling model_fn.
W0618 10:15:10.289334 47184071132032 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560874510.225611 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874510.225996 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874510.226321 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:10.289226 47237466932096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_0_0
I0618 10:15:10.290415 46951320703872 estimator.py:1111] Calling model_fn.
W0618 10:15:10.290528 46951320703872 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:15:10.290681 47184071132032 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:15:10.290342 47237466932096 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp969jron2
I0618 10:15:10.291419 47237466932096 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp969jron2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af69d060e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:10.291859 47237466932096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:10.292026 46951320703872 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:15:10.296789 47237466932096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874510.227570 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874510.227945 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874510.228265 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:10.298408 47532030829440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 10:15:10.299378 47532030829440 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpifd4955_
I0618 10:15:10.300340 47532030829440 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpifd4955_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3b32667dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:10.300727 47532030829440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874510.215217 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874510.215980 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874510.216649 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:10.300942 47497588282240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560874510.210858 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874510.211779 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874510.212571 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:10.300992 47234962830208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 10:15:10.301961 47497588282240 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpx5r3pl6t
W0618 10:15:10.301995 47234962830208 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpizep7pkt
I0618 10:15:10.302951 47497588282240 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpx5r3pl6t', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b332d76de80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:10.302980 47234962830208 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpizep7pkt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af607c48e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:10.303423 47497588282240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:10.303446 47234962830208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:10.305247 47532030829440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:10.308255 47497588282240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:10.308286 47234962830208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:10.316217 47237466932096 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874510.226588 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874510.227503 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874510.228350 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:10.319591 47914556416896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560874510.232411 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874510.233165 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874510.233860 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:10.319894 47614923223936 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 10:15:10.320726 47914556416896 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpueor6ye0
W0618 10:15:10.321002 47614923223936 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpa1zqakiq
I0618 10:15:10.321827 47914556416896 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpueor6ye0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9442b3be80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:10.322093 47614923223936 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpa1zqakiq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4e7f2c0e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:10.322273 47914556416896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:10.322527 47614923223936 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874510.255312 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874510.255694 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874510.256034 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:10.321785 47299442652032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560874510.256392 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874510.256767 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874510.257095 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:10.321767 47377610797952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 10:15:10.324773 47532030829440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:10.322748 47299442652032 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp5xl6514d
W0618 10:15:10.322777 47377610797952 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpgcoljmg6
I0618 10:15:10.323745 47299442652032 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp5xl6514d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b050b107e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:10.323747 47377610797952 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpgcoljmg6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b173e3fce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:10.324144 47299442652032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:10.324145 47377610797952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:10.327997 47497588282240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:10.328016 47234962830208 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:10.327752 47914556416896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:10.327783 47614923223936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:10.328742 47299442652032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:10.328749 47377610797952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874510.231033 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874510.231834 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874510.232647 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:10.329337 47299876209536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560874510.232501 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874510.233245 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874510.233950 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:10.329395 47789336884096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 10:15:10.330378 47299876209536 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp885y_9nl
W0618 10:15:10.330406 47789336884096 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpp24wjc4g
I0618 10:15:10.331382 47299876209536 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp885y_9nl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0524e81e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:10.331395 47789336884096 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpp24wjc4g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b771b094da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:10.331791 47789336884096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:10.331794 47299876209536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:10.336694 47789336884096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:10.336698 47299876209536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:10.337178 47721858491264 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:15:10.337568 47500222358400 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:15:10.341445 47721858491264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:15:10.341850 47500222358400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:15:10.346487 47721858491264 estimator.py:1111] Calling model_fn.
W0618 10:15:10.346596 47721858491264 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:15:10.346883 47500222358400 estimator.py:1111] Calling model_fn.
W0618 10:15:10.346990 47500222358400 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:15:10.347843 47377610797952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:10.347935 47721858491264 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:15:10.348011 47299442652032 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:10.348336 47500222358400 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:15:10.349878 47914556416896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:10.350216 47614923223936 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874510.287097 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874510.287530 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874510.287901 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:10.355103 47624595645312 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560874510.286137 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874510.286582 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874510.286983 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:10.355069 46920160928640 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_0_0
I0618 10:15:10.356090 47624595645312 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b50bfb17d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:15:10.356078 46920160928640 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpbtao0use
I0618 10:15:10.357036 46920160928640 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpbtao0use', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aacbc1cae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:10.357207 47624595645312 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:10.357428 46920160928640 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:10.356111 47299876209536 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:10.356352 47789336884096 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:10.361816 47624595645312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:10.361956 46920160928640 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:10.364197 47237466932096 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560874510.274894 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874510.275652 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874510.276396 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:10.364413 47004892791680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560874510.277758 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874510.278532 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874510.279247 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:10.364748 47744737809280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 10:15:10.365512 47004892791680 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpq3wceo8s
W0618 10:15:10.365817 47744737809280 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp1pwa6qar
I0618 10:15:10.366556 47004892791680 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpq3wceo8s', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac076865e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:10.366823 47744737809280 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp1pwa6qar', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6cb8b96e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:10.366969 47004892791680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:10.367229 47744737809280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874510.302311 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874510.302733 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874510.303102 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:10.367239 47285591720832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 10:15:10.368530 47237466932096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560874510.305446 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874510.305842 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874510.306171 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:10.368518 47140150129536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 10:15:10.368254 47285591720832 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp4j7jdi5c
I0618 10:15:10.369285 47285591720832 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp4j7jdi5c', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b01d17c1e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:10.369723 47285591720832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:10.369547 47140150129536 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpfp3klheg
I0618 10:15:10.370596 47140150129536 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpfp3klheg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adff47d8e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:10.370990 47140150129536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:10.372489 47532030829440 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:15:10.371876 47004892791680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:10.372057 47744737809280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:15:10.373615 47237466932096 estimator.py:1111] Calling model_fn.
W0618 10:15:10.373723 47237466932096 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:15:10.374372 47285591720832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:10.375095 47237466932096 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:15:10.375486 47140150129536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874510.297031 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874510.297580 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874510.298070 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:10.374215 47225341850496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 10:15:10.376363 47497588282240 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:15:10.376902 47234962830208 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:15:10.376832 47532030829440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:15:10.375209 47225341850496 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpqqt8ylp2
:::MLL 1560874510.302573 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874510.303084 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874510.303490 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:10.375996 47953873134464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000007-000003.tfrecord.zz_0_0
I0618 10:15:10.376188 47225341850496 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpqqt8ylp2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af3ca500e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:10.376584 47225341850496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:10.376977 47953873134464 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp5eh6lowy
I0618 10:15:10.378027 47953873134464 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp5eh6lowy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9d6a292e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:10.378420 47953873134464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:10.380697 47497588282240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:15:10.380948 47624595645312 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:10.381215 46920160928640 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:10.381274 47234962830208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.[2019-06-18 10:15:48] iteration time 16: 48.046 seconds
2019-06-18 10:15:49.651738: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
Got 343572 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000009.tfrecord.zz: 14.181 seconds
Got 377166 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000004.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000004.tfrecord.zz: 14.699 seconds
Got 380485 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000005.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000005.tfrecord.zz: 14.685 seconds
Got 347710 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000006.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000006.tfrecord.zz: 14.504 seconds
Got 391241 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000000.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000000.tfrecord.zz: 16.342 seconds
Got 383923 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000002.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000002.tfrecord.zz: 15.096 seconds
Got 348718 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000007.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000007.tfrecord.zz: 11.628 seconds
Got 346300 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000008.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000008.tfrecord.zz: 14.179 seconds
Got 389066 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000003.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000003.tfrecord.zz: 12.655 seconds
Got 386677 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000001.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000000-000001.tfrecord.zz: 15.167 seconds
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/checkpoint_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/checkpointlog.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000001-000001_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000001-000001log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000002-000002_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000002-000002log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000003-000002_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000003-000002log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000004-000003_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000004-000003log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000005-000004_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000005-000004log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000006-000004_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000006-000004log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000007-000005_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000007-000005log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000008-000005_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000008-000005log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000009-000005_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000009-000005log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000010-000006_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000010-000006log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000011-000007_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000011-000007log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000012-000008_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000012-000008log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000013-000009_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000013-000009log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000014-000009_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000014-000009log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000015-000009_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000015-000009log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000016-000010_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000016-000010log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000017-000010_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000017-000010log.txt['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874548.671731 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 17}}
[2019-06-18 10:15:52] minmax time: 3.231 seconds
2019-06-18 10:15:52.892949: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:15:52.898427: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:15:52.903104: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874552.916592 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 16}}
[2019-06-18 10:15:52] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000018-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000018-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000018-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000018-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000018-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000018-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000018-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000018-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000018-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000018-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000018-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:15:52] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-18-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000017-000010 --seed=18 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000017-000010 --seed=1023779849 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000017-000010 --seed=2047559680 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000017-000010 --seed=3071339511 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000017-000010 --seed=4095119342 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000017-000010 --seed=5118899173 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000017-000010 --seed=6142679004 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000017-000010 --seed=7166458835 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000017-000010 --seed=8190238666 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000017-000010 --seed=9214018497 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000017-000010 --seed=10237798328 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000017-000010 --seed=11261578159 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000017-000010 --seed=12285357990 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000017-000010 --seed=13309137821 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000017-000010 --seed=14332917652 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000017-000010 --seed=15356697483 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000017-000010 --seed=16380477314 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000017-000010 --seed=17404257145 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000017-000010 --seed=18428036976 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000017-000010 --seed=19451816807 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000017-000010 --seed=20475596638 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:16:04] eval finished: 11.565 seconds
[2019-06-18 10:16:04] Win rate 000017-000010 vs 000015-000009: 0.410
:::MLL 1560874564.545453 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 16}}
[2019-06-18 10:16:04] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-19-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000018-000009 --seed=19 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000018-000009 --seed=1023779850 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000018-000009 --seed=2047559681 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000018-000009 --seed=3071339512 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000018-000009 --seed=4095119343 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000018-000009 --seed=5118899174 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000018-000009 --seed=6142679005 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000018-000009 --seed=7166458836 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000018-000009 --seed=8190238667 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000018-000009 --seed=9214018498 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000018-000009 --seed=10237798329 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000018-000009 --seed=11261578160 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000018-000009 --seed=12285357991 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000018-000009 --seed=13309137822 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000018-000009 --seed=14332917653 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000018-000009 --seed=15356697484 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000018-000009 --seed=16380477315 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000018-000009 --seed=17404257146 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000018-000009 --seed=18428036977 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:16:34] selfplay finished: 29.959 seconds
[2019-06-18 10:16:34] selfplay mn: 29.979 seconds
[2019-06-18 10:16:34] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-19-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779850 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559681 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339512 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119343 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899174 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142679005 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458836 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238667 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018498 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798329 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578160 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285357991 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137822 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917653 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697484 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477315 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257146 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036977 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816808 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596639 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376470 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156301 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golde
[2019-06-18 10:16:36] train finished: 43.322 seconds
:::MLL 1560874558.196811 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874558.197697 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874558.198473 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:58.291700 47472153871232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_0_0
:::MLL 1560874558.197897 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874558.198725 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874558.199455 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:58.291750 46989931275136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 10:15:58.292691 47472153871232 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp4hc5svwj
W0618 10:15:58.292736 46989931275136 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpmlljar0d
I0618 10:15:58.293673 47472153871232 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp4hc5svwj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2d41749e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:58.293732 46989931275136 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpmlljar0d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abcfabfae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:58.294074 47472153871232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:58.294143 46989931275136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:58.298916 47472153871232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:58.299019 46989931275136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874558.204284 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874558.205014 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874558.205691 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:58.304127 47366573515648 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_0_0
:::MLL 1560874558.198262 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874558.199160 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874558.199997 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:58.304276 47545796146048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 10:15:58.305188 47366573515648 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp8genssir
W0618 10:15:58.305227 47545796146048 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpyr7hov3y
I0618 10:15:58.306199 47545796146048 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpyr7hov3y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3e66e08e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:58.306200 47366573515648 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp8genssir', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b14ac602e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:58.306597 47545796146048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:58.306650 47366573515648 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:58.311499 47545796146048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:58.311621 47366573515648 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:58.318594 47472153871232 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:58.319114 46989931275136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:58.330778 47545796146048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:58.330968 47366573515648 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874558.237278 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874558.238158 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874558.238972 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:58.334223 46967650530176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_0_0
:::MLL 1560874558.237439 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874558.238357 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874558.239175 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:58.334282 47888829748096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 10:15:58.335255 46967650530176 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpslobxtlm
W0618 10:15:58.335284 47888829748096 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp2w5bhxas
I0618 10:15:58.336250 46967650530176 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpslobxtlm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab7cab68da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:58.336269 47888829748096 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp2w5bhxas', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8e4545ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:58.336643 46967650530176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:58.336661 47888829748096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874558.250392 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874558.251151 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874558.251831 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:58.340558 47811748762496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_0_0
:::MLL 1560874558.244205 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874558.245064 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874558.245859 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:58.340832 47298222183296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 10:15:58.341697 47888829748096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:58.341713 46967650530176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:58.341679 47811748762496 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp8v61yzto
W0618 10:15:58.341873 47298222183296 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpz7d36w3o
I0618 10:15:58.342793 47811748762496 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp8v61yzto', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7c52e36e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:58.342971 47298222183296 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpz7d36w3o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b04c251ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:58.343246 47811748762496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:58.343415 47298222183296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:58.348564 47811748762496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:58.348601 47298222183296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874558.276431 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874558.276888 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874558.277300 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:58.350610 47791895729024 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 10:15:58.351642 47791895729024 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp2ngtzyea
I0618 10:15:58.352673 47791895729024 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp2ngtzyea', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b77b38e1e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:58.353076 47791895729024 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874558.278432 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874558.278948 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874558.279376 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:58.354860 47572439556992 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_0_0
I0618 10:15:58.355832 47572439556992 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b449af2bcf8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:58.356930 47572439556992 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:58.357749 47791895729024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874558.277482 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874558.277987 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874558.278425 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:58.360998 47960962098048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 10:15:58.361469 47572439556992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874558.282377 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874558.282783 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874558.283137 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:58.361798 47020717761408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 10:15:58.361989 47960962098048 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmptf18x_zr
W0618 10:15:58.360901 47888829748096 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:15:58.362975 47960962098048 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmptf18x_zr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9f10b23e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:15:58.361136 46967650530176 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:15:58.363365 47960962098048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:58.362770 47020717761408 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpmutk28fv
I0618 10:15:58.363734 47020717761408 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpmutk28fv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac425c43dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:58.364138 47020717761408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:58.367451 47472153871232 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:15:58.367964 46989931275136 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:15:58.368053 47960962098048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:58.368737 47020717761408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:58.371784 47472153871232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:15:58.372276 46989931275136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560874558.275867 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874558.276794 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874558.277671 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:58.371110 47690366079872 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_0_0
:::MLL 1560874558.285186 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874558.285918 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874558.286631 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:58.371253 47404223067008 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 10:15:58.370527 47811748762496 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:58.370558 47298222183296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:58.372134 47690366079872 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp2jegq9hy
W0618 10:15:58.372248 47404223067008 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp1m5rixsi
I0618 10:15:58.373234 47690366079872 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp2jegq9hy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b600feaae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:58.373321 47404223067008 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp1m5rixsi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1d70769e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:58.373677 47690366079872 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:58.373772 47404223067008 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:58.376909 47791895729024 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:15:58.376922 47472153871232 estimator.py:1111] Calling model_fn.
W0618 10:15:58.377032 47472153871232 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:15:58.377357 46989931275136 estimator.py:1111] Calling model_fn.
W0618 10:15:58.377465 46989931275136 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:15:58.378399 47472153871232 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:15:58.378814 46989931275136 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:15:58.378952 47366573515648 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:15:58.378985 47545796146048 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:15:58.378510 47404223067008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:58.378536 47690366079872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:58.380487 47572439556992 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:58.383247 47366573515648 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:15:58.383311 47545796146048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560874558.310380 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874558.310959 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874558.311481 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:58.382164 47945782604672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 10:15:58.383149 47945782604672 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpxu6dlbxq
I0618 10:15:58.384132 47945782604672 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpxu6dlbxq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9b87ed8e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:58.384535 47945782604672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874558.317814 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874558.318261 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874558.318656 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:58.384700 47894322160512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 10:15:58.387035 47960962098048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:58.387684 47020717761408 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:15:58.388317 47366573515648 estimator.py:1111] Calling model_fn.
W0618 10:15:58.385681 47894322160512 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpffyigngn
W0618 10:15:58.388426 47366573515648 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:15:58.388426 47545796146048 estimator.py:1111] Calling model_fn.
W0618 10:15:58.388534 47545796146048 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:15:58.386667 47894322160512 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpffyigngn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8f8ca56e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:58.387064 47894322160512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:58.389774 47366573515648 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:15:58.389880 47545796146048 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:15:58.389177 47945782604672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:58.391576 47894322160512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874558.326220 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874558.326679 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874558.327110 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:58.395934 47564147303296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_0_0
:::MLL 1560874558.326220 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874558.326682 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874558.327107 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:58.396046 47270692594560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 10:15:58.397879 47404223067008 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:58.397966 47690366079872 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:58.396922 47564147303296 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpnudvji4p
W0618 10:15:58.397026 47270692594560 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp3ivp3lgh
I0618 10:15:58.397912 47564147303296 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpnudvji4p', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b42acb0fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:58.398031 47270692594560 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp3ivp3lgh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afe596d7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:58.398311 47564147303296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:58.398430 47270692594560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:58.402935 47564147303296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:58.403041 47270692594560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874558.241302 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874558.242221 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874558.243071 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:58.408953 47928218141568 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_0_0
:::MLL 1560874558.246401 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874558.247197 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874558.247878 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:58.409362 47021545419648 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 10:15:58.408224 47888829748096 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:15:58.408283 47945782604672 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:58.408750 46967650530176 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:15:58.410119 47928218141568 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp3l08jc4o
I0618 10:15:58.411261 47928218141568 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp3l08jc4o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9771011e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:15:58.410491 47021545419648 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpe5j8l8km
I0618 10:15:58.411625 47021545419648 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpe5j8l8km', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac457194e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:58.411710 47928218141568 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:58.410656 47894322160512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:15:58.412085 47021545419648 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:58.412501 47888829748096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:15:58.413068 46967650530176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:15:58.416811 47928218141568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:58.417059 47021545419648 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:15:58.417590 47888829748096 estimator.py:1111] Calling model_fn.
W0618 10:15:58.417699 47888829748096 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:15:58.418216 46967650530176 estimator.py:1111] Calling model_fn.
W0618 10:15:58.418323 46967650530176 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:15:58.419056 47888829748096 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:15:58.419679 46967650530176 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:15:58.420457 47298222183296 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:15:58.420541 47811748762496 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:15:58.422205 47270692594560 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:58.422179 47564147303296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:58.424561 47791895729024 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560874558.355164 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874558.355665 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874558.356112 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:58.423571 47883726390144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 10:15:58.424597 47883726390144 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpx8ir0coc
I0618 10:15:58.425593 47883726390144 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpx8ir0coc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8d1516be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:15:58.424765 47298222183296 de[2019-06-18 10:16:37] divide_golden_chunk finished: 3.252 seconds
[2019-06-18 10:16:37] generate golden chunk: 3.267 seconds
[2019-06-18 10:16:37] iteration time 17: 49.121 seconds
2019-06-18 10:16:38.843683: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874597.793284 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 18}}
[2019-06-18 10:16:42] minmax time: 3.207 seconds
2019-06-18 10:16:42.060850: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:16:42.066212: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:16:42.070630: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874602.083428 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 17}}
[2019-06-18 10:16:42] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000019-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000019-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000019-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000019-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000019-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000019-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000019-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000019-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000019-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000019-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000019-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:16:42] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-19-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000018-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000018-000010 --seed=19 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000018-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000018-000010 --seed=1023779850 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000018-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000018-000010 --seed=2047559681 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000018-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000018-000010 --seed=3071339512 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000018-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000018-000010 --seed=4095119343 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000018-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000018-000010 --seed=5118899174 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000018-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000018-000010 --seed=6142679005 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000018-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000018-000010 --seed=7166458836 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000018-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000018-000010 --seed=8190238667 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000018-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000018-000010 --seed=9214018498 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000018-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000018-000010 --seed=10237798329 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000018-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000018-000010 --seed=11261578160 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000018-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000018-000010 --seed=12285357991 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000018-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000018-000010 --seed=13309137822 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000018-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000018-000010 --seed=14332917653 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000018-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000018-000010 --seed=15356697484 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000018-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000018-000010 --seed=16380477315 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000018-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000018-000010 --seed=17404257146 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000018-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000018-000010 --seed=18428036977 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000018-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000018-000010 --seed=19451816808 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000018-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000018-000010 --seed=20475596639 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:16:54] eval finished: 12.056 seconds
[2019-06-18 10:16:54] Win rate 000018-000010 vs 000015-000009: 0.440
:::MLL 1560874614.204192 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 17}}
[2019-06-18 10:16:54] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-20-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000019-000009 --seed=20 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000019-000009 --seed=1023779851 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000019-000009 --seed=2047559682 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000019-000009 --seed=3071339513 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000019-000009 --seed=4095119344 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000019-000009 --seed=5118899175 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000019-000009 --seed=6142679006 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000019-000009 --seed=7166458837 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000019-000009 --seed=8190238668 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000019-000009 --seed=9214018499 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000019-000009 --seed=10237798330 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000019-000009 --seed=11261578161 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000019-000009 --seed=12285357992 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000019-000009 --seed=13309137823 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000019-000009 --seed=14332917654 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000019-000009 --seed=15356697485 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000019-000009 --seed=16380477316 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000019-000009 --seed=17404257147 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000019-000009 --seed=18428036978 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:17:24] selfplay finished: 29.823 seconds
[2019-06-18 10:17:24] selfplay mn: 29.842 seconds
[2019-06-18 10:17:24] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-20-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779851 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559682 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339513 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119344 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899175 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142679006 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458837 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238668 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018499 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798330 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578161 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285357992 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137823 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917654 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697485 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477316 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257147 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036978 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816809 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596640 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376471 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156302 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000019-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golde
[2019-06-18 10:17:25] train finished: 43.038 seconds
:::MLL 1560874607.328800 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874607.329534 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874607.330169 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:47.423379 47210606150528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_0_0
:::MLL 1560874607.324403 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874607.325321 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874607.326096 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:47.423470 47447598793600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_0_0
W0618 10:16:47.424462 47210606150528 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp2fb2oxei
W0618 10:16:47.424553 47447598793600 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp1jodo3lu
I0618 10:16:47.425569 47210606150528 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp2fb2oxei', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af05bff0e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:47.425648 47447598793600 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp1jodo3lu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2789dbde80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:47.425968 47210606150528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:16:47.426049 47447598793600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:16:47.430660 47447598793600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:47.430667 47210606150528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:47.450307 47210606150528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:16:47.450267 47447598793600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874607.355291 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874607.356081 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874607.356786 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:47.452812 47596469080960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_0_0
:::MLL 1560874607.358255 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874607.358962 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874607.359644 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:47.453144 47640173958016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_0_0
W0618 10:16:47.453930 47596469080960 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpdme8m3vw
W0618 10:16:47.454235 47640173958016 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpkfkef3pl
I0618 10:16:47.455056 47596469080960 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpdme8m3vw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4a33382e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:47.455331 47640173958016 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpkfkef3pl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b54603bae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:47.455502 47596469080960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:16:47.455790 47640173958016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:16:47.460819 47596469080960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:47.460990 47640173958016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874607.366531 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874607.367421 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874607.368242 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:47.468703 47433790808960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_0_0
:::MLL 1560874607.366605 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874607.367508 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874607.368325 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:47.468681 47698033636224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_0_0
:::MLL 1560874607.373330 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874607.374042 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874607.374759 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:47.471308 47210801582976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_0_0
:::MLL 1560874607.367189 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874607.368095 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874607.368995 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:47.471345 46986208838528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_0_0
W0618 10:16:47.469731 47433790808960 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpkljhp3o3
W0618 10:16:47.469699 47698033636224 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpkbfb7hwd
I0618 10:16:47.470700 47698033636224 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpkbfb7hwd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b61d8f04e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:47.470731 47433790808960 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpkljhp3o3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2452d69e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:47.471107 47698033636224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:16:47.471134 47433790808960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:16:47.472360 47210801582976 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp93okum2u
W0618 10:16:47.472396 46986208838528 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp45lhokfq
I0618 10:16:47.473380 47210801582976 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp93okum2u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af067a52e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:47.473403 46986208838528 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp45lhokfq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abc1cdfde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:47.473778 47210801582976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:16:47.473835 46986208838528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:16:47.476077 47433790808960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:47.476089 47698033636224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:47.478685 47210801582976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:47.478695 46986208838528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874607.408282 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874607.408733 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874607.409142 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:47.480893 47485429425024 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_0_0
:::MLL 1560874607.408397 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874607.408856 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874607.409262 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:47.480994 47123973882752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_0_0
I0618 10:16:47.482162 47485429425024 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3058bd7d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:16:47.482160 47123973882752 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp3s_2qtqn
I0618 10:16:47.483243 47123973882752 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp3s_2qtqn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adc304f7e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:47.483366 47485429425024 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:16:47.483662 47123973882752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:16:47.482561 47596469080960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:16:47.482964 47640173958016 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:16:47.488312 47485429425024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:47.488496 47123973882752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:47.495533 47433790808960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:16:47.495669 47698033636224 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:16:47.498036 47210801582976 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:16:47.498187 46986208838528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874607.372566 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874607.373277 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874607.373938 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:47.497876 47462586852224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_0_0
:::MLL 1560874607.370376 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874607.371149 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874607.371871 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:47.498107 47190468649856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_0_0
W0618 10:16:47.498999 47447598793600 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:16:47.499187 47210606150528 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:16:47.499050 47462586852224 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpdm44tthm
W0618 10:16:47.499201 47190468649856 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp1v3ah9vm
I0618 10:16:47.500166 47462586852224 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpdm44tthm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2b07377e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:47.500286 47190468649856 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp1v3ah9vm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aebabb53e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:47.500633 47462586852224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:16:47.500736 47190468649856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:16:47.503301 47447598793600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:16:47.503503 47210606150528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560874607.431422 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874607.431851 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874607.432256 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:47.503147 47278069445504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_0_0
:::MLL 1560874607.432347 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874607.432760 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874607.433090 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:47.503340 47631700837248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_0_0
W0618 10:16:47.504161 47278069445504 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpkanwkb47
W0618 10:16:47.504299 47631700837248 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpfsfz_59d
W0618 10:16:47.506149 47462586852224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:47.506140 47190468649856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:16:47.505160 47278069445504 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpkanwkb47', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b00111f3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:47.505292 47631700837248 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpfsfz_59d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5267321e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:47.505554 47278069445504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:16:47.505682 47631700837248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:16:47.508391 47447598793600 estimator.py:1111] Calling model_fn.
W0618 10:16:47.508503 47447598793600 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:16:47.508650 47210606150528 estimator.py:1111] Calling model_fn.
W0618 10:16:47.508690 47485429425024 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:16:47.508760 47210606150528 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:16:47.508860 47123973882752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:16:47.509869 47447598793600 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:16:47.510118 47210606150528 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560874607.415353 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874607.416243 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874607.417098 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:47.510209 47807113241472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_0_0
:::MLL 1560874607.416117 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874607.417026 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874607.417727 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:47.510169 47395433444224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_0_0
W0618 10:16:47.510153 47278069445504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:47.510237 47631700837248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:47.511221 47395433444224 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp8yl8lk_8
W0618 10:16:47.511253 47807113241472 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpti96irg3
I0618 10:16:47.512214 47395433444224 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp8yl8lk_8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1b648fbe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:47.512255 47807113241472 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpti96irg3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7b3e96fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:47.512609 47395433444224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:16:47.512655 47807113241472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:16:47.517595 47395433444224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:47.517613 47807113241472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:47.528170 47190468649856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:16:47.528551 47462586852224 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:16:47.529224 47278069445504 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:16:47.529386 47631700837248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874607.456195 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874607.456657 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874607.457072 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:47.530134 47121598718848 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_0_0
:::MLL 1560874607.456365 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874607.456837 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874607.457231 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:47.530223 47679598289792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_0_0
:::MLL 1560874607.459595 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874607.460078 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874607.460510 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:47.532607 47439775400832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_0_0
W0618 10:16:47.531666 47596469080960 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:16:47.532018 47640173958016 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:16:47.531146 47121598718848 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpoge2qw3j
W0618 10:16:47.531213 47679598289792 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp2tl6po9p
I0618 10:16:47.532138 47121598718848 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpoge2qw3j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adba2bd7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:47.532197 47679598289792 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp2tl6po9p', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5d8e1b3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:47.532530 47121598718848 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:16:47.533610 47439775400832 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpyy1g0xt2
I0618 10:16:47.532591 47679598289792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:16:47.534599 47439775400832 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpyy1g0xt2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b25b78c5dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:47.535002 47439775400832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874607.465449 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874607.465899 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874607.466286 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:47.535705 47986603828096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_0_0
W0618 10:16:47.536672 47986603828096 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpt5on_fzc
I0618 10:16:47.537672 47986603828096 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpt5on_fzc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba5090ffe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:16:47.535963 47596469080960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:16:47.538072 47986603828096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:16:47.536356 47640173958016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560874607.437188 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874607.437604 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874607.437970 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:47.537349 47272827655040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_0_0
W0618 10:16:47.537243 47807113241472 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874607.436301 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874607.436738 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874607.437151 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:47.537401 47811298456448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000009-000004.tfrecord.zz_0_0
W0618 10:16:47.537285 47395433444224 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:16:47.537213 47121598718848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:47.537244 47679598289792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:47.539633 47439775400832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:47.538377 47272827655040 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpysj6l5au
W0618 10:16:47.538404 47811298456448 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmptlvbgup9
I0618 10:16:47.539391 47272827655040 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpysj6l5au', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afed8afee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:47.539391 47811298456448 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmptlvbgup9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7c380c4e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:47.539796 47272827655040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:16:47.539792 47811298456448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:16:47.542654 47986603828096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:16:47.541052 47596469080960 estimator.py:1111] Calling model_fn.
W0618 10:16:47.541159 47596469080960 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:16:47.541494 47640173958016 estimator.py:1111] Calling model_fn.
W0618 10:16:47.541604 47640173958016 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:16:47.542517 47596469080960 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:16:47.542981 47640173958016 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:16:47.544495 47272827655040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:47.544501 47811298456448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:47.543875 47433790808960 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:16:47.544236 47698033636224 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:16:47.546267 46986208838528 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:16:47.546326 47210801582976 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:16:47.548167 47433790808960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:16:47.548549 47698033636224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:16:47.550575 46986208838528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:16:47.550657 47210801582976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: Datase[2019-06-18 10:17:27] divide_golden_chunk finished: 3.410 seconds
[2019-06-18 10:17:27] generate golden chunk: 3.424 seconds
[2019-06-18 10:17:27] iteration time 18: 49.679 seconds
2019-06-18 10:17:28.562412: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874647.472887 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 19}}
[2019-06-18 10:17:31] minmax time: 3.208 seconds
2019-06-18 10:17:31.780394: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:17:31.785832: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:17:31.790287: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874651.802852 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 18}}
[2019-06-18 10:17:31] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000020-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000020-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000020-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000020-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000020-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000020-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000020-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000020-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000020-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000020-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000020-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:17:31] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-20-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000019-000010 --seed=20 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000019-000010 --seed=1023779851 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000019-000010 --seed=2047559682 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000019-000010 --seed=3071339513 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000019-000010 --seed=4095119344 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000019-000010 --seed=5118899175 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000019-000010 --seed=6142679006 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000019-000010 --seed=7166458837 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000019-000010 --seed=8190238668 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000019-000010 --seed=9214018499 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000019-000010 --seed=10237798330 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000019-000010 --seed=11261578161 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000019-000010 --seed=12285357992 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000019-000010 --seed=13309137823 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000019-000010 --seed=14332917654 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000019-000010 --seed=15356697485 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000019-000010 --seed=16380477316 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000019-000010 --seed=17404257147 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000019-000010 --seed=18428036978 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000019-000010 --seed=19451816809 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000019-000010 --seed=20475596640 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:17:43] eval finished: 11.467 seconds
[2019-06-18 10:17:43] Win rate 000019-000010 vs 000015-000009: 0.490
:::MLL 1560874663.333835 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 18}}
[2019-06-18 10:17:43] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-21-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000020-000009 --seed=21 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000020-000009 --seed=1023779852 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000020-000009 --seed=2047559683 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000020-000009 --seed=3071339514 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000020-000009 --seed=4095119345 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000020-000009 --seed=5118899176 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000020-000009 --seed=6142679007 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000020-000009 --seed=7166458838 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000020-000009 --seed=8190238669 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000020-000009 --seed=9214018500 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000020-000009 --seed=10237798331 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000020-000009 --seed=11261578162 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000020-000009 --seed=12285357993 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000020-000009 --seed=13309137824 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000020-000009 --seed=14332917655 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000020-000009 --seed=15356697486 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000020-000009 --seed=16380477317 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000020-000009 --seed=17404257148 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000020-000009 --seed=18428036979 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:18:12] selfplay finished: 29.524 seconds
[2019-06-18 10:18:12] selfplay mn: 29.546 seconds
[2019-06-18 10:18:12] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-21-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779852 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559683 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339514 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119345 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899176 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142679007 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458838 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238669 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018500 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798331 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578162 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285357993 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137824 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917655 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697486 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477317 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257148 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036979 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816810 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596641 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376472 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156303 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000020-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golde
[2019-06-18 10:18:15] train finished: 43.395 seconds
:::MLL 1560874657.079964 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874657.080754 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874657.081582 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:37.179982 47718829368192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_0_0
:::MLL 1560874657.088896 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874657.089639 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874657.090339 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:37.180021 47314893108096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_0_0
W0618 10:17:37.181074 47718829368192 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpqqy95fo3
W0618 10:17:37.181107 47314893108096 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpt_u5kuo7
I0618 10:17:37.182101 47718829368192 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpqqy95fo3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b66b075fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:37.182139 47314893108096 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpt_u5kuo7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b08a3fbbe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:37.182499 47718829368192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:17:37.182542 47314893108096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:17:37.187381 47314893108096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:37.187379 47718829368192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:37.206829 47314893108096 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:17:37.206884 47718829368192 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874657.124429 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874657.125147 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874657.125761 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:37.214474 47307558171520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_0_0
:::MLL 1560874657.116462 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874657.117407 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874657.118253 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:37.214674 47205520429952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_0_0
W0618 10:17:37.215490 47307558171520 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp_mgv6qpd
W0618 10:17:37.215672 47205520429952 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpx_ouhx2x
I0618 10:17:37.216477 47307558171520 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp_mgv6qpd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b06eec97e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:37.216656 47205520429952 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpx_ouhx2x', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aef2cdd0e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:37.216882 47307558171520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:17:37.217063 47205520429952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:17:37.221882 47307558171520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:37.221961 47205520429952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874657.123217 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874657.123973 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874657.124622 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:37.227682 47631926985600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_0_0
:::MLL 1560874657.120759 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874657.121523 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874657.122195 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:37.227946 47867399635840 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_0_0
W0618 10:17:37.228769 47631926985600 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpnw50fdtm
W0618 10:17:37.229008 47867399635840 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp4bfpd0tl
I0618 10:17:37.229855 47631926985600 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpnw50fdtm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5274acde10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:37.230111 47867399635840 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp4bfpd0tl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8947f05e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:37.230307 47631926985600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:17:37.230556 47867399635840 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:17:37.235660 47631926985600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:37.235857 47867399635840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:37.241160 47307558171520 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:17:37.241445 47205520429952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874657.176019 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874657.176457 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874657.176825 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:37.253684 47361420661632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_0_0
:::MLL 1560874657.180190 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874657.180649 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874657.181064 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:37.254601 47629154681728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_0_0
:::MLL 1560874657.145214 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874657.145988 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874657.146649 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:37.254385 47145681683328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_0_0
:::MLL 1560874657.142717 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874657.143448 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874657.144152 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:37.254389 47152755618688 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_0_0
W0618 10:17:37.254702 47361420661632 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpabu3lrm5
I0618 10:17:37.255691 47361420661632 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpabu3lrm5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b13793dee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:17:37.255681 47314893108096 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:17:37.255702 47718829368192 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:17:37.256097 47361420661632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:17:37.255558 47629154681728 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpr4se6cnc
I0618 10:17:37.256554 47629154681728 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpr4se6cnc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b51cf6ede48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:17:37.255478 47145681683328 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpjg671i1h
I0618 10:17:37.256953 47629154681728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:17:37.255507 47152755618688 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp6gn0gyiy
I0618 10:17:37.256584 47145681683328 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpjg671i1h', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae13e325e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:37.256590 47152755618688 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp6gn0gyiy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae2e3d60e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:37.257042 47145681683328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:17:37.257042 47152755618688 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874657.160419 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874657.161205 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874657.161962 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:37.257535 46974560596864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_0_0
:::MLL 1560874657.162500 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874657.163264 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874657.164011 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:37.257500 47786560406400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_0_0
W0618 10:17:37.257950 47631926985600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:17:37.258403 47867399635840 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:17:37.259996 47314893108096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:17:37.260049 47718829368192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:17:37.260917 47361420661632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:37.258521 47786560406400 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpohts0koe
W0618 10:17:37.258549 46974560596864 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpbjq956_x
I0618 10:17:37.259654 47786560406400 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpohts0koe', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b76758b8e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:37.259668 46974560596864 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpbjq956_x', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab96695bda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:17:37.261675 47629154681728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:17:37.260111 47786560406400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:17:37.260116 46974560596864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:17:37.262358 47145681683328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:37.262372 47152755618688 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:17:37.265048 47314893108096 estimator.py:1111] Calling model_fn.
W0618 10:17:37.265159 47314893108096 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:17:37.265143 47718829368192 estimator.py:1111] Calling model_fn.
W0618 10:17:37.265250 47718829368192 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:17:37.266508 47314893108096 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:17:37.266608 47718829368192 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:17:37.264930 46974560596864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:37.264922 47786560406400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874657.201133 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874657.201571 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874657.201942 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:37.276235 47438033314688 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_0_0
:::MLL 1560874657.202580 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874657.203014 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874657.203401 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:37.276617 47348396172160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_0_0
I0618 10:17:37.277282 47438033314688 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b254fb63d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:17:37.277617 47348396172160 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpoeec_tvm
I0618 10:17:37.278387 47438033314688 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:17:37.278594 47348396172160 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpoeec_tvm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1070ebfe80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:37.278990 47348396172160 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:17:37.280323 47361420661632 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874657.193176 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874657.193962 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874657.194663 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:37.279694 46963659142016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_0_0
:::MLL 1560874657.183259 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874657.184213 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874657.185103 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:37.279855 47721242354560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_0_0
:::MLL 1560874657.200731 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874657.201175 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874657.201588 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:37.278943 47388150875008 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_0_0
:::MLL 1560874657.201596 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874657.202018 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874657.202361 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:37.278929 47732258575232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_0_0
W0618 10:17:37.281013 47629154681728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:17:37.280698 46963659142016 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpj90c_leh
W0618 10:17:37.280857 47721242354560 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp83y56msq
W0618 10:17:37.279938 47388150875008 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmphidvtzmx
W0618 10:17:37.279967 47732258575232 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpv1rnlrzo
I0618 10:17:37.281688 46963659142016 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpj90c_leh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab6dccebe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:37.280940 47388150875008 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmphidvtzmx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b19b27c9e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:37.280942 47732258575232 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpv1rnlrzo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b69d0e75e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:37.281843 47721242354560 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp83y56msq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6740492e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:37.282086 46963659142016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:17:37.283044 47438033314688 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:17:37.281349 47388150875008 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:17:37.281349 47732258575232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:17:37.282244 47721242354560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:17:37.283602 47348396172160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:37.284244 47145681683328 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:17:37.284252 47152755618688 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:17:37.284105 47786560406400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:17:37.284227 46974560596864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:17:37.286013 47388150875008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:37.286998 46963659142016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:37.286052 47732258575232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:37.287129 47721242354560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:37.289404 47307558171520 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:17:37.289716 47205520429952 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:17:37.293797 47307558171520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:17:37.294083 47205520429952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560874657.206198 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874657.206625 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874657.206986 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:37.297790 47267533255552 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_0_0
:::MLL 1560874657.208357 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874657.208802 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874657.209371 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:37.298008 47655036916608 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_0_0
I0618 10:17:37.298901 47307558171520 estimator.py:1111] Calling model_fn.
W0618 10:17:37.299009 47307558171520 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:17:37.299247 47205520429952 estimator.py:1111] Calling model_fn.
W0618 10:17:37.299355 47205520429952 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:17:37.298811 47267533255552 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpeggirtcm
W0618 10:17:37.298994 47655036916608 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp47pb9rh4
W0618 10:17:37.300374 47307558171520 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:17:37.299784 47267533255552 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpeggirtcm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afd9d1dbe80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:37.299971 47655036916608 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp47pb9rh4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b57d6226e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:17:37.300741 47205520429952 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:17:37.300187 47267533255552 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:17:37.300369 47655036916608 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:17:37.302085 47438033314688 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:17:37.302746 47348396172160 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:17:37.304940 47267533255552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:37.305030 47655036916608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:37.305114 47388150875008 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:17:37.306043 46963659142016 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:17:37.305116 47732258575232 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:17:37.306652 47721242354560 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:17:37.307135 47867399635840 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:17:37.307271 47631926985600 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:17:37.311420 47867399635840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:17:37.311584 47631926985600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:17:37.316478 47867399635840 estimator.py:1111] Calling model_fn.
W0618 10:17:37.316583 47867399635840 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:17:37.316643 47631926985600 estimator.py:1111] Calling model_fn.
W0618 10:17:37.316753 47631926985600 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:17:37.317943 47867399635840 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:17:37.318106 47631926985600 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560874657.245689 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874657.246141 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874657.246482 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:37.320688 47070366172032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_0_0
:::MLL 1560874657.246403 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874657.246786 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874657.247105 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:37.320988 47004896211840 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000010-000004.tfrecord.zz_0_0
W0618 10:17:37.321678 47070366172032 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp56fjbyj9
W0618 10:17:37.321949 47004896211840 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp4vhgkddg
I0618 10:17:37.322654 47070366172032 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp56fjbyj9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acfb50ade10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:17:37.324042 47655036916608 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:17:37.324070 47267533255552 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:17:37.322904 47004896211840 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp4vhgkddg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac076ba8e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:37.323060 47070366172032 train.py:201] Training, steps [2019-06-18 10:18:16] divide_golden_chunk finished: 3.417 seconds
[2019-06-18 10:18:16] generate golden chunk: 3.431 seconds
[2019-06-18 10:18:16] moving /lfs/lfs12/gma_akey/results/epb312/models/000020-000010.index --> /lfs/lfs12/gma_akey/results/epb312/models/000020-000011.index
[2019-06-18 10:18:16] moving /lfs/lfs12/gma_akey/results/epb312/models/000020-000010.meta --> /lfs/lfs12/gma_akey/results/epb312/models/000020-000011.meta
[2019-06-18 10:18:16] moving /lfs/lfs12/gma_akey/results/epb312/models/000020-000010.pb --> /lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb
[2019-06-18 10:18:16] moving /lfs/lfs12/gma_akey/results/epb312/models/000020-000010.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb312/models/000020-000011.data-00000-of-00001
[2019-06-18 10:18:16] iteration time 19: 48.887 seconds
2019-06-18 10:18:17.559089: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874696.359912 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 20}}
[2019-06-18 10:18:20] minmax time: 3.256 seconds
2019-06-18 10:18:20.825209: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:18:20.830557: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:18:20.835046: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874700.846275 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 19}}
[2019-06-18 10:18:20] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000021-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000021-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000021-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000021-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000021-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000021-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000021-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000021-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000021-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000021-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000021-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:18:20] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-21-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000020-000011 --seed=21 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000020-000011 --seed=1023779852 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000020-000011 --seed=2047559683 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000020-000011 --seed=3071339514 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000020-000011 --seed=4095119345 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000020-000011 --seed=5118899176 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000020-000011 --seed=6142679007 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000020-000011 --seed=7166458838 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000020-000011 --seed=8190238669 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000020-000011 --seed=9214018500 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000020-000011 --seed=10237798331 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000020-000011 --seed=11261578162 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000020-000011 --seed=12285357993 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000020-000011 --seed=13309137824 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000020-000011 --seed=14332917655 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000020-000011 --seed=15356697486 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000020-000011 --seed=16380477317 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000020-000011 --seed=17404257148 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000020-000011 --seed=18428036979 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000020-000011 --seed=19451816810 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000019-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000020-000011 --seed=20475596641 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:18:33] eval finished: 12.580 seconds
[2019-06-18 10:18:33] Win rate 000020-000011 vs 000019-000010: 0.520
:::MLL 1560874713.487756 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 19}}
[2019-06-18 10:18:33] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-22-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000021-000010 --seed=22 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000021-000010 --seed=1023779853 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000021-000010 --seed=2047559684 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000021-000010 --seed=3071339515 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000021-000010 --seed=4095119346 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000021-000010 --seed=5118899177 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000021-000010 --seed=6142679008 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000021-000010 --seed=7166458839 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000021-000010 --seed=8190238670 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000021-000010 --seed=9214018501 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000021-000010 --seed=10237798332 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000021-000010 --seed=11261578163 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000021-000010 --seed=12285357994 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000021-000010 --seed=13309137825 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000021-000010 --seed=14332917656 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000021-000010 --seed=15356697487 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000021-000010 --seed=16380477318 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000021-000010 --seed=17404257149 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000021-000010 --seed=18428036980 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:19:03] selfplay finished: 29.879 seconds
[2019-06-18 10:19:03] selfplay mn: 29.896 seconds
[2019-06-18 10:19:03] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-22-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779853 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559684 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339515 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119346 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899177 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142679008 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458839 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238670 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018501 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798332 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578163 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285357994 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137825 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917656 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697487 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477318 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257149 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036980 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816811 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596642 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376473 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156304 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golde
[2019-06-18 10:19:04] train finished: 43.607 seconds
:::MLL 1560874706.094759 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874706.095633 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874706.096374 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:26.199345 47563722597248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560874706.099070 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874706.099752 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874706.100424 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:26.199628 47471384040320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 10:18:26.200425 47563722597248 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpz94w474k
W0618 10:18:26.200631 47471384040320 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp_89f7ia0
I0618 10:18:26.201428 47563722597248 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpz94w474k', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4293607e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:26.201612 47471384040320 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp_89f7ia0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2d1391ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:26.201830 47563722597248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:18:26.202020 47471384040320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:18:26.206614 47563722597248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:26.206675 47471384040320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874706.117671 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874706.118400 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874706.119119 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:26.217341 47413168165760 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560874706.114006 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874706.114882 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874706.115566 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:26.217412 47265622451072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 10:18:26.218451 47413168165760 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpuk8aqyhe
W0618 10:18:26.218503 47265622451072 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmphk6rw94_
I0618 10:18:26.219455 47413168165760 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpuk8aqyhe', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1f85a22e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:26.219524 47265622451072 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmphk6rw94_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afd2b393e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:26.219855 47413168165760 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:18:26.219937 47265622451072 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:18:26.226270 47563722597248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:26.226281 47471384040320 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:26.224587 47413168165760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:26.224657 47265622451072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874706.141485 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874706.142244 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874706.142908 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:26.237978 47230256227200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560874706.137590 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874706.138488 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874706.139276 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:26.238191 47895363343232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 10:18:26.238991 47230256227200 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp0x74wtie
W0618 10:18:26.239173 47895363343232 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmptf9zncms
I0618 10:18:26.239970 47230256227200 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp0x74wtie', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af4ef3b7e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:26.240148 47895363343232 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmptf9zncms', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8fcab4ae80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:26.240375 47230256227200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:18:26.240547 47895363343232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:18:26.245313 47230256227200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:26.245411 47895363343232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:26.244099 47413168165760 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:26.244479 47265622451072 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:26.264893 47895363343232 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:26.265093 47230256227200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874706.161484 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874706.162398 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874706.163249 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:26.268788 47488136602496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560874706.173131 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874706.173815 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874706.174531 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:26.269120 47139720364928 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 10:18:26.269945 47488136602496 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp3n6azwz4
W0618 10:18:26.270241 47139720364928 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpdj1dmla_
I0618 10:18:26.271053 47488136602496 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp3n6azwz4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b30fa19be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:26.271346 47139720364928 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpdj1dmla_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adfdadfce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:26.271493 47488136602496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874706.191574 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874706.191994 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874706.192348 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:26.272977 47191878255488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_0_0
I0618 10:18:26.271794 47139720364928 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874706.193921 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874706.194293 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874706.194625 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:26.273446 47609205703552 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 10:18:26.274050 47191878255488 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpzqtsj_t2
W0618 10:18:26.275010 47471384040320 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:18:26.275069 47191878255488 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpzqtsj_t2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aebffba1dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:18:26.274487 47609205703552 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpkbmf939m
W0618 10:18:26.275409 47563722597248 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:18:26.275486 47191878255488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:18:26.275512 47609205703552 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpkbmf939m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4d2a619e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:26.275941 47609205703552 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:18:26.276868 47488136602496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874706.198890 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874706.199334 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874706.199764 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:26.276574 47695165244288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560874706.199889 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874706.200348 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874706.200720 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:26.276629 47837700604800 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 10:18:26.277095 47139720364928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:26.279355 47471384040320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:18:26.279808 47563722597248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:18:26.277586 47695165244288 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpqnatt8m4
W0618 10:18:26.277620 47837700604800 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp8hafql3d
W0618 10:18:26.280243 47191878255488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:18:26.278589 47695165244288 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpqnatt8m4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b612df81e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:26.278602 47837700604800 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp8hafql3d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b825dbd0e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:18:26.280653 47609205703552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:18:26.278997 47695165244288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:18:26.279009 47837700604800 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:18:26.284426 47471384040320 estimator.py:1111] Calling model_fn.
W0618 10:18:26.284540 47471384040320 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:18:26.284946 47563722597248 estimator.py:1111] Calling model_fn.
W0618 10:18:26.285056 47563722597248 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:18:26.283690 47695165244288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:26.283654 47837700604800 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:26.285912 47471384040320 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:18:26.286418 47563722597248 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560874706.158250 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874706.158996 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874706.159699 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:26.287451 47973218685824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560874706.155627 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874706.156393 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874706.157124 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:26.287698 47578859189120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 10:18:26.288596 47973218685824 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpn3tkrho1
W0618 10:18:26.288782 47578859189120 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpm05chqnu
I0618 10:18:26.289710 47973218685824 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpn3tkrho1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba1eb3ede80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:26.289870 47578859189120 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpm05chqnu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4619968e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:26.290159 47973218685824 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:18:26.290310 47578859189120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:18:26.292198 47413168165760 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560874706.211472 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874706.211950 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874706.212388 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:26.294255 47648972292992 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560874706.212800 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874706.213298 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874706.213753 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:26.294293 47969163551616 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 10:18:26.293042 47265622451072 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:18:26.295277 47648972292992 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpszp41ze4
I0618 10:18:26.295298 47969163551616 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba0f98a7d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:18:26.295487 47973218685824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:18:26.296237 47648972292992 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpszp41ze4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b566ca79e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:18:26.295658 47578859189120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:18:26.296409 47969163551616 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:18:26.296627 47648972292992 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:18:26.296502 47413168165760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:18:26.297410 47265622451072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:18:26.299741 47191878255488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:26.300207 47609205703552 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:26.298802 47488136602496 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:26.299231 47139720364928 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:26.301039 47969163551616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:26.301233 47648972292992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874706.201722 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874706.202625 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874706.203534 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:26.302331 47551878132608 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_0_0
I0618 10:18:26.301548 47413168165760 estimator.py:1111] Calling model_fn.
:::MLL 1560874706.207811 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874706.208557 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874706.209280 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:26.302395 47044548092800 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 10:18:26.301655 47413168165760 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:18:26.302538 47265622451072 estimator.py:1111] Calling model_fn.
W0618 10:18:26.302650 47265622451072 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:18:26.302735 47837700604800 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:26.302862 47695165244288 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:26.303009 47413168165760 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:18:26.303374 47551878132608 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp69ov16p5
W0618 10:18:26.303407 47044548092800 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpx0ftgaf1
I0618 10:18:26.304485 47551878132608 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp69ov16p5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3fd1644e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:26.304511 47044548092800 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpx0ftgaf1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac9b22a0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:26.304939 47551878132608 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:18:26.304966 47044548092800 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:18:26.304031 47265622451072 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:18:26.309758 47044548092800 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:26.309866 47551878132608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:26.313536 47895363343232 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:18:26.313813 47230256227200 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:18:26.317142 47973218685824 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:26.317854 47895363343232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:18:26.318139 47230256227200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:18:26.317568 47578859189120 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:26.320138 47969163551616 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:26.320351 47648972292992 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:18:26.322941 47895363343232 estimator.py:1111] Calling model_fn.
W0618 10:18:26.323054 47895363343232 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:18:26.323213 47230256227200 estimator.py:1111] Calling model_fn.
W0618 10:18:26.323320 47230256227200 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:18:26.324421 47895363343232 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:18:26.324695 47230256227200 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560874706.244939 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874706.245359 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874706.245705 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:26.323217 47080899310464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560874706.244264 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874706.244722 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874706.245117 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:26.323407 47503310226304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560874706.213140 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874706.213555 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874706.213922 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:26.325548 46960832357248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560874706.215353 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874706.215777 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874706.216142 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:26.325879 47493107102592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 10:18:26.324241 47080899310464 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmptp4t5tsp
W0618 10:18:26.324386 47503310226304 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp35nx05q2
I0618 10:18:26.325232 47080899310464 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmptp4t5tsp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad228ddce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:26.325377 47503310226304 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp35nx05q2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b348284dda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:26.325634 47080899310464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:18:26.325768 47503310226304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:18:26.326575 46960832357248 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpnjflt_94
I0618 10:18:26.327594 46960832357248 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpnjflt_94', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab634517e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:18:26.326931 47493107102592 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpyaj9lgpm
I0618 10:18:26.327905 47493107102592 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpyaj9lgpm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b32225d7e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:26.327998 46960832357248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:18:26.328299 47493107102592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:18:26.329004 47044548092800 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:26.329795 47551878132608 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:26.330305 47080899310464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:26.330349 47503310226304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:26.332721 46960832357248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:26.332879 47493107102592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value[2019-06-18 10:19:06] divide_golden_chunk finished: 3.299 seconds
[2019-06-18 10:19:06] generate golden chunk: 3.314 seconds
[2019-06-18 10:19:06] moving /lfs/lfs12/gma_akey/results/epb312/models/000021-000011.pb --> /lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb
[2019-06-18 10:19:06] moving /lfs/lfs12/gma_akey/results/epb312/models/000021-000011.index --> /lfs/lfs12/gma_akey/results/epb312/models/000021-000012.index
[2019-06-18 10:19:06] moving /lfs/lfs12/gma_akey/results/epb312/models/000021-000011.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb312/models/000021-000012.data-00000-of-00001
[2019-06-18 10:19:06] moving /lfs/lfs12/gma_akey/results/epb312/models/000021-000011.meta --> /lfs/lfs12/gma_akey/results/epb312/models/000021-000012.meta
[2019-06-18 10:19:06] iteration time 20: 50.381 seconds
2019-06-18 10:19:07.934553: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874746.741239 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 21}}
[2019-06-18 10:19:11] minmax time: 3.263 seconds
2019-06-18 10:19:11.207520: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:19:11.213004: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:19:11.217516: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874751.228567 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 20}}
[2019-06-18 10:19:11] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000022-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000022-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000022-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000022-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000022-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000022-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000022-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000022-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000022-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000022-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000022-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:19:11] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-22-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000021-000012 --seed=22 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000021-000012 --seed=1023779853 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000021-000012 --seed=2047559684 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000021-000012 --seed=3071339515 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000021-000012 --seed=4095119346 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000021-000012 --seed=5118899177 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000021-000012 --seed=6142679008 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000021-000012 --seed=7166458839 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000021-000012 --seed=8190238670 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000021-000012 --seed=9214018501 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000021-000012 --seed=10237798332 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000021-000012 --seed=11261578163 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000021-000012 --seed=12285357994 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000021-000012 --seed=13309137825 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000021-000012 --seed=14332917656 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000021-000012 --seed=15356697487 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000021-000012 --seed=16380477318 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000021-000012 --seed=17404257149 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000021-000012 --seed=18428036980 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000021-000012 --seed=19451816811 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000021-000012 --seed=20475596642 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:19:22] eval finished: 11.050 seconds
[2019-06-18 10:19:22] Win rate 000021-000012 vs 000020-000011: 0.660
:::MLL 1560874762.340651 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 20}}
[2019-06-18 10:19:22] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-23-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000022-000011 --seed=23 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000022-000011 --seed=1023779854 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000022-000011 --seed=2047559685 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000022-000011 --seed=3071339516 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000022-000011 --seed=4095119347 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000022-000011 --seed=5118899178 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000022-000011 --seed=6142679009 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000022-000011 --seed=7166458840 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000022-000011 --seed=8190238671 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000022-000011 --seed=9214018502 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000022-000011 --seed=10237798333 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000022-000011 --seed=11261578164 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000022-000011 --seed=12285357995 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000022-000011 --seed=13309137826 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000022-000011 --seed=14332917657 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000022-000011 --seed=15356697488 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000022-000011 --seed=16380477319 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000022-000011 --seed=17404257150 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000022-000011 --seed=18428036981 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:19:51] selfplay finished: 29.465 seconds
[2019-06-18 10:19:51] selfplay mn: 29.486 seconds
[2019-06-18 10:19:51] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-23-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=23 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779854 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559685 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339516 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119347 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899178 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142679009 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458840 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238671 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018502 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798333 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578164 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285357995 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137826 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917657 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697488 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477319 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257150 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036981 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816812 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596643 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376474 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156305 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golde
[2019-06-18 10:19:55] divide_golden_chunk finished: 3.245 seconds
[2019-06-18 10:19:55] generate golden chunk: 3.260 seconds
[2019-06-18 10:19:55] train finished: 44.154 seconds
:::MLL 1560874756.494574 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874756.495485 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874756.496340 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:16.608180 47943902282624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 10:19:16.609293 47943902282624 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp1_tpbe4n
I0618 10:19:16.610382 47943902282624 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp1_tpbe4n', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9b17da1e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:16.610851 47943902282624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874756.502088 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874756.503014 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874756.503844 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:16.615794 47386123764608 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560874756.512631 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874756.513393 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874756.514092 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:16.616059 47298658464640 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560874756.516129 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874756.516873 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874756.517576 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:16.614749 46961497183104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560874756.507521 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874756.508408 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874756.509243 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:16.614768 47057611006848 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 10:19:16.616169 47943902282624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:16.616829 47386123764608 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp4hhtzasq
W0618 10:19:16.617057 47298658464640 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpgh20otza
I0618 10:19:16.617844 47386123764608 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp4hhtzasq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1939a95e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:16.618045 47298658464640 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpgh20otza', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b04dc52be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:16.618246 47386123764608 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:19:16.615869 46961497183104 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpudf3yjfy
I0618 10:19:16.618448 47298658464640 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:19:16.615899 47057611006848 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp7tcf237o
I0618 10:19:16.616984 46961497183104 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpudf3yjfy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab65bf1ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:16.616989 47057611006848 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp7tcf237o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2accbcc67e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:16.617431 46961497183104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:19:16.617443 47057611006848 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:19:16.623187 47386123764608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:16.623281 47298658464640 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874756.521933 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874756.522660 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874756.523387 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:16.623514 47348107043712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560874756.519796 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874756.520529 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874756.521223 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:16.623746 47939901637504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 10:19:16.622695 46961497183104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:16.622732 47057611006848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:16.624521 47348107043712 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpxe2f1qn5
W0618 10:19:16.624733 47939901637504 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp94chg6ui
I0618 10:19:16.625531 47348107043712 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpxe2f1qn5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b105fb03e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:16.625737 47939901637504 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp94chg6ui', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9a29651e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:16.625930 47348107043712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:19:16.626174 47939901637504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:19:16.630867 47348107043712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:16.631072 47939901637504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:16.638008 47943902282624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:19:16.642574 47386123764608 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:19:16.642870 47298658464640 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:19:16.644510 47057611006848 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:19:16.644504 46961497183104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874756.544082 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874756.544987 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874756.545816 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:16.647397 47934489285504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560874756.543830 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874756.544725 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874756.545554 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:16.647688 47293648290688 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 10:19:16.650160 47348107043712 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:19:16.650710 47939901637504 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:19:16.648439 47934489285504 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp5saxxznd
W0618 10:19:16.648651 47293648290688 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp5htxgwtt
I0618 10:19:16.649433 47934489285504 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp5saxxznd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b98e6cb2e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:16.649655 47293648290688 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp5htxgwtt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b03b1b19e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:16.649836 47934489285504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:19:16.650053 47293648290688 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:19:16.654682 47934489285504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:16.654885 47293648290688 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874756.550642 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874756.551567 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874756.552445 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:16.660857 47354414363520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560874756.565640 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874756.566384 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874756.567112 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:16.661031 47475349267328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 10:19:16.661894 47354414363520 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpeco7pq0_
W0618 10:19:16.662015 47475349267328 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpt_k8jssd
I0618 10:19:16.662906 47354414363520 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpeco7pq0_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b11d7a24e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:16.663025 47475349267328 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpt_k8jssd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2dffea7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:16.663310 47354414363520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:19:16.663431 47475349267328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:19:16.668071 47354414363520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:16.668177 47475349267328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874756.592784 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874756.593376 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874756.593873 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:16.674505 47319473959808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560874756.588865 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874756.589338 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874756.589770 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:16.674609 47324452385664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560874756.590112 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874756.590597 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874756.591015 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:16.674655 47908415566720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 10:19:16.673876 47934489285504 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:19:16.674317 47293648290688 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:19:16.675520 47319473959808 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpa1wxdksr
W0618 10:19:16.675690 47324452385664 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpkc6yxdf5
I0618 10:19:16.676555 47319473959808 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpa1wxdksr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b09b5060e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:19:16.675660 47908415566720 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpnz98bpjz
I0618 10:19:16.676642 47908415566720 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpnz98bpjz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b92d4adce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:16.676677 47324452385664 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpkc6yxdf5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0addc2ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:16.676985 47319473959808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:19:16.677042 47908415566720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:19:16.677085 47324452385664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:19:16.681649 47324452385664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:16.681758 47319473959808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:16.681668 47908415566720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874756.599231 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874756.599672 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874756.600055 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:16.679907 47332211848064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 10:19:16.680933 47332211848064 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp7e96g_6b
:::MLL 1560874756.603522 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874756.603940 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874756.604301 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:16.681601 47387362890624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_0_0
I0618 10:19:16.681930 47332211848064 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp7e96g_6b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0cac429e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560874756.610573 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874756.611010 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874756.611847 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:16.683607 47164339991424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_0_0
I0618 10:19:16.682335 47332211848064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:19:16.682571 47387362890624 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp0i855hw7
I0618 10:19:16.683568 47387362890624 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp0i855hw7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b198384de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:16.684599 47164339991424 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae596517d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:16.683948 47387362890624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:19:16.685717 47164339991424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:19:16.687431 47354414363520 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:19:16.686945 47332211848064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:16.687912 47475349267328 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:19:16.688490 47387362890624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:16.690257 47164339991424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:16.690838 47386123764608 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:19:16.691073 47298658464640 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:19:16.692175 47943902282624 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:19:16.695134 47386123764608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:19:16.695391 47298658464640 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:19:16.694523 46961497183104 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:19:16.694679 47057611006848 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:19:16.697099 47943902282624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:19:16.698837 47348107043712 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:19:16.699015 47939901637504 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:19:16.700182 47386123764608 estimator.py:1111] Calling model_fn.
W0618 10:19:16.700293 47386123764608 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:19:16.700496 47298658464640 estimator.py:1111] Calling model_fn.
W0618 10:19:16.698812 46961497183104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:19:16.700605 47298658464640 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:19:16.698950 47057611006848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:19:16.700711 47324452385664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:19:16.700770 47908415566720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:19:16.700850 47319473959808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:19:16.701655 47386123764608 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:19:16.701983 47298658464640 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560874756.545870 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874756.546789 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874756.547637 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:16.702318 47191430828928 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 10:19:16.703167 47348107043712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:19:16.703333 47939901637504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:19:16.702894 47943902282624 estimator.py:1111] Calling model_fn.
W0618 10:19:16.703014 47943902282624 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:19:16.703388 47191430828928 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpyibhsxzi
I0618 10:19:16.704459 47191430828928 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpyibhsxzi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aebe50eee80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:19:16.704527 47943902282624 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:19:16.704894 47191430828928 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:19:16.703817 46961497183104 estimator.py:1111] Calling model_fn.
W0618 10:19:16.703925 46961497183104 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:19:16.703970 47057611006848 estimator.py:1111] Calling model_fn.
W0618 10:19:16.704082 47057611006848 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:19:16.705256 46961497183104 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:19:16.705430 47057611006848 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:19:16.705991 47332211848064 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:19:16.708260 47348107043712 estimator.py:1111] Calling model_fn.
W0618 10:19:16.708370 47348107043712 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:19:16.708385 47939901637504 estimator.py:1111] Calling model_fn.
W0618 10:19:16.708493 47939901637504 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560874756.627927 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874756.628516 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874756.628891 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:16.706982 47539495142272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 10:19:16.707485 47387362890624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:19:16.709355 47164339991424 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874756.626211 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874756.626685 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874756.627069 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:16.707474 47519543669632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 10:19:16.709734 47348107043712 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:19:16.709848 47939901637504 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:19:16.709722 47191430828928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:16.707991 47539495142272 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp8j43d1h3
I0618 10:19:16.708982 47539495142272 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp8j43d1h3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3cef4ede10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:19:16.708456 47519543669632 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpx53990rg
I0618 10:19:16.709375 47539495142272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:19:16.709425 47519543669632 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpx53990rg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b384a1b6e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:16.709824 47519543669632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:19:16.714000 47539495142272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:16.714351 47519543669632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874756.587429 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874756.587948 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874756.588422 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:16.720390 47998844289920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 10:19:16.721434 47998844289920 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmps0si03h3
I0618 10:19:16.722419 47998844289920 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmps0si03h3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba7e2a69e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:16.722826 47998844289920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:19:16.721971 47934489285504 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_f[2019-06-18 10:19:55] moving /lfs/lfs12/gma_akey/results/epb312/models/000022-000012.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb312/models/000022-000013.data-00000-of-00001
[2019-06-18 10:19:55] moving /lfs/lfs12/gma_akey/results/epb312/models/000022-000012.meta --> /lfs/lfs12/gma_akey/results/epb312/models/000022-000013.meta
[2019-06-18 10:19:55] moving /lfs/lfs12/gma_akey/results/epb312/models/000022-000012.index --> /lfs/lfs12/gma_akey/results/epb312/models/000022-000013.index
[2019-06-18 10:19:55] moving /lfs/lfs12/gma_akey/results/epb312/models/000022-000012.pb --> /lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb
[2019-06-18 10:19:55] iteration time 21: 48.711 seconds
2019-06-18 10:19:56.655381: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874795.452841 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 22}}
[2019-06-18 10:19:59] minmax time: 3.290 seconds
2019-06-18 10:19:59.955643: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:19:59.961225: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:19:59.965923: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874799.977300 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 21}}
[2019-06-18 10:19:59] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000023-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000023-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000023-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000023-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000023-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000023-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000023-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000023-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000023-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000023-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000023-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:20:00] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-23-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000022-000013 --seed=23 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000022-000013 --seed=1023779854 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000022-000013 --seed=2047559685 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000022-000013 --seed=3071339516 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000022-000013 --seed=4095119347 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000022-000013 --seed=5118899178 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000022-000013 --seed=6142679009 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000022-000013 --seed=7166458840 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000022-000013 --seed=8190238671 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000022-000013 --seed=9214018502 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000022-000013 --seed=10237798333 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000022-000013 --seed=11261578164 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000022-000013 --seed=12285357995 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000022-000013 --seed=13309137826 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000022-000013 --seed=14332917657 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000022-000013 --seed=15356697488 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000022-000013 --seed=16380477319 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000022-000013 --seed=17404257150 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000022-000013 --seed=18428036981 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000022-000013 --seed=19451816812 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000021-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000022-000013 --seed=20475596643 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:20:10] eval finished: 10.940 seconds
[2019-06-18 10:20:10] Win rate 000022-000013 vs 000021-000012: 0.610
:::MLL 1560874810.980837 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 21}}
[2019-06-18 10:20:10] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-24-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000023-000012 --seed=24 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000023-000012 --seed=1023779855 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000023-000012 --seed=2047559686 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000023-000012 --seed=3071339517 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000023-000012 --seed=4095119348 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000023-000012 --seed=5118899179 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000023-000012 --seed=6142679010 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000023-000012 --seed=7166458841 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000023-000012 --seed=8190238672 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000023-000012 --seed=9214018503 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000023-000012 --seed=10237798334 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000023-000012 --seed=11261578165 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000023-000012 --seed=12285357996 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000023-000012 --seed=13309137827 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000023-000012 --seed=14332917658 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000023-000012 --seed=15356697489 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000023-000012 --seed=16380477320 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000023-000012 --seed=17404257151 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000023-000012 --seed=18428036982 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:20:40] selfplay finished: 29.820 seconds
[2019-06-18 10:20:40] selfplay mn: 29.838 seconds
[2019-06-18 10:20:40] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-24-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=24 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779855 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559686 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339517 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119348 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899179 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142679010 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458841 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238672 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018503 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798334 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578165 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285357996 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137827 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917658 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697489 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477320 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257151 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036982 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816813 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596644 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376475 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156306 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golde
[2019-06-18 10:20:44] divide_golden_chunk finished: 3.321 seconds
[2019-06-18 10:20:44] generate golden chunk: 3.335 seconds
[2019-06-18 10:20:44] train finished: 44.209 seconds
:::MLL 1560874805.197912 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874805.198701 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874805.199422 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:05.305306 47675853607808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_0_0
:::MLL 1560874805.196873 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874805.197694 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874805.198426 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:05.305506 47409285510016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_0_0
W0618 10:20:05.306347 47675853607808 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpntm37fia
W0618 10:20:05.306513 47409285510016 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpht494hae
I0618 10:20:05.307349 47675853607808 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpntm37fia', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5caee7ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:05.307484 47409285510016 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpht494hae', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1e9e358e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:05.307749 47675853607808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:20:05.307883 47409285510016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:05.312589 47675853607808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:05.312629 47409285510016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:05.331877 47409285510016 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:05.332020 47675853607808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874805.237747 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874805.238630 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874805.239510 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:05.337817 47286725104512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_0_0
W0618 10:20:05.338930 47286725104512 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp0l7smxlv
I0618 10:20:05.340049 47286725104512 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp0l7smxlv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b02150a2e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560874805.225767 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874805.226714 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874805.227564 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:05.341600 47306157687680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_0_0
I0618 10:20:05.340504 47286725104512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:05.342700 47306157687680 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp7n56yzyy
I0618 10:20:05.343819 47306157687680 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp7n56yzyy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b069b4fde80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:05.344268 47306157687680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:05.345853 47286725104512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:05.349451 47306157687680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874805.262497 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874805.263365 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874805.264101 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:05.352399 47038793446272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_0_0
W0618 10:20:05.353389 47038793446272 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp0qroypsr
I0618 10:20:05.354530 47038793446272 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp0qroypsr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac85b294e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:05.354964 47038793446272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:05.359642 47038793446272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874805.272804 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874805.273686 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874805.274480 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:05.360073 47815024903040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_0_0
W0618 10:20:05.361193 47815024903040 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpkrvnhdrm
I0618 10:20:05.362317 47815024903040 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpkrvnhdrm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7d16295e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:05.362793 47815024903040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:05.369067 47306157687680 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:05.367953 47286725104512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:05.368108 47815024903040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874805.274753 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874805.275525 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874805.276227 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:05.371737 47343241249664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_0_0
:::MLL 1560874805.264785 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874805.265714 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874805.266559 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:05.371992 46946793530240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_0_0
:::MLL 1560874805.287041 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874805.287549 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874805.287945 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:05.374886 47416901813120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_0_0
W0618 10:20:05.372815 47343241249664 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpfunpdicd
W0618 10:20:05.373038 46946793530240 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpn39d9o47
I0618 10:20:05.373927 47343241249664 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpfunpdicd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0f3daa0da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:05.374153 46946793530240 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpn39d9o47', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab2ef89fda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:05.374353 47343241249664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:20:05.374547 46946793530240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:05.375966 47416901813120 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpnzk7rksv
I0618 10:20:05.376958 47416901813120 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpnzk7rksv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b20642d1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:05.377360 47416901813120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:05.378981 47038793446272 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:05.380155 47409285510016 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:05.380330 47675853607808 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:05.379019 47343241249664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:05.379205 46946793530240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:05.382040 47416901813120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874805.286805 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874805.287331 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874805.287732 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:05.382524 47641873654656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_0_0
W0618 10:20:05.383497 47641873654656 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpjnaldwri
I0618 10:20:05.384474 47641873654656 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpjnaldwri', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b54c58afe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:20:05.384459 47409285510016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:20:05.384643 47675853607808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:20:05.384871 47641873654656 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:05.389374 47641873654656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:20:05.389540 47409285510016 estimator.py:1111] Calling model_fn.
W0618 10:20:05.389651 47409285510016 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:20:05.389737 47675853607808 estimator.py:1111] Calling model_fn.
W0618 10:20:05.389852 47675853607808 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:20:05.391009 47409285510016 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:20:05.391214 47675853607808 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:20:05.390615 47815024903040 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874805.294214 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874805.295138 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874805.296030 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:05.397947 47530148328320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_0_0
W0618 10:20:05.398172 47343241249664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874805.306929 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874805.307672 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874805.308346 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:05.399045 46920293172096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_0_0
W0618 10:20:05.398679 46946793530240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:05.398967 47530148328320 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp2kh9jpui
I0618 10:20:05.399974 47530148328320 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp2kh9jpui', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3ac231ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:05.400381 47530148328320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:05.401385 47416901813120 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:05.400050 46920293172096 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpau88t1ua
I0618 10:20:05.401084 46920293172096 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpau88t1ua', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aacc3fe8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:05.401518 46920293172096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:05.405352 47530148328320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:05.406154 46920293172096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:05.408316 47641873654656 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874805.328973 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874805.329545 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874805.330034 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:05.408335 47435669312384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_0_0
I0618 10:20:05.409416 47435669312384 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b24c2ce5d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:05.410604 47435669312384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874805.337655 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874805.338125 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874805.338624 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:05.413544 47160419943296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_0_0
W0618 10:20:05.414551 47160419943296 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpv5mv9fu9
W0618 10:20:05.415342 47435669312384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:20:05.415519 47160419943296 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpv5mv9fu9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae4acaa2e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:05.415915 47160419943296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:05.418203 47306157687680 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:05.420419 47160419943296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:05.422559 47306157687680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:20:05.421309 47286725104512 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560874805.339246 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874805.339738 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874805.340140 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:05.421229 47067299054464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_0_0
W0618 10:20:05.422240 47067299054464 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp7d6j820c
I0618 10:20:05.423221 47067299054464 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp7d6j820c', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acefe3a5e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560874805.342494 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874805.342894 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874805.343340 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:05.423453 47705776182144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_0_0
I0618 10:20:05.423620 47067299054464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:05.425256 47530148328320 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:05.425662 46920293172096 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:05.426587 47038793446272 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:05.424425 47705776182144 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpapbqvssw
I0618 10:20:05.425403 47705776182144 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpapbqvssw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b63a66e1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:20:05.425771 47286725104512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:20:05.425810 47705776182144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:20:05.427659 47306157687680 estimator.py:1111] Calling model_fn.
W0618 10:20:05.427770 47306157687680 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:20:05.429166 47306157687680 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:20:05.428190 47067299054464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:05.430891 47038793446272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:20:05.430509 47705776182144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:20:05.431152 47286725104512 estimator.py:1111] Calling model_fn.
W0618 10:20:05.431264 47286725104512 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:20:05.432683 47286725104512 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:20:05.434551 47435669312384 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:20:05.435955 47038793446272 estimator.py:1111] Calling model_fn.
W0618 10:20:05.436066 47038793446272 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:20:05.437427 47038793446272 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:20:05.439548 47160419943296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874805.357676 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874805.358124 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874805.358474 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:05.440264 47053938480000 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_0_0
:::MLL 1560874805.356760 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874805.357255 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874805.357679 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:05.440323 47999973213056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_0_0
W0618 10:20:05.442070 47815024903040 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:05.441351 47999973213056 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp9uehewz6
W0618 10:20:05.441382 47053938480000 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpcez8n2yu
I0618 10:20:05.442336 47999973213056 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp9uehewz6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba825f09e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:05.442359 47053938480000 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpcez8n2yu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acbe1e01e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:05.442739 47999973213056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:20:05.442763 47053938480000 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:05.445999 47343241249664 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:05.446560 47815024903040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:20:05.447018 46946793530240 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:05.448715 47416901813120 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:05.447420 47067299054464 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:05.447382 47999973213056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:05.447381 47053938480000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874805.267466 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874805.268332 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874805.269011 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:05.448408 47552838046592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_0_0
:::MLL 1560874805.270951 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874805.271687 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874805.272359 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:05.449719 47106845459328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_0_0
W0618 10:20:05.449561 47552838046592 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmppkidw1na
I0618 10:20:05.450666 47552838046592 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmppkidw1na', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b400a9b6e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:20:05.449677 47705776182144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:20:05.451131 47552838046592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:05.450273 47343241249664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:20:05.450849 47106845459328 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpz4i1lb0t
I0618 10:20:05.451960 47106845459328 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpz4i1lb0t', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad833608e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:05.452419 47106845459328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:05.453014 47416901813120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:20:05.451371 46946793530240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:20:05.451831 47815024903040 estimator.py:1111] Calling model_fn.
W0618 10:20:05.451944 47815024903040 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:20:05.453438 47815024903040 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:20:05.455217 47641873654656 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560874805.370509 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874805.371071 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874805.371561 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:05.455136 47304971178880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000013-000007.tfrecord.zz_0_0
I0618 10:20:05.455279 47343241249664 estimator.py:1111] Calling model_fn.
W0618 10:20:05.455388 47343241249664 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutiona[2019-06-18 10:20:44] moving /lfs/lfs12/gma_akey/results/epb312/models/000023-000013.meta --> /lfs/lfs12/gma_akey/results/epb312/models/000023-000014.meta
[2019-06-18 10:20:44] moving /lfs/lfs12/gma_akey/results/epb312/models/000023-000013.pb --> /lfs/lfs12/gma_akey/results/epb312/models/000023-000014.pb
[2019-06-18 10:20:44] moving /lfs/lfs12/gma_akey/results/epb312/models/000023-000013.index --> /lfs/lfs12/gma_akey/results/epb312/models/000023-000014.index
[2019-06-18 10:20:44] moving /lfs/lfs12/gma_akey/results/epb312/models/000023-000013.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb312/models/000023-000014.data-00000-of-00001
[2019-06-18 10:20:44] iteration time 22: 48.795 seconds
2019-06-18 10:20:45.535371: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874844.248479 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 23}}
[2019-06-18 10:20:48] minmax time: 3.238 seconds
2019-06-18 10:20:48.783651: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:20:48.789210: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:20:48.793825: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874848.805048 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 22}}
[2019-06-18 10:20:48] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000024-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000024-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000024-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000024-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000024-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000024-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000024-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000024-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000024-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000024-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000024-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:20:48] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-24-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000023-000014 --seed=24 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000023-000014 --seed=1023779855 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000023-000014 --seed=2047559686 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000023-000014 --seed=3071339517 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000023-000014 --seed=4095119348 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000023-000014 --seed=5118899179 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000023-000014 --seed=6142679010 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000023-000014 --seed=7166458841 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000023-000014 --seed=8190238672 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000023-000014 --seed=9214018503 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000023-000014 --seed=10237798334 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000023-000014 --seed=11261578165 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000023-000014 --seed=12285357996 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000023-000014 --seed=13309137827 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000023-000014 --seed=14332917658 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000023-000014 --seed=15356697489 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000023-000014 --seed=16380477320 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000023-000014 --seed=17404257151 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000023-000014 --seed=18428036982 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000023-000014 --seed=19451816813 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000023-000014 --seed=20475596644 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:21:00] eval finished: 11.267 seconds
[2019-06-18 10:21:00] Win rate 000023-000014 vs 000022-000013: 0.360
:::MLL 1560874860.136269 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 22}}
[2019-06-18 10:21:00] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-25-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000024-000013 --seed=25 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000024-000013 --seed=1023779856 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000024-000013 --seed=2047559687 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000024-000013 --seed=3071339518 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000024-000013 --seed=4095119349 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000024-000013 --seed=5118899180 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000024-000013 --seed=6142679011 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000024-000013 --seed=7166458842 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000024-000013 --seed=8190238673 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000024-000013 --seed=9214018504 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000024-000013 --seed=10237798335 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000024-000013 --seed=11261578166 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000024-000013 --seed=12285357997 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000024-000013 --seed=13309137828 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000024-000013 --seed=14332917659 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000024-000013 --seed=15356697490 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000024-000013 --seed=16380477321 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000024-000013 --seed=17404257152 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000024-000013 --seed=18428036983 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:21:29] selfplay finished: 29.803 seconds
[2019-06-18 10:21:29] selfplay mn: 29.821 seconds
[2019-06-18 10:21:29] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-25-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=25 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779856 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559687 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339518 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119349 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899180 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142679011 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458842 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238673 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018504 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798335 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578166 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285357997 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137828 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917659 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697490 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477321 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257152 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036983 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816814 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596645 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376476 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156307 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golde
[2019-06-18 10:21:32] train finished: 43.636 seconds
:::MLL 1560874853.997124 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874853.998000 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874853.998819 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:54.099164 47381792850816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_0_0
:::MLL 1560874854.006088 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874854.006793 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874854.007538 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:54.100185 47450206282624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_0_0
W0618 10:20:54.100203 47381792850816 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpf9ak1qrr
I0618 10:20:54.101223 47381792850816 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpf9ak1qrr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b183784de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:54.101630 47381792850816 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:54.101176 47450206282624 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpb3yfos_g
I0618 10:20:54.102195 47450206282624 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpb3yfos_g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b282546fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:54.102589 47450206282624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:54.106559 47381792850816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:54.107593 47450206282624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:54.125679 47381792850816 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:54.127608 47450206282624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874854.059684 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874854.060437 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874854.061101 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:54.155252 47574837146496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_0_0
:::MLL 1560874854.056826 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874854.057542 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874854.058210 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:54.155368 47513918464896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_0_0
W0618 10:20:54.156303 47574837146496 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp2rw9i7rl
W0618 10:20:54.156347 47513918464896 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpyol6ohl6
I0618 10:20:54.157334 47574837146496 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp2rw9i7rl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4529db0e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:54.157334 47513918464896 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpyol6ohl6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b36fad1be80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:54.157728 47513918464896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:20:54.157741 47574837146496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:54.162722 47574837146496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:54.162851 47513918464896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874854.066281 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874854.067225 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874854.068103 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:54.167111 47228181390208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_0_0
W0618 10:20:54.168238 47228181390208 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp02z5czn5
I0618 10:20:54.169363 47228181390208 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp02z5czn5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af4738ffe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:54.169830 47228181390208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:54.173906 47381792850816 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560874854.081214 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874854.082067 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874854.082845 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:54.173164 47375184225152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_0_0
W0618 10:20:54.174285 47375184225152 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpdrhfx8uv
W0618 10:20:54.175179 47228181390208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:20:54.175395 47375184225152 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpdrhfx8uv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b16ad9d3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:54.175852 47375184225152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:54.177506 47450206282624 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:54.178208 47381792850816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:20:54.182240 47513918464896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:54.182382 47574837146496 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:54.182240 47450206282624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:20:54.181072 47375184225152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:20:54.183727 47381792850816 estimator.py:1111] Calling model_fn.
W0618 10:20:54.183836 47381792850816 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:20:54.185235 47381792850816 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:20:54.187597 47450206282624 estimator.py:1111] Calling model_fn.
W0618 10:20:54.187704 47450206282624 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:20:54.189075 47450206282624 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560874854.108449 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874854.108894 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874854.109296 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:54.193648 47808286409600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_0_0
:::MLL 1560874854.089917 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874854.090672 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874854.091359 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:54.192636 47896131441536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_0_0
:::MLL 1560874854.082247 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874854.083109 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874854.083963 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:54.192694 47801074733952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_0_0
W0618 10:20:54.194728 47808286409600 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpaswt5ron
I0618 10:20:54.195778 47808286409600 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpaswt5ron', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7b84840e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:20:54.193749 47801074733952 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp3pfecfi0
W0618 10:20:54.193777 47896131441536 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpgvhz4yb0
I0618 10:20:54.196247 47808286409600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:20:54.194728 47801074733952 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp3pfecfi0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b79d6aaae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:54.194773 47896131441536 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpgvhz4yb0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8ff87cee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:54.195124 47801074733952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:20:54.195173 47896131441536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:54.197531 47228181390208 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:54.201252 47808286409600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:54.200042 47896131441536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:54.200052 47801074733952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:54.203365 47375184225152 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874854.118591 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874854.119062 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874854.119485 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:54.207670 46939565638528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_0_0
W0618 10:20:54.208727 46939565638528 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpgeh869ix
I0618 10:20:54.209753 46939565638528 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpgeh869ix', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab140b91e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:54.210178 46939565638528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:54.214979 46939565638528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874854.132891 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874854.133392 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874854.133829 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:54.217202 47043151057792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_0_0
W0618 10:20:54.218226 47043151057792 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpabysa629
I0618 10:20:54.219208 47043151057792 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpabysa629', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac95ee51e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:54.219608 47043151057792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874854.138301 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874854.138752 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874854.139158 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:54.219822 47128811369344 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_0_0
W0618 10:20:54.219054 47801074733952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:54.219156 47896131441536 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:20:54.220827 47128811369344 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2add50a5bd68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:20:54.221635 47808286409600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:20:54.221946 47128811369344 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:54.224235 47043151057792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874854.118479 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874854.119312 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874854.120068 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:54.223413 47504226288512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_0_0
:::MLL 1560874854.118595 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874854.119452 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874854.120255 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:54.223612 47017845965696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_0_0
W0618 10:20:54.224469 47504226288512 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpbdyeqasi
W0618 10:20:54.224593 47017845965696 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpvoixswpa
I0618 10:20:54.225468 47504226288512 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpbdyeqasi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b34b91ece48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:54.225571 47017845965696 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpvoixswpa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac37a981e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:20:54.226499 47128811369344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:20:54.225877 47504226288512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:20:54.225971 47017845965696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:54.231043 47513918464896 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:54.231168 47574837146496 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:54.230584 47504226288512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:54.230592 47017845965696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:54.235038 46939565638528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:54.235376 47513918464896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:20:54.235479 47574837146496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:20:54.240494 47513918464896 estimator.py:1111] Calling model_fn.
I0618 10:20:54.240562 47574837146496 estimator.py:1111] Calling model_fn.
W0618 10:20:54.240606 47513918464896 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:20:54.240674 47574837146496 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:20:54.241970 47513918464896 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:20:54.242044 47574837146496 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:20:54.243313 47043151057792 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:54.245596 47128811369344 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874854.161596 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874854.161977 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874854.162309 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:54.246335 47153905968000 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_0_0
:::MLL 1560874854.163187 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874854.163562 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874854.163896 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:54.247041 47853781922688 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_0_0
W0618 10:20:54.247350 47153905968000 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpyyrcatjt
I0618 10:20:54.248379 47153905968000 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpyyrcatjt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae32866fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:54.248800 47153905968000 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:54.248037 47853781922688 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpk37hhmp5
I0618 10:20:54.249100 47853781922688 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpk37hhmp5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b861c427e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:20:54.249945 47504226288512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:20:54.249518 47853781922688 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:54.250699 47017845965696 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:54.249949 47228181390208 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:54.253431 47153905968000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:54.254012 47853781922688 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:54.254241 47228181390208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:20:54.255121 47375184225152 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560874854.172683 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874854.173188 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874854.173621 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:54.255878 47502188618624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_0_0
W0618 10:20:54.256891 47502188618624 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp_55vz2un
I0618 10:20:54.257876 47502188618624 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp_55vz2un', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b343faa7da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:54.258282 47502188618624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874854.176639 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874854.177083 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874854.177461 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:54.258408 47831202919296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_0_0
I0618 10:20:54.259304 47228181390208 estimator.py:1111] Calling model_fn.
W0618 10:20:54.259414 47228181390208 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:20:54.259447 47375184225152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:20:54.259345 47831202919296 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpheysot4q
I0618 10:20:54.260318 47831202919296 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpheysot4q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b80da724e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:54.260718 47831202919296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:54.260756 47228181390208 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:20:54.262985 47502188618624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:20:54.264585 47375184225152 estimator.py:1111] Calling model_fn.
W0618 10:20:54.264697 47375184225152 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:20:54.265318 47831202919296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:54.266077 47375184225152 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:20:54.266728 47801074733952 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:54.267328 47896131441536 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:54.271574 47808286409600 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:54.271024 47801074733952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:20:54.271615 47896131441536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:20:54.272345 47153905968000 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:54.273086 47853781922688 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:54.276197 47808286409600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:20:54.276090 47801074733952 estimator.py:1111] Calling model_fn.
W0618 10:20:54.276200 47801074733952 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:20:54.276698 47896131441536 estimator.py:1111] Calling model_fn.
W0618 10:20:54.276810 47896131441536 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:20:54.277547 47801074733952 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:20:54.278162 47896131441536 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:20:54.281682 47808286409600 estimator.py:1111] Calling model_fn.
W0618 10:20:54.281793 47808286409600 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560874854.085451 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874854.086263 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874854.087016 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:54.282146 47928664052608 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_0_0
:::MLL 1560874854.086396 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874854.087199 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874854.087864 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:54.282450 47107666424704 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000014-000008.tfrecord.zz_0_0
W0618 10:20:54.283260 47808286409600 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:20:54.282427 47502188618624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:54.283288 47928664052608 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpfuo8zlt2
W0618 10:20:54.283580 47107666424704 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpybld_e2l
I0618 10:20:54.284383 47928664052608 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpfuo8zlt2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b978b951e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '[2019-06-18 10:21:33] divide_golden_chunk finished: 3.331 seconds
[2019-06-18 10:21:33] generate golden chunk: 3.346 seconds
[2019-06-18 10:21:33] iteration time 23: 49.056 seconds
2019-06-18 10:21:34.571007: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874893.305054 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 24}}
[2019-06-18 10:21:37] minmax time: 3.250 seconds
2019-06-18 10:21:37.830909: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:21:37.836258: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:21:37.840874: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874897.853539 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 23}}
[2019-06-18 10:21:37] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:21:37] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-25-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000024-000014 --seed=25 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000024-000014 --seed=1023779856 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000024-000014 --seed=2047559687 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000024-000014 --seed=3071339518 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000024-000014 --seed=4095119349 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000024-000014 --seed=5118899180 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000024-000014 --seed=6142679011 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000024-000014 --seed=7166458842 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000024-000014 --seed=8190238673 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000024-000014 --seed=9214018504 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000024-000014 --seed=10237798335 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000024-000014 --seed=11261578166 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000024-000014 --seed=12285357997 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000024-000014 --seed=13309137828 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000024-000014 --seed=14332917659 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000024-000014 --seed=15356697490 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000024-000014 --seed=16380477321 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000024-000014 --seed=17404257152 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000024-000014 --seed=18428036983 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000024-000014 --seed=19451816814 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000024-000014 --seed=20475596645 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:21:48] eval finished: 10.689 seconds
[2019-06-18 10:21:48] Win rate 000024-000014 vs 000022-000013: 0.590
:::MLL 1560874908.606865 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 23}}
[2019-06-18 10:21:48] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-26-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000025-000013 --seed=26 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000025-000013 --seed=1023779857 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000025-000013 --seed=2047559688 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000025-000013 --seed=3071339519 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000025-000013 --seed=4095119350 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000025-000013 --seed=5118899181 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000025-000013 --seed=6142679012 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000025-000013 --seed=7166458843 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000025-000013 --seed=8190238674 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000025-000013 --seed=9214018505 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000025-000013 --seed=10237798336 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000025-000013 --seed=11261578167 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000025-000013 --seed=12285357998 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000025-000013 --seed=13309137829 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000025-000013 --seed=14332917660 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000025-000013 --seed=15356697491 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000025-000013 --seed=16380477322 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000025-000013 --seed=17404257153 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000025-000013 --seed=18428036984 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:22:18] selfplay finished: 29.636 seconds
[2019-06-18 10:22:18] selfplay mn: 29.657 seconds
[2019-06-18 10:22:18] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-26-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=26 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779857 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559688 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339519 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119350 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899181 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142679012 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458843 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238674 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018505 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798336 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578167 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285357998 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137829 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917660 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697491 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477322 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257153 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036984 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816815 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596646 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376477 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156308 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golde
[2019-06-18 10:22:21] divide_golden_chunk finished: 3.248 seconds
[2019-06-18 10:22:21] generate golden chunk: 3.262 seconds
[2019-06-18 10:22:21] train finished: 43.851 seconds
:::MLL 1560874903.135300 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.136023 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.136698 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.234626 47280862794624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_0_0
:::MLL 1560874903.120555 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.121484 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.122337 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.234763 47169822311296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_0_0
W0618 10:21:43.235649 47280862794624 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmphnp33q1j
W0618 10:21:43.235741 47169822311296 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpy3nrbssa
I0618 10:21:43.236636 47280862794624 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmphnp33q1j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b00b79e5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.236716 47169822311296 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpy3nrbssa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae6dd171e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.237049 47280862794624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:21:43.237113 47169822311296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:21:43.241936 47169822311296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.241962 47280862794624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874903.142005 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.142946 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.143774 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.250611 47260782195584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_0_0
:::MLL 1560874903.148353 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.149112 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.149822 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.250768 47870840189824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_0_0
W0618 10:21:43.251771 47260782195584 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpfcr52vv1
W0618 10:21:43.251849 47870840189824 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp6s1bw50e
I0618 10:21:43.252796 47260782195584 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpfcr52vv1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afc0ab8be80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.252848 47870840189824 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp6s1bw50e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8a1502ee80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.253216 47260782195584 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:21:43.253253 47870840189824 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:21:43.258028 47260782195584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.258034 47870840189824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.261106 47169822311296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.261152 47280862794624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874903.164586 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.165351 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.166061 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.274964 47526743188352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_0_0
:::MLL 1560874903.162251 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.163010 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.163781 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.275277 47872543503232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_0_0
W0618 10:21:43.277289 47260782195584 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.277349 47870840189824 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.276013 47526743188352 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpzivq9trx
W0618 10:21:43.276265 47872543503232 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpegocb6ht
I0618 10:21:43.277018 47526743188352 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpzivq9trx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b39f73b4e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.277258 47872543503232 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpegocb6ht', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8a7a898e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.277413 47526743188352 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:21:43.277655 47872543503232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:21:43.282255 47526743188352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.282365 47872543503232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874903.181360 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.182108 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.182774 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.294318 47286442746752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_0_0
:::MLL 1560874903.177216 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.178149 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.178881 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.294584 47703791481728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_0_0
W0618 10:21:43.295458 47286442746752 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp2gvnkore
W0618 10:21:43.295670 47703791481728 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpjiva65nz
I0618 10:21:43.296574 47286442746752 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp2gvnkore', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b020435be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.296757 47703791481728 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpjiva65nz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b633021fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.297012 47286442746752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:21:43.297230 47703791481728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:21:43.301509 47526743188352 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.301874 47872543503232 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.302304 47286442746752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.302454 47703791481728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.309265 47280862794624 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:21:43.309345 47169822311296 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:21:43.313683 47280862794624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:21:43.313771 47169822311296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:21:43.318714 47280862794624 estimator.py:1111] Calling model_fn.
W0618 10:21:43.318819 47280862794624 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:21:43.318843 47169822311296 estimator.py:1111] Calling model_fn.
W0618 10:21:43.318959 47169822311296 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:21:43.320171 47280862794624 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:21:43.320313 47169822311296 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560874903.228793 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.229331 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.229777 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.321033 47023254926208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_0_0
W0618 10:21:43.322068 47023254926208 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp0749m80c
:::MLL 1560874903.238200 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.238678 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.239069 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.322865 47586203415424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_0_0
I0618 10:21:43.323056 47023254926208 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp0749m80c', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac4bcfe4e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.323464 47023254926208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874903.227076 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.227664 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.228100 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.323830 47326056678272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_0_0
:::MLL 1560874903.231016 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.231397 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.231716 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.323915 47509459764096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_0_0
I0618 10:21:43.323890 47586203415424 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b47cf568d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.325008 47586203415424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:21:43.325648 47260782195584 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:21:43.324004 47286442746752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.324909 47509459764096 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp39lipazw
W0618 10:21:43.324874 47326056678272 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp3b7ov2ay
W0618 10:21:43.324218 47703791481728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.325923 47870840189824 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:21:43.325880 47509459764096 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp39lipazw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b35f10f5dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.325879 47326056678272 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp3b7ov2ay', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0b3d624e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.326280 47509459764096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:21:43.326279 47326056678272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:21:43.328117 47023254926208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.329584 47586203415424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.329971 47260782195584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:21:43.330246 47870840189824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:21:43.330923 47326056678272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.330981 47509459764096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:21:43.335052 47260782195584 estimator.py:1111] Calling model_fn.
W0618 10:21:43.335162 47260782195584 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:21:43.335345 47870840189824 estimator.py:1111] Calling model_fn.
W0618 10:21:43.335455 47870840189824 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:21:43.336532 47260782195584 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:21:43.336824 47870840189824 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560874903.167209 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.167954 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.168640 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.336087 47923607958400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_0_0
:::MLL 1560874903.169652 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.170370 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.171066 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.336342 47136534143872 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_0_0
W0618 10:21:43.337268 47923607958400 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp7vwy442f
W0618 10:21:43.337434 47136534143872 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpzav550ek
I0618 10:21:43.338392 47923607958400 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp7vwy442f', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b965e373e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.338675 47136534143872 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpzav550ek', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adf1cf5ee80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.338838 47923607958400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:21:43.339139 47136534143872 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874903.249638 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.250096 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.250468 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.338191 47667028910976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_0_0
:::MLL 1560874903.247405 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.247876 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.248276 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.338201 47918716027776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_0_0
W0618 10:21:43.339235 47667028910976 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpdgrcji_8
W0618 10:21:43.339266 47918716027776 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp4tfaobj5
I0618 10:21:43.340230 47667028910976 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpdgrcji_8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5aa0e9ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560874903.217797 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.218723 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.219598 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.340868 47584058401664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_0_0
I0618 10:21:43.340251 47918716027776 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp4tfaobj5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b953aa24e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560874903.218757 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.219656 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.220390 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.340964 47287799608192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_0_0
I0618 10:21:43.340630 47667028910976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:21:43.340651 47918716027776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:21:43.341928 47584058401664 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpu92rfu9j
W0618 10:21:43.341959 47287799608192 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpovdw5gzd
I0618 10:21:43.342945 47584058401664 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpu92rfu9j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b474f7c3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.342956 47287799608192 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpovdw5gzd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b025515ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.343347 47287799608192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:21:43.343354 47584058401664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:21:43.344148 47923607958400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.344394 47136534143872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.347133 47023254926208 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.345337 47667028910976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.345338 47918716027776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.348511 47586203415424 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.348162 47287799608192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.348279 47584058401664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.349874 47326056678272 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.349965 47509459764096 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.349390 47526743188352 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:21:43.349456 47872543503232 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560874903.254459 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.254966 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.255430 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.351054 47380988740480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_0_0
:::MLL 1560874903.260434 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.260852 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.261215 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.351071 47877995180928 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_0_0
W0618 10:21:43.352182 47380988740480 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpoqwbxk21
W0618 10:21:43.352150 47877995180928 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpm79grqyz
I0618 10:21:43.353144 47877995180928 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpm79grqyz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8bbf7b7da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.353183 47380988740480 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpoqwbxk21', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1807971e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.353544 47877995180928 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:21:43.353592 47380988740480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:21:43.353738 47872543503232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:21:43.353689 47526743188352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:21:43.358186 47877995180928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.358232 47380988740480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:21:43.358765 47872543503232 estimator.py:1111] Calling model_fn.
I0618 10:21:43.358734 47526743188352 estimator.py:1111] Calling model_fn.
W0618 10:21:43.358845 47526743188352 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:21:43.358873 47872543503232 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:21:43.360194 47526743188352 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:21:43.360220 47872543503232 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:21:43.364240 47918716027776 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.364299 47667028910976 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.365652 47923607958400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.366045 47136534143872 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.367553 47584058401664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.367678 47287799608192 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.372812 47703791481728 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:21:43.373185 47286442746752 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560874903.242524 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.242935 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.243297 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.375223 47415621329792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_0_0
:::MLL 1560874903.240185 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.240636 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.241015 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.375350 47726787203968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000015-000008.tfrecord.zz_0_0
W0618 10:21:43.376244 47415621329792 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpe_ixtgpe
W0618 10:21:43.376334 47726787203968 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpgy0bv_m8
I0618 10:21:43.377247 47415621329792 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpe_ixtgpe', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2017da6e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.377304 47726787203968 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpgy0bv_m8', '_tf_random_seed': None, '_[2019-06-18 10:22:21] moving /lfs/lfs12/gma_akey/results/epb312/models/000025-000014.meta --> /lfs/lfs12/gma_akey/results/epb312/models/000025-000015.meta
[2019-06-18 10:22:21] moving /lfs/lfs12/gma_akey/results/epb312/models/000025-000014.index --> /lfs/lfs12/gma_akey/results/epb312/models/000025-000015.index
[2019-06-18 10:22:21] moving /lfs/lfs12/gma_akey/results/epb312/models/000025-000014.pb --> /lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb
[2019-06-18 10:22:21] moving /lfs/lfs12/gma_akey/results/epb312/models/000025-000014.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb312/models/000025-000015.data-00000-of-00001
[2019-06-18 10:22:21] iteration time 24: 48.471 seconds
2019-06-18 10:22:23.120880: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874941.776102 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 25}}
[2019-06-18 10:22:26] minmax time: 3.264 seconds
2019-06-18 10:22:26.395095: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:22:26.400571: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:22:26.405160: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874946.416652 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 24}}
[2019-06-18 10:22:26] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000026-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000026-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000026-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000026-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000026-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000026-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000026-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000026-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000026-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000026-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000026-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:22:26] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-26-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000025-000015 --seed=26 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000025-000015 --seed=1023779857 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000025-000015 --seed=2047559688 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000025-000015 --seed=3071339519 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000025-000015 --seed=4095119350 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000025-000015 --seed=5118899181 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000025-000015 --seed=6142679012 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000025-000015 --seed=7166458843 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000025-000015 --seed=8190238674 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000025-000015 --seed=9214018505 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000025-000015 --seed=10237798336 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000025-000015 --seed=11261578167 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000025-000015 --seed=12285357998 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000025-000015 --seed=13309137829 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000025-000015 --seed=14332917660 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000025-000015 --seed=15356697491 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000025-000015 --seed=16380477322 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000025-000015 --seed=17404257153 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000025-000015 --seed=18428036984 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000025-000015 --seed=19451816815 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000024-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000025-000015 --seed=20475596646 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:22:38] eval finished: 11.648 seconds
[2019-06-18 10:22:38] Win rate 000025-000015 vs 000024-000014: 0.520
:::MLL 1560874958.128251 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 24}}
[2019-06-18 10:22:38] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-27-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000026-000014 --seed=27 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000026-000014 --seed=1023779858 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000026-000014 --seed=2047559689 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000026-000014 --seed=3071339520 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000026-000014 --seed=4095119351 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000026-000014 --seed=5118899182 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000026-000014 --seed=6142679013 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000026-000014 --seed=7166458844 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000026-000014 --seed=8190238675 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000026-000014 --seed=9214018506 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000026-000014 --seed=10237798337 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000026-000014 --seed=11261578168 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000026-000014 --seed=12285357999 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000026-000014 --seed=13309137830 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000026-000014 --seed=14332917661 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000026-000014 --seed=15356697492 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000026-000014 --seed=16380477323 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000026-000014 --seed=17404257154 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000026-000014 --seed=18428036985 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:23:07] selfplay finished: 29.778 seconds
[2019-06-18 10:23:07] selfplay mn: 29.797 seconds
[2019-06-18 10:23:07] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-27-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=27 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779858 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559689 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339520 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119351 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899182 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142679013 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458844 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238675 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018506 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798337 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578168 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285357999 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137830 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917661 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697492 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477323 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257154 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036985 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816816 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596647 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376478 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156309 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golde
[2019-06-18 10:23:10] train finished: 44.199 seconds
:::MLL 1560874951.660419 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.661148 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.661821 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.771091 47000186770304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_0_0
:::MLL 1560874951.657011 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.657775 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.658431 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.771254 47894565458816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 10:22:31.772133 47000186770304 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpjt3akqx1
W0618 10:22:31.772261 47894565458816 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp2izrhwn9
I0618 10:22:31.773158 47000186770304 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpjt3akqx1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abf5e062e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.773296 47894565458816 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp2izrhwn9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8f9b25ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.773577 47000186770304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:22:31.773702 47894565458816 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:22:31.778364 47000186770304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.778415 47894565458816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.797698 47000186770304 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.797736 47894565458816 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874951.708198 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.709125 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.710005 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.821337 47435815236480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_0_0
:::MLL 1560874951.720091 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.720816 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.721476 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.821469 47177993937792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 10:22:31.822410 47435815236480 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpbmo7hshh
W0618 10:22:31.822506 47177993937792 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpkaykuvz8
I0618 10:22:31.823408 47435815236480 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpbmo7hshh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b24cb810e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.823512 47177993937792 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpkaykuvz8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae8c4282e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.823807 47435815236480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:22:31.823920 47177993937792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:22:31.828691 47435815236480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.828789 47177993937792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.845792 47894565458816 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:22:31.845877 47000186770304 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:22:31.847952 47435815236480 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.848206 47177993937792 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.850195 47894565458816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:22:31.850282 47000186770304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560874951.737856 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.738597 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.739312 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.851434 47858787832704 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_0_0
:::MLL 1560874951.740493 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.741238 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.741959 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.851498 47314452411264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_0_0
:::MLL 1560874951.767321 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.767721 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.768048 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.854196 47971559936896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 10:22:31.852573 47858787832704 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp0b4py8la
W0618 10:22:31.852726 47314452411264 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpoat2h6pz
I0618 10:22:31.853651 47858787832704 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp0b4py8la', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8746a2ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.855263 47894565458816 estimator.py:1111] Calling model_fn.
I0618 10:22:31.853806 47314452411264 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpoat2h6pz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0889b73e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:22:31.855386 47894565458816 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:22:31.855391 47000186770304 estimator.py:1111] Calling model_fn.
W0618 10:22:31.855507 47000186770304 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:22:31.854099 47858787832704 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:22:31.854250 47314452411264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:22:31.855273 47971559936896 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpz8d5v1ny
I0618 10:22:31.856256 47971559936896 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpz8d5v1ny', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba188606e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.856656 47971559936896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:22:31.856807 47894565458816 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:22:31.856927 47000186770304 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:22:31.859417 47858787832704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.859470 47314452411264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.861351 47971559936896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874951.721517 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.722407 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.723264 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.861776 46937805108096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_0_0
:::MLL 1560874951.735536 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.736284 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.736982 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.862945 47935039697792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_0_0
:::MLL 1560874951.765332 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.765744 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.766095 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.863737 47840175408000 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 10:22:31.862944 46937805108096 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp2rxcy12t
I0618 10:22:31.864045 46937805108096 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp2rxcy12t', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab0d7c98e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.864516 46937805108096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:22:31.864049 47935039697792 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpjrou6shu
W0618 10:22:31.864726 47840175408000 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpiqc575t1
I0618 10:22:31.865154 47935039697792 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpjrou6shu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b990799be80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.865688 47840175408000 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpiqc575t1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b82f13f8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.866096 47840175408000 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:22:31.865606 47935039697792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:22:31.869833 46937805108096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.870695 47840175408000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.870788 47935039697792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.880609 47971559936896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.881210 47858787832704 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.881942 47314452411264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874951.795770 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.796271 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.796690 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.885452 47407365448576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_0_0
:::MLL 1560874951.792529 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.793075 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.793481 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.885923 47527059788672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_0_0
I0618 10:22:31.886510 47407365448576 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1e2bc3acf8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.887627 47407365448576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:22:31.886927 47527059788672 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpmby_f04j
I0618 10:22:31.887918 47527059788672 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpmby_f04j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3a0a1a6e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.888318 47527059788672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:22:31.889611 47840175408000 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.891551 46937805108096 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.892309 47407365448576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.892922 47527059788672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874951.749075 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.749816 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.750525 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.890906 47735637853056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 10:22:31.892852 47935039697792 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.891994 47735637853056 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpnpio5qdd
I0618 10:22:31.893132 47735637853056 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpnpio5qdd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6a9a531e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.893532 47735637853056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:22:31.896067 47435815236480 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:22:31.896520 47177993937792 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560874951.762269 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.763083 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.763818 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.896741 47850124104576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_0_0
:::MLL 1560874951.765502 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.766232 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.766951 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.896728 46942105547648 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_0_0
:::MLL 1560874951.739750 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.740674 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.741551 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.897334 47158093534080 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 10:22:31.897818 47850124104576 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmptexnk3jr
W0618 10:22:31.897786 46942105547648 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpmamh28z3
I0618 10:22:31.898794 46942105547648 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpmamh28z3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab1d81d0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.898819 47850124104576 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmptexnk3jr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b85423cae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:22:31.898314 47735637853056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:22:31.899203 46942105547648 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:22:31.899232 47850124104576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:22:31.900348 47435815236480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:22:31.898355 47158093534080 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpaz0ix86a
W0618 10:22:31.900825 47177993937792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:22:31.899348 47158093534080 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpaz0ix86a', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae422002da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.899746 47158093534080 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:22:31.904170 46942105547648 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.904215 47850124104576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:22:31.905381 47435815236480 estimator.py:1111] Calling model_fn.
W0618 10:22:31.905490 47435815236480 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:22:31.905884 47177993937792 estimator.py:1111] Calling model_fn.
W0618 10:22:31.905993 47177993937792 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:22:31.904637 47158093534080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.906844 47435815236480 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:22:31.907350 47177993937792 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:22:31.911195 47407365448576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.912037 47527059788672 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874951.792131 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.792638 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.793077 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.911593 47214541747072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_0_0
:::MLL 1560874951.800168 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.800600 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.801023 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.912259 47781790274432 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 10:22:31.912691 47214541747072 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpzlxu8gwd
I0618 10:22:31.913732 47214541747072 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpzlxu8gwd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af146937e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560874951.815641 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.816054 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.816415 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.912506 47751789732736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_0_0
:::MLL 1560874951.814600 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.815031 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.815434 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.912523 47614510011264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 10:22:31.913326 47781790274432 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpacev18n5
I0618 10:22:31.914165 47214541747072 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:22:31.914366 47781790274432 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpacev18n5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7559391e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.914798 47781790274432 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:22:31.913553 47751789732736 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmprzry6k7m
W0618 10:22:31.913581 47614510011264 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp6cd1djua
I0618 10:22:31.914535 47751789732736 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmprzry6k7m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6e5d0d3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.914551 47614510011264 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp6cd1djua', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4e668aee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.914940 47751789732736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:22:31.914949 47614510011264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:22:31.919081 47214541747072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.917901 47735637853056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.919566 47781790274432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.919662 47751789732736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.919676 47614510011264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.923515 47850124104576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.923551 46942105547648 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.924225 47158093534080 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.928543 47971559936896 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:22:31.931295 47858787832704 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:22:31.932883 47971559936896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:22:31.931612 47314452411264 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:22:31.936506 47840175408000 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:22:31.935654 47858787832704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:22:31.935945 47314452411264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:22:31.937978 47971559936896 estimator.py:1111] Calling model_fn.
W0618 10:22:31.938088 47971559936896 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:22:31.938206 47214541747072 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.938663 47781790274432 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.939470 47971559936896 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:22:31.938633 47751789732736 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.938686 47614510011264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.940788 47840175408000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:22:31.940785 47858787832704 estimator.py:1111] Calling model_fn.
W0618 10:22:31.941718 46937805108096 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:22:31.940896 47858787832704 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:22:31.941044 47314452[2019-06-18 10:23:11] divide_golden_chunk finished: 3.319 seconds
[2019-06-18 10:23:11] generate golden chunk: 3.334 seconds
[2019-06-18 10:23:11] moving /lfs/lfs12/gma_akey/results/epb312/models/000026-000015.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb312/models/000026-000016.data-00000-of-00001
[2019-06-18 10:23:11] moving /lfs/lfs12/gma_akey/results/epb312/models/000026-000015.index --> /lfs/lfs12/gma_akey/results/epb312/models/000026-000016.index
[2019-06-18 10:23:11] moving /lfs/lfs12/gma_akey/results/epb312/models/000026-000015.meta --> /lfs/lfs12/gma_akey/results/epb312/models/000026-000016.meta
[2019-06-18 10:23:11] moving /lfs/lfs12/gma_akey/results/epb312/models/000026-000015.pb --> /lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb
[2019-06-18 10:23:11] iteration time 25: 49.527 seconds
2019-06-18 10:23:12.655499: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874991.303697 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 26}}
[2019-06-18 10:23:15] minmax time: 3.269 seconds
2019-06-18 10:23:15.934110: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:23:15.939654: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:23:15.944339: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874995.955667 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 25}}
[2019-06-18 10:23:15] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:23:16] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-27-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000026-000016 --seed=27 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000026-000016 --seed=1023779858 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000026-000016 --seed=2047559689 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000026-000016 --seed=3071339520 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000026-000016 --seed=4095119351 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000026-000016 --seed=5118899182 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000026-000016 --seed=6142679013 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000026-000016 --seed=7166458844 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000026-000016 --seed=8190238675 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000026-000016 --seed=9214018506 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000026-000016 --seed=10237798337 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000026-000016 --seed=11261578168 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000026-000016 --seed=12285357999 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000026-000016 --seed=13309137830 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000026-000016 --seed=14332917661 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000026-000016 --seed=15356697492 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000026-000016 --seed=16380477323 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000026-000016 --seed=17404257154 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000026-000016 --seed=18428036985 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000026-000016 --seed=19451816816 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000026-000016 --seed=20475596647 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:23:27] eval finished: 11.054 seconds
[2019-06-18 10:23:27] Win rate 000026-000016 vs 000025-000015: 0.550
:::MLL 1560875007.071995 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 25}}
[2019-06-18 10:23:27] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-28-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000027-000015 --seed=28 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000027-000015 --seed=1023779859 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000027-000015 --seed=2047559690 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000027-000015 --seed=3071339521 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000027-000015 --seed=4095119352 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000027-000015 --seed=5118899183 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000027-000015 --seed=6142679014 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000027-000015 --seed=7166458845 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000027-000015 --seed=8190238676 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000027-000015 --seed=9214018507 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000027-000015 --seed=10237798338 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000027-000015 --seed=11261578169 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000027-000015 --seed=12285358000 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000027-000015 --seed=13309137831 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000027-000015 --seed=14332917662 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000027-000015 --seed=15356697493 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000027-000015 --seed=16380477324 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000027-000015 --seed=17404257155 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000027-000015 --seed=18428036986 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:23:57] selfplay finished: 30.480 seconds
[2019-06-18 10:23:57] selfplay mn: 30.502 seconds
[2019-06-18 10:23:57] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-28-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=28 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779859 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559690 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339521 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119352 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899183 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142679014 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458845 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238676 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018507 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798338 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578169 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285358000 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137831 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917662 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697493 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477324 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257155 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036986 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816817 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596648 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376479 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156310 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golde
[2019-06-18 10:23:59] train finished: 43.594 seconds
:::MLL 1560875001.190393 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875001.191271 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875001.192048 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:21.307434 47516156367744 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_0_0
:::MLL 1560875001.199009 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875001.199723 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875001.200401 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:21.307509 46922162717568 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 10:23:21.308548 47516156367744 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpr7pmlnw3
W0618 10:23:21.308580 46922162717568 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpp52nv1ar
I0618 10:23:21.309596 47516156367744 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpr7pmlnw3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3780356e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:21.309621 46922162717568 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpp52nv1ar', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aad336d8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:21.309993 47516156367744 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:23:21.310029 46922162717568 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:23:21.315117 47516156367744 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:21.315118 46922162717568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875001.215760 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875001.216682 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875001.217591 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:21.331974 47132950467456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_0_0
:::MLL 1560875001.231269 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875001.231993 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875001.232702 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:21.333045 47546128970624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 10:23:21.333017 47132950467456 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpqczi5hun
I0618 10:23:21.334038 47132950467456 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpqczi5hun', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ade475b6e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:21.334771 47132950467456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:23:21.334021 47546128970624 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpoxvy39jx
W0618 10:23:21.334738 47516156367744 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:23:21.334796 46922162717568 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:23:21.335154 47546128970624 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpoxvy39jx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3e7ab6fe80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:21.335594 47546128970624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:23:21.339698 47132950467456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:21.340222 47546128970624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:21.359008 47132950467456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:23:21.359402 47546128970624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875001.231070 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875001.231901 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875001.232632 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:21.369777 47692523365248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_0_0
:::MLL 1560875001.230171 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875001.231040 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875001.231807 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:21.370034 47571364840320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 10:23:21.370954 47692523365248 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpne5zb178
W0618 10:23:21.371143 47571364840320 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmptrpmmrzc
I0618 10:23:21.372064 47692523365248 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpne5zb178', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6090803e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:21.372219 47571364840320 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmptrpmmrzc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b445ae3de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:21.372514 47692523365248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:23:21.372659 47571364840320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875001.273145 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875001.273841 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875001.274531 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:21.376414 47262350463872 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_0_0
:::MLL 1560875001.261867 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875001.262784 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875001.263655 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:21.376622 47359709045632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_0_0
:::MLL 1560875001.227969 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875001.228780 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875001.229473 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:21.377018 47300863828864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_0_0
:::MLL 1560875001.231439 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875001.232206 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875001.232900 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:21.377117 47222708970368 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 10:23:21.377417 47262350463872 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpbhu1fwou
W0618 10:23:21.377628 47359709045632 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmppb9_tour
I0618 10:23:21.378420 47262350463872 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpbhu1fwou', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afc6832ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:23:21.377791 47692523365248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:23:21.378626 47359709045632 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmppb9_tour', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b131338be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:23:21.377866 47571364840320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:23:21.378836 47262350463872 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:23:21.379263 47359709045632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:23:21.378081 47300863828864 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpctggi2au
W0618 10:23:21.378116 47222708970368 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpb9wai48i
I0618 10:23:21.379084 47300863828864 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpctggi2au', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b055fc5fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:21.379115 47222708970368 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpb9wai48i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af32d617e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:21.379488 47300863828864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:23:21.379525 47222708970368 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:23:21.383972 46922162717568 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:23:21.384084 47516156367744 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:23:21.383814 47262350463872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:21.384125 47359709045632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:21.384471 47300863828864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:21.384459 47222708970368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:21.388459 46922162717568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:23:21.388554 47516156367744 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:23:21.393687 46922162717568 estimator.py:1111] Calling model_fn.
W0618 10:23:21.393800 46922162717568 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:23:21.393822 47516156367744 estimator.py:1111] Calling model_fn.
W0618 10:23:21.393937 47516156367744 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:23:21.395270 46922162717568 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:23:21.395430 47516156367744 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560875001.306827 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875001.307312 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875001.307724 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:21.399748 47468605019008 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_0_0
:::MLL 1560875001.309042 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875001.309500 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875001.309870 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:21.399801 46959315018624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 10:23:21.399201 47692523365248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:23:21.399641 47571364840320 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:23:21.400809 46959315018624 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab5d9e0bd68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:23:21.400747 47468605019008 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp694wmb4q
I0618 10:23:21.401719 47468605019008 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp694wmb4q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2c6ded6e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:21.401910 46959315018624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:23:21.402122 47468605019008 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875001.306580 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875001.307024 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875001.307407 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:21.402692 47956432769920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 10:23:21.403164 47262350463872 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875001.309855 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875001.310284 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875001.310710 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:21.404155 46932843561856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 10:23:21.403727 47956432769920 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp5bnp0f7_
W0618 10:23:21.403753 47359709045632 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:23:21.404719 47956432769920 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp5bnp0f7_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9e02ba2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:21.405123 47956432769920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:23:21.404171 47222708970368 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:23:21.405122 46932843561856 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpf6dspv2s
W0618 10:23:21.404248 47300863828864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:23:21.406101 46932843561856 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpf6dspv2s', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aafb00e5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:21.406500 46932843561856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:23:21.406692 46959315018624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:21.406861 47468605019008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:21.407463 47546128970624 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:23:21.408291 47132950467456 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:23:21.409783 47956432769920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:21.411055 46932843561856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:21.411801 47546128970624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:23:21.412604 47132950467456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:23:21.416864 47546128970624 estimator.py:1111] Calling model_fn.
W0618 10:23:21.416972 47546128970624 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:23:21.417689 47132950467456 estimator.py:1111] Calling model_fn.
W0618 10:23:21.417800 47132950467456 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560875001.226786 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875001.227552 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875001.228270 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:21.417252 47411328627584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 10:23:21.418345 47546128970624 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560875001.223907 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875001.224674 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875001.225386 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:21.417626 47857856545664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 10:23:21.419180 47132950467456 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:23:21.418402 47411328627584 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpt0e3fw5k
W0618 10:23:21.418702 47857856545664 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpk03byeck
I0618 10:23:21.419516 47411328627584 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpt0e3fw5k', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1f17fd0e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:21.419774 47857856545664 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpk03byeck', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b870f205e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:21.419970 47411328627584 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:23:21.420221 47857856545664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875001.304473 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875001.304918 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875001.305317 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:21.422088 47875446965120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_0_0
:::MLL 1560875001.304347 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875001.304795 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875001.305199 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:21.422099 47723527590784 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 10:23:21.423164 47875446965120 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmps1r7u86l
W0618 10:23:21.425652 46959315018624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:23:21.423196 47723527590784 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpameb0w14
I0618 10:23:21.424142 47875446965120 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmps1r7u86l', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8b2798ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:21.424182 47723527590784 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpameb0w14', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b67c87f2e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:23:21.425294 47411328627584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:21.425946 47468605019008 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:23:21.425470 47857856545664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:23:21.424540 47875446965120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:23:21.424585 47723527590784 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:23:21.428695 47956432769920 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:23:21.430200 46932843561856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:23:21.429219 47875446965120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:21.429237 47723527590784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875001.308701 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875001.309162 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875001.309581 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:21.430229 47448701182848 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_0_0
:::MLL 1560875001.309943 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875001.310410 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875001.310823 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:21.430339 47864849380224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 10:23:21.431270 47448701182848 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpvm4w45br
W0618 10:23:21.431369 47864849380224 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmprn8o_ibx
I0618 10:23:21.432330 47448701182848 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpvm4w45br', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b27cb90fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:21.432436 47864849380224 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmprn8o_ibx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b88afee8da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:21.432751 47448701182848 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:23:21.432862 47864849380224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:23:21.437578 47448701182848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:21.437675 47864849380224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875001.353305 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875001.353747 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875001.354120 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:21.445004 47102697169792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 10:23:21.445961 47411328627584 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875001.354974 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875001.355403 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875001.355778 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:21.445833 47099666690944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 10:23:21.446473 47857856545664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:23:21.446042 47102697169792 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpmgcks471
I0618 10:23:21.447025 47102697169792 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpmgcks471', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad73c1ebe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:21.447420 47102697169792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:23:21.446830 47099666690944 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpp26_wdo7
I0618 10:23:21.447825 47099666690944 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpp26_wdo7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad6877d3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:21.448234 47099666690944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:23:21.447521 47692523365248 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:23:21.448266 47571364840320 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:23:21.448290 47875446965120 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:23:21.448313 47723527590784 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875001.291880 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875001.292299 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875001.292661 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:21.451546 47185423840128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_0_0
:::MLL 1560875001.287351 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875001.287903 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875001.288352 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:21.451559 47501691032448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 10:23:21.451459 47262350463872 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:23:21.451947 47359709045632 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:23:21.452078 47102697169792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:21.451795 47692523365248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util[2019-06-18 10:24:00] divide_golden_chunk finished: 3.311 seconds
[2019-06-18 10:24:00] generate golden chunk: 3.326 seconds
[2019-06-18 10:24:00] moving /lfs/lfs12/gma_akey/results/epb312/models/000027-000016.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb312/models/000027-000017.data-00000-of-00001
[2019-06-18 10:24:00] moving /lfs/lfs12/gma_akey/results/epb312/models/000027-000016.meta --> /lfs/lfs12/gma_akey/results/epb312/models/000027-000017.meta
[2019-06-18 10:24:00] moving /lfs/lfs12/gma_akey/results/epb312/models/000027-000016.index --> /lfs/lfs12/gma_akey/results/epb312/models/000027-000017.index
[2019-06-18 10:24:00] moving /lfs/lfs12/gma_akey/results/epb312/models/000027-000016.pb --> /lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb
[2019-06-18 10:24:00] iteration time 26: 49.644 seconds
2019-06-18 10:24:02.402368: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560875040.947510 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 27}}
[2019-06-18 10:24:05] minmax time: 3.222 seconds
2019-06-18 10:24:05.634207: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:24:05.639674: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:24:05.644287: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560875045.655519 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 26}}
[2019-06-18 10:24:05] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:24:05] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-28-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000027-000017 --seed=28 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000027-000017 --seed=1023779859 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000027-000017 --seed=2047559690 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000027-000017 --seed=3071339521 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000027-000017 --seed=4095119352 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000027-000017 --seed=5118899183 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000027-000017 --seed=6142679014 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000027-000017 --seed=7166458845 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000027-000017 --seed=8190238676 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000027-000017 --seed=9214018507 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000027-000017 --seed=10237798338 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000027-000017 --seed=11261578169 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000027-000017 --seed=12285358000 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000027-000017 --seed=13309137831 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000027-000017 --seed=14332917662 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000027-000017 --seed=15356697493 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000027-000017 --seed=16380477324 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000027-000017 --seed=17404257155 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000027-000017 --seed=18428036986 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000027-000017 --seed=19451816817 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000027-000017 --seed=20475596648 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:24:16] eval finished: 11.061 seconds
[2019-06-18 10:24:16] Win rate 000027-000017 vs 000026-000016: 0.580
:::MLL 1560875056.780937 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 26}}
[2019-06-18 10:24:16] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-29-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000028-000016 --seed=29 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000028-000016 --seed=1023779860 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000028-000016 --seed=2047559691 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000028-000016 --seed=3071339522 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000028-000016 --seed=4095119353 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000028-000016 --seed=5118899184 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000028-000016 --seed=6142679015 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000028-000016 --seed=7166458846 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000028-000016 --seed=8190238677 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000028-000016 --seed=9214018508 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000028-000016 --seed=10237798339 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000028-000016 --seed=11261578170 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000028-000016 --seed=12285358001 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000028-000016 --seed=13309137832 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000028-000016 --seed=14332917663 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000028-000016 --seed=15356697494 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000028-000016 --seed=16380477325 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000028-000016 --seed=17404257156 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000028-000016 --seed=18428036987 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:24:46] selfplay finished: 29.792 seconds
[2019-06-18 10:24:46] selfplay mn: 29.811 seconds
[2019-06-18 10:24:46] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-29-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=29 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779860 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559691 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339522 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119353 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899184 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142679015 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458846 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238677 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018508 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798339 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578170 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285358001 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137832 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917663 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697494 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477325 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257156 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036987 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816818 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596649 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376480 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156311 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golde
[2019-06-18 10:24:49] train finished: 43.743 seconds
:::MLL 1560875050.904721 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875050.905451 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875050.906143 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.031916 47797421097856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_0_0
:::MLL 1560875050.907395 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875050.908118 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875050.908767 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.032000 47116326155136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_0_0
W0618 10:24:11.033002 47797421097856 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpyuqqzua3
W0618 10:24:11.033039 47116326155136 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpy7kpcagn
I0618 10:24:11.034015 47797421097856 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpyuqqzua3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b78fce49e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.034028 47116326155136 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpy7kpcagn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ada68787e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.034426 47797421097856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:24:11.034427 47116326155136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:24:11.039328 47797421097856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.039370 47116326155136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875050.925442 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875050.926163 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875050.926832 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.042197 47865806009216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_0_0
:::MLL 1560875050.927984 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875050.928738 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875050.929384 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.042480 47271848219520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_0_0
W0618 10:24:11.043245 47865806009216 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpc9w0vkpr
W0618 10:24:11.043480 47271848219520 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp3w7zrv6y
I0618 10:24:11.044267 47865806009216 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpc9w0vkpr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b88e8f38e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.044474 47271848219520 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp3w7zrv6y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afe9e4eee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.044683 47865806009216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:24:11.044888 47271848219520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:24:11.049497 47865806009216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.049593 47271848219520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.058675 47797421097856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:24:11.058889 47116326155136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:24:11.068665 47865806009216 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:24:11.069279 47271848219520 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875050.982905 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875050.983416 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875050.983883 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.094478 47783688291200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_0_0
:::MLL 1560875050.984130 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875050.984601 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875050.985036 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.094608 46955200545664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_0_0
I0618 10:24:11.095522 47783688291200 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b75ca5a9d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:24:11.095616 46955200545664 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpqqsnwm_7
I0618 10:24:11.096597 46955200545664 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpqqsnwm_7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab4e4a2ce80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.096647 47783688291200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:24:11.096999 46955200545664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875050.980216 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875050.981070 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875050.981888 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.095446 47373693936512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_0_0
W0618 10:24:11.096498 47373693936512 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp6nlgk4en
I0618 10:24:11.097506 47373693936512 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp6nlgk4en', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1654c93e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.097982 47373693936512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:24:11.101349 47783688291200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.101564 46955200545664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875050.955255 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875050.955958 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875050.956681 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.101834 47801370403712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_0_0
:::MLL 1560875050.949251 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875050.950167 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875050.951024 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.102385 47999081915264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_0_0
W0618 10:24:11.102972 47801370403712 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpm920r0gv
I0618 10:24:11.104110 47801370403712 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpm920r0gv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b79e84a3e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:24:11.103013 47373693936512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.103479 47999081915264 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp478s8uzh
I0618 10:24:11.104557 47801370403712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:24:11.104587 47999081915264 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp478s8uzh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba7f0d06e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.105041 47999081915264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:24:11.107077 47797421097856 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:24:11.107576 47116326155136 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:24:11.109914 47801370403712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.110245 47999081915264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.111375 47797421097856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:24:11.111901 47116326155136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560875050.981081 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875050.981961 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875050.982699 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.109952 47941508830080 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_0_0
W0618 10:24:11.110939 47941508830080 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpau9kcc_f
I0618 10:24:11.111955 47941508830080 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpau9kcc_f', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9a8930ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.112363 47941508830080 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:24:11.116439 47797421097856 estimator.py:1111] Calling model_fn.
W0618 10:24:11.116548 47797421097856 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:24:11.116990 47116326155136 estimator.py:1111] Calling model_fn.
W0618 10:24:11.116811 47865806009216 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:24:11.117109 47116326155136 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:24:11.117897 47797421097856 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:24:11.117793 47271848219520 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:24:11.118480 47116326155136 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:24:11.117269 47941508830080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875051.021983 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.022464 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.022897 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.119080 47063563514752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_0_0
W0618 10:24:11.120426 47783688291200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:24:11.120510 46955200545664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875051.026937 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.027386 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.027779 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.120523 47264849904512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_0_0
W0618 10:24:11.120082 47063563514752 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp8j1hxvjp
I0618 10:24:11.121070 47063563514752 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp8j1hxvjp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ace1f927e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:24:11.121129 47865806009216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:24:11.121472 47063563514752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:24:11.122126 47271848219520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:24:11.121484 47264849904512 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpqow5b5te
I0618 10:24:11.122451 47264849904512 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpqow5b5te', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afcfd2d0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.122853 47264849904512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:24:11.122907 47373693936512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:24:11.126146 47063563514752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:24:11.126222 47865806009216 estimator.py:1111] Calling model_fn.
W0618 10:24:11.126328 47865806009216 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:24:11.127201 47271848219520 estimator.py:1111] Calling model_fn.
W0618 10:24:11.127312 47271848219520 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:24:11.127440 47264849904512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.127717 47865806009216 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:24:11.128659 47271848219520 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:24:11.131985 47801370403712 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:24:11.132094 47999081915264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:24:11.136801 47941508830080 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:24:11.145015 47063563514752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:24:11.146584 47264849904512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875050.986292 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875050.987162 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875050.987876 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.147852 47644020532096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_0_0
:::MLL 1560875050.985239 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875050.986093 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875050.986901 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.148225 47495906956160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_0_0
:::MLL 1560875051.010175 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.010708 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.011187 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.149494 47583933952896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_0_0
W0618 10:24:11.148877 47644020532096 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpe3ym2zt3
I0618 10:24:11.149875 47644020532096 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpe3ym2zt3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b554581add8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:24:11.149219 47495906956160 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpd7yccpnn
:::MLL 1560875051.014225 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.014636 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.014984 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.150189 46989848458112 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_0_0
I0618 10:24:11.150224 47495906956160 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpd7yccpnn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b32c93fee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.150280 47644020532096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:24:11.150623 47495906956160 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:24:11.150510 47583933952896 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmppb3ykdru
I0618 10:24:11.151517 47583933952896 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmppb3ykdru', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4748113e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:24:11.151153 46989848458112 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp8cvfw1_g
I0618 10:24:11.151924 47583933952896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:24:11.152147 46989848458112 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp8cvfw1_g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abcf5cffe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.152561 46989848458112 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:24:11.155163 47644020532096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.155529 47495906956160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.156829 47583933952896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.157336 46989848458112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.167736 47783688291200 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:24:11.167836 46955200545664 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:24:11.172003 47783688291200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:24:11.172100 46955200545664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560875051.064747 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.065284 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.065780 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.171914 47608661320576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_0_0
W0618 10:24:11.172107 47373693936512 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560875051.070352 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.070814 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.071222 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.172391 47007711994752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000018-000009.tfrecord.zz_0_0
W0618 10:24:11.172908 47608661320576 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmppkdh4fg1
I0618 10:24:11.173889 47608661320576 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmppkdh4fg1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4d09eeee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:24:11.174727 47644020532096 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:24:11.173361 47007711994752 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpci4pt1ru
I0618 10:24:11.174291 47608661320576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:24:11.175056 47495906956160 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:24:11.174339 47007711994752 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpci4pt1ru', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac11e8feda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.174737 47007711994752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:24:11.175905 47583933952896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:24:11.177033 47783688291200 estimator.py:1111] Calling model_fn.
W0618 10:24:11.176456 46989848458112 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:24:11.177103 46955200545664 estimator.py:1111] Calling model_fn.
W0618 10:24:11.177141 47783688291200 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:24:11.177209 46955200545664 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:24:11.176537 47373693936512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:24:11.178489 47783688291200 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:24:11.178564 46955200545664 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:24:11.178940 47608661320576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.179348 47007711994752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:24:11.181714 47373693936512 estimator.py:1111] Calling model_fn.
W0618 10:24:11.181833 47373693936512 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:24:11.182859 47801370403712 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:24:11.183677 47999081915264 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:24:11.183200 47373693936512 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:24:11.184423 47941508830080 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:24:11.187478 47801370403712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:24:11.188344 47999081915264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:24:11.188696 47941508830080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:24:11.191845 47063563514752 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:24:11.192919 47801370403712 estimator.py:1111] Calling model_fn.
W0618 10:24:11.193038 47801370403712 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:24:11.194010 47264849904512 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:24:11.193801 47999081915264 estimator.py:1111] Calling model_fn.
W0618 10:24:11.193918 47999081915264 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:24:11.194507 47801370403712 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:24:11.1937[2019-06-18 10:24:49] divide_golden_chunk finished: 3.246 seconds
[2019-06-18 10:24:49] generate golden chunk: 3.261 seconds
[2019-06-18 10:24:49] moving /lfs/lfs12/gma_akey/results/epb312/models/000028-000017.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb312/models/000028-000018.data-00000-of-00001
[2019-06-18 10:24:49] moving /lfs/lfs12/gma_akey/results/epb312/models/000028-000017.index --> /lfs/lfs12/gma_akey/results/epb312/models/000028-000018.index
[2019-06-18 10:24:49] moving /lfs/lfs12/gma_akey/results/epb312/models/000028-000017.meta --> /lfs/lfs12/gma_akey/results/epb312/models/000028-000018.meta
[2019-06-18 10:24:49] moving /lfs/lfs12/gma_akey/results/epb312/models/000028-000017.pb --> /lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb
[2019-06-18 10:24:49] iteration time 27: 48.946 seconds
2019-06-18 10:24:51.383580: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560875089.893758 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 28}}
[2019-06-18 10:24:54] minmax time: 3.300 seconds
2019-06-18 10:24:54.693967: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:24:54.699381: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:24:54.703819: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560875094.715182 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 27}}
[2019-06-18 10:24:54] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000029-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000029-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000029-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000029-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000029-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000029-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000029-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000029-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000029-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000029-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000029-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:24:54] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-29-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000028-000018 --seed=29 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000028-000018 --seed=1023779860 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000028-000018 --seed=2047559691 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000028-000018 --seed=3071339522 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000028-000018 --seed=4095119353 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000028-000018 --seed=5118899184 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000028-000018 --seed=6142679015 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000028-000018 --seed=7166458846 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000028-000018 --seed=8190238677 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000028-000018 --seed=9214018508 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000028-000018 --seed=10237798339 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000028-000018 --seed=11261578170 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000028-000018 --seed=12285358001 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000028-000018 --seed=13309137832 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000028-000018 --seed=14332917663 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000028-000018 --seed=15356697494 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000028-000018 --seed=16380477325 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000028-000018 --seed=17404257156 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000028-000018 --seed=18428036987 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000028-000018 --seed=19451816818 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000028-000018 --seed=20475596649 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:25:08] eval finished: 13.345 seconds
[2019-06-18 10:25:08] Win rate 000028-000018 vs 000027-000017: 0.570
:::MLL 1560875108.122870 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 27}}
[2019-06-18 10:25:08] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-30-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000029-000017 --seed=30 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000029-000017 --seed=1023779861 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000029-000017 --seed=2047559692 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000029-000017 --seed=3071339523 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000029-000017 --seed=4095119354 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000029-000017 --seed=5118899185 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000029-000017 --seed=6142679016 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000029-000017 --seed=7166458847 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000029-000017 --seed=8190238678 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000029-000017 --seed=9214018509 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000029-000017 --seed=10237798340 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000029-000017 --seed=11261578171 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000029-000017 --seed=12285358002 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000029-000017 --seed=13309137833 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000029-000017 --seed=14332917664 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000029-000017 --seed=15356697495 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000029-000017 --seed=16380477326 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000029-000017 --seed=17404257157 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000029-000017 --seed=18428036988 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:25:37] selfplay finished: 29.099 seconds
[2019-06-18 10:25:37] selfplay mn: 29.121 seconds
[2019-06-18 10:25:37] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-30-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=30 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779861 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559692 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339523 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119354 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899185 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142679016 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458847 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238678 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018509 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798340 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578171 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285358002 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137833 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917664 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697495 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477326 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257157 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036988 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816819 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596650 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376481 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156312 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golde
[2019-06-18 10:25:38] train finished: 44.207 seconds
:::MLL 1560875099.991540 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875099.992266 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875099.992981 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.110244 47732480070528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_0_0
:::MLL 1560875099.987578 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875099.988488 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875099.989301 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.110429 47569898898304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_0_0
W0618 10:25:00.111271 47732480070528 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmposq8vdel
W0618 10:25:00.111427 47569898898304 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp0ms6ftpy
I0618 10:25:00.112281 47732480070528 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmposq8vdel', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b69de1b2dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.112419 47569898898304 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp0ms6ftpy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4403833e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.112689 47732480070528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:00.112824 47569898898304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:00.117623 47732480070528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:00.117712 47569898898304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:00.137032 47732480070528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:00.137225 47569898898304 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875100.004226 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.004969 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.005779 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.137411 46932085056384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_0_0
:::MLL 1560875100.005895 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.006627 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.007301 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.138008 47804589679488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_0_0
W0618 10:25:00.138444 46932085056384 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpc7ifhtpn
I0618 10:25:00.139450 46932085056384 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpc7ifhtpn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aaf82d86e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:25:00.138979 47804589679488 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpkvdtqznq
I0618 10:25:00.139856 46932085056384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:00.139965 47804589679488 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpkvdtqznq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7aa82c6e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.140380 47804589679488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:00.144876 46932085056384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:00.145370 47804589679488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:00.164286 46932085056384 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:00.164928 47804589679488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875100.041066 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.041833 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.042631 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.164084 47796116824960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_0_0
:::MLL 1560875100.042892 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.043576 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.044290 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.165146 47239801942912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_0_0
W0618 10:25:00.165245 47796116824960 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp7sw3bqzp
I0618 10:25:00.166381 47796116824960 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp7sw3bqzp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b78af26fe80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.166856 47796116824960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:00.166238 47239801942912 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp41g91tlh
I0618 10:25:00.167346 47239801942912 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp41g91tlh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af728337e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.167804 47239801942912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:00.172246 47796116824960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:00.172998 47239801942912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:00.185072 47732480070528 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:00.185044 47569898898304 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:00.189336 47569898898304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:25:00.189437 47732480070528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560875100.085301 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.085800 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.086334 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.191335 47493505061760 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_0_0
:::MLL 1560875100.093969 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.094613 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.094997 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.191987 47274521023360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_0_0
W0618 10:25:00.192376 47493505061760 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp0xy58t1l
I0618 10:25:00.193357 47493505061760 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp0xy58t1l', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b323a15ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:25:00.193000 47274521023360 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp8h6_vca7
I0618 10:25:00.193752 47493505061760 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:00.193983 47274521023360 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp8h6_vca7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aff3d9eae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.194379 47274521023360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:00.194322 47569898898304 estimator.py:1111] Calling model_fn.
W0618 10:25:00.194429 47569898898304 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:25:00.194488 47732480070528 estimator.py:1111] Calling model_fn.
W0618 10:25:00.194598 47732480070528 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:25:00.194287 47796116824960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:00.194826 47239801942912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:00.195763 47569898898304 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:25:00.195991 47732480070528 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560875100.074003 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.074565 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.074975 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.197190 46982257922944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_0_0
:::MLL 1560875100.077461 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.077923 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.078347 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.198278 47000967889792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_0_0
W0618 10:25:00.198347 47493505061760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:25:00.198258 46982257922944 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abb3161ad68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:25:00.198926 47274521023360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:25:00.199370 46982257922944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:00.199291 47000967889792 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpe9y8nt6l
:::MLL 1560875100.055166 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.055947 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.056617 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.198215 46916633547648 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_0_0
I0618 10:25:00.200269 47000967889792 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpe9y8nt6l', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abf8c951e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.200664 47000967889792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:00.199267 46916633547648 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmprpyonc3p
I0618 10:25:00.200275 46916633547648 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmprpyonc3p', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aabe9dd1da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.200666 46916633547648 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:00.204039 46982257922944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:00.205181 47000967889792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:00.205439 46916633547648 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875100.050853 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.051764 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.052532 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.210173 47323122578304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_0_0
W0618 10:25:00.213153 46932085056384 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:00.213594 47804589679488 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:00.211193 47323122578304 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp12rxwu36
I0618 10:25:00.212407 47323122578304 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp12rxwu36', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0a8e7f8e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.212862 47323122578304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:00.217262 47493505061760 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:00.217508 46932085056384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:25:00.217950 47804589679488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:25:00.217794 47274521023360 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:00.217570 47323122578304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:25:00.222616 46932085056384 estimator.py:1111] Calling model_fn.
W0618 10:25:00.222726 46932085056384 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:25:00.223085 47804589679488 estimator.py:1111] Calling model_fn.
W0618 10:25:00.223110 46982257922944 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:00.223195 47804589679488 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:25:00.224114 46932085056384 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:25:00.224125 47000967889792 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:00.224568 47804589679488 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:25:00.224858 46916633547648 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875100.113356 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.113792 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.114158 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.229955 47261764080512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_0_0
:::MLL 1560875100.112137 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.112563 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.112973 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.230027 47659521373056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_0_0
W0618 10:25:00.230998 47261764080512 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpuglkgox_
W0618 10:25:00.231027 47659521373056 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpco1nbapm
I0618 10:25:00.231991 47261764080512 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpuglkgox_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afc453f2e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.232002 47659521373056 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpco1nbapm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b58e16dbe80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.232386 47261764080512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:00.232398 47659521373056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:00.237060 47261764080512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:00.237082 47659521373056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:00.237574 47323122578304 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:00.243635 47796116824960 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:00.244035 47239801942912 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:00.247974 47796116824960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:25:00.248383 47239801942912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560875100.110130 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.111054 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.111945 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.247919 47556507198336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_0_0
:::MLL 1560875100.116917 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.117651 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.118348 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.248024 47340875555712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_0_0
W0618 10:25:00.248946 47556507198336 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmppflrep8g
W0618 10:25:00.249038 47340875555712 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpfl0n76oz
I0618 10:25:00.249954 47556507198336 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmppflrep8g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b40e54e2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.250036 47340875555712 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpfl0n76oz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0eb0a86e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.250354 47556507198336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:00.250428 47340875555712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:00.253065 47796116824960 estimator.py:1111] Calling model_fn.
W0618 10:25:00.253170 47796116824960 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:25:00.253472 47239801942912 estimator.py:1111] Calling model_fn.
W0618 10:25:00.253582 47239801942912 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:25:00.254549 47796116824960 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:25:00.254951 47239801942912 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:25:00.255239 47340875555712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:00.255269 47556507198336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:00.256161 47659521373056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:00.256216 47261764080512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875100.061333 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.062241 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.063171 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.261457 47964614988672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_0_0
:::MLL 1560875100.061317 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.062241 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.063163 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.262163 47457953543040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_0_0
W0618 10:25:00.264364 47493505061760 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:00.262583 47964614988672 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpv4_p3mib
W0618 10:25:00.264812 47274521023360 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:25:00.263687 47964614988672 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpv4_p3mib', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9fea6cde10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:25:00.263245 47457953543040 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp5g5gso_h
I0618 10:25:00.264140 47964614988672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:00.264399 47457953543040 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp5g5gso_h', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b29f30cce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.264856 47457953543040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875100.135179 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.135721 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.136346 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.266817 47201775825792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_0_0
:::MLL 1560875100.140845 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.141321 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.141739 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.267093 47422331081600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000019-000009.tfrecord.zz_0_0
W0618 10:25:00.268634 47493505061760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:25:00.269108 47274521023360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:25:00.267823 47201775825792 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpcvt7u_k0
I0618 10:25:00.268807 47201775825792 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpcvt7u_k0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aee4dab0e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:25:00.268102 47422331081600 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpih2f8kbh
W0618 10:25:00.270542 46982257922944 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:25:00.269127 47422331081600 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpih2f8kbh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b21a7c91e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.269213 47201775825792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:00.269436 47964614988672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:25:00.269523 47422331081600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:00.271196 47000967889792 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:00.270247 47457953543040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:25:00.273668 47493505061760 estimator.py:1111] Calling model_fn.
W0618 10:25:00.273772 47493505061760 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:25:00.272404 46916633547648 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:25:00.274168 47274521023360 estimator.py:1111] Calling model_fn.
W0618 10:25:00.274277 47274521023360 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:25:00.274830 46982257922944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:25:00.274431 47340875555712 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.inter[2019-06-18 10:25:40] divide_golden_chunk finished: 3.273 seconds
[2019-06-18 10:25:40] generate golden chunk: 3.287 seconds
[2019-06-18 10:25:40] moving /lfs/lfs12/gma_akey/results/epb312/models/000029-000018.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb312/models/000029-000019.data-00000-of-00001
[2019-06-18 10:25:40] moving /lfs/lfs12/gma_akey/results/epb312/models/000029-000018.pb --> /lfs/lfs12/gma_akey/results/epb312/models/000029-000019.pb
[2019-06-18 10:25:40] moving /lfs/lfs12/gma_akey/results/epb312/models/000029-000018.meta --> /lfs/lfs12/gma_akey/results/epb312/models/000029-000019.meta
[2019-06-18 10:25:40] moving /lfs/lfs12/gma_akey/results/epb312/models/000029-000018.index --> /lfs/lfs12/gma_akey/results/epb312/models/000029-000019.index
[2019-06-18 10:25:40] iteration time 28: 50.681 seconds
2019-06-18 10:25:42.046897: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560875140.574723 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 29}}
[2019-06-18 10:25:45] minmax time: 3.286 seconds
2019-06-18 10:25:45.343283: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:25:45.348741: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:25:45.353364: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560875145.364556 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 28}}
[2019-06-18 10:25:45] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:25:45] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-30-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000029-000019 --seed=30 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000029-000019 --seed=1023779861 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000029-000019 --seed=2047559692 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000029-000019 --seed=3071339523 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000029-000019 --seed=4095119354 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000029-000019 --seed=5118899185 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000029-000019 --seed=6142679016 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000029-000019 --seed=7166458847 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000029-000019 --seed=8190238678 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000029-000019 --seed=9214018509 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000029-000019 --seed=10237798340 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000029-000019 --seed=11261578171 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000029-000019 --seed=12285358002 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000029-000019 --seed=13309137833 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000029-000019 --seed=14332917664 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000029-000019 --seed=15356697495 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000029-000019 --seed=16380477326 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000029-000019 --seed=17404257157 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000029-000019 --seed=18428036988 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000029-000019 --seed=19451816819 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000029-000019 --seed=20475596650 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:25:56] eval finished: 10.675 seconds
[2019-06-18 10:25:56] Win rate 000029-000019 vs 000028-000018: 0.410
:::MLL 1560875156.101732 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 28}}
[2019-06-18 10:25:56] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-31-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000030-000018 --seed=31 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000030-000018 --seed=1023779862 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000030-000018 --seed=2047559693 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000030-000018 --seed=3071339524 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000030-000018 --seed=4095119355 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000030-000018 --seed=5118899186 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000030-000018 --seed=6142679017 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000030-000018 --seed=7166458848 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000030-000018 --seed=8190238679 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000030-000018 --seed=9214018510 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000030-000018 --seed=10237798341 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000030-000018 --seed=11261578172 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000030-000018 --seed=12285358003 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000030-000018 --seed=13309137834 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000030-000018 --seed=14332917665 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000030-000018 --seed=15356697496 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000030-000018 --seed=16380477327 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000030-000018 --seed=17404257158 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000030-000018 --seed=18428036989 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:26:26] selfplay finished: 30.061 seconds
[2019-06-18 10:26:26] selfplay mn: 30.079 seconds
[2019-06-18 10:26:26] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-31-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=31 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779862 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559693 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339524 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119355 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899186 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142679017 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458848 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238679 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018510 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798341 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578172 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285358003 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137834 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917665 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697496 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477327 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257158 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036989 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816820 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596651 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376482 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156313 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golde
[2019-06-18 10:26:29] train finished: 43.944 seconds
:::MLL 1560875150.617276 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875150.618002 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875150.618710 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:50.735294 47041225679744 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_0_0
:::MLL 1560875150.610913 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875150.611775 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875150.612605 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:50.735413 47952472781696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_0_0
W0618 10:25:50.736316 47041225679744 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmphnjodv78
W0618 10:25:50.736376 47952472781696 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpdcjkt5gk
I0618 10:25:50.737314 47041225679744 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmphnjodv78', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac8ec223e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:50.737344 47952472781696 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpdcjkt5gk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9d16b18e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:50.737718 47041225679744 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:50.737744 47952472781696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:50.742503 47952472781696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:50.742538 47041225679744 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:50.762017 47952472781696 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:50.762148 47041225679744 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875150.622462 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875150.623112 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875150.623770 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:50.764023 47073802916736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_0_0
:::MLL 1560875150.615040 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875150.615946 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875150.616768 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:50.764343 47496681104256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_0_0
W0618 10:25:50.765064 47073802916736 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmprd5pp1t7
W0618 10:25:50.765344 47496681104256 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpcubalmpg
I0618 10:25:50.766059 47073802916736 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmprd5pp1t7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad081e36e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:50.766334 47496681104256 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpcubalmpg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b32f7647e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:50.766462 47073802916736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:50.766735 47496681104256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:50.771442 47073802916736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:50.771709 47496681104256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875150.656624 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875150.657404 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875150.658158 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:50.779196 47589169025920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_0_0
W0618 10:25:50.780251 47589169025920 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp20hqzwpf
I0618 10:25:50.781251 47589169025920 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp20hqzwpf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b48801a2e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:50.781653 47589169025920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875150.658751 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875150.659460 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875150.660192 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:50.781666 47339116012416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_0_0
W0618 10:25:50.782669 47339116012416 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpu5i7shuv
I0618 10:25:50.783668 47339116012416 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpu5i7shuv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0e47c7fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:50.784066 47339116012416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:50.786422 47589169025920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:50.788653 47339116012416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:50.790552 47073802916736 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:50.790659 47496681104256 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:50.805616 47589169025920 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:50.808222 47339116012416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:50.809890 47952472781696 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:50.810622 47041225679744 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560875150.698364 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875150.698880 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875150.699352 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:50.810858 47124702999424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_0_0
:::MLL 1560875150.698635 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875150.699175 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875150.699599 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:50.811149 47039331378048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_0_0
I0618 10:25:50.811905 47124702999424 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adc5bc4fd68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:25:50.812163 47039331378048 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpau8aamwt
I0618 10:25:50.813003 47124702999424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:50.813150 47039331378048 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpau8aamwt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac87b396e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:50.813551 47039331378048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:50.814180 47952472781696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:25:50.814972 47041225679744 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560875150.697292 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875150.698051 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875150.698782 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:50.814108 47578888217472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_0_0
:::MLL 1560875150.682959 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875150.683847 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875150.684698 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:50.814401 47302418125696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_0_0
W0618 10:25:50.815121 47578888217472 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp6g5zyt72
I0618 10:25:50.816109 47578888217472 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp6g5zyt72', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b461b516e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:25:50.815400 47302418125696 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp7kswja0e
I0618 10:25:50.816396 47302418125696 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp7kswja0e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b05bc6aae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:50.816506 47578888217472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:50.817667 47124702999424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:25:50.816815 47302418125696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:50.818047 47039331378048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:25:50.819267 47952472781696 estimator.py:1111] Calling model_fn.
W0618 10:25:50.819375 47952472781696 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:25:50.820137 47041225679744 estimator.py:1111] Calling model_fn.
W0618 10:25:50.820244 47041225679744 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:25:50.820711 47952472781696 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:25:50.821603 47041225679744 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:25:50.821505 47578888217472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:50.821856 47302418125696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875150.708973 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875150.709522 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875150.710016 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:50.830523 47554501141376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_0_0
:::MLL 1560875150.715051 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875150.715509 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875150.715918 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:50.830761 47490829382528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_0_0
W0618 10:25:50.831556 47554501141376 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpnh6gkgp5
W0618 10:25:50.831748 47490829382528 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpagesp5jg
I0618 10:25:50.832544 47554501141376 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpnh6gkgp5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b406dbc3dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:50.832723 47490829382528 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpagesp5jg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b319a9a4dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:50.832950 47554501141376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:50.833124 47490829382528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:50.836715 47124702999424 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:50.837106 47039331378048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:50.837558 47554501141376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:50.837656 47490829382528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:50.839100 47496681104256 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:50.839188 47073802916736 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:50.840567 47578888217472 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:50.840953 47302418125696 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:50.843411 47496681104256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:25:50.843509 47073802916736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:25:50.848507 47496681104256 estimator.py:1111] Calling model_fn.
W0618 10:25:50.848616 47496681104256 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:25:50.848624 47073802916736 estimator.py:1111] Calling model_fn.
W0618 10:25:50.848734 47073802916736 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:25:50.849984 47496681104256 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:25:50.850106 47073802916736 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560875150.750856 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875150.751339 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875150.751757 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:50.850636 47742963368832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_0_0
:::MLL 1560875150.748799 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875150.749243 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875150.749670 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:50.851106 47300396340096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_0_0
W0618 10:25:50.851682 47742963368832 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpfbb2ezzd
I0618 10:25:50.852707 47742963368832 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpfbb2ezzd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6c4ef58e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:25:50.852094 47300396340096 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpvjdetx43
I0618 10:25:50.853079 47300396340096 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpvjdetx43', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0543e89da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:50.853114 47742963368832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:50.853471 47300396340096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:50.853849 47589169025920 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:50.856636 47490829382528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:50.856660 47554501141376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:50.856297 47339116012416 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:50.857747 47742963368832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:50.858028 47300396340096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:50.858168 47589169025920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560875150.663592 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875150.664522 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875150.665352 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:50.858603 47703290778496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_0_0
W0618 10:25:50.859733 47703290778496 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp_vcr_4wj
W0618 10:25:50.860652 47339116012416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:25:50.860837 47703290778496 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp_vcr_4wj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b631249ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:50.861290 47703290778496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:50.863296 47589169025920 estimator.py:1111] Calling model_fn.
W0618 10:25:50.863407 47589169025920 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:25:50.864788 47589169025920 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:25:50.865779 47339116012416 estimator.py:1111] Calling model_fn.
W0618 10:25:50.865891 47339116012416 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:25:50.866349 47703290778496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:50.867259 47339116012416 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:25:50.876912 47742963368832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:50.877084 47300396340096 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875150.669985 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875150.670704 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875150.671419 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:50.878902 47118610375552 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_0_0
:::MLL 1560875150.776162 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875150.776736 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875150.777220 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:50.881172 47046394512256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_0_0
W0618 10:25:50.879944 47118610375552 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpryj3yvn9
I0618 10:25:50.881030 47118610375552 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpryj3yvn9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adaf09efe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560875150.780348 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875150.780824 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875150.781232 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:50.881800 47865454728064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_0_0
I0618 10:25:50.881480 47118610375552 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:50.882217 47046394512256 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpbn0hbxmz
I0618 10:25:50.883201 47046394512256 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpbn0hbxmz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aca20385dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:25:50.882792 47865454728064 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpwxnpgkdz
I0618 10:25:50.883597 47046394512256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:50.884394 47039331378048 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:50.884470 47124702999424 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:25:50.883780 47865454728064 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpwxnpgkdz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b88d4035e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:50.884177 47865454728064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:50.886584 47118610375552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:50.888683 47039331378048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:25:50.888788 47124702999424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:25:50.888218 47046394512256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:50.887786 47703290778496 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:50.888726 47865454728064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:50.889435 47302418125696 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:50.889502 47578888217472 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:25:50.893782 47039331378048 estimator.py:1111] Calling model_fn.
I0618 10:25:50.893872 47124702999424 estimator.py:1111] Calling model_fn.
W0618 10:25:50.893890 47039331378048 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:25:50.893979 47124702999424 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:25:50.893743 47302418125696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:25:50.893775 47578888217472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:25:50.895239 47039331378048 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:25:50.895357 47124702999424 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560875150.659311 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875150.660218 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875150.661043 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:50.898507 47669099721600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000020-000009.tfrecord.zz_0_0
I0618 10:25:50.898830 47302418125696 estimator.py:1111] Calling model_fn.
I0618 10:25:50.898848 47578888217472 estimator.py:1111] Calling model_fn.
W0618 10:25:50.898939 47302418125696 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:25:50.898956 47578888217472 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:25:50.899597 47669099721600 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpcmc4mnex
W0618 10:25:50.900300 47302418125696 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:25:50.900306 47578888217472 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:25:50.900698 47669099721600 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpcmc4mnex', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_step[2019-06-18 10:26:29] divide_golden_chunk finished: 3.294 seconds
[2019-06-18 10:26:29] generate golden chunk: 3.309 seconds
[2019-06-18 10:26:29] iteration time 29: 48.916 seconds
2019-06-18 10:26:31.046388: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560875189.490755 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 30}}
[2019-06-18 10:26:34] minmax time: 3.231 seconds
2019-06-18 10:26:34.288392: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:26:34.293884: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:26:34.298437: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560875194.311737 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 29}}
[2019-06-18 10:26:34] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000031-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000031-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000031-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb332 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000031-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000031-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000031-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000031-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb051 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000031-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000031-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000031-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb312/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb312/models/000031-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb333 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:26:34] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-eval-31-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000030-000019 --seed=31 : \
-host epb318 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000030-000019 --seed=1023779862 : \
-host epb352 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000030-000019 --seed=2047559693 : \
-host epb339 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000030-000019 --seed=3071339524 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000030-000019 --seed=4095119355 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000030-000019 --seed=5118899186 : \
-host epb315 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000030-000019 --seed=6142679017 : \
-host epb338 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000030-000019 --seed=7166458848 : \
-host epb336 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000030-000019 --seed=8190238679 : \
-host epb335 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000030-000019 --seed=9214018510 : \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000030-000019 --seed=10237798341 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000030-000019 --seed=11261578172 : \
-host epb319 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000030-000019 --seed=12285358003 : \
-host epb317 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000030-000019 --seed=13309137834 : \
-host epb314 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000030-000019 --seed=14332917665 : \
-host epb316 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000030-000019 --seed=15356697496 : \
-host epb313 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000030-000019 --seed=16380477327 : \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000030-000019 --seed=17404257158 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000030-000019 --seed=18428036989 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000030-000019 --seed=19451816820 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/000030-000019 --seed=20475596651 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:26:45] eval finished: 11.023 seconds
[2019-06-18 10:26:45] Win rate 000030-000019 vs 000028-000018: 0.560
:::MLL 1560875205.399651 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 29}}
[2019-06-18 10:26:45] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-selfplay-32-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb312 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000031-000018 --seed=32 : \
-host epb318 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000031-000018 --seed=1023779863 : \
-host epb352 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000031-000018 --seed=2047559694 : \
-host epb339 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000031-000018 --seed=3071339525 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000031-000018 --seed=4095119356 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000031-000018 --seed=5118899187 : \
-host epb315 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000031-000018 --seed=6142679018 : \
-host epb338 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000031-000018 --seed=7166458849 : \
-host epb336 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000031-000018 --seed=8190238680 : \
-host epb335 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000031-000018 --seed=9214018511 : \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000031-000018 --seed=10237798342 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000031-000018 --seed=11261578173 : \
-host epb319 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000031-000018 --seed=12285358004 : \
-host epb317 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000031-000018 --seed=13309137835 : \
-host epb314 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000031-000018 --seed=14332917666 : \
-host epb316 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000031-000018 --seed=15356697497 : \
-host epb313 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000031-000018 --seed=16380477328 : \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000031-000018 --seed=17404257159 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb312/data/holdout/000031-000018 --seed=18428036990 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb312/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000030-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb31
[2019-06-18 10:27:14] selfplay finished: 29.199 seconds
[2019-06-18 10:27:14] selfplay mn: 29.217 seconds
[2019-06-18 10:27:14] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb312/mpi/out-divide_golden_chunk-32-%r.txt \
-host epb312 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000031-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=32 : \
-host epb318 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000031-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=1023779863 : \
-host epb352 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000031-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=2047559694 : \
-host epb339 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000031-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=3071339525 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000031-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=4095119356 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000031-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=5118899187 : \
-host epb315 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000031-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=6142679018 : \
-host epb338 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000031-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=7166458849 : \
-host epb336 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000031-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=8190238680 : \
-host epb335 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000031-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=9214018511 : \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000031-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=10237798342 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000031-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=11261578173 : \
-host epb319 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000031-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=12285358004 : \
-host epb317 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000031-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=13309137835 : \
-host epb314 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000031-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=14332917666 : \
-host epb316 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000031-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=15356697497 : \
-host epb313 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000031-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=16380477328 : \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000031-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=17404257159 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000031-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=18428036990 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000031-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=19451816821 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000031-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=20475596652 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000031-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=21499376483 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000031-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb312 --seed=22523156314 : \
-host epb001 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb312/data/selfplay/000031-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb312/data/golde
[2019-06-18 10:27:17] divide_golden_chunk finished: 3.300 seconds
[2019-06-18 10:27:17] generate golden chunk: 3.315 seconds
[2019-06-18 10:27:18] train finished: 43.704 seconds
:::MLL 1560875199.543442 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875199.544218 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875199.545017 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:39.668030 47089996166016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_0_0
:::MLL 1560875199.544917 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875199.545686 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875199.546367 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:39.668537 47776372560768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_0_0
W0618 10:26:39.669080 47089996166016 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmphlsj3diq
I0618 10:26:39.670093 47089996166016 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmphlsj3diq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad44714ce80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:26:39.669511 47776372560768 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpurj_haha
I0618 10:26:39.670505 47089996166016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:26:39.670502 47776372560768 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpurj_haha', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b74164d6e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:39.670894 47776372560768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:26:39.675436 47089996166016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:39.675731 47776372560768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:39.694534 47089996166016 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:26:39.695295 47776372560768 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875199.550997 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875199.551774 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875199.552459 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:39.707589 47606180926336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_0_0
:::MLL 1560875199.549464 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875199.550234 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875199.551025 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:39.708075 47729426400128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_0_0
W0618 10:26:39.708627 47606180926336 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpml7j3gtj
I0618 10:26:39.709646 47606180926336 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpml7j3gtj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4c76172e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:26:39.709081 47729426400128 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp_v0_wsgm
I0618 10:26:39.710059 47606180926336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:26:39.710080 47729426400128 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp_v0_wsgm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b692817de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:39.710485 47729426400128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:26:39.714854 47606180926336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:39.715265 47729426400128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:39.734033 47606180926336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:26:39.734760 47729426400128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875199.603126 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875199.603869 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875199.604587 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:39.733915 47845387330432 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_0_0
W0618 10:26:39.734937 47845387330432 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpk2hyqdou
I0618 10:26:39.735944 47845387330432 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpk2hyqdou', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8427e73dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:39.736352 47845387330432 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:26:39.741070 47845387330432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875199.623863 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875199.624360 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875199.624804 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:39.742204 47999374529408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_0_0
:::MLL 1560875199.624174 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875199.624675 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875199.625114 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:39.742217 47199300801408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_0_0
W0618 10:26:39.742856 47089996166016 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:26:39.743449 47776372560768 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:26:39.743249 47999374529408 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb312/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba802416d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:26:39.743234 47199300801408 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp1g1x8sbr
I0618 10:26:39.744210 47199300801408 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp1g1x8sbr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aedba252e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:39.744376 47999374529408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:26:39.744607 47199300801408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:26:39.747175 47089996166016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:26:39.747771 47776372560768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:26:39.749061 47999374529408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:39.749254 47199300801408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:26:39.752248 47089996166016 estimator.py:1111] Calling model_fn.
W0618 10:26:39.752358 47089996166016 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:26:39.752845 47776372560768 estimator.py:1111] Calling model_fn.
W0618 10:26:39.752955 47776372560768 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:26:39.753722 47089996166016 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:26:39.754320 47776372560768 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560875199.606179 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875199.606952 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875199.607638 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:39.754664 47827963515776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_0_0
W0618 10:26:39.755697 47827963515776 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpegmrw211
I0618 10:26:39.756718 47827963515776 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpegmrw211', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b80195cee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:39.757122 47827963515776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:26:39.761458 47845387330432 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:26:39.761880 47827963515776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:39.768009 47999374529408 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:26:39.768229 47199300801408 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875199.632346 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875199.632925 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875199.633508 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:39.773826 47953234695040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_0_0
:::MLL 1560875199.644552 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875199.645077 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875199.645521 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:39.773853 47243600417664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_0_0
W0618 10:26:39.774872 47243600417664 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpnov4jy_s
W0618 10:26:39.774834 47953234695040 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpm0vgbf0l
I0618 10:26:39.775820 47953234695040 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpm0vgbf0l', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9d441b6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:39.775854 47243600417664 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpnov4jy_s', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af80a9bae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:39.776232 47953234695040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:26:39.776256 47243600417664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:26:39.780887 47243600417664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:39.780913 47953234695040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875199.585793 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875199.586719 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875199.587531 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:39.780552 47489066038144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_0_0
W0618 10:26:39.781659 47606180926336 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:26:39.782089 47729426400128 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:26:39.781420 47827963515776 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:26:39.781702 47489066038144 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpszgclegv
:::MLL 1560875199.618494 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875199.619415 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875199.620328 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:39.781461 47698260231040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_0_0
I0618 10:26:39.782814 47489066038144 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpszgclegv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b31317fce80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560875199.624648 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875199.625383 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875199.626038 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:39.781768 47942607876992 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_0_0
I0618 10:26:39.783272 47489066038144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:26:39.782573 47698260231040 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmptlijbgx8
I0618 10:26:39.783667 47698260231040 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmptlijbgx8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b61e671de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:26:39.782874 47942607876992 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmperamjg1w
I0618 10:26:39.783967 47942607876992 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmperamjg1w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9acab2de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:39.784120 47698260231040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:26:39.784423 47942607876992 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:26:39.785946 47606180926336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:26:39.786393 47729426400128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560875199.613644 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875199.614346 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875199.614944 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:39.786824 47115958821760 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_0_0
:::MLL 1560875199.611420 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875199.612057 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875199.612688 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:39.787022 47901423137664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_0_0
W0618 10:26:39.788580 47489066038144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:39.787885 47115958821760 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpbe8t6qgq
W0618 10:26:39.788015 47901423137664 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp7siuo9gb
:::MLL 1560875199.593673 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875199.594433 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875199.595137 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:39.789546 48007984075648 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_0_0
I0618 10:26:39.788883 47115958821760 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpbe8t6qgq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ada52937e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:39.789022 47901423137664 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp7siuo9gb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9133e5cda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:39.789284 47115958821760 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:26:39.789426 47901423137664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:26:39.789463 47698260231040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:39.789550 47942607876992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:26:39.791004 47606180926336 estimator.py:1111] Calling model_fn.
W0618 10:26:39.791117 47606180926336 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:26:39.791424 47729426400128 estimator.py:1111] Calling model_fn.
W0618 10:26:39.791532 47729426400128 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:26:39.790651 48007984075648 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpp59m5bvt
I0618 10:26:39.791764 48007984075648 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpp59m5bvt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2baa036c9e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:26:39.792471 47606180926336 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:26:39.792208 48007984075648 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:26:39.792891 47729426400128 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:26:39.794170 47115958821760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:39.794230 47901423137664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:39.797322 48007984075648 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:39.799933 47243600417664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:26:39.799892 47953234695040 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:26:39.809878 47489066038144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:26:39.810127 47845387330432 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:26:39.811401 47698260231040 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:26:39.811491 47942607876992 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:26:39.813241 47115958821760 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:26:39.813517 47901423137664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:26:39.815173 47999374529408 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:26:39.814406 47845387330432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:26:39.815486 47199300801408 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560875199.686952 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875199.687445 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875199.687880 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:39.815663 47271656649600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_0_0
:::MLL 1560875199.688225 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875199.688686 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875199.689095 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:39.815701 47805813420928 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_0_0
W0618 10:26:39.816701 47271656649600 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpdn91cp6b
W0618 10:26:39.816738 47805813420928 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpvsw7v680
W0618 10:26:39.817787 48007984075648 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:26:39.817694 47271656649600 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpdn91cp6b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afe92e3ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:39.817718 47805813420928 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmpvsw7v680', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7af11d4dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:39.818110 47271656649600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:26:39.818116 47805813420928 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:26:39.819459 47999374529408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:26:39.819801 47199300801408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:26:39.819471 47845387330432 estimator.py:1111] Calling model_fn.
W0618 10:26:39.819583 47845387330432 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:26:39.820950 47845387330432 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:26:39.822869 47271656649600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:39.822829 47805813420928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:26:39.824550 47999374529408 estimator.py:1111] Calling model_fn.
W0618 10:26:39.824662 47999374529408 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:26:39.824890 47199300801408 estimator.py:1111] Calling model_fn.
W0618 10:26:39.824996 47199300801408 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560875199.649089 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875199.649594 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875199.650046 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:39.825079 47411139081088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_0_0
:::MLL 1560875199.653232 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875199.653686 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875199.654067 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:39.825179 47144927179648 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_0_0
W0618 10:26:39.826028 47999374529408 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:26:39.826368 47199300801408 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:26:39.826082 47411139081088 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp6cq3jw0y
W0618 10:26:39.826192 47144927179648 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmp_3iq8hn7
I0618 10:26:39.827074 47411139081088 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp6cq3jw0y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1f0cb0ce80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:39.827178 47144927179648 estimator.py:201] Using config: {'_model_dir': '/tmp/96727.tmpdir/tmp_3iq8hn7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae111397e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:39.827466 47411139081088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:26:39.827576 47144927179648 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:26:39.829010 47827963515776 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:26:39.832115 47411139081088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:39.832213 47144927179648 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:39.833281 47827963515776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560875199.696117 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875199.696612 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875199.697057 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:39.835761 47184309949312 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_0_0
:::MLL 1560875199.699751 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875199.700188 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875199.700553 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:39.836000 47862510453632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/000021-000010.tfrecord.zz_0_0
W0618 10:26:39.836794 47184309949312 estimator.py:1760] Using temporary folder as model directory: /tmp/96727.tmpdir/tmpop5f50f2
I0618 10:26:39.838289 47827963515776 estimator.py:1111] Calling model_fn.
W0618 10:26:39.837001 47862[2019-06-18 10:27:18] moving /lfs/lfs12/gma_akey/results/epb312/models/000031-000019.pb --> /lfs/lfs12/gma_akey/results/epb312/models/000031-000020.pb
[2019-06-18 10:27:18] moving /lfs/lfs12/gma_akey/results/epb312/models/000031-000019.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb312/models/000031-000020.data-00000-of-00001
[2019-06-18 10:27:18] moving /lfs/lfs12/gma_akey/results/epb312/models/000031-000019.meta --> /lfs/lfs12/gma_akey/results/epb312/models/000031-000020.meta
[2019-06-18 10:27:18] moving /lfs/lfs12/gma_akey/results/epb312/models/000031-000019.index --> /lfs/lfs12/gma_akey/results/epb312/models/000031-000020.index
[2019-06-18 10:27:18] iteration time 30: 48.587 seconds
:::MLL 1560875238.078269 epoch_stop: {"value": null, "metadata": {'lineno': 737, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 30}}
[2019-06-18 10:27:18] Total time: 1706.115 seconds

numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000018-000010_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000018-000010log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000019-000010_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000019-000010log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000020-000011_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000020-000011log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000021-000012_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000021-000012log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000022-000013_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000022-000013log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000023-000014_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000023-000014log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000024-000014_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000024-000014log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000025-000015_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000025-000015log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000026-000016_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000026-000016log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000027-000017_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000027-000017log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000028-000018_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000028-000018log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000029-000019_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000029-000019log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb312/models/000030-000019_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb312/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb312/models/000030-000019log.txt
:::MLL 1560875240.707160 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 0}}
I0618 10:27:20.707908 47651553973120 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/target --seed=1
I0618 10:27:47.833598 47651553973120 utils.py:86] eval finished: 27.125 seconds
I0618 10:27:47.837075 47651553973120 reference_implementation.py:563] Win rate 000001-000001 vs target: 0.060
:::MLL 1560875267.837754 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 0}}
:::MLL 1560875267.838080 eval_accuracy: {"value": 0.06, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 0}}
:::MLL 1560875267.838405 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 1}}
I0618 10:27:47.838711 47651553973120 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/target --seed=2
I0618 10:28:16.243107 47651553973120 utils.py:86] eval finished: 28.404 seconds
I0618 10:28:16.246058 47651553973120 reference_implementation.py:563] Win rate 000002-000002 vs target: 0.030
:::MLL 1560875296.247179 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 1}}
:::MLL 1560875296.247527 eval_accuracy: {"value": 0.03, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 1}}
:::MLL 1560875296.247849 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 2}}
I0618 10:28:16.248168 47651553973120 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/target --seed=3
I0618 10:28:42.593981 47651553973120 utils.py:86] eval finished: 26.346 seconds
I0618 10:28:42.596941 47651553973120 reference_implementation.py:563] Win rate 000003-000002 vs target: 0.080
:::MLL 1560875322.597647 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 2}}
:::MLL 1560875322.597972 eval_accuracy: {"value": 0.08, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 2}}
:::MLL 1560875322.598298 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 3}}
I0618 10:28:42.598610 47651553973120 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/target --seed=4
I0618 10:29:08.132411 47651553973120 utils.py:86] eval finished: 25.534 seconds
I0618 10:29:08.135287 47651553973120 reference_implementation.py:563] Win rate 000004-000003 vs target: 0.130
:::MLL 1560875348.135936 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 3}}
:::MLL 1560875348.136252 eval_accuracy: {"value": 0.13, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 3}}
:::MLL 1560875348.136596 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 4}}
I0618 10:29:08.136895 47651553973120 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/target --seed=5
I0618 10:29:33.396850 47651553973120 utils.py:86] eval finished: 25.260 seconds
I0618 10:29:33.399729 47651553973120 reference_implementation.py:563] Win rate 000005-000004 vs target: 0.060
:::MLL 1560875373.400617 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 4}}
:::MLL 1560875373.400955 eval_accuracy: {"value": 0.06, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 4}}
:::MLL 1560875373.401291 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 5}}
I0618 10:29:33.401622 47651553973120 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/target --seed=6
I0618 10:29:57.561168 47651553973120 utils.py:86] eval finished: 24.159 seconds
I0618 10:29:57.564060 47651553973120 reference_implementation.py:563] Win rate 000006-000004 vs target: 0.230
:::MLL 1560875397.564735 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 5}}
:::MLL 1560875397.565043 eval_accuracy: {"value": 0.23, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 5}}
:::MLL 1560875397.565351 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 6}}
I0618 10:29:57.565657 47651553973120 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/target --seed=7
I0618 10:30:22.195743 47651553973120 utils.py:86] eval finished: 24.630 seconds
I0618 10:30:22.198570 47651553973120 reference_implementation.py:563] Win rate 000007-000005 vs target: 0.180
:::MLL 1560875422.199600 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 6}}
:::MLL 1560875422.199935 eval_accuracy: {"value": 0.18, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 6}}
:::MLL 1560875422.200268 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 7}}
I0618 10:30:22.200592 47651553973120 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/target --seed=8
I0618 10:30:47.354348 47651553973120 utils.py:86] eval finished: 25.154 seconds
I0618 10:30:47.357266 47651553973120 reference_implementation.py:563] Win rate 000008-000005 vs target: 0.200
:::MLL 1560875447.358154 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 7}}
:::MLL 1560875447.358497 eval_accuracy: {"value": 0.2, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 7}}
:::MLL 1560875447.358830 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 8}}
I0618 10:30:47.359145 47651553973120 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/target --seed=9
I0618 10:31:11.786578 47651553973120 utils.py:86] eval finished: 24.427 seconds
I0618 10:31:11.789498 47651553973120 reference_implementation.py:563] Win rate 000009-000005 vs target: 0.250
:::MLL 1560875471.790182 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 8}}
:::MLL 1560875471.790525 eval_accuracy: {"value": 0.25, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 8}}
:::MLL 1560875471.790852 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 9}}
I0618 10:31:11.791168 47651553973120 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/target --seed=10
I0618 10:31:36.128974 47651553973120 utils.py:86] eval finished: 24.338 seconds
I0618 10:31:36.131871 47651553973120 reference_implementation.py:563] Win rate 000010-000006 vs target: 0.190
:::MLL 1560875496.132555 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 9}}
:::MLL 1560875496.132888 eval_accuracy: {"value": 0.19, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 9}}
:::MLL 1560875496.133214 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 10}}
I0618 10:31:36.133533 47651553973120 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/target --seed=11
I0618 10:32:02.880228 47651553973120 utils.py:86] eval finished: 26.747 seconds
I0618 10:32:02.883075 47651553973120 reference_implementation.py:563] Win rate 000011-000007 vs target: 0.250
:::MLL 1560875522.883947 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 10}}
:::MLL 1560875522.884282 eval_accuracy: {"value": 0.25, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 10}}
:::MLL 1560875522.884599 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 11}}
I0618 10:32:02.884904 47651553973120 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/target --seed=12
I0618 10:32:26.219340 47651553973120 utils.py:86] eval finished: 23.334 seconds
I0618 10:32:26.222261 47651553973120 reference_implementation.py:563] Win rate 000012-000008 vs target: 0.350
:::MLL 1560875546.223386 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 11}}
:::MLL 1560875546.223724 eval_accuracy: {"value": 0.35, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 11}}
:::MLL 1560875546.224048 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 12}}
I0618 10:32:26.224386 47651553973120 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000013-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/target --seed=13
I0618 10:32:50.290168 47651553973120 utils.py:86] eval finished: 24.066 seconds
I0618 10:32:50.293258 47651553973120 reference_implementation.py:563] Win rate 000013-000009 vs target: 0.260
:::MLL 1560875570.294002 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 12}}
:::MLL 1560875570.294316 eval_accuracy: {"value": 0.26, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 12}}
:::MLL 1560875570.294620 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 13}}
I0618 10:32:50.294975 47651553973120 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/target --seed=14
I0618 10:33:16.500057 47651553973120 utils.py:86] eval finished: 26.205 seconds
I0618 10:33:16.503127 47651553973120 reference_implementation.py:563] Win rate 000014-000009 vs target: 0.160
:::MLL 1560875596.504071 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 13}}
:::MLL 1560875596.504409 eval_accuracy: {"value": 0.16, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 13}}
:::MLL 1560875596.504726 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 14}}
I0618 10:33:16.505074 47651553973120 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb312/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb312/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb312/sgf/eval/target --seed=15
I0618 10:33:42.035691 47651553973120 utils.py:86] eval finished: 25.530 seconds
I0618 10:33:42.038696 47651553973120 reference_implementation.py:563] Win rate 000015-000009 vs target: 0.510
:::MLL 1560875622.039382 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 14}}
:::MLL 1560875622.039693 eval_accuracy: {"value": 0.51, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 14}}
:::MLL 1560875622.040032 eval_result: {"value": null, "metadata": {'lineno': 52, 'file': 'ml_perf/eval_models.py', 'iteration': 14, 'timestamp': 746.014}}
:::MLL 1560875622.040346 run_stop: {"value": null, "metadata": {'lineno': 53, 'file': 'ml_perf/eval_models.py', 'status': 'success'}}
Model 000015-000009 beat target after 746.014s
~/submission/benchmarks/minigo/clx-8260l-2s-x32
