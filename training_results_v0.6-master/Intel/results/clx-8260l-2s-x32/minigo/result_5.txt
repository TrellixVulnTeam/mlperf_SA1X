:::MLL 1560879986.538318697 submission_org: {"value": "Intel_Corp", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560879986.539797460 submission_platform: {"value": "32xCLX-8260L_CPUs", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560879986.541156524 submission_division: {"value": "closed", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560879986.542447533 submission_status: {"value": "onprem", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560879986.543774655 submission_benchmark: {"value": "minigo", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560879986.545183573 submission_poc_name: {"value": "Guokai Ma, Letian Kang, Christine Cheng, Mingxiao Huang", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560879986.546587420 submission_poc_email: {"value": "guokai.ma@intel.com, letian.kang@intel.com, christine.cheng@intel.com, mingxiao.huang@intel.com", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560879986.548016119 submission_entry: {"value": {"framework": "TensorFlow 1.13.1", "power": "none", "notes": "none", "interconnect": "OPA", "os": "Oracle Linux Server 7.6", "libraries": "MKLDNN (v0.18), MKL (v2019.0.3.20190220), IntelMPI (2018.1.163)", "compilers": "GCC6.3", "nodes": [{"num_nodes": 32, "cpu": "Intel(R) Xeon(R) Platinum 8260L CPU @ 2.40GHz", "num_cores": 48, "num_vcpus": "NA", "accelerator": "NA", "num_accelerators": 0, "sys_mem_size": "192G", "sys_storage_type": "SSD", "sys_storage_size": "800G", "cpu_accel_interconnect": "100Gb OPA", "network_card": "100Gb OPA", "num_network_cards": 1, "notes": "NA"}]}, "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560880007.188579449 cache_clear: {value: true, metadata: {lineno: 0, file: manual}}
~/submission/benchmarks/minigo/implementations/tensorflow ~/submission/benchmarks/minigo/clx-8260l-2s-x32
Physical cores = 48
Virtual cores = 96
NUMA cores = 24
KMP_HW_SUBSET = 2T
Output to /lfs/lfs12/gma_akey
./run_mn.sh: line 20: ulimit: max user processes: cannot modify limit: Operation not permitted
Wiping dir /lfs/lfs12/gma_akey/results/epb330
:::MLL 1560880014.517714 init_start: {"value": null, "metadata": {'lineno': 742, 'file': 'ml_perf/reference_implementation.py'}}
Making dir /lfs/lfs12/gma_akey/results/epb330/models
Making dir /lfs/lfs12/gma_akey/results/epb330/data/selfplay
Making dir /lfs/lfs12/gma_akey/results/epb330/data/holdout
Making dir /lfs/lfs12/gma_akey/results/epb330/sgf/eval
Making dir /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks
Making dir /lfs/lfs12/gma_akey/results/epb330/work_dir
Making dir /lfs/lfs12/gma_akey/results/epb330/mpi
[2019-06-18 11:46:54] Selfplay nodes = ['epb330', 'epb255', 'epb288', 'epb286', 'epb158', 'epb282', 'epb280', 'epb137', 'epb164', 'epb159', 'epb331', 'epb295', 'epb150', 'epb156', 'epb289', 'epb297', 'epb285', 'epb281', 'epb294', 'epb290', 'epb115', 'epb296', 'epb117', 'epb293', 'epb155', 'epb101']
[2019-06-18 11:46:54] Train nodes = ['epb103', 'epb105', 'epb108', 'epb291', 'epb292', 'epb154']
[2019-06-18 11:46:54] Eval nodes = ['epb330', 'epb255', 'epb288', 'epb286', 'epb158', 'epb282', 'epb280', 'epb137', 'epb164', 'epb159', 'epb331', 'epb295', 'epb150', 'epb156', 'epb289', 'epb297', 'epb285', 'epb281', 'epb294', 'epb290', 'epb115', 'epb296', 'epb117', 'epb293', 'epb155', 'epb101']
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.58s/it]
[2019-06-18 11:49:45] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/tools/strip_unused_lib.py:86: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
[2019-06-18 11:49:45] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/tools/optimize_for_inference_lib.py:113: remove_training_nodes (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.remove_training_nodes`
2019-06-18 11:49:45.167576: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX512F
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2019-06-18 11:49:45.180033: I tensorflow/core/common_runtime/process_util.cc:113] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
[2019-06-18 11:49:45] From ./quantize_graph.py:351: quantize_v2 (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.
Instructions for updating:
`tf.quantize_v2` is deprecated, please use `tf.quantization.quantize` instead.
2019-06-18 11:49:45.510101: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
[2019-06-18 11:49:45] From ./dual_net.py:679: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.gfile.GFile.
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_99']
Reading tf_records from 1 inputs
[2019-06-18 11:49:49] minmax time: 3.799 seconds
2019-06-18 11:49:49.320780: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:49:49.326197: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:49:49.330766: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880189.415398 init_stop: {"value": null, "metadata": {'lineno': 614, 'file': 'ml_perf/reference_implementation.py'}}
:::MLL 1560880189.415771 run_start: {"value": null, "metadata": {'lineno': 615, 'file': 'ml_perf/reference_implementation.py'}}
:::MLL 1560880189.416162 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 0}}
[2019-06-18 11:49:49] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir 
[2019-06-18 11:49:49] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-2-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000001-000000 --seed=2 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000001-000000 --seed=1023779833 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000001-000000 --seed=2047559664 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000001-000000 --seed=3071339495 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000001-000000 --seed=4095119326 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000001-000000 --seed=5118899157 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000001-000000 --seed=6142678988 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000001-000000 --seed=7166458819 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000001-000000 --seed=8190238650 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000001-000000 --seed=9214018481 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000001-000000 --seed=10237798312 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000001-000000 --seed=11261578143 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000001-000000 --seed=12285357974 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000001-000000 --seed=13309137805 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000001-000000 --seed=14332917636 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000001-000000 --seed=15356697467 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000001-000000 --seed=16380477298 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000001-000000 --seed=17404257129 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000001-000000 --seed=18428036960 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000001-000000 --seed=19451816791 : \
-host epb1
[2019-06-18 11:50:23] selfplay finished: 33.554 seconds
[2019-06-18 11:50:23] selfplay mn: 33.576 seconds
[2019-06-18 11:50:23] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-2-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779833 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559664 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339495 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119326 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899157 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142678988 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458819 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238650 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018481 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798312 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578143 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285357974 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137805 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917636 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697467 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477298 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257129 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036960 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816791 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596622 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376453 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156284 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_
[2019-06-18 11:50:38] divide_golden_chunk finished: 15.855 seconds
[2019-06-18 11:50:38] generate golden chunk: 15.872 seconds
[2019-06-18 11:50:46] train finished: 56.947 seconds
:::MLL 1560880205.927713 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880205.928445 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880205.929230 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:06.428869 47741100311424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880206.003273 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880206.003707 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880206.004095 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:06.429039 47358927410048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880205.921883 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880205.922681 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880205.923515 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:06.429538 47705210909568 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880206.005434 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880206.005877 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880206.006252 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:06.429702 46924219257728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 11:50:06.429929 47741100311424 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpbsjj7k76
I0618 11:50:06.430681 47741100311424 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpbsjj7k76', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6bdfe99e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:06.431037 47741100311424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:06.430498 47358927410048 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp_7qtp_vu
W0618 11:50:06.430975 47705210909568 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpol2740t9
I0618 11:50:06.431597 47358927410048 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp_7qtp_vu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b12e4a1ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:06.431737 47705210909568 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpol2740t9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6384bcce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:50:06.430999 46924219257728 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpl4_qswdu
I0618 11:50:06.432047 47358927410048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:06.432076 46924219257728 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpl4_qswdu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aadae01ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:06.432101 47705210909568 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:06.432522 46924219257728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:06.439402 47705210909568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:06.439445 47741100311424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:06.439615 47358927410048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:06.439628 46924219257728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880205.923931 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880205.924813 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880205.925663 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:06.440915 47713165947776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880205.933049 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880205.933795 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880205.934520 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:06.440977 47540080120704 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880205.988418 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880205.988887 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880205.989274 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:06.440958 47362722935680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880205.986959 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880205.987411 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880205.987788 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:06.441052 47775080498048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 11:50:06.441502 47713165947776 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp7_vik80p
W0618 11:50:06.441537 47540080120704 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp00gea_qz
I0618 11:50:06.442181 47713165947776 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp7_vik80p', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b655ee4fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:06.442208 47540080120704 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp00gea_qz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3d122cde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:06.442497 47713165947776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:06.442522 47540080120704 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:06.442062 47362722935680 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp8do66758
I0618 11:50:06.442167 47775080498048 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb330/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b73c94a1d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:06.443159 47362722935680 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp8do66758', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b13c6dd0dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:06.443397 47775080498048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:06.443605 47362722935680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880206.053701 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880206.054180 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880206.054570 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:06.448797 47582060356480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880206.047233 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880206.047715 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880206.048155 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:06.448836 47308763747200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880205.951530 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880205.952440 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880205.953310 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:06.449166 46941067121536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880205.977839 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880205.978641 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880205.979361 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:06.449116 47635380417408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 11:50:06.449892 47582060356480 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp_q966hu0
W0618 11:50:06.449925 47308763747200 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpc380874d
I0618 11:50:06.450974 47582060356480 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp_q966hu0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b46d8645e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:06.450997 47308763747200 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpc380874d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0736a52e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:50:06.450399 46941067121536 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmploriuul1
W0618 11:50:06.450366 47635380417408 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpzxym5jxw
I0618 11:50:06.451412 47582060356480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:06.451431 47308763747200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:06.451468 47635380417408 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpzxym5jxw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b534283fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:06.451484 46941067121536 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmploriuul1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab19a37ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:06.451940 47635380417408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:06.451951 46941067121536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:06.457148 46941067121536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:06.457182 47635380417408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880206.007958 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880206.008314 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880206.008636 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:06.459663 47374732084096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880206.010315 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880206.010685 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880206.011004 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:06.459691 47636481991552 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880205.945669 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880205.946569 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880205.947402 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:06.459945 47258787001216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880205.945635 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880205.946531 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880205.947360 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:06.459999 47725466370944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 11:50:06.460748 47374732084096 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpyupgx_5o
W0618 11:50:06.461040 47705210909568 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:50:06.461521 47374732084096 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpyupgx_5o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1692aa1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:50:06.460174 47362722935680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:06.461138 47741100311424 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:06.460184 47775080498048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:50:06.461861 47374732084096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:06.461171 47636481991552 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp88ymo06o
I0618 11:50:06.462267 47636481991552 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp88ymo06o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b53842cbe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:50:06.461895 46924219257728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:06.462031 47358927410048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:50:06.462709 47636481991552 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880205.947628 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880205.948357 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880205.949044 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:06.463235 47511812486016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880205.945746 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880205.946500 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880205.947298 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:06.463270 46942974264192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880206.014782 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880206.015149 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880206.015476 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:06.463487 47559500043136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880206.014330 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880206.014711 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880206.015057 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:06.463479 47250588742528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 11:50:06.464380 47258787001216 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp0mme1p7i
W0618 11:50:06.464406 47725466370944 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpoitvg1eu
I0618 11:50:06.465503 47725466370944 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpoitvg1eu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b683c0e7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:06.465528 47258787001216 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp0mme1p7i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afb93cc7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:06.465939 47725466370944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:06.466009 47258787001216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:06.467472 47511812486016 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpad2aq_id
W0618 11:50:06.467696 46942974264192 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpbascnrq2
I0618 11:50:06.468547 47511812486016 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpad2aq_id', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b367d4afe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:06.468776 46942974264192 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpbascnrq2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab20be49e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:50:06.468047 47559500043136 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpbk89o557
W0618 11:50:06.468739 47308763747200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:06.468061 47250588742528 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp5zsv1gs1
I0618 11:50:06.468985 47511812486016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:06.469847 47374732084096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:50:06.469205 46942974264192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:06.469210 47250588742528 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp5zsv1gs1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af9ab24fdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:50:06.470049 47636481991552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:50:06.469248 47559500043136 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpbk89o557', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4197b16e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:06.469711 47250588742528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:06.469756 47559500043136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:06.471117 47725466370944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:06.471241 47258787001216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:06.471444 47582060356480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:06.472900 47540080120704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:06.473498 47713165947776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:06.477219 46941067121536 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:06.477612 47511812486016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:06.477509 47635380417408 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:06.477626 46942974264192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:06.477718 47559500043136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:06.477738 47250588742528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:06.481607 47362722935680 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:06.481790 47775080498048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:06.489398 47374732084096 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:06.490178 47636481991552 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:06.490141 47308763747200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:06.492215 47540080120704 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:06.493631 47725466370944 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:06.493800 47258787001216 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:06.492917 47582060356480 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:06.492702 47713165947776 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:06.497375 46942974264192 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:06.497375 47511812486016 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:06.499338 47559500043136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:06.499375 47250588742528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:06.517506 46924219257728 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:50:06.517723 47705210909568 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:50:06.519953 47358927410048 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:50:06.520047 47741100311424 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:50:06.521870 46924219257728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:50:06.522477 47705210909568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:50:06.524286 47358927410048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:50:06.524784 47741100311424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:50:06.526976 46924219257728 estimator.py:1111] Calling model_fn.
W0618 11:50:06.527090 46924219257728 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:50:06.528033 47705210909568 estimator.py:1111] Calling model_fn.
W0618 11:50:06.528129 47705210909568 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:50:06.528526 46924219257728 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 11:50:06.529396 47358927410048 estimator.py:1111] Calling model_fn.
W0618 11:50:06.529505 47358927410048 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:50:06.529490 47705210909568 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 11:50:06.530319 47741100311424 estimator.py:1111] Calling model_fn.
W0618 11:50:06.530436 47741100311424 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:50:06.530938 47358927410048 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:50:06.531830 47741100311424 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:50:06.535840 46941067121536 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:50:06.538820 47635380417408 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:50:06.540137 46941067121536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:50:06.540443 47308763747200 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880206.029265 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880206.030153 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880206.031011 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:06.545113 47381563806592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880206.029242 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880206.030111 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880206.030949 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:06.545151 47823897203584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 11:50:06.543106 47582060356480 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880206.083350 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880206.083770 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880206.084156 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:06.545286 46983717139328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 11:50:06.543164 47635380417408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880206.084600 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880206.085005 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880206.085401 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:06.545351 47895497819008 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 11:50:06.545740 47381563806592 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp355njiw3
W0618 11:50:06.545771 47823897203584 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp5vswpfik
W0618 11:50:06.544909 47374732084096 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelera[2019-06-18 11:50:46] iteration time 0: 56.976 seconds
2019-06-18 11:50:46.754667: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880246.392695 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 1}}
[2019-06-18 11:50:50] minmax time: 3.248 seconds
2019-06-18 11:50:50.012474: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:50:50.017632: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:50:50.022209: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880250.033217 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 0}}
[2019-06-18 11:50:50] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir 
[2019-06-18 11:50:50] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-2-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000001-000001 --seed=2 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000001-000001 --seed=1023779833 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000001-000001 --seed=2047559664 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000001-000001 --seed=3071339495 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000001-000001 --seed=4095119326 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000001-000001 --seed=5118899157 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000001-000001 --seed=6142678988 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000001-000001 --seed=7166458819 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000001-000001 --seed=8190238650 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000001-000001 --seed=9214018481 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000001-000001 --seed=10237798312 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000001-000001 --seed=11261578143 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000001-000001 --seed=12285357974 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000001-000001 --seed=13309137805 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000001-000001 --seed=14332917636 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000001-000001 --seed=15356697467 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000001-000001 --seed=16380477298 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000001-000001 --seed=17404257129 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000001-000001 --seed=18428036960 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000001-000001 --seed=19451816791 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000001-000001 --seed=20475596622 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_
[2019-06-18 11:51:00] eval finished: 10.679 seconds
[2019-06-18 11:51:00] Win rate 000001-000001 vs checkpoint: 0.620
:::MLL 1560880260.782336 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 0}}
[2019-06-18 11:51:00] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-3-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000002-000000 --seed=3 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000002-000000 --seed=1023779834 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000002-000000 --seed=2047559665 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000002-000000 --seed=3071339496 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000002-000000 --seed=4095119327 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000002-000000 --seed=5118899158 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000002-000000 --seed=6142678989 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000002-000000 --seed=7166458820 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000002-000000 --seed=8190238651 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000002-000000 --seed=9214018482 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000002-000000 --seed=10237798313 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000002-000000 --seed=11261578144 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000002-000000 --seed=12285357975 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000002-000000 --seed=13309137806 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000002-000000 --seed=14332917637 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000002-000000 --seed=15356697468 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000002-000000 --seed=16380477299 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000002-000000 --seed=17404257130 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000002-000000 --seed=18428036961 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/
[2019-06-18 11:51:30] selfplay finished: 29.468 seconds
[2019-06-18 11:51:30] selfplay mn: 29.485 seconds
[2019-06-18 11:51:30] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-3-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779834 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559665 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339496 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119327 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899158 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142678989 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458820 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238651 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018482 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798313 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578144 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285357975 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137806 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917637 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697468 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477299 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257130 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036961 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816792 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596623 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376454 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156285 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_
[2019-06-18 11:51:33] divide_golden_chunk finished: 3.352 seconds
[2019-06-18 11:51:33] generate golden chunk: 3.366 seconds
[2019-06-18 11:51:34] train finished: 44.252 seconds
:::MLL 1560880255.286147 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880255.286971 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880255.287742 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:55.352497 47480842994560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880255.287425 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880255.288241 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880255.288918 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:55.352535 46958047843200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:50:55.353552 47480842994560 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp7p3ddbj_
W0618 11:50:55.353576 46958047843200 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpsjghpgvn
I0618 11:50:55.354589 47480842994560 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp7p3ddbj_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2f475e1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:55.354609 46958047843200 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpsjghpgvn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab58e592e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:55.355020 47480842994560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:55.355040 46958047843200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:55.360334 47480842994560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:55.360359 46958047843200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:55.380268 46958047843200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:55.380331 47480842994560 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880255.363912 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880255.364356 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880255.364737 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:55.392061 47455538074496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:50:55.393121 47455538074496 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpg4m6_sdn
:::MLL 1560880255.367364 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880255.367818 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880255.368213 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:55.393995 47586866832256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000001.tfrecord.zz_0
I0618 11:50:55.394177 47455538074496 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpg4m6_sdn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b296313ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:55.394584 47455538074496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:55.394993 47586866832256 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp0ea3148m
I0618 11:50:55.396013 47586866832256 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp0ea3148m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b47f6e16e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:55.396426 47586866832256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:55.399573 47455538074496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:55.401224 47586866832256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:55.419361 47455538074496 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:55.420887 47586866832256 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:55.428228 47480842994560 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:50:55.428343 46958047843200 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:50:55.432542 47480842994560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:50:55.432664 46958047843200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:50:55.437591 47480842994560 estimator.py:1111] Calling model_fn.
W0618 11:50:55.437696 47480842994560 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:50:55.437742 46958047843200 estimator.py:1111] Calling model_fn.
W0618 11:50:55.437863 46958047843200 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:50:55.439061 47480842994560 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:50:55.439229 46958047843200 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560880255.386522 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880255.387306 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880255.388035 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:55.449143 47274080056192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880255.375544 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880255.376482 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880255.377338 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:55.449135 47209693090688 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880255.372792 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880255.373699 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880255.374547 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:55.450234 47246472434560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880255.381152 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880255.381859 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880255.382536 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:55.450249 47529677263744 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880255.375441 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880255.376348 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880255.377194 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:55.449696 47582856078208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880255.383248 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880255.383999 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880255.384730 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:55.449723 46988493874048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:50:55.450285 47274080056192 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpmtsic5_7
W0618 11:50:55.450311 47209693090688 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpbyxu3vo9
W0618 11:50:55.451292 47246472434560 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp2hutd8kl
W0618 11:50:55.451314 47529677263744 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp1xh9ws3n
I0618 11:50:55.451278 47274080056192 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpmtsic5_7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aff2355fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:55.451299 47209693090688 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpbyxu3vo9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af02592de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:50:55.450710 46988493874048 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpq0oe_vb2
W0618 11:50:55.450682 47582856078208 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp0efzxyc3
I0618 11:50:55.452323 47246472434560 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp2hutd8kl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af8b5cb2e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:55.452342 47529677263744 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp1xh9ws3n', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3aa61dde10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:55.451733 47582856078208 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp0efzxyc3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4707d23e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:55.451669 47274080056192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:55.451759 46988493874048 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpq0oe_vb2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abca512ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:55.451695 47209693090688 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:55.452743 47246472434560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:55.452761 47529677263744 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:55.452143 47582856078208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:55.452172 46988493874048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:55.456721 47209693090688 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:55.456734 47274080056192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:55.457869 47246472434560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:55.457899 47529677263744 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:55.457326 47582856078208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:55.457345 46988493874048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:55.466770 47455538074496 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880255.396435 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880255.397329 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880255.398196 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:55.466484 47270899819392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880255.396388 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880255.397270 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880255.398114 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:55.466487 47278218179456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:50:55.468317 47586866832256 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:50:55.467487 47270899819392 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpy9qpncw9
W0618 11:50:55.467505 47278218179456 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpg20n48d2
I0618 11:50:55.468466 47278218179456 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpg20n48d2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0019fcbe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:55.468466 47270899819392 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpy9qpncw9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afe65c77e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:55.468859 47270899819392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:55.468861 47278218179456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:55.471053 47455538074496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:50:55.472640 47586866832256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:50:55.473733 47270899819392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:55.473754 47278218179456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880255.447654 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880255.448049 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880255.448405 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:55.476026 47947774444416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880255.447938 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880255.448353 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880255.448681 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:55.476025 47359416669056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000001.tfrecord.zz_0
I0618 11:50:55.476063 47455538074496 estimator.py:1111] Calling model_fn.
W0618 11:50:55.476171 47455538074496 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:50:55.476301 47209693090688 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:55.476551 47274080056192 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:55.477528 47455538074496 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:50:55.477441 47359416669056 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmps7mrj03a
I0618 11:50:55.477727 47586866832256 estimator.py:1111] Calling model_fn.
W0618 11:50:55.477466 47947774444416 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpoj8qtyfa
W0618 11:50:55.477837 47586866832256 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:50:55.478411 47359416669056 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmps7mrj03a', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1301cb6e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:55.478422 47947774444416 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpoj8qtyfa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9bfea69e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880255.407603 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880255.408540 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880255.409445 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:55.479888 46969110614912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:50:55.478714 47246472434560 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880255.412676 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880255.413489 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880255.414180 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:55.479909 47472723035008 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:50:55.478736 47529677263744 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:50:55.478800 47947774444416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:55.478803 47359416669056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:55.478199 47582856078208 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:55.478405 46988493874048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:55.479197 47586866832256 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:50:55.480933 46969110614912 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpdg0__aqd
W0618 11:50:55.480906 47472723035008 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpfg6jshbx
I0618 11:50:55.481963 47472723035008 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpfg6jshbx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2d63614e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:55.481990 46969110614912 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpdg0__aqd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab821bdae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880255.453968 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880255.454459 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880255.455044 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:55.479779 46991622931328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000001.tfrecord.zz_0
I0618 11:50:55.482364 47472723035008 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:55.482393 46969110614912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:55.480795 46991622931328 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpfo45ihnt
I0618 11:50:55.481808 46991622931328 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpfo45ihnt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abd5f945e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:55.482194 46991622931328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:55.483526 47947774444416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:55.483524 47359416669056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880255.458561 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880255.459008 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880255.459346 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:55.483268 47655771181952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:50:55.484219 47655771181952 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpdo386bb5
I0618 11:50:55.485162 47655771181952 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpdo386bb5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5801e65e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:50:55.487394 46969110614912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:55.487396 47472723035008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:50:55.485556 47655771181952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:55.486788 46991622931328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880255.459635 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880255.460011 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880255.460339 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:55.487532 47664757703552 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880255.461358 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880255.461736 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880255.462128 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:55.488780 47516725969792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:50:55.488512 47664757703552 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpcs_a_359
I0618 11:50:55.489477 47664757703552 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpcs_a_359', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5a1989de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880255.460986 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880255.461430 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880255.461855 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:55.489101 47805676368768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000001.tfrecord.zz_0
I0618 11:50:55.489873 47664757703552 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:55.490146 47655771181952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:55.489708 47516725969792 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp77kdf7ci
I0618 11:50:55.490726 47516725969792 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp77kdf7ci', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b37a228ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:55.491149 47516725969792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:55.490112 47805676368768 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp1dl58l5u
I0618 11:50:55.491142 47805676368768 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp1dl58l5u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7ae8f20dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:55.491567 47805676368768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880255.464633 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880255.465065 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880255.465455 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:55.491698 47323080131456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000001.tfrecord.zz_0
I0618 11:50:55.492713 47323080131456 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb330/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0a8bf7dd30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:50:55.493650 47270899819392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:55.493660 47278218179456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:50:55.493796 47323080131456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:55.494640 47664757703552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:55.495753 47516725969792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:55.496249 47805676368768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:55.498451 47323080131456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:55.503276 47947774444416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:55.503291 47359416669056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:55.507254 46969110614912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:55.507260 47472723035008 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:55.506544 46991622931328 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:55.509901 47655771181952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:55.514383 47664757703552 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:55.515302 47516725969792 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880255.488451 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880255.488850 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880255.489217 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:55.517391 47640788226944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880255.489230 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880255.489614 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880255.489936 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:55.517465 47822324183936 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:50:55.516013 47805676368768 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:55.518445 47822324183936 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpl6716xj1
W0618 11:50:55.518417 47640788226944 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpskv_18a5
I0618 11:50:55.519389 47640788226944 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpskv_18a5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5484d8ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:55.519406 47822324183936 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpl6716xj1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7ec93b8e[2019-06-18 11:51:34] moving /lfs/lfs12/gma_akey/results/epb330/models/000002-000001.meta --> /lfs/lfs12/gma_akey/results/epb330/models/000002-000002.meta
[2019-06-18 11:51:34] moving /lfs/lfs12/gma_akey/results/epb330/models/000002-000001.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb330/models/000002-000002.data-00000-of-00001
[2019-06-18 11:51:34] moving /lfs/lfs12/gma_akey/results/epb330/models/000002-000001.index --> /lfs/lfs12/gma_akey/results/epb330/models/000002-000002.index
[2019-06-18 11:51:34] moving /lfs/lfs12/gma_akey/results/epb330/models/000002-000001.pb --> /lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb
[2019-06-18 11:51:34] iteration time 1: 47.962 seconds
2019-06-18 11:51:34.759078: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880294.354398 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 2}}
[2019-06-18 11:51:37] minmax time: 3.232 seconds
2019-06-18 11:51:38.000532: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:51:38.005911: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:51:38.010406: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880298.020020 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 1}}
[2019-06-18 11:51:38] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir 
[2019-06-18 11:51:38] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-3-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000002-000002 --seed=3 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000002-000002 --seed=1023779834 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000002-000002 --seed=2047559665 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000002-000002 --seed=3071339496 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000002-000002 --seed=4095119327 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000002-000002 --seed=5118899158 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000002-000002 --seed=6142678989 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000002-000002 --seed=7166458820 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000002-000002 --seed=8190238651 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000002-000002 --seed=9214018482 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000002-000002 --seed=10237798313 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000002-000002 --seed=11261578144 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000002-000002 --seed=12285357975 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000002-000002 --seed=13309137806 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000002-000002 --seed=14332917637 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000002-000002 --seed=15356697468 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000002-000002 --seed=16380477299 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000002-000002 --seed=17404257130 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000002-000002 --seed=18428036961 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000002-000002 --seed=19451816792 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000002-000002 --seed=20475596623 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 11:51:50] eval finished: 12.479 seconds
[2019-06-18 11:51:50] Win rate 000002-000002 vs 000001-000001: 0.810
:::MLL 1560880310.571040 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 1}}
[2019-06-18 11:51:50] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-4-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000003-000001 --seed=4 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000003-000001 --seed=1023779835 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000003-000001 --seed=2047559666 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000003-000001 --seed=3071339497 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000003-000001 --seed=4095119328 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000003-000001 --seed=5118899159 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000003-000001 --seed=6142678990 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000003-000001 --seed=7166458821 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000003-000001 --seed=8190238652 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000003-000001 --seed=9214018483 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000003-000001 --seed=10237798314 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000003-000001 --seed=11261578145 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000003-000001 --seed=12285357976 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000003-000001 --seed=13309137807 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000003-000001 --seed=14332917638 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000003-000001 --seed=15356697469 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000003-000001 --seed=16380477300 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000003-000001 --seed=17404257131 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000003-000001 --seed=18428036962 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/
[2019-06-18 11:52:23] train finished: 45.577 seconds
:::MLL 1560880303.319823 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880303.320690 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880303.321505 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:43.388768 47403315581824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880303.319864 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880303.320736 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880303.321554 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:43.388926 46985935745920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:51:43.389820 47403315581824 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpgz3m6022
W0618 11:51:43.389916 46985935745920 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpeimp0rso
I0618 11:51:43.390896 47403315581824 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpgz3m6022', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1d3a5fae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:43.390959 46985935745920 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpeimp0rso', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abc0c98ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:43.391316 47403315581824 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:43.391366 46985935745920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:43.396564 46985935745920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:43.396570 47403315581824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:43.416238 47403315581824 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:43.416722 46985935745920 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880303.347268 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880303.348161 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880303.348963 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:43.419828 47777005826944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880303.353158 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880303.353899 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880303.354599 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:43.419912 47836827726720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:51:43.421115 47777005826944 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp49b38dw1
W0618 11:51:43.421144 47836827726720 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpehnbmudj
I0618 11:51:43.422119 47836827726720 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpehnbmudj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8229b60e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:43.422124 47777005826944 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp49b38dw1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b743c0c3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:43.422559 47836827726720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:43.422577 47777005826944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:43.427344 47836827726720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:43.427352 47777005826944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880303.401105 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880303.401546 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880303.401939 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:43.439903 47457325671296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880303.400944 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880303.401377 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880303.401765 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:43.439955 47564088058752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:51:43.440887 47457325671296 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpvmhvlkms
W0618 11:51:43.440960 47564088058752 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp3_sxtbkf
I0618 11:51:43.441936 47457325671296 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpvmhvlkms', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b29cda01e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:43.442008 47564088058752 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp3_sxtbkf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b42a928edd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:43.442362 47457325671296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:43.442424 47564088058752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:43.447064 47457325671296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:43.447089 47564088058752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:43.447148 47777005826944 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:43.447159 47836827726720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:43.464096 47403315581824 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:51:43.464688 46985935745920 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880303.421161 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880303.421533 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880303.421851 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:43.465056 47950113481600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880303.420152 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880303.420532 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880303.420870 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:43.465115 47280504910720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:51:43.466743 47457325671296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:43.466919 47564088058752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:43.466097 47950113481600 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpeuu_fgf7
I0618 11:51:43.466216 47280504910720 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb330/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b00a2498d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:43.467163 47950113481600 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpeuu_fgf7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9c8a117dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:43.467436 47280504910720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:43.467604 47950113481600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:43.468384 47403315581824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:51:43.469005 46985935745920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880303.403435 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880303.404183 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880303.404860 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:43.472626 47788763616128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880303.400050 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880303.400852 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880303.401528 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:43.472677 47289545974656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:51:43.473664 47788763616128 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp365k5oj3
W0618 11:51:43.473693 47289545974656 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp44kxite1
I0618 11:51:43.474754 47788763616128 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp365k5oj3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b76f8ddee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:43.474773 47289545974656 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp44kxite1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b02bd2d3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:51:43.472338 47280504910720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:43.472341 47950113481600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:51:43.475191 47788763616128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:43.475206 47289545974656 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:43.473453 47403315581824 estimator.py:1111] Calling model_fn.
W0618 11:51:43.473561 47403315581824 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:51:43.474070 46985935745920 estimator.py:1111] Calling model_fn.
W0618 11:51:43.474178 46985935745920 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:51:43.474913 47403315581824 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:51:43.475527 46985935745920 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:51:43.480260 47289545974656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:43.480278 47788763616128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:43.491854 47950113481600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:43.492068 47280504910720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880303.419052 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880303.419928 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880303.420775 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:43.495714 47738727121792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880303.420014 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880303.420903 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880303.421618 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:43.495723 47424747008896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:51:43.495100 47777005826944 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:51:43.495298 47836827726720 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:51:43.496794 47424747008896 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmppy7fvkgi
W0618 11:51:43.496822 47738727121792 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp0b2uzswl
I0618 11:51:43.497900 47424747008896 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmppy7fvkgi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2237c93e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:43.497909 47738727121792 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp0b2uzswl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6b52759e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880303.418860 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880303.419785 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880303.420638 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:43.497020 47829979562880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880303.428344 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880303.429075 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880303.429765 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:43.497056 47336005202816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000002.tfrecord.zz_0
I0618 11:51:43.498350 47424747008896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:43.498359 47738727121792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:43.500351 47788763616128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:43.500397 47289545974656 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:43.498112 47829979562880 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpoq408wr0
W0618 11:51:43.498144 47336005202816 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp951owf7t
I0618 11:51:43.499179 47829979562880 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpoq408wr0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8091875e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:43.499196 47336005202816 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp951owf7t', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0d8e5cce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:43.499603 47829979562880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:43.499618 47336005202816 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:43.499417 47777005826944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:51:43.499639 47836827726720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:51:43.503760 47738727121792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:43.503771 47424747008896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:43.504750 47829979562880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:43.504798 47336005202816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:51:43.504516 47777005826944 estimator.py:1111] Calling model_fn.
W0618 11:51:43.504625 47777005826944 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:51:43.504745 47836827726720 estimator.py:1111] Calling model_fn.
W0618 11:51:43.504854 47836827726720 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:51:43.505983 47777005826944 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:51:43.506212 47836827726720 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560880303.437508 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880303.438313 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880303.439148 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:43.508138 47317623051136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880303.438896 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880303.439728 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880303.440441 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:43.508173 47103211344768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:51:43.509244 47317623051136 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp6cwoi1vr
W0618 11:51:43.509212 47103211344768 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpehwupa7o
I0618 11:51:43.510213 47103211344768 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpehwupa7o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad75ac46e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:43.510262 47317623051136 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp6cwoi1vr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0946b36e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:43.510607 47103211344768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:43.510664 47317623051136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880303.480958 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880303.481345 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880303.481692 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:43.514225 47117942109056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880303.482176 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880303.482555 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880303.482884 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:43.514246 47018258215808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:51:43.515225 47018258215808 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpdqdggt36
W0618 11:51:43.515253 47117942109056 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpx9ygwyw1
W0618 11:51:43.514204 47457325671296 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 11:51:43.516199 47018258215808 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpdqdggt36', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac3932a6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:43.516225 47117942109056 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpx9ygwyw1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adac8ca0dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:43.516596 47018258215808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:43.516623 47117942109056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:43.514845 47564088058752 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:51:43.515624 47317623051136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:43.515631 47103211344768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:43.518504 47457325671296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:51:43.519200 47564088058752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:51:43.521349 47117942109056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:43.521364 47018258215808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:51:43.523571 47457325671296 estimator.py:1111] Calling model_fn.
W0618 11:51:43.523678 47457325671296 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:51:43.524294 47564088058752 estimator.py:1111] Calling model_fn.
:::MLL 1560880303.491929 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880303.492312 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880303.492667 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:43.524487 47581038191488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:51:43.524404 47564088058752 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560880303.492787 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880303.493173 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880303.493507 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:43.525053 46948528575360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:51:43.525020 47457325671296 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:51:43.525756 47564088058752 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:51:43.526174 47424747008896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:43.525574 47581038191488 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpsufh7r62
W0618 11:51:43.526487 47738727121792 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:51:43.526618 47581038191488 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpsufh7r62', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b469b777e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:51:43.526077 46948528575360 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmplcmet3nz
I0618 11:51:43.527039 47581038191488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:43.527101 46948528575360 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmplcmet3nz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab356f4ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:43.527513 46948528575360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:43.527275 47829979562880 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:43.527476 47336005202816 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:43.531899 47581038191488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:43.532258 46948528575360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880303.501704 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880303.502103 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880303.502589 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:43.534692 47716589118336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880303.502768 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880303.503134 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880303.503482 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:43.534694 48010798748544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:51:43.535384 47103211344768 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:43.535462 47317623051136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:43.535633 48010798748544 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp3vabydic
W0618 11:51:43.535664 47716589118336 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp_woqawl2
I0618 11:51:43.536602 48010798748544 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp3vabydic', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2baaab311e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:43.536619 47716589118336 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp_woqawl2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b662aee7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:43.536981 48010798748544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:43.537009 47716589118336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:43.541066 47018258215808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:43.541094 47117942109056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:43.539145 47950113481600 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all [2019-06-18 11:52:23] selfplay finished: 33.213 seconds
[2019-06-18 11:52:23] selfplay mn: 33.229 seconds
[2019-06-18 11:52:23] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-4-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779835 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559666 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339497 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119328 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899159 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142678990 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458821 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238652 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018483 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798314 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578145 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285357976 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137807 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917638 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697469 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477300 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257131 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036962 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816793 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596624 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376455 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156286 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_
[2019-06-18 11:52:27] divide_golden_chunk finished: 3.379 seconds
[2019-06-18 11:52:27] generate golden chunk: 3.394 seconds
[2019-06-18 11:52:27] moving /lfs/lfs12/gma_akey/results/epb330/models/000003-000002.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb330/models/000003-000003.data-00000-of-00001
[2019-06-18 11:52:27] moving /lfs/lfs12/gma_akey/results/epb330/models/000003-000002.pb --> /lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb
[2019-06-18 11:52:27] moving /lfs/lfs12/gma_akey/results/epb330/models/000003-000002.meta --> /lfs/lfs12/gma_akey/results/epb330/models/000003-000003.meta
[2019-06-18 11:52:27] moving /lfs/lfs12/gma_akey/results/epb330/models/000003-000002.index --> /lfs/lfs12/gma_akey/results/epb330/models/000003-000003.index
[2019-06-18 11:52:27] iteration time 2: 52.886 seconds
2019-06-18 11:52:27.687458: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880347.240557 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 3}}
[2019-06-18 11:52:30] minmax time: 3.242 seconds
2019-06-18 11:52:30.940200: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:52:30.945531: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:52:30.949794: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880350.959755 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 2}}
[2019-06-18 11:52:30] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000004-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000004-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000004-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000004-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000004-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000004-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000004-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000004-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000004-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000004-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000004-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir 
[2019-06-18 11:52:31] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-4-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000003-000003 --seed=4 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000003-000003 --seed=1023779835 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000003-000003 --seed=2047559666 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000003-000003 --seed=3071339497 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000003-000003 --seed=4095119328 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000003-000003 --seed=5118899159 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000003-000003 --seed=6142678990 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000003-000003 --seed=7166458821 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000003-000003 --seed=8190238652 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000003-000003 --seed=9214018483 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000003-000003 --seed=10237798314 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000003-000003 --seed=11261578145 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000003-000003 --seed=12285357976 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000003-000003 --seed=13309137807 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000003-000003 --seed=14332917638 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000003-000003 --seed=15356697469 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000003-000003 --seed=16380477300 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000003-000003 --seed=17404257131 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000003-000003 --seed=18428036962 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000003-000003 --seed=19451816793 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000003-000003 --seed=20475596624 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 11:52:41] eval finished: 10.589 seconds
[2019-06-18 11:52:41] Win rate 000003-000003 vs 000002-000002: 0.590
:::MLL 1560880361.620459 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 2}}
[2019-06-18 11:52:41] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-5-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000004-000002 --seed=5 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000004-000002 --seed=1023779836 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000004-000002 --seed=2047559667 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000004-000002 --seed=3071339498 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000004-000002 --seed=4095119329 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000004-000002 --seed=5118899160 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000004-000002 --seed=6142678991 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000004-000002 --seed=7166458822 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000004-000002 --seed=8190238653 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000004-000002 --seed=9214018484 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000004-000002 --seed=10237798315 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000004-000002 --seed=11261578146 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000004-000002 --seed=12285357977 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000004-000002 --seed=13309137808 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000004-000002 --seed=14332917639 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000004-000002 --seed=15356697470 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000004-000002 --seed=16380477301 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000004-000002 --seed=17404257132 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000004-000002 --seed=18428036963 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/
[2019-06-18 11:53:12] selfplay finished: 30.418 seconds
[2019-06-18 11:53:12] selfplay mn: 30.437 seconds
[2019-06-18 11:53:12] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-5-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779836 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559667 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339498 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119329 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899160 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142678991 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458822 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238653 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018484 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798315 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578146 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285357977 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137808 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917639 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697470 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477301 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257132 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036963 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816794 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596625 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376456 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156287 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_
[2019-06-18 11:53:15] train finished: 44.309 seconds
:::MLL 1560880356.285802 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880356.286612 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880356.287305 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:36.353128 47708881875840 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880356.289187 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880356.289914 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880356.290557 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:36.353104 47127398802304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:52:36.354174 47708881875840 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp5om4xl9y
W0618 11:52:36.354202 47127398802304 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpfb29cbqk
I0618 11:52:36.355175 47708881875840 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp5om4xl9y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b645f8b4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:36.355201 47127398802304 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpfb29cbqk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adcfc73be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:36.355578 47708881875840 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:36.355596 47127398802304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:36.360694 47708881875840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:36.360701 47127398802304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:36.380775 47127398802304 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:36.380894 47708881875840 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880356.360020 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880356.360422 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880356.360770 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:36.398148 47827794269056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880356.361748 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880356.362128 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880356.362449 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:36.398134 47222678385536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:52:36.399133 47222678385536 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp7xjnr41j
W0618 11:52:36.399163 47827794269056 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmptw3xbj9r
:::MLL 1560880356.320693 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880356.321628 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880356.322496 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:36.400348 47271488754560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000003.tfrecord.zz_0
I0618 11:52:36.400155 47222678385536 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp7xjnr41j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af32b8ecdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:36.400197 47827794269056 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmptw3xbj9r', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b800f466e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880356.327398 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880356.328115 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880356.328795 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:36.400516 47678569022336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000003.tfrecord.zz_0
I0618 11:52:36.400568 47222678385536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:36.400608 47827794269056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880356.326406 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880356.327190 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880356.327894 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:36.400818 47482617824128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880356.323859 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880356.324563 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880356.325181 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:36.400909 47414925828992 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:52:36.401451 47271488754560 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpb2qmrza7
W0618 11:52:36.401627 47678569022336 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpk0jwtjfv
I0618 11:52:36.402543 47271488754560 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpb2qmrza7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afe88e1dda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:36.402765 47678569022336 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpk0jwtjfv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5d50c1ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:36.402987 47271488754560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:36.403236 47678569022336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:36.401866 47482617824128 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpztgr8or5
W0618 11:52:36.401896 47414925828992 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp44vhn9n6
I0618 11:52:36.402860 47414925828992 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp44vhn9n6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1fee65fdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:36.402865 47482617824128 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpztgr8or5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2fb127de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:36.403249 47414925828992 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:36.403303 47482617824128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:36.405362 47827794269056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:36.405367 47222678385536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:36.408281 47271488754560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:36.408710 47678569022336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:36.407970 47414925828992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:36.408024 47482617824128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880356.345530 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880356.346375 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880356.347137 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:36.409821 47135608112000 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880356.335657 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880356.336602 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880356.337458 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:36.409814 47885690135424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:52:36.410900 47135608112000 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp2g5qhqhm
W0618 11:52:36.410943 47885690135424 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpllr3r5up
I0618 11:52:36.411947 47135608112000 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp2g5qhqhm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adee5c3de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:36.411982 47885690135424 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpllr3r5up', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8d8a233e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:36.412366 47135608112000 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:36.412401 47885690135424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:36.417542 47885690135424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:36.417589 47135608112000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880356.343556 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880356.344346 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880356.345134 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:36.417139 47114184242048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880356.344976 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880356.345759 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880356.346452 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:36.417285 47717584724864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:52:36.418164 47114184242048 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp1_sg7v8p
W0618 11:52:36.418321 47717584724864 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp554wjops
I0618 11:52:36.419191 47114184242048 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp1_sg7v8p', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad9e8cd8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:36.419363 47717584724864 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp554wjops', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6666462e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:36.419590 47114184242048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:36.419778 47717584724864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:36.424866 47827794269056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:36.424970 47222678385536 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:36.424268 47114184242048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:36.424610 47717584724864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880356.356527 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880356.357474 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880356.358299 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:36.427986 47961754903424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880356.361063 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880356.361797 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880356.362493 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:36.428005 47647091786624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:52:36.429027 47647091786624 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpst9pw96u
W0618 11:52:36.429058 47961754903424 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpc4gbesdg
I0618 11:52:36.430096 47647091786624 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpst9pw96u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b55fc915e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:52:36.427908 47414925828992 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:52:36.430118 47961754903424 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpc4gbesdg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9f3ff37e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:52:36.428141 47482617824128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:52:36.430501 47647091786624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:36.430523 47961754903424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:36.429170 47708881875840 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:52:36.429350 47127398802304 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880356.393443 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880356.393818 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880356.394152 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:36.430175 47997973549952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880356.395072 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880356.395487 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880356.395848 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:36.430469 47689903231872 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:52:36.430767 47271488754560 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:36.431826 47678569022336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:36.431315 47997973549952 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp4wvr3dut
W0618 11:52:36.431533 47689903231872 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpro2mq0ps
I0618 11:52:36.432277 47997973549952 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp4wvr3dut', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba7aec02e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:36.432501 47689903231872 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpro2mq0ps', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5ff4542da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:36.432667 47997973549952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:36.432891 47689903231872 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:36.433515 47708881875840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:52:36.433711 47127398802304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:52:36.435640 47647091786624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:36.435655 47961754903424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:36.437280 47997973549952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:36.437428 47689903231872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:52:36.438576 47708881875840 estimator.py:1111] Calling model_fn.
W0618 11:52:36.438685 47708881875840 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:52:36.438808 47127398802304 estimator.py:1111] Calling model_fn.
W0618 11:52:36.438916 47127398802304 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:52:36.440057 47708881875840 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:52:36.440276 47127398802304 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560880356.403872 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880356.404278 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880356.404626 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:36.439802 47168612619136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:52:36.440314 47885690135424 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:36.440976 47135608112000 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880356.406042 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880356.406487 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880356.406890 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:36.441295 47771721634688 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:52:36.440852 47168612619136 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpkfn7dpdq
I0618 11:52:36.441889 47168612619136 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpkfn7dpdq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae694fcae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:36.442301 47168612619136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:36.442296 47771721634688 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpjtuz1xsr
I0618 11:52:36.443240 47771721634688 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpjtuz1xsr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b730115edd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880356.405089 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880356.405605 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880356.406077 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:36.442814 47737482490752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000003.tfrecord.zz_0
I0618 11:52:36.443633 47771721634688 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:36.444240 47114184242048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:36.443895 47737482490752 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpj4ikqb4b
I0618 11:52:36.444970 47737482490752 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpj4ikqb4b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6b0845ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:52:36.445108 47717584724864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:52:36.445395 47737482490752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880356.409811 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880356.410250 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880356.410646 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:36.445617 47422311797632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:52:36.446883 47168612619136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:52:36.446738 47422311797632 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb330/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b21a6a2ed30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:52:36.448115 47771721634688 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:52:36.447840 47422311797632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:36.450138 47737482490752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880356.414839 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880356.415426 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880356.415801 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:36.450741 48006846120832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880356.415569 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880356.415959 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880356.416296 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:36.450902 47821492843392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:52:36.451771 48006846120832 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp0i6dugg2
W0618 11:52:36.451890 47821492843392 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpmyhvd_ko
I0618 11:52:36.452734 48006846120832 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp0i6dugg2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba9bf98de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:36.452839 47821492843392 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpmyhvd_ko', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7e97ae4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:52:36.452349 47422311797632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:52:36.453120 48006846120832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:36.453230 47821492843392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:36.455460 47647091786624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:36.455494 47961754903424 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:36.456850 47997973549952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:36.457062 47689903231872 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:36.457681 48006846120832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:36.457785 47821492843392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:36.466501 47168612619136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:36.467811 47771721634688 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:36.469833 47737482490752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:36.472130 47827794269056 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:52:36.472445 47222678385536 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:52:36.471997 47422311797632 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880356.439350 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880356.439790 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880356.440167 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:36.475281 47195136570240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:52:36.476335 47195136570240 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp8q8tayao
I0618 11:52:36.477400 47195136570240 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp8q8tayao', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aecc1f00e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:36.477829 47195136570240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:36.476401 47827794269056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:52:36.476089 47414925828992 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:52:36.476726 47222678385536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:52:36.476338 47482617824128 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880356.443731 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880356.444175 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880356.444572 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:36.478743 47575341769600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:52:36.477388 48006846120832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:36.477444 47821492843392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:36.479107 47271488754560 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:52:36.479776 47575341769600 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpa2q21yh4
I0618 11:52:36.480847 47575341769600 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpa2q21yh4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4547eeedd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:52:36.479810 47678569022336 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 11:52:36.481228 47575341769600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:36.480423 47414925828992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:52:36.482640 47195136570240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:36.480690 47482617824128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:52:36.481412 47827794269056 estimator.py:1111] Calling model_fn.
W0618 11:52:36.481532 47827794269056 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:52:36.481791 47222678385536 estimator.py:1111] Calling model_fn.
W0618 11:52:36.481903 47222678385536 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:52:36.482886 47827794269056 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:52:36.483596 47271488754560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:52:36.483266 47222678385536 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:52:36.484300 47678569022336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:52:36.485839 47575341769600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:52:36.485501 47414925828992 estimator.py:1111] Calling model_fn.
W0618 11:52:36.485604 47414925828992 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:52:36.485811 47482617824128 estimator.py:1111] Calling model_fn.
W0618 11:52:36.485923 47482617824128 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be r[2019-06-18 11:53:15] divide_golden_chunk finished: 3.278 seconds
[2019-06-18 11:53:15] generate golden chunk: 3.293 seconds
[2019-06-18 11:53:15] moving /lfs/lfs12/gma_akey/results/epb330/models/000004-000003.meta --> /lfs/lfs12/gma_akey/results/epb330/models/000004-000004.meta
[2019-06-18 11:53:15] moving /lfs/lfs12/gma_akey/results/epb330/models/000004-000003.index --> /lfs/lfs12/gma_akey/results/epb330/models/000004-000004.index
[2019-06-18 11:53:15] moving /lfs/lfs12/gma_akey/results/epb330/models/000004-000003.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb330/models/000004-000004.data-00000-of-00001
[2019-06-18 11:53:15] moving /lfs/lfs12/gma_akey/results/epb330/models/000004-000003.pb --> /lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb
[2019-06-18 11:53:15] iteration time 3: 48.162 seconds
2019-06-18 11:53:15.881411: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880395.402333 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 4}}
[2019-06-18 11:53:19] minmax time: 3.201 seconds
2019-06-18 11:53:19.092461: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:53:19.097804: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:53:19.101976: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880399.111493 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 3}}
[2019-06-18 11:53:19] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000005-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000005-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000005-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000005-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000005-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000005-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000005-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000005-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000005-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000005-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000005-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir 
[2019-06-18 11:53:19] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-5-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000004-000004 --seed=5 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000004-000004 --seed=1023779836 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000004-000004 --seed=2047559667 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000004-000004 --seed=3071339498 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000004-000004 --seed=4095119329 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000004-000004 --seed=5118899160 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000004-000004 --seed=6142678991 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000004-000004 --seed=7166458822 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000004-000004 --seed=8190238653 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000004-000004 --seed=9214018484 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000004-000004 --seed=10237798315 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000004-000004 --seed=11261578146 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000004-000004 --seed=12285357977 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000004-000004 --seed=13309137808 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000004-000004 --seed=14332917639 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000004-000004 --seed=15356697470 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000004-000004 --seed=16380477301 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000004-000004 --seed=17404257132 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000004-000004 --seed=18428036963 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000004-000004 --seed=19451816794 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000004-000004 --seed=20475596625 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 11:53:30] eval finished: 10.997 seconds
[2019-06-18 11:53:30] Win rate 000004-000004 vs 000003-000003: 0.530
:::MLL 1560880410.179236 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 3}}
[2019-06-18 11:53:30] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-6-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000005-000003 --seed=6 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000005-000003 --seed=1023779837 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000005-000003 --seed=2047559668 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000005-000003 --seed=3071339499 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000005-000003 --seed=4095119330 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000005-000003 --seed=5118899161 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000005-000003 --seed=6142678992 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000005-000003 --seed=7166458823 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000005-000003 --seed=8190238654 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000005-000003 --seed=9214018485 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000005-000003 --seed=10237798316 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000005-000003 --seed=11261578147 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000005-000003 --seed=12285357978 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000005-000003 --seed=13309137809 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000005-000003 --seed=14332917640 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000005-000003 --seed=15356697471 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000005-000003 --seed=16380477302 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000005-000003 --seed=17404257133 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000005-000003 --seed=18428036964 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/
[2019-06-18 11:54:01] selfplay finished: 31.056 seconds
[2019-06-18 11:54:01] selfplay mn: 31.072 seconds
[2019-06-18 11:54:01] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-6-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779837 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559668 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339499 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119330 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899161 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142678992 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458823 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238654 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018485 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798316 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578147 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285357978 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137809 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917640 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697471 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477302 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257133 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036964 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816795 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596626 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376457 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156288 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000005-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_
[2019-06-18 11:54:02] train finished: 43.814 seconds
:::MLL 1560880404.364072 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880404.364765 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880404.365441 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:24.428691 47508600304512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880404.359828 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880404.360721 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880404.361469 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:24.428665 47350305948544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:53:24.429812 47508600304512 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp5r4dx15z
W0618 11:53:24.429780 47350305948544 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpht55fwyr
I0618 11:53:24.430922 47350305948544 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpht55fwyr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b10e2c0de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:24.430944 47508600304512 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp5r4dx15z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b35bdd50dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:24.431363 47350305948544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:24.431380 47508600304512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:24.436675 47350305948544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:24.436689 47508600304512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:24.456595 47350305948544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:24.456788 47508600304512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880404.438535 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880404.438915 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880404.439234 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:24.478346 47649091564416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880404.437674 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880404.438079 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880404.438434 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:24.478468 47702404088704 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:53:24.479337 47649091564416 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpnae_kgfa
W0618 11:53:24.479400 47702404088704 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpe5yne66a
I0618 11:53:24.480315 47649091564416 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpnae_kgfa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5673c37e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:24.480354 47702404088704 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpe5yne66a', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b62dd701dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:24.480703 47649091564416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:24.480739 47702404088704 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:24.485359 47649091564416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:24.485356 47702404088704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880404.418330 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880404.419082 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880404.419748 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:24.491881 47541259895680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880404.409468 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880404.410378 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880404.411223 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:24.491900 48006124053376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880404.413868 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880404.414693 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880404.415503 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:24.493162 47255436333952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880404.414387 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880404.415281 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880404.416056 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:24.493292 47076739892096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:53:24.492889 47541259895680 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpqrs7xbg6
W0618 11:53:24.492913 48006124053376 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpdeod0nlr
I0618 11:53:24.493937 47541259895680 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpqrs7xbg6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3d587ede48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:24.494036 48006124053376 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpdeod0nlr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba9948efe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:24.494383 47541259895680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:24.494251 47255436333952 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpxsf7zdnr
W0618 11:53:24.494311 47076739892096 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpyw89lz2v
I0618 11:53:24.494515 48006124053376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:24.495353 47255436333952 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpxsf7zdnr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afacc156e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:24.495393 47076739892096 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpyw89lz2v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad130f1fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:24.495784 47255436333952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:24.495831 47076739892096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:24.499847 47541259895680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:24.500101 48006124053376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:24.501330 47255436333952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:24.501366 47076739892096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880404.424003 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880404.424928 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880404.425801 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:24.505524 47877775680384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880404.452517 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880404.453379 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880404.454178 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:24.505626 47991829873536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:53:24.504456 47350305948544 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:53:24.504869 47508600304512 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:53:24.504917 47649091564416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:24.504912 47702404088704 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:24.506586 47877775680384 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpte4xnswh
W0618 11:53:24.506626 47991829873536 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp0rrf28oo
:::MLL 1560880404.426399 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880404.427280 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880404.428146 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:24.505271 47985524974464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880404.434406 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880404.435178 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880404.435885 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:24.505264 47824878408576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000004.tfrecord.zz_0
I0618 11:53:24.507703 47877775680384 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpte4xnswh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8bb2663e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:24.507735 47991829873536 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp0rrf28oo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba6408f1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:24.508104 47877775680384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:24.508129 47991829873536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:24.506439 47985524974464 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp6yppeanp
W0618 11:53:24.506468 47824878408576 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmplmmodptm
I0618 11:53:24.507447 47985524974464 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp6yppeanp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba4c8c1fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:24.507463 47824878408576 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmplmmodptm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7f6179edd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:24.507853 47985524974464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:24.507861 47824878408576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:24.508735 47350305948544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:53:24.509193 47508600304512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:53:24.513185 47877775680384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:24.513208 47991829873536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:24.512783 47824878408576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:24.512835 47985524974464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:53:24.513788 47350305948544 estimator.py:1111] Calling model_fn.
W0618 11:53:24.513900 47350305948544 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:53:24.514256 47508600304512 estimator.py:1111] Calling model_fn.
W0618 11:53:24.514362 47508600304512 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:53:24.515262 47350305948544 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:53:24.515711 47508600304512 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560880404.451040 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880404.451832 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880404.452548 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:24.515509 47122086024064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880404.441853 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880404.442788 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880404.443647 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:24.515588 47447883527040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:53:24.516514 47122086024064 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp430cl83n
W0618 11:53:24.516587 47447883527040 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpsmevnnpz
I0618 11:53:24.517500 47122086024064 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp430cl83n', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adbbfc91e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:24.517593 47447883527040 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpsmevnnpz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b279ad47e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:24.517896 47122086024064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:24.517988 47447883527040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:24.522907 47541259895680 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:24.523748 47255436333952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:24.523791 47076739892096 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:24.522857 47447883527040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:24.522870 47122086024064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:24.524206 48006124053376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880404.490710 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880404.491161 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880404.491543 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:24.528393 47229443494784 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880404.491363 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880404.491738 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880404.492061 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:24.529283 47351221584768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:53:24.529498 47229443494784 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp2na045b8
W0618 11:53:24.530336 47351221584768 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpxq6t31on
:::MLL 1560880404.493598 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880404.494040 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880404.494425 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:24.531199 47389606785920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000004.tfrecord.zz_0
I0618 11:53:24.530615 47229443494784 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp2na045b8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af4beca2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:24.531356 47351221584768 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpxq6t31on', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1119545e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:53:24.532984 47877775680384 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:53:24.531753 47351221584768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:24.531026 47229443494784 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:24.533093 47991829873536 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880404.495562 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880404.495998 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880404.496401 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:24.531271 47230799160192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:53:24.532191 47389606785920 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmps5uh2pju
I0618 11:53:24.533272 47389606785920 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmps5uh2pju', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1a09440e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:53:24.532402 47824878408576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:24.532207 47230799160192 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpegymvhr1
I0618 11:53:24.533706 47389606785920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:24.533168 47230799160192 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpegymvhr1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af50f97ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:53:24.533171 47985524974464 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:53:24.533564 47230799160192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:24.535669 47229443494784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:24.536683 47351221584768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:24.538211 47389606785920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:24.538110 47230799160192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:24.543001 47447883527040 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:24.543133 47122086024064 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880404.514507 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880404.514944 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880404.515347 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:24.548222 47492613927808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880404.508756 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880404.509214 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880404.509595 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:24.547114 47459619992448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:53:24.549348 47492613927808 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpvuspin5o
:::MLL 1560880404.508972 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880404.509447 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880404.509822 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:24.547585 47613493056384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000004.tfrecord.zz_0
I0618 11:53:24.550462 47492613927808 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpvuspin5o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3204f84e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880404.511009 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880404.511485 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880404.511892 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:24.548189 47046223905664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000004.tfrecord.zz_0
I0618 11:53:24.550906 47492613927808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:24.548106 47459619992448 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpwjbwbmlp
I0618 11:53:24.549087 47459619992448 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpwjbwbmlp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2a5660ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:24.549487 47459619992448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:24.549150 47046223905664 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp9ltin98i
W0618 11:53:24.548640 47613493056384 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpk3y4nxub
I0618 11:53:24.550111 47046223905664 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp9ltin98i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aca160d1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:24.549723 47613493056384 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpk3y4nxub', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4e29ed6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:24.550492 47046223905664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880404.512057 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880404.512526 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880404.512914 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:24.549926 46964821590912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000004.tfrecord.zz_0
I0618 11:53:24.550112 47613493056384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:24.550929 46964821590912 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb330/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab722185cc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:53:24.552397 47702404088704 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 11:53:24.552036 46964821590912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:24.553213 47649091564416 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:53:24.556206 47492613927808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:24.554233 47459619992448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:24.555028 47046223905664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:24.555244 47229443494784 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:24.554742 47613493056384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:24.556454 47351221584768 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:24.556669 47702404088704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:53:24.556622 46964821590912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:24.557819 47389606785920 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:24.557557 47649091564416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:53:24.557768 47230799160192 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880404.528416 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880404.528895 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880404.529289 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:24.561161 47724320150400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:53:24.562210 47724320150400 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp7ztxaawa
I0618 11:53:24.563249 47724320150400 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp7ztxaawa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b67f7bcadd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:24.561677 47702404088704 estimator.py:1111] Calling model_fn.
W0618 11:53:24.561781 47702404088704 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:53:24.563669 47724320150400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:24.562652 47649091564416 estimator.py:1111] Calling model_fn.
W0618 11:53:24.562760 47649091564416 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:53:24.563128 47702404088704 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:53:24.564122 47649091564416 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:53:24.568589 47724320150400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:24.572445 47076739892096 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.[2019-06-18 11:54:04] divide_golden_chunk finished: 3.305 seconds
[2019-06-18 11:54:04] generate golden chunk: 3.319 seconds
[2019-06-18 11:54:04] moving /lfs/lfs12/gma_akey/results/epb330/models/000005-000004.pb --> /lfs/lfs12/gma_akey/results/epb330/models/000005-000005.pb
[2019-06-18 11:54:04] moving /lfs/lfs12/gma_akey/results/epb330/models/000005-000004.index --> /lfs/lfs12/gma_akey/results/epb330/models/000005-000005.index
[2019-06-18 11:54:04] moving /lfs/lfs12/gma_akey/results/epb330/models/000005-000004.meta --> /lfs/lfs12/gma_akey/results/epb330/models/000005-000005.meta
[2019-06-18 11:54:04] moving /lfs/lfs12/gma_akey/results/epb330/models/000005-000004.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb330/models/000005-000005.data-00000-of-00001
[2019-06-18 11:54:04] iteration time 4: 49.211 seconds
2019-06-18 11:54:05.131688: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880444.613204 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 5}}
[2019-06-18 11:54:08] minmax time: 3.233 seconds
2019-06-18 11:54:08.374229: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:54:08.379601: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:54:08.383745: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880448.393263 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 4}}
[2019-06-18 11:54:08] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000006-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000006-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000006-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000006-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000006-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000006-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000006-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000006-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000006-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000006-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000006-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir 
[2019-06-18 11:54:08] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-6-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000005-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000005-000005 --seed=6 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000005-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000005-000005 --seed=1023779837 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000005-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000005-000005 --seed=2047559668 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000005-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000005-000005 --seed=3071339499 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000005-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000005-000005 --seed=4095119330 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000005-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000005-000005 --seed=5118899161 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000005-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000005-000005 --seed=6142678992 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000005-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000005-000005 --seed=7166458823 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000005-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000005-000005 --seed=8190238654 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000005-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000005-000005 --seed=9214018485 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000005-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000005-000005 --seed=10237798316 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000005-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000005-000005 --seed=11261578147 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000005-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000005-000005 --seed=12285357978 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000005-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000005-000005 --seed=13309137809 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000005-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000005-000005 --seed=14332917640 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000005-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000005-000005 --seed=15356697471 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000005-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000005-000005 --seed=16380477302 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000005-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000005-000005 --seed=17404257133 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000005-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000005-000005 --seed=18428036964 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000005-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000005-000005 --seed=19451816795 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000005-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000005-000005 --seed=20475596626 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 11:54:20] eval finished: 11.610 seconds
[2019-06-18 11:54:20] Win rate 000005-000005 vs 000004-000004: 0.440
:::MLL 1560880460.071384 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 4}}
[2019-06-18 11:54:20] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-7-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000006-000004 --seed=7 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000006-000004 --seed=1023779838 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000006-000004 --seed=2047559669 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000006-000004 --seed=3071339500 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000006-000004 --seed=4095119331 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000006-000004 --seed=5118899162 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000006-000004 --seed=6142678993 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000006-000004 --seed=7166458824 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000006-000004 --seed=8190238655 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000006-000004 --seed=9214018486 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000006-000004 --seed=10237798317 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000006-000004 --seed=11261578148 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000006-000004 --seed=12285357979 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000006-000004 --seed=13309137810 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000006-000004 --seed=14332917641 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000006-000004 --seed=15356697472 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000006-000004 --seed=16380477303 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000006-000004 --seed=17404257134 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000006-000004 --seed=18428036965 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/
[2019-06-18 11:54:50] selfplay finished: 30.840 seconds
[2019-06-18 11:54:50] selfplay mn: 30.858 seconds
[2019-06-18 11:54:50] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-7-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779838 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559669 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339500 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119331 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899162 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142678993 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458824 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238655 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018486 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798317 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578148 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285357979 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137810 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917641 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697472 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477303 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257134 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036965 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816796 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596627 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376458 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156289 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000006-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_
[2019-06-18 11:54:52] train finished: 43.630 seconds
:::MLL 1560880453.666241 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880453.666929 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880453.667614 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:13.733124 47356321895296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880453.662519 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880453.663343 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880453.664028 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:13.733348 47900632920960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:54:13.734200 47356321895296 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpxhn2_p43
W0618 11:54:13.734349 47900632920960 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp0yn3bvx0
I0618 11:54:13.735257 47356321895296 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpxhn2_p43', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b124954ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:13.735399 47900632920960 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp0yn3bvx0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9104cc0dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:13.735680 47356321895296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:13.735820 47900632920960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:13.740968 47356321895296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:13.741078 47900632920960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:13.761815 47356321895296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:13.762617 47900632920960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880453.724624 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880453.725424 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880453.726165 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:13.776081 47421149369216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880453.700392 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880453.701292 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880453.702182 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:13.776163 47476253270912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:54:13.777160 47476253270912 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpjupqu0ew
W0618 11:54:13.777127 47421149369216 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpmrh5wum0
I0618 11:54:13.778163 47421149369216 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpmrh5wum0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2161599e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:13.778201 47476253270912 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpjupqu0ew', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2e35cc6e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:13.778589 47421149369216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:13.778627 47476253270912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880453.716492 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880453.717242 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880453.717916 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:13.782327 47027758568320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880453.709656 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880453.710554 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880453.711428 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:13.782436 47571934610304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:54:13.783976 47421149369216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:13.784041 47476253270912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880453.742303 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880453.742676 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880453.743058 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:13.784015 47393213809536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880453.743581 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880453.743989 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880453.744339 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:13.784268 47311197520768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:54:13.783389 47027758568320 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpc0293fkb
W0618 11:54:13.783461 47571934610304 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpw405tju7
I0618 11:54:13.784379 47027758568320 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpc0293fkb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac5c96e6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:13.784448 47571934610304 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpw405tju7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b447cd9de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:13.784776 47027758568320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:13.784845 47571934610304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:13.785022 47393213809536 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmphaceoluv
W0618 11:54:13.785263 47311197520768 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmphg46ef5d
I0618 11:54:13.785994 47393213809536 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmphaceoluv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1ae042de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:13.786230 47311197520768 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmphg46ef5d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b07c7b58e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:13.786391 47393213809536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:13.786626 47311197520768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:13.789839 47027758568320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:13.789869 47571934610304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:13.791236 47393213809536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:13.791553 47311197520768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:13.804932 47421149369216 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:13.805299 47476253270912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:13.809665 47571934610304 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:13.809765 47027758568320 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:13.810786 47393213809536 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:13.810949 47356321895296 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:54:13.811350 47311197520768 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:13.811385 47900632920960 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:54:13.815263 47356321895296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:54:13.815713 47900632920960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:54:13.820344 47356321895296 estimator.py:1111] Calling model_fn.
W0618 11:54:13.820454 47356321895296 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560880453.743931 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880453.744817 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880453.745663 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:13.819429 47218270114688 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880453.750892 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880453.751661 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880453.752349 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:13.819451 47948154975104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000005.tfrecord.zz_0
I0618 11:54:13.820774 47900632920960 estimator.py:1111] Calling model_fn.
W0618 11:54:13.820885 47900632920960 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:54:13.821827 47356321895296 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:54:13.820495 47218270114688 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpcki6sbev
W0618 11:54:13.820524 47948154975104 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpvo7t211m
W0618 11:54:13.822283 47900632920960 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 11:54:13.821534 47218270114688 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpcki6sbev', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af224cdee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:13.821553 47948154975104 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpvo7t211m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9c15550e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:13.821956 47218270114688 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:13.821967 47948154975104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:13.827338 47948154975104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:13.827344 47218270114688 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880453.760609 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880453.761345 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880453.762032 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:13.829981 47095592547200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880453.753714 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880453.754673 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880453.755507 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:13.829982 47973019358080 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:54:13.831057 47973019358080 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpzp1u3llr
W0618 11:54:13.831087 47095592547200 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpca0z8_l4
I0618 11:54:13.832128 47973019358080 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpzp1u3llr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba1df5d6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:13.832142 47095592547200 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpca0z8_l4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad594a6be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:13.832557 47973019358080 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:13.832570 47095592547200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880453.787278 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880453.787674 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880453.788010 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:13.834689 47230758019968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880453.787893 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880453.788276 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880453.788596 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:13.834873 47372674085760 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:54:13.835715 47230758019968 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpwws105zl
W0618 11:54:13.835886 47372674085760 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpp2y9qay0
I0618 11:54:13.836774 47230758019968 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpwws105zl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af50d243e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:13.836977 47372674085760 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpp2y9qay0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1617ff8e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:13.837220 47230758019968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:13.837426 47372674085760 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880453.795681 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880453.796129 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880453.796497 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:13.837021 47193544582016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880453.796387 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880453.796804 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880453.797159 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:13.837143 47393121870720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:54:13.838128 47973019358080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:13.838199 47095592547200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:13.837995 47193544582016 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpo5ywksu3
W0618 11:54:13.838092 47393121870720 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmprir_6glf
I0618 11:54:13.838966 47193544582016 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpo5ywksu3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aec630c2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:13.839037 47393121870720 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmprir_6glf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1adac7de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:13.839359 47193544582016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:13.839423 47393121870720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:13.842156 47230758019968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:13.842335 47372674085760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:13.844129 47393121870720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:13.844146 47193544582016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:13.847811 47218270114688 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:13.847829 47948154975104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880453.803647 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880453.804475 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880453.805200 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:13.859001 47651114419072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880453.786073 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880453.786996 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880453.787916 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:13.859120 47763681252224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:54:13.857952 47571934610304 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:54:13.858378 47393213809536 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:54:13.858977 47421149369216 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:54:13.858512 47027758568320 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:54:13.860059 47651114419072 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpfbz_lwaw
W0618 11:54:13.860290 47763681252224 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmphtl_fpmq
W0618 11:54:13.859710 47476253270912 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 11:54:13.861096 47651114419072 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpfbz_lwaw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b56ec55de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:54:13.859535 47311197520768 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 11:54:13.861358 47763681252224 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmphtl_fpmq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7121d76e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:13.861520 47651114419072 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:13.861791 47763681252224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:13.860013 47973019358080 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:13.860545 47095592547200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:13.862255 47571934610304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:54:13.863090 47372674085760 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:13.862650 47393213809536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:54:13.863159 47230758019968 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880453.819659 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880453.820159 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880453.820610 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:13.861931 46923989668736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:54:13.862863 47027758568320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:54:13.863853 47421149369216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:54:13.863888 47311197520768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:54:13.863635 47393121870720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:13.863721 47193544582016 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:13.864669 47476253270912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:54:13.862978 46923989668736 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpgjgtkc3k
I0618 11:54:13.863972 46923989668736 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpgjgtkc3k', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aada052ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880453.823344 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880453.823825 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880453.824234 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:13.863907 47015433139072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:54:13.866629 47651114419072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:13.866787 47763681252224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:54:13.864373 46923989668736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:13.864882 47015433139072 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb330/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac2eac74d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:13.865959 47015433139072 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:13.867311 47571934610304 estimator.py:1111] Calling model_fn.
I0618 11:54:13.867679 47393213809536 estimator.py:1111] Calling model_fn.
W0618 11:54:13.867785 47393213809536 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:54:13.867418 47571934610304 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:54:13.867951 47027758568320 estimator.py:1111] Calling model_fn.
W0618 11:54:13.868057 47027758568320 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:54:13.869018 47311197520768 estimator.py:1111] Calling model_fn.
W0618 11:54:13.869130 47311197520768 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:54:13.869139 47393213809536 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:54:13.868770 47571934610304 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 11:54:13.869633 47421149369216 estimator.py:1111] Calling model_fn.
W0618 11:54:13.869766 47421149369216 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:54:13.869420 47027758568320 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:54:13.869078 46923989668736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:54:13.870530 47476253270912 estimator.py:1111] Calling model_fn.
W0618 11:54:13.870651 47476253270912 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:54:13.870518 47311197520768 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:54:13.871300 47421149369216 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:54:13.870559 47015433139072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:13.872196 47476253270912 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:54:13.886912 47651114419072 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:13.886937 47763681252224 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions [2019-06-18 11:54:54] divide_golden_chunk finished: 3.249 seconds
[2019-06-18 11:54:54] generate golden chunk: 3.263 seconds
[2019-06-18 11:54:54] iteration time 5: 49.582 seconds
2019-06-18 11:54:54.763749: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880494.194903 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 6}}
[2019-06-18 11:54:58] minmax time: 3.238 seconds
2019-06-18 11:54:58.011720: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:54:58.017164: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:54:58.021617: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880498.033339 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 5}}
[2019-06-18 11:54:58] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000007-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000007-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000007-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000007-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000007-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000007-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000007-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000007-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000007-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000007-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000007-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir 
[2019-06-18 11:54:58] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-7-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000006-000005 --seed=7 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000006-000005 --seed=1023779838 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000006-000005 --seed=2047559669 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000006-000005 --seed=3071339500 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000006-000005 --seed=4095119331 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000006-000005 --seed=5118899162 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000006-000005 --seed=6142678993 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000006-000005 --seed=7166458824 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000006-000005 --seed=8190238655 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000006-000005 --seed=9214018486 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000006-000005 --seed=10237798317 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000006-000005 --seed=11261578148 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000006-000005 --seed=12285357979 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000006-000005 --seed=13309137810 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000006-000005 --seed=14332917641 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000006-000005 --seed=15356697472 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000006-000005 --seed=16380477303 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000006-000005 --seed=17404257134 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000006-000005 --seed=18428036965 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000006-000005 --seed=19451816796 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000006-000005 --seed=20475596627 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 11:55:10] eval finished: 12.865 seconds
[2019-06-18 11:55:10] Win rate 000006-000005 vs 000004-000004: 0.510
:::MLL 1560880510.969529 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 5}}
[2019-06-18 11:55:10] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-8-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000007-000004 --seed=8 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000007-000004 --seed=1023779839 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000007-000004 --seed=2047559670 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000007-000004 --seed=3071339501 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000007-000004 --seed=4095119332 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000007-000004 --seed=5118899163 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000007-000004 --seed=6142678994 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000007-000004 --seed=7166458825 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000007-000004 --seed=8190238656 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000007-000004 --seed=9214018487 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000007-000004 --seed=10237798318 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000007-000004 --seed=11261578149 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000007-000004 --seed=12285357980 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000007-000004 --seed=13309137811 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000007-000004 --seed=14332917642 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000007-000004 --seed=15356697473 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000007-000004 --seed=16380477304 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000007-000004 --seed=17404257135 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000007-000004 --seed=18428036966 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/
[2019-06-18 11:55:40] selfplay finished: 29.082 seconds
[2019-06-18 11:55:40] selfplay mn: 29.102 seconds
[2019-06-18 11:55:40] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-8-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779839 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559670 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339501 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119332 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899163 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142678994 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458825 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238656 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018487 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798318 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578149 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285357980 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137811 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917642 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697473 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477304 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257135 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036966 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816797 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596628 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376459 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156290 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000007-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_
[2019-06-18 11:55:42] train finished: 44.164 seconds
:::MLL 1560880503.257829 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880503.258724 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880503.259572 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:03.330238 47016994800512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880503.264969 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880503.265702 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880503.266406 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:03.330352 47050759197568 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:55:03.331246 47016994800512 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpesmmpdz3
W0618 11:55:03.331348 47050759197568 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp5nkrvhki
I0618 11:55:03.332241 47016994800512 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpesmmpdz3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac347dc5dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:03.332342 47050759197568 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp5nkrvhki', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acb24601e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:03.332642 47016994800512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:03.332744 47050759197568 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:03.337634 47016994800512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:03.337655 47050759197568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:03.357501 47016994800512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:03.357636 47050759197568 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880503.341367 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880503.341769 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880503.342121 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:03.392332 47714663588736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880503.341513 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880503.341918 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880503.342256 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:03.392319 47864793002880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:55:03.393301 47864793002880 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp7zmtlxlg
W0618 11:55:03.393333 47714663588736 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpv5a99h0z
I0618 11:55:03.394258 47864793002880 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp7zmtlxlg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b88ac924e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:03.394301 47714663588736 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpv5a99h0z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b65b8293dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:03.394645 47864793002880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:03.394687 47714663588736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:03.399242 47864793002880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:03.399310 47714663588736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:03.406238 47050759197568 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:03.406400 47016994800512 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880503.330741 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880503.331633 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880503.332493 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:03.409102 47050542044032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880503.331746 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880503.332632 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880503.333375 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:03.409214 47741736891264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:55:03.410553 47050759197568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:03.410664 47016994800512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:03.410219 47050542044032 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp3kornc_3
W0618 11:55:03.410323 47741736891264 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpjd2wmnzd
I0618 11:55:03.411318 47050542044032 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp3kornc_3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acb176eae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:03.411437 47741736891264 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpjd2wmnzd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6c05db0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:03.411759 47050542044032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:03.411890 47741736891264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:03.415613 47050759197568 estimator.py:1111] Calling model_fn.
I0618 11:55:03.415683 47016994800512 estimator.py:1111] Calling model_fn.
W0618 11:55:03.415723 47050759197568 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:55:03.415788 47016994800512 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:55:03.417088 47050759197568 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:55:03.417162 47016994800512 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560880503.335679 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880503.336609 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880503.337343 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:03.417519 47503940121472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880503.339546 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880503.340273 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880503.340977 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:03.417634 47356076016512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880503.338161 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880503.339018 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880503.339852 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:03.416486 47892463145856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:55:03.417150 47050542044032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:03.417276 47741736891264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880503.337853 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880503.338707 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880503.339527 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:03.416745 47841916691328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:55:03.418862 47864793002880 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:03.418994 47714663588736 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:03.418622 47503940121472 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpr82x_kf7
W0618 11:55:03.418706 47356076016512 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp2n_l40yn
W0618 11:55:03.417607 47892463145856 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpd5li1m9w
I0618 11:55:03.419719 47503940121472 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpr82x_kf7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b34a8104e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:03.419773 47356076016512 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp2n_l40yn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b123aad1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:55:03.417851 47841916691328 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpqfz9qyoq
I0618 11:55:03.418609 47892463145856 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpd5li1m9w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8f1dd72dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:03.418876 47841916691328 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpqfz9qyoq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8359097e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:03.420176 47503940121472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:03.420232 47356076016512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:03.419021 47892463145856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:03.419294 47841916691328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:03.423784 47892463145856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:03.424127 47841916691328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:03.425531 47503940121472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:03.425580 47356076016512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880503.350850 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880503.351793 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880503.352506 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:03.428699 47517046633344 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880503.356699 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880503.357430 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880503.358106 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:03.428718 47936474956672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:55:03.429748 47517046633344 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp2wokazk7
W0618 11:55:03.429779 47936474956672 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp1ai9w33_
I0618 11:55:03.430757 47517046633344 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp2wokazk7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b37b545bdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:03.430774 47936474956672 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp1ai9w33_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b995d261dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:03.431155 47517046633344 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:03.431162 47936474956672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:03.436256 47936474956672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:03.436281 47517046633344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880503.369608 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880503.370354 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880503.371079 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:03.436357 47225198228352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880503.361686 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880503.362560 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880503.363459 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:03.436440 47825147323264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:55:03.437354 47225198228352 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpo33ddguf
W0618 11:55:03.437403 47825147323264 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpnh2iw9e2
I0618 11:55:03.438348 47225198228352 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpo33ddguf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af3c1c07e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:03.438379 47825147323264 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpnh2iw9e2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7f71813e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:03.438745 47225198228352 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:03.438769 47825147323264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:03.439965 47050542044032 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:03.440605 47741736891264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:03.443868 47225198228352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:03.443891 47825147323264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:03.443970 47892463145856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:03.445027 47841916691328 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880503.403126 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880503.403594 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880503.403971 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:03.446362 47570123596672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:55:03.448213 47503940121472 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880503.406708 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880503.407159 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880503.407566 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:03.447453 47067483800448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:55:03.448395 47356076016512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:03.447379 47570123596672 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmps8bgdcze
I0618 11:55:03.448343 47570123596672 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmps8bgdcze', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4410e7fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:03.448737 47570123596672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880503.403098 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880503.403561 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880503.403944 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:03.448209 47139123737472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880503.398811 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880503.399357 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880503.399845 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:03.448207 47993890915200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:55:03.448416 47067483800448 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp4gqkmi0a
I0618 11:55:03.449375 47067483800448 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp4gqkmi0a', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acf093d5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:03.449764 47067483800448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:03.449254 47139123737472 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb330/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adfb7500cc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:55:03.449259 47993890915200 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpkemktwm1
I0618 11:55:03.450295 47993890915200 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpkemktwm1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba6bb681e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:03.450434 47139123737472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:03.450723 47993890915200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:03.453588 47570123596672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:03.455972 47517046633344 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:03.455935 47936474956672 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:03.454482 47067483800448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:03.455335 47139123737472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:03.455479 47993890915200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880503.413421 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880503.413794 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880503.414118 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:03.456792 47512093213568 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880503.415322 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880503.415698 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880503.416113 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:03.457244 47452099924864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:55:03.457785 47512093213568 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpco75oqu1
I0618 11:55:03.458748 47512093213568 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpco75oqu1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b368e069e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:55:03.458215 47452099924864 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp1vqu1m41
I0618 11:55:03.459143 47512093213568 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:03.459188 47452099924864 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp1vqu1m41', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b289625ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:03.459581 47452099924864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:03.463721 47512093213568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:03.464176 47452099924864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:03.464099 47225198228352 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:03.464342 47825147323264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:03.466134 47864793002880 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:03.466650 47714663588736 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:03.470424 47864793002880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:03.470950 47714663588736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:03.473084 47570123596672 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:03.474104 47067483800448 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:55:03.475440 47864793002880 estimator.py:1111] Calling model_fn.
W0618 11:55:03.475546 47864793002880 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:55:03.476011 47714663588736 estimator.py:1111] Calling model_fn.
W0618 11:55:03.476121 47714663588736 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:55:03.475118 47139123737472 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:03.475119 47993890915200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:03.476891 47864793002880 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:55:03.477492 47714663588736 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:55:03.483160 47512093213568 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:03.483685 47452099924864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880503.445421 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880503.445806 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880503.446138 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:03.488978 46954196075392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880503.446600 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880503.446970 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880503.447294 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:03.489172 47214653219712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880503.444232 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880503.444628 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880503.444969 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:03.487490 46922094314368 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880503.444037 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880503.444431 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880503.444781 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:03.487491 47369665655680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:55:03.490047 46954196075392 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpg8laali9
W0618 11:55:03.490207 47214653219712 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmptafyug5o
I0618 11:55:03.491016 46954196075392 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpg8laali9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab4a8c3ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:03.491155 47214653219712 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmptafyug5o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af14d387e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:55:03.488526 46922094314368 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpfdq56qm2
I0618 11:55:03.491411 46954196075392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:03.488500 47369665655680 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpuzeomr0d
I0618 11:55:03.491548 47214653219712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:03.489454 47369665655680 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpuzeomr0d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1564ae8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:03.489472 46922094314368 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpfdq56qm2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aad2f59de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:03.489842 47369665655680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:03.489858 46922094314368 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:03.491754 47050542044032 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:03.491939 47741736891264 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.pyth[2019-06-18 11:55:45] divide_golden_chunk finished: 5.233 seconds
[2019-06-18 11:55:45] generate golden chunk: 5.248 seconds
[2019-06-18 11:55:45] moving /lfs/lfs12/gma_akey/results/epb330/models/000007-000005.meta --> /lfs/lfs12/gma_akey/results/epb330/models/000007-000006.meta
[2019-06-18 11:55:45] moving /lfs/lfs12/gma_akey/results/epb330/models/000007-000005.pb --> /lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb
[2019-06-18 11:55:45] moving /lfs/lfs12/gma_akey/results/epb330/models/000007-000005.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb330/models/000007-000006.data-00000-of-00001
[2019-06-18 11:55:45] moving /lfs/lfs12/gma_akey/results/epb330/models/000007-000005.index --> /lfs/lfs12/gma_akey/results/epb330/models/000007-000006.index
[2019-06-18 11:55:45] iteration time 6: 51.165 seconds
2019-06-18 11:55:46.071996: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880545.359775 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 7}}
[2019-06-18 11:55:49] minmax time: 3.240 seconds
2019-06-18 11:55:49.321887: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:55:49.327217: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:55:49.331660: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880549.341801 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 6}}
[2019-06-18 11:55:49] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000008-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000008-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000008-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000008-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000008-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000008-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000008-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000008-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000008-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000008-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000008-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir 
[2019-06-18 11:55:49] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-8-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000007-000006 --seed=8 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000007-000006 --seed=1023779839 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000007-000006 --seed=2047559670 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000007-000006 --seed=3071339501 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000007-000006 --seed=4095119332 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000007-000006 --seed=5118899163 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000007-000006 --seed=6142678994 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000007-000006 --seed=7166458825 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000007-000006 --seed=8190238656 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000007-000006 --seed=9214018487 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000007-000006 --seed=10237798318 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000007-000006 --seed=11261578149 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000007-000006 --seed=12285357980 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000007-000006 --seed=13309137811 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000007-000006 --seed=14332917642 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000007-000006 --seed=15356697473 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000007-000006 --seed=16380477304 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000007-000006 --seed=17404257135 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000007-000006 --seed=18428036966 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000007-000006 --seed=19451816797 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000007-000006 --seed=20475596628 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 11:56:01] eval finished: 11.699 seconds
[2019-06-18 11:56:01] Win rate 000007-000006 vs 000006-000005: 0.600
:::MLL 1560880561.111683 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 6}}
[2019-06-18 11:56:01] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-9-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000008-000005 --seed=9 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000008-000005 --seed=1023779840 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000008-000005 --seed=2047559671 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000008-000005 --seed=3071339502 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000008-000005 --seed=4095119333 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000008-000005 --seed=5118899164 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000008-000005 --seed=6142678995 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000008-000005 --seed=7166458826 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000008-000005 --seed=8190238657 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000008-000005 --seed=9214018488 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000008-000005 --seed=10237798319 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000008-000005 --seed=11261578150 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000008-000005 --seed=12285357981 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000008-000005 --seed=13309137812 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000008-000005 --seed=14332917643 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000008-000005 --seed=15356697474 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000008-000005 --seed=16380477305 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000008-000005 --seed=17404257136 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000008-000005 --seed=18428036967 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/
[2019-06-18 11:56:30] selfplay finished: 29.404 seconds
[2019-06-18 11:56:30] selfplay mn: 29.422 seconds
[2019-06-18 11:56:30] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-9-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779840 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559671 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339502 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119333 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899164 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142678995 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458826 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238657 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018488 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798319 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578150 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285357981 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137812 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917643 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697474 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477305 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257136 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036967 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816798 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596629 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376460 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156291 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000008-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_
[2019-06-18 11:56:33] train finished: 44.063 seconds
:::MLL 1560880554.556445 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880554.557286 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880554.558057 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:54.630988 47256099197824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880554.556804 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880554.557631 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880554.558409 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:54.631161 46967825654656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 11:55:54.632062 47256099197824 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpwy8agjcl
W0618 11:55:54.632175 46967825654656 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpfgs0rzir
I0618 11:55:54.633131 47256099197824 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpwy8agjcl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afaf397ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:54.633229 46967825654656 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpfgs0rzir', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab7d526be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:54.633554 47256099197824 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:54.633651 46967825654656 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:54.638813 47256099197824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:54.638829 46967825654656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:54.658877 46967825654656 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:54.659007 47256099197824 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880554.607255 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880554.608153 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880554.608882 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:54.684819 47957285725056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880554.610927 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880554.611662 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880554.612348 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:54.684898 47336776708992 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 11:55:54.685809 47957285725056 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpnpzmy9cp
W0618 11:55:54.685909 47336776708992 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpvh7rb_3q
I0618 11:55:54.686772 47957285725056 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpnpzmy9cp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9e35913e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:54.686874 47336776708992 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpvh7rb_3q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0dbc590da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:54.687165 47957285725056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:54.687273 47336776708992 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880554.642202 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880554.642573 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880554.642896 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:54.687875 47895715373952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880554.641233 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880554.641612 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880554.641962 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:54.687983 47863545926528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 11:55:54.688835 47895715373952 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp7nxjkf0s
W0618 11:55:54.688961 47863545926528 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp09omn1px
I0618 11:55:54.689821 47895715373952 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp7nxjkf0s', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8fdfb02e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:54.689960 47863545926528 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp09omn1px', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b88623d5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:54.690253 47895715373952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:54.690380 47863545926528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:54.691845 47957285725056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:54.691904 47336776708992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880554.616613 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880554.617560 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880554.618438 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:54.693155 47091424146304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880554.621415 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880554.622143 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880554.622803 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:54.693241 47946347533184 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880554.617438 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880554.618195 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880554.618862 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:54.691942 47807999976320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880554.609135 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880554.610022 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880554.610878 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:54.691988 46999054680960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 11:55:54.694195 47091424146304 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpwg80zq5v
W0618 11:55:54.694264 47946347533184 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmprq7zsfkk
I0618 11:55:54.695224 47091424146304 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpwg80zq5v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad49c31fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:54.695297 47946347533184 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmprq7zsfkk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9ba999ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:54.695654 47091424146304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:54.695713 47946347533184 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:54.693028 47807999976320 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpszextx5p
W0618 11:55:54.693065 46999054680960 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp0l5texsr
I0618 11:55:54.694108 47807999976320 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpszextx5p', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7b73715e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:54.694136 46999054680960 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp0l5texsr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abf1a8bde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:54.694551 47807999976320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:54.694574 46999054680960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:54.694928 47895715373952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:54.695027 47863545926528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:54.700891 47946347533184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:54.700905 47091424146304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:54.699912 46999054680960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:54.699914 47807999976320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:54.707392 46967825654656 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:54.708102 47256099197824 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:54.711680 46967825654656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:54.712428 47256099197824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:54.714433 47957285725056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:54.714886 47336776708992 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:54.714425 47895715373952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:54.714639 47863545926528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:55:54.716763 46967825654656 estimator.py:1111] Calling model_fn.
W0618 11:55:54.716887 46967825654656 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:55:54.717520 47256099197824 estimator.py:1111] Calling model_fn.
W0618 11:55:54.717629 47256099197824 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:55:54.718251 46967825654656 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:55:54.719013 47256099197824 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:55:54.720815 47946347533184 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:54.720873 47091424146304 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:54.722315 47807999976320 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:54.722346 46999054680960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880554.659527 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880554.660234 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880554.660940 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:54.736386 47454839702400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880554.654816 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880554.655717 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880554.656579 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:54.736469 47521611092864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880554.689237 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880554.689660 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880554.690032 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:54.736979 47077190448000 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 11:55:54.737407 47454839702400 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp7r4r8wot
W0618 11:55:54.737445 47521611092864 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp29xy9_11
I0618 11:55:54.738416 47454839702400 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp7r4r8wot', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2939734e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:54.738431 47521611092864 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp29xy9_11', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b38c555ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:54.738812 47454839702400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:54.738018 47077190448000 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpdpeut20k
I0618 11:55:54.738876 47521611092864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:54.739100 47077190448000 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpdpeut20k', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad14bccee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:54.739516 47077190448000 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:54.743622 47521611092864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:54.743638 47454839702400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:54.744420 47077190448000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880554.693195 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880554.693627 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880554.694003 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:54.748234 47789700293504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880554.682555 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880554.682998 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880554.683379 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:54.749149 47679330444160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880554.686251 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880554.686629 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880554.686980 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:54.749320 47370020328320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880554.695387 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880554.695810 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880554.696338 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:54.751340 47607048188800 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880554.696463 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880554.696869 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880554.697227 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:54.751355 47998204883840 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 11:55:54.749154 47789700293504 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp17et5qn1
I0618 11:55:54.750113 47789700293504 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp17et5qn1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7730b27e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:55:54.750134 47679330444160 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp8zbghz_2
W0618 11:55:54.750255 47370020328320 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpjktzg4u2
I0618 11:55:54.751113 47679330444160 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp8zbghz_2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5d7e243e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:54.750503 47789700293504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:54.751234 47370020328320 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpjktzg4u2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1579d25e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:54.751511 47679330444160 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:54.751626 47370020328320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:54.752369 47998204883840 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp9fa9lmsr
W0618 11:55:54.752401 47607048188800 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmppomjrmwe
I0618 11:55:54.753331 47998204883840 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp9fa9lmsr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba7bc89fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:54.753403 47607048188800 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmppomjrmwe', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4ca9c88e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:54.753772 47998204883840 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:54.753830 47607048188800 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:54.755015 47789700293504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:54.756129 47679330444160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:54.756204 47370020328320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:54.758601 47998204883840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:54.758596 47607048188800 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:54.762215 47895715373952 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:54.762520 47863545926528 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880554.680263 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880554.681157 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880554.681981 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:54.761507 47107423032192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880554.698570 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880554.699405 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880554.700158 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:54.761645 47393112175488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 11:55:54.763310 47454839702400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:54.762520 47107423032192 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp_jxccgrf
W0618 11:55:54.763745 47521611092864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:54.762617 47393112175488 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpxp59xrla
I0618 11:55:54.763533 47107423032192 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp_jxccgrf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad855cd9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:55:54.763954 47077190448000 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:55:54.763588 47393112175488 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpxp59xrla', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1ada340dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:54.763934 47107423032192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:54.763985 47393112175488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:54.766541 47895715373952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:54.767008 47957285725056 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:54.766818 47863545926528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:54.767789 47336776708992 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:54.769089 47091424146304 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:54.769280 47946347533184 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:54.768846 47393112175488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:54.768970 47107423032192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:54.771644 47957285725056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:55:54.771622 47895715373952 estimator.py:1111] Calling model_fn.
W0618 11:55:54.771727 47895715373952 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:55:54.771890 47863545926528 estimator.py:1111] Calling model_fn.
W0618 11:55:54.773486 47091424146304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:54.772000 47863545926528 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:55:54.772473 47336776708992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:54.773717 47946347533184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:54.772624 46999054680960 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:54.773095 47895715373952 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:55:54.772806 47807999976320 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:54.773358 47863545926528 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:55:54.774654 47789700293504 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:54.775746 47679330444160 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:54.775943 47370020328320 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:55:54.777110 47957285725056 estimator.py:1111] Calling model_fn.
W0618 11:55:54.778373 47607048188800 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:54.777224 47957285725056 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:55:54.778434 47998204883840 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:55:54.778583 47091424146304 estimator.py:1111] Calling model_fn.
W0618 11:55:54.778690 47091424146304 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:55:54.778793 47946347533184 estimator.py:1111] Calling model_fn.
W0618 11:55:54.778899 47946347533184 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:55:54.776[2019-06-18 11:56:35] divide_golden_chunk finished: 4.545 seconds
[2019-06-18 11:56:35] generate golden chunk: 4.560 seconds
[2019-06-18 11:56:35] moving /lfs/lfs12/gma_akey/results/epb330/models/000008-000006.index --> /lfs/lfs12/gma_akey/results/epb330/models/000008-000007.index
[2019-06-18 11:56:35] moving /lfs/lfs12/gma_akey/results/epb330/models/000008-000006.meta --> /lfs/lfs12/gma_akey/results/epb330/models/000008-000007.meta
[2019-06-18 11:56:35] moving /lfs/lfs12/gma_akey/results/epb330/models/000008-000006.pb --> /lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb
[2019-06-18 11:56:35] moving /lfs/lfs12/gma_akey/results/epb330/models/000008-000006.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb330/models/000008-000007.data-00000-of-00001
[2019-06-18 11:56:35] iteration time 7: 49.778 seconds
2019-06-18 11:56:35.774883: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880595.138396 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 8}}
[2019-06-18 11:56:39] minmax time: 3.261 seconds
2019-06-18 11:56:39.046340: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:56:39.051841: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:56:39.056452: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880599.066745 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 7}}
[2019-06-18 11:56:39] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000009-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000009-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000009-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000009-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000009-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000009-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000009-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000009-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000009-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000009-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000009-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 11:56:39] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-9-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000008-000007 --seed=9 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000008-000007 --seed=1023779840 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000008-000007 --seed=2047559671 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000008-000007 --seed=3071339502 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000008-000007 --seed=4095119333 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000008-000007 --seed=5118899164 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000008-000007 --seed=6142678995 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000008-000007 --seed=7166458826 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000008-000007 --seed=8190238657 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000008-000007 --seed=9214018488 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000008-000007 --seed=10237798319 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000008-000007 --seed=11261578150 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000008-000007 --seed=12285357981 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000008-000007 --seed=13309137812 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000008-000007 --seed=14332917643 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000008-000007 --seed=15356697474 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000008-000007 --seed=16380477305 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000008-000007 --seed=17404257136 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000008-000007 --seed=18428036967 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000008-000007 --seed=19451816798 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000008-000007 --seed=20475596629 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 11:56:49] eval finished: 10.602 seconds
[2019-06-18 11:56:49] Win rate 000008-000007 vs 000007-000006: 0.720
:::MLL 1560880609.738220 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 7}}
[2019-06-18 11:56:49] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-10-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000009-000006 --seed=10 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000009-000006 --seed=1023779841 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000009-000006 --seed=2047559672 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000009-000006 --seed=3071339503 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000009-000006 --seed=4095119334 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000009-000006 --seed=5118899165 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000009-000006 --seed=6142678996 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000009-000006 --seed=7166458827 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000009-000006 --seed=8190238658 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000009-000006 --seed=9214018489 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000009-000006 --seed=10237798320 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000009-000006 --seed=11261578151 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000009-000006 --seed=12285357982 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000009-000006 --seed=13309137813 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000009-000006 --seed=14332917644 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000009-000006 --seed=15356697475 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000009-000006 --seed=16380477306 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000009-000006 --seed=17404257137 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000009-000006 --seed=18428036968 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 11:57:19] selfplay finished: 29.740 seconds
[2019-06-18 11:57:19] selfplay mn: 29.759 seconds
[2019-06-18 11:57:19] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-10-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779841 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559672 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339503 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119334 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899165 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142678996 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458827 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238658 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018489 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798320 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578151 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285357982 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137813 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917644 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697475 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477306 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257137 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036968 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816799 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596630 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376461 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156292 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000009-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golde
[2019-06-18 11:57:22] divide_golden_chunk finished: 3.410 seconds
[2019-06-18 11:57:22] generate golden chunk: 3.425 seconds
[2019-06-18 11:57:23] train finished: 44.206 seconds
:::MLL 1560880604.274027 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880604.274918 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880604.275742 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:44.350228 47596594799488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560880604.280960 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880604.281700 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880604.282406 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:44.350330 47970315748224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:56:44.351293 47596594799488 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmph2b010y4
W0618 11:56:44.351384 47970315748224 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpw3827d4d
I0618 11:56:44.352295 47596594799488 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmph2b010y4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4a3ab67e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:44.352378 47970315748224 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpw3827d4d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba13e379e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:44.352693 47596594799488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:56:44.352771 47970315748224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:56:44.357630 47596594799488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:44.357668 47970315748224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:44.377360 47596594799488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:44.377403 47970315748224 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880604.330028 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880604.330765 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880604.331432 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:44.406399 47585349497728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560880604.326880 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880604.327673 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880604.328345 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:44.406495 47483613029248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:56:44.407376 47585349497728 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpnp9q3vjh
W0618 11:56:44.407454 47483613029248 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpoljle8gs
I0618 11:56:44.408357 47585349497728 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpnp9q3vjh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b479c70be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:44.408441 47483613029248 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpoljle8gs', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2fec797e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:44.408758 47585349497728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:56:44.408826 47483613029248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:56:44.413521 47585349497728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:44.413554 47483613029248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880604.341665 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880604.342417 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880604.343134 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:44.418396 47726145831808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560880604.339661 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880604.340396 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880604.341119 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:44.418581 47275221918592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:56:44.419459 47726145831808 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpvdjgj72e
W0618 11:56:44.419661 47275221918592 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpi6cm7yfs
I0618 11:56:44.420471 47726145831808 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpvdjgj72e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b68648e4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:44.420656 47275221918592 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpi6cm7yfs', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aff67657e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:44.420879 47726145831808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:56:44.421045 47275221918592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880604.364681 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880604.365113 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880604.365519 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:44.421613 47133371519872 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560880604.365030 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880604.365489 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880604.365847 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:44.421880 47826259673984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:56:44.422614 47133371519872 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpep8qpone
W0618 11:56:44.422823 47826259673984 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpaltykb68
I0618 11:56:44.423607 47133371519872 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpep8qpone', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ade60740e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:44.423776 47826259673984 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpaltykb68', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7fb3ce5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:44.424011 47133371519872 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:56:44.424169 47826259673984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:56:44.425169 47596594799488 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:56:44.425797 47970315748224 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:56:44.425725 47726145831808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:44.425845 47275221918592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:44.428727 47133371519872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:44.428900 47826259673984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:44.429432 47596594799488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:56:44.430090 47970315748224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880604.343873 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880604.344632 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880604.345336 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:44.429871 47822050734976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560880604.346059 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880604.346773 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880604.347480 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:44.429932 47871391908736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:56:44.430957 47822050734976 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp5b8fuc1q
W0618 11:56:44.431039 47871391908736 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpecs_e025
I0618 11:56:44.432084 47822050734976 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp5b8fuc1q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7eb8eefe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:44.432144 47871391908736 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpecs_e025', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8a35e58dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:44.432543 47822050734976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:56:44.432600 47871391908736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:56:44.434445 47596594799488 estimator.py:1111] Calling model_fn.
W0618 11:56:44.434557 47596594799488 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:56:44.435150 47970315748224 estimator.py:1111] Calling model_fn.
W0618 11:56:44.435266 47970315748224 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:56:44.435770 47483613029248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:44.435967 47585349497728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:44.435999 47596594799488 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:56:44.436697 47970315748224 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:56:44.437886 47871391908736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:44.437969 47822050734976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880604.362179 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880604.363104 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880604.363935 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:44.440593 47469791425408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560880604.363173 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880604.364032 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880604.364747 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:44.440574 47309910438784 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:56:44.441641 47309910438784 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp5yw_hjiz
W0618 11:56:44.441672 47469791425408 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpuzfitobo
I0618 11:56:44.442734 47309910438784 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp5yw_hjiz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b077afe3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:44.442787 47469791425408 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpuzfitobo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2cb4a48e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:44.443189 47309910438784 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:56:44.443252 47469791425408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:56:44.445711 47726145831808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:44.445900 47275221918592 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:44.448232 47133371519872 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:44.447904 47309910438784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:44.448325 47826259673984 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:44.447914 47469791425408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880604.410878 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880604.411389 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880604.411726 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:44.459336 47177900098432 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560880604.413028 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880604.413437 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880604.413789 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:44.460059 47099316487040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:56:44.460198 47871391908736 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:44.460301 47177900098432 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp1e8d4a7d
I0618 11:56:44.461298 47177900098432 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp1e8d4a7d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae8be904e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:56:44.460815 47822050734976 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:56:44.461714 47177900098432 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:56:44.461024 47099316487040 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp0kakch9g
I0618 11:56:44.462071 47099316487040 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp0kakch9g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad6729d9e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880604.412744 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880604.413248 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880604.413733 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:44.460701 47768486687616 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000008.tfrecord.zz_0
I0618 11:56:44.462495 47099316487040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880604.385104 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880604.385963 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880604.386785 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:44.463533 47517192184704 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560880604.386185 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880604.387086 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880604.387806 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:44.463719 47089450136448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:56:44.461771 47768486687616 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp4un6rqy1
I0618 11:56:44.462813 47768486687616 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp4un6rqy1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7240448e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:56:44.464560 47517192184704 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpfxm50t56
W0618 11:56:44.464706 47089450136448 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpekxkqbwa
I0618 11:56:44.463235 47768486687616 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:56:44.465691 47517192184704 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpfxm50t56', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b37bdf2add8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:44.465802 47089450136448 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpekxkqbwa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad42688ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:44.466090 47517192184704 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:56:44.466190 47089450136448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880604.417632 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880604.418067 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880604.418452 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:44.464585 47226490930048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:56:44.466523 47177900098432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:44.467218 47099316487040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:56:44.465582 47226490930048 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb330/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af40ecd8d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880604.419240 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880604.419625 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880604.419954 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:44.466852 47628457468800 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000008.tfrecord.zz_0
I0618 11:56:44.466679 47226490930048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880604.420357 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880604.420731 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880604.421048 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:44.466853 47639565742976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:56:44.467899 47469791425408 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:44.467953 47309910438784 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:44.468077 47768486687616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:44.467859 47628457468800 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp7hxdjlqh
W0618 11:56:44.467888 47639565742976 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpmjfbbhix
I0618 11:56:44.468856 47628457468800 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp7hxdjlqh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b51a5e03e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:44.468867 47639565742976 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpmjfbbhix', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b543bfb0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:56:44.470947 47517192184704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:44.470992 47089450136448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:56:44.469252 47628457468800 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:56:44.469265 47639565742976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:56:44.471204 47226490930048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:44.474012 47628457468800 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:44.474052 47639565742976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880604.436081 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880604.436525 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880604.436912 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:44.484096 47438923305856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:56:44.486077 47177900098432 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:44.485094 47438923305856 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp00cjc8ro
W0618 11:56:44.486758 47099316487040 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:56:44.486152 47438923305856 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp00cjc8ro', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2584c26e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:44.486589 47438923305856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880604.440514 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880604.440955 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880604.441340 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:44.486750 47456623301504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:56:44.487633 47768486687616 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:44.487762 47456623301504 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpu_k7bqxz
W0618 11:56:44.489301 47483613029248 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:56:44.489481 47585349497728 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 11:56:44.488741 47456623301504 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpu_k7bqxz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b29a3c2edd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:56:44.490728 47517192184704 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:44.490872 47089450136448 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:56:44.489134 47456623301504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:56:44.490659 47226490930048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:44.491228 47438923305856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:44.494183 47483613029248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:56:44.494370 47585349497728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:56:44.493637 47628457468800 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:44.493617 47456623301504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:44.493778 47639565742976 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:44.493599 47726145831808 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:56:44.494028 47275221918592 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:56:44.495820 47826259673984 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:56:44.495900 47133371519872 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:56:44.497893 47726145831808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:56:44.498326 47275221918592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:56:44.499898 47483613029248 estimator.py:1111] Calling model_fn.
W0618 11:56:44.500026 47483613029248 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:56:44.500114 47585349497728 estimator.py:1111] Calling model_fn.
W0618 11:56:44.500235 47585349497728 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementation[2019-06-18 11:57:23] moving /lfs/lfs12/gma_akey/results/epb330/models/000009-000007.index --> /lfs/lfs12/gma_akey/results/epb330/models/000009-000008.index
[2019-06-18 11:57:23] moving /lfs/lfs12/gma_akey/results/epb330/models/000009-000007.meta --> /lfs/lfs12/gma_akey/results/epb330/models/000009-000008.meta
[2019-06-18 11:57:23] moving /lfs/lfs12/gma_akey/results/epb330/models/000009-000007.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb330/models/000009-000008.data-00000-of-00001
[2019-06-18 11:57:23] moving /lfs/lfs12/gma_akey/results/epb330/models/000009-000007.pb --> /lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb
[2019-06-18 11:57:23] iteration time 8: 48.203 seconds
2019-06-18 11:57:24.021340: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880643.341425 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 9}}
[2019-06-18 11:57:27] minmax time: 3.244 seconds
2019-06-18 11:57:27.275917: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:57:27.281205: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:57:27.285602: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880647.296176 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 8}}
[2019-06-18 11:57:27] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000010-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000010-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000010-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000010-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000010-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000010-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000010-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000010-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000010-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000010-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000010-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 11:57:27] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-10-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000009-000008 --seed=10 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000009-000008 --seed=1023779841 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000009-000008 --seed=2047559672 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000009-000008 --seed=3071339503 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000009-000008 --seed=4095119334 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000009-000008 --seed=5118899165 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000009-000008 --seed=6142678996 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000009-000008 --seed=7166458827 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000009-000008 --seed=8190238658 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000009-000008 --seed=9214018489 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000009-000008 --seed=10237798320 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000009-000008 --seed=11261578151 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000009-000008 --seed=12285357982 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000009-000008 --seed=13309137813 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000009-000008 --seed=14332917644 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000009-000008 --seed=15356697475 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000009-000008 --seed=16380477306 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000009-000008 --seed=17404257137 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000009-000008 --seed=18428036968 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000009-000008 --seed=19451816799 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000009-000008 --seed=20475596630 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 11:57:38] eval finished: 10.776 seconds
[2019-06-18 11:57:38] Win rate 000009-000008 vs 000008-000007: 0.600
:::MLL 1560880658.141658 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 8}}
[2019-06-18 11:57:38] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-11-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000010-000007 --seed=11 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000010-000007 --seed=1023779842 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000010-000007 --seed=2047559673 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000010-000007 --seed=3071339504 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000010-000007 --seed=4095119335 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000010-000007 --seed=5118899166 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000010-000007 --seed=6142678997 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000010-000007 --seed=7166458828 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000010-000007 --seed=8190238659 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000010-000007 --seed=9214018490 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000010-000007 --seed=10237798321 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000010-000007 --seed=11261578152 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000010-000007 --seed=12285357983 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000010-000007 --seed=13309137814 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000010-000007 --seed=14332917645 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000010-000007 --seed=15356697476 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000010-000007 --seed=16380477307 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000010-000007 --seed=17404257138 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000010-000007 --seed=18428036969 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 11:58:07] selfplay finished: 29.342 seconds
[2019-06-18 11:58:07] selfplay mn: 29.362 seconds
[2019-06-18 11:58:07] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-11-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779842 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559673 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339504 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119335 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899166 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142678997 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458828 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238659 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018490 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798321 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578152 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285357983 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137814 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917645 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697476 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477307 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257138 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036969 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816800 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596631 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376462 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156293 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000010-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golde
[2019-06-18 11:58:10] divide_golden_chunk finished: 3.342 seconds
[2019-06-18 11:58:10] generate golden chunk: 3.357 seconds
[2019-06-18 11:58:11] train finished: 44.287 seconds
:::MLL 1560880652.602236 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880652.602978 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880652.603676 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:32.676338 46933593731968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880652.592123 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880652.593034 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880652.593882 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:32.676481 47585598874496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:57:32.677390 46933593731968 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpg_vw395y
W0618 11:57:32.677498 47585598874496 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpr41c_o01
I0618 11:57:32.678475 46933593731968 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpg_vw395y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aafdcc4fda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:32.678556 47585598874496 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpr41c_o01', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b47ab4dfe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:32.678879 46933593731968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:32.678947 47585598874496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:57:32.683861 46933593731968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:32.683930 47585598874496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880652.607523 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880652.608278 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880652.608974 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:32.683671 47224451478400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880652.603441 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880652.604340 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880652.605045 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:32.683783 47992048526208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:57:32.684700 47224451478400 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmppgabyb90
W0618 11:57:32.684766 47992048526208 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpsiftv3s6
I0618 11:57:32.685688 47224451478400 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmppgabyb90', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af3953e0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:32.685739 47992048526208 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpsiftv3s6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba64d977e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:32.686097 47224451478400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:32.686139 47992048526208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:57:32.691228 47992048526208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:32.691225 47224451478400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880652.617310 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880652.618056 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880652.618738 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:32.691761 47970935464832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880652.613385 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880652.614316 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880652.615000 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:32.691734 47144539472768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:57:32.692778 47970935464832 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmphwid_shl
W0618 11:57:32.692749 47144539472768 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmphlcd4yok
I0618 11:57:32.693745 47144539472768 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmphlcd4yok', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae0fa1d9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:32.693793 47970935464832 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmphwid_shl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba16327ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:32.694154 47144539472768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:32.694199 47970935464832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:57:32.699099 47144539472768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:32.699112 47970935464832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880652.620520 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880652.621363 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880652.622173 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:32.704198 47016625914752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880652.620553 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880652.621417 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880652.622192 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:32.704307 46918738527104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:57:32.706226 46933593731968 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:32.706425 47585598874496 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:32.705250 47016625914752 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmplbzowe7f
W0618 11:57:32.705315 46918738527104 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp8ira9vfd
I0618 11:57:32.706257 47016625914752 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmplbzowe7f', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac331df8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:32.706320 46918738527104 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp8ira9vfd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aac67548e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:32.706672 47016625914752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:32.706740 46918738527104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:57:32.711500 47992048526208 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:32.711587 47224451478400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:32.711742 47016625914752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:32.711764 46918738527104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880652.623730 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880652.624635 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880652.625498 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:32.713387 46963877229440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880652.634811 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880652.635532 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880652.636209 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:32.713485 47689968341888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880652.632900 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880652.633812 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880652.634648 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:32.715516 47825629946752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880652.642944 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880652.643671 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880652.644339 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:32.715521 47040298980224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:57:32.714490 46963877229440 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpsp6rf80n
W0618 11:57:32.714590 47689968341888 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp89sqv7h8
W0618 11:57:32.716583 47825629946752 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp26qpf67e
W0618 11:57:32.716611 47040298980224 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp_suf2k0v
I0618 11:57:32.715580 46963877229440 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpsp6rf80n', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab6e9ce8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:32.717576 47825629946752 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp26qpf67e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7f8e457e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:32.715675 47689968341888 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp89sqv7h8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5ff835ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:32.717612 47040298980224 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp_suf2k0v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac8b4e5ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:32.716010 46963877229440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:32.717968 47825629946752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:32.718003 47040298980224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:32.716120 47689968341888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:57:32.718956 47970935464832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:32.718930 47144539472768 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:32.722893 47825629946752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:32.722903 47040298980224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:32.721275 46963877229440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:32.721283 47689968341888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880652.673082 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880652.673583 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880652.674025 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:32.722078 47288011629440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:57:32.723198 47288011629440 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp9hpbj3d3
I0618 11:57:32.724168 47288011629440 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp9hpbj3d3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0261b8fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880652.676525 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880652.676976 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880652.677358 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:32.724286 47981170836352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_0
I0618 11:57:32.724568 47288011629440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:57:32.725256 47981170836352 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpzm8q9ag5
I0618 11:57:32.726239 47981170836352 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpzm8q9ag5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba3c53b1dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:32.726629 47981170836352 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:57:32.729223 47288011629440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:32.731362 47981170836352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880652.681206 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880652.681687 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880652.682007 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:32.731566 46932017435520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880652.683773 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880652.684168 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880652.684531 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:32.732156 47177160917888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:57:32.731636 47016625914752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:32.732033 46918738527104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:32.732549 46932017435520 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpq25pgy7c
I0618 11:57:32.733523 46932017435520 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpq25pgy7c', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aaf7ed0ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:57:32.733118 47177160917888 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpr_gf0r0x
I0618 11:57:32.733916 46932017435520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:32.734102 47177160917888 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpr_gf0r0x', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae892812e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:32.734523 47177160917888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:57:32.738513 46932017435520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:32.739052 47177160917888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880652.679520 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880652.680034 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880652.680434 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:32.740126 47300350698368 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880652.682715 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880652.683177 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880652.683577 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:32.740146 47916417352576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:57:32.743154 47825629946752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:32.743177 47040298980224 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:57:32.741133 47300350698368 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb330/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0541301d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:57:32.741139 47916417352576 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp5vqiwgh0
I0618 11:57:32.742158 47916417352576 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp5vqiwgh0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b94b19f4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:32.742309 47300350698368 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:32.742581 47916417352576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:57:32.743631 46963877229440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:32.743993 47689968341888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:32.747102 47300350698368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:32.747302 47916417352576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:32.748964 47288011629440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880652.699148 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880652.699578 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880652.699908 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:32.748597 47222621430656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880652.698778 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880652.699218 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880652.699589 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:32.748685 47271197930368 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:57:32.749657 47222621430656 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp1wvua5dl
W0618 11:57:32.750880 47981170836352 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:32.749693 47271197930368 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp_zkchwfh
I0618 11:57:32.750697 47222621430656 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp1wvua5dl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af328299e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:32.750739 47271197930368 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp_zkchwfh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afe778c4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:32.751137 47222621430656 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:32.751188 47271197930368 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:57:32.755872 47271197930368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:32.755882 47222621430656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880652.707210 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880652.707631 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880652.707995 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:32.756218 46926327575424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880652.707633 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880652.708051 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880652.708375 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:32.756403 47922800042880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:57:32.757919 46932017435520 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:32.758553 47177160917888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:32.757191 46926327575424 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpwhi5l5nx
W0618 11:57:32.757374 47922800042880 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp_7i3gs_6
W0618 11:57:32.758841 47585598874496 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 11:57:32.758171 46926327575424 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpwhi5l5nx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aae2bac4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:57:32.758818 46933593731968 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 11:57:32.758362 47922800042880 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp_7i3gs_6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b962e0f7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:32.758568 46926327575424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:32.758758 47922800042880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:57:32.759518 47992048526208 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:57:32.759963 47224451478400 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:57:32.763501 47585598874496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:57:32.763460 46933593731968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:57:32.763160 46926327575424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:32.763302 47922800042880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:32.763822 47992048526208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:57:32.764281 47224451478400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:57:32.767023 47970935464832 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:57:32.766740 47300350698368 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:32.767354 47144539472768 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:57:32.766977 47916417352576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880652.720531 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880652.721012 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880652.721395 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:32.769175 47842108347264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_0
I0618 11:57:32.768923 46933593731968 estimator.py:1111] Calling model_fn.
I0618 11:57:32.768973 47585598874496 estimator.py:1111] Calling model_fn.
W0618 11:57:32.769043 46933593731968 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:57:32.769104 47585598874496 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:57:32.768859 47992048526208 estimator.py:1111] Calling model_fn.
W0618 11:57:32.768970 47992048526208 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:57:32.769341 47224451478400 estimator.py:1111] Calling model_fn.
W0618 11:57:32.769450 47224451478400 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:57:32.770272 47842108347264 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpti_bf8o2
I0618 11:57:32.771335 47842108347264 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpti_bf8o2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b836475ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:32.771762 47842108347264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:57:32.770547 47585598874496 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:57:32.770509 46933593731968 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:57:32.770321 47992048526208 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560880652.723899 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880652.724372 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880652.724753 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:32.771858 47062580056960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:57:32.770810 47224451478400 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:57:32.771338 47970935464832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a [2019-06-18 11:58:11] moving /lfs/lfs12/gma_akey/results/epb330/models/000010-000008.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb330/models/000010-000009.data-00000-of-00001
[2019-06-18 11:58:11] moving /lfs/lfs12/gma_akey/results/epb330/models/000010-000008.meta --> /lfs/lfs12/gma_akey/results/epb330/models/000010-000009.meta
[2019-06-18 11:58:11] moving /lfs/lfs12/gma_akey/results/epb330/models/000010-000008.index --> /lfs/lfs12/gma_akey/results/epb330/models/000010-000009.index
[2019-06-18 11:58:11] moving /lfs/lfs12/gma_akey/results/epb330/models/000010-000008.pb --> /lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb
[2019-06-18 11:58:11] iteration time 9: 48.310 seconds
2019-06-18 11:58:12.368501: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880691.651871 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 10}}
[2019-06-18 11:58:15] minmax time: 3.261 seconds
2019-06-18 11:58:15.639791: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:58:15.645132: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:58:15.649593: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880695.659883 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 9}}
[2019-06-18 11:58:15] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000011-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000011-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000011-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000011-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000011-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000011-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000011-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000011-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000011-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000011-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000011-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 11:58:15] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-11-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000010-000009 --seed=11 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000010-000009 --seed=1023779842 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000010-000009 --seed=2047559673 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000010-000009 --seed=3071339504 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000010-000009 --seed=4095119335 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000010-000009 --seed=5118899166 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000010-000009 --seed=6142678997 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000010-000009 --seed=7166458828 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000010-000009 --seed=8190238659 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000010-000009 --seed=9214018490 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000010-000009 --seed=10237798321 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000010-000009 --seed=11261578152 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000010-000009 --seed=12285357983 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000010-000009 --seed=13309137814 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000010-000009 --seed=14332917645 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000010-000009 --seed=15356697476 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000010-000009 --seed=16380477307 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000010-000009 --seed=17404257138 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000010-000009 --seed=18428036969 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000010-000009 --seed=19451816800 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000010-000009 --seed=20475596631 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 11:58:26] eval finished: 11.125 seconds
[2019-06-18 11:58:26] Win rate 000010-000009 vs 000009-000008: 0.610
:::MLL 1560880706.855959 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 9}}
[2019-06-18 11:58:26] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-12-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000011-000008 --seed=12 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000011-000008 --seed=1023779843 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000011-000008 --seed=2047559674 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000011-000008 --seed=3071339505 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000011-000008 --seed=4095119336 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000011-000008 --seed=5118899167 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000011-000008 --seed=6142678998 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000011-000008 --seed=7166458829 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000011-000008 --seed=8190238660 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000011-000008 --seed=9214018491 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000011-000008 --seed=10237798322 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000011-000008 --seed=11261578153 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000011-000008 --seed=12285357984 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000011-000008 --seed=13309137815 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000011-000008 --seed=14332917646 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000011-000008 --seed=15356697477 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000011-000008 --seed=16380477308 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000011-000008 --seed=17404257139 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000011-000008 --seed=18428036970 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 11:58:57] selfplay finished: 30.213 seconds
[2019-06-18 11:58:57] selfplay mn: 30.230 seconds
[2019-06-18 11:58:57] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-12-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779843 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559674 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339505 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119336 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899167 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142678998 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458829 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238660 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018491 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798322 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578153 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285357984 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137815 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917646 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697477 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477308 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257139 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036970 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816801 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596632 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376463 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156294 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000011-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golde
[2019-06-18 11:58:59] train finished: 44.313 seconds
:::MLL 1560880700.979131 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880700.979886 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880700.980573 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:21.056707 47965470831488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560880700.976318 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880700.977077 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880700.977768 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:21.056818 47739481023360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:58:21.057693 47965470831488 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpip8kdxmb
W0618 11:58:21.057814 47739481023360 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp23hyb6zq
I0618 11:58:21.058680 47965470831488 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpip8kdxmb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba01d700e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:21.058812 47739481023360 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp23hyb6zq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6b7f653e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:21.059080 47965470831488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:21.059211 47739481023360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:21.063779 47965470831488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:21.063984 47739481023360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880700.994817 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880700.995541 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880700.996226 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:21.065139 47905872364416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560880700.982467 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880700.983402 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880700.984251 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:21.065143 47451129316224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:58:21.066193 47905872364416 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpskr8sa_o
W0618 11:58:21.066220 47451129316224 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp8ybc1koz
I0618 11:58:21.067236 47905872364416 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpskr8sa_o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b923d179dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:21.067235 47451129316224 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp8ybc1koz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b285c4b5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:21.067637 47905872364416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:21.067639 47451129316224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:21.072728 47905872364416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:21.072710 47451129316224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880700.994462 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880700.995349 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880700.996004 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:21.080406 47851035689856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560880700.993469 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880700.994357 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880700.995177 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:21.080428 47089639363456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:58:21.081516 47089639363456 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpyuqa82ut
W0618 11:58:21.081547 47851035689856 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmptnb4urql
I0618 11:58:21.082569 47089639363456 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpyuqa82ut', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad431d05e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:21.082592 47851035689856 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmptnb4urql', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8578924e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:21.083027 47089639363456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:21.083031 47851035689856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:21.083336 47965470831488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:21.084067 47739481023360 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:21.088277 47851035689856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:21.088281 47089639363456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880701.005352 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880701.006285 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880701.007138 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:21.087607 47264019317632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560880701.024446 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880701.025252 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880701.025991 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:21.087631 46914805138304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:58:21.088636 46914805138304 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpaf9s30ne
W0618 11:58:21.088607 47264019317632 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpfqe97lfq
I0618 11:58:21.089594 47264019317632 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpfqe97lfq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afccbab5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:21.089628 46914805138304 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpaf9s30ne', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aab7ce1ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:21.089993 47264019317632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:21.090023 46914805138304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:21.092136 47451129316224 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:21.092405 47905872364416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:21.095074 46914805138304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:21.095092 47264019317632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880701.053252 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880701.053666 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880701.054070 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:21.105863 47787111961472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560880701.054250 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880701.054657 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880701.055080 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:21.105997 47766384030592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:58:21.106861 47787111961472 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp9d7np6to
W0618 11:58:21.106954 47766384030592 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp_m7u44os
I0618 11:58:21.107836 47787111961472 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp9d7np6to', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b76966bae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:21.107911 47766384030592 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp_m7u44os', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b71c2f08dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:21.108231 47787111961472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:21.108299 47766384030592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:21.110553 47851035689856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:21.111050 47089639363456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880701.033712 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880701.034465 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880701.035182 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:21.110161 47806004040576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560880701.029051 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880701.029960 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880701.030808 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:21.110320 47927051682688 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:58:21.112741 47787111961472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:21.111179 47806004040576 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpdrf_8gx0
W0618 11:58:21.112836 47766384030592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:21.111308 47927051682688 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp9t006wdh
I0618 11:58:21.112163 47806004040576 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpdrf_8gx0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7afc79edd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:21.112299 47927051682688 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp9t006wdh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b972b7a5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:21.112570 47806004040576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:21.112693 47927051682688 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:21.116565 46914805138304 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:21.116677 47264019317632 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:21.117532 47927051682688 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880701.041817 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880701.042738 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880701.043616 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:21.119608 47039198393216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:58:21.117529 47806004040576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880701.049572 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880701.050301 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880701.050923 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:21.119726 47308968919936 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:58:21.120618 47039198393216 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp_14y0pxu
W0618 11:58:21.120697 47308968919936 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpp17g_jlv
I0618 11:58:21.121613 47039198393216 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp_14y0pxu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac8734c4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:21.121688 47308968919936 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpp17g_jlv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0742dfde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:21.122019 47039198393216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:21.122084 47308968919936 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880701.072437 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880701.072889 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880701.073274 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:21.123845 47469327876992 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560880701.072430 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880701.072880 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880701.073262 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:21.123870 47550241493888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:58:21.124925 47550241493888 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpqbvvah_f
W0618 11:58:21.124896 47469327876992 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpsbj1lhlb
I0618 11:58:21.125880 47469327876992 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpsbj1lhlb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2c99035e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:21.125887 47550241493888 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpqbvvah_f', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3f6fd72e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:58:21.127121 47039198393216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:21.127172 47308968919936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:58:21.126277 47550241493888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:21.126280 47469327876992 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:21.130888 47550241493888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:21.130931 47469327876992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:21.131273 47965470831488 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880701.080683 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880701.081158 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880701.081574 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:21.131361 46990570550144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:58:21.132087 47787111961472 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:21.132169 47766384030592 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:21.132125 47739481023360 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:58:21.132461 46990570550144 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp5k6pw5us
I0618 11:58:21.133479 46990570550144 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp5k6pw5us', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abd20da3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:21.133890 46990570550144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880701.086317 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880701.086762 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880701.087153 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:21.134781 47046452179840 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:58:21.135566 47965470831488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:58:21.136453 47739481023360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:58:21.135730 47046452179840 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp20yae4z5
I0618 11:58:21.136689 47046452179840 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp20yae4z5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aca23a82e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:21.137090 47046452179840 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:21.137143 47927051682688 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:21.137230 47806004040576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:21.138519 46990570550144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:58:21.140598 47965470831488 estimator.py:1111] Calling model_fn.
W0618 11:58:21.140707 47965470831488 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:58:21.140332 47451129316224 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:58:21.140786 47905872364416 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 11:58:21.141524 47739481023360 estimator.py:1111] Calling model_fn.
W0618 11:58:21.141632 47739481023360 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:58:21.141558 47046452179840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:21.142071 47965470831488 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:58:21.142989 47739481023360 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:58:21.144649 47451129316224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:58:21.146856 47308968919936 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:21.145107 47905872364416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:58:21.146863 47039198393216 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880701.097735 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880701.098175 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880701.098567 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:21.148416 47340282770304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:58:21.150274 47550241493888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:21.150540 47469327876992 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:58:21.149716 47451129316224 estimator.py:1111] Calling model_fn.
W0618 11:58:21.149830 47451129316224 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560880701.095821 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880701.096268 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880701.096652 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:21.149391 47616454108032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:58:21.149448 47340282770304 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpmwdmietl
I0618 11:58:21.150219 47905872364416 estimator.py:1111] Calling model_fn.
:::MLL 1560880701.101122 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880701.101559 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880701.101922 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:21.150138 47631338574720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:58:21.150329 47905872364416 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:58:21.150433 47340282770304 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpmwdmietl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0e8d534e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:21.150836 47340282770304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880701.097519 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880701.097943 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880701.098318 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:21.150446 47901801526144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:58:21.151188 47451129316224 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:58:21.150384 47616454108032 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpy8oio4bz
W0618 11:58:21.151706 47905872364416 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 11:58:21.151360 47616454108032 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpy8oio4bz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4eda6b7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:58:21.151109 47631338574720 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp_m0n8a1i
I0618 11:58:21.152065 47631338574720 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp_m0n8a1i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b52519a6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:21.151761 47616454108032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:21.152462 47631338574720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:21.151427 47901801526144 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb330/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b914a737d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:21.152537 47901801526144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:21.155486 47340282770304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:21.156397 47616454108032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:21.157095 47631338574720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:21.157077 47901801526144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:21.158039 46990570550144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:21.160968 47046452179840 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:21.162726 47851035689856 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:58:21.162775 47089639363456 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:58:21.167494 47851035689856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:58:21.167504 47089639363456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:58:21.167999 46914805138304 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:58:21.168279 47264019317632 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the seman[2019-06-18 11:59:00] divide_golden_chunk finished: 3.311 seconds
[2019-06-18 11:59:00] generate golden chunk: 3.325 seconds
[2019-06-18 11:59:00] moving /lfs/lfs12/gma_akey/results/epb330/models/000011-000009.meta --> /lfs/lfs12/gma_akey/results/epb330/models/000011-000010.meta
[2019-06-18 11:59:00] moving /lfs/lfs12/gma_akey/results/epb330/models/000011-000009.index --> /lfs/lfs12/gma_akey/results/epb330/models/000011-000010.index
[2019-06-18 11:59:00] moving /lfs/lfs12/gma_akey/results/epb330/models/000011-000009.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb330/models/000011-000010.data-00000-of-00001
[2019-06-18 11:59:00] moving /lfs/lfs12/gma_akey/results/epb330/models/000011-000009.pb --> /lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb
[2019-06-18 11:59:00] iteration time 10: 48.801 seconds
2019-06-18 11:59:01.212635: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880740.453353 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 11}}
[2019-06-18 11:59:04] minmax time: 3.235 seconds
2019-06-18 11:59:04.456835: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:59:04.462191: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:59:04.466787: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880744.477466 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 10}}
[2019-06-18 11:59:04] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000012-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000012-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000012-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000012-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000012-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000012-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000012-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000012-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000012-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000012-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000012-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 11:59:04] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-12-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000011-000010 --seed=12 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000011-000010 --seed=1023779843 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000011-000010 --seed=2047559674 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000011-000010 --seed=3071339505 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000011-000010 --seed=4095119336 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000011-000010 --seed=5118899167 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000011-000010 --seed=6142678998 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000011-000010 --seed=7166458829 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000011-000010 --seed=8190238660 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000011-000010 --seed=9214018491 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000011-000010 --seed=10237798322 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000011-000010 --seed=11261578153 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000011-000010 --seed=12285357984 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000011-000010 --seed=13309137815 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000011-000010 --seed=14332917646 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000011-000010 --seed=15356697477 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000011-000010 --seed=16380477308 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000011-000010 --seed=17404257139 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000011-000010 --seed=18428036970 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000011-000010 --seed=19451816801 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000011-000010 --seed=20475596632 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 11:59:15] eval finished: 11.376 seconds
[2019-06-18 11:59:15] Win rate 000011-000010 vs 000010-000009: 0.520
:::MLL 1560880755.925663 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 10}}
[2019-06-18 11:59:15] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-13-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000012-000009 --seed=13 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000012-000009 --seed=1023779844 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000012-000009 --seed=2047559675 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000012-000009 --seed=3071339506 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000012-000009 --seed=4095119337 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000012-000009 --seed=5118899168 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000012-000009 --seed=6142678999 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000012-000009 --seed=7166458830 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000012-000009 --seed=8190238661 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000012-000009 --seed=9214018492 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000012-000009 --seed=10237798323 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000012-000009 --seed=11261578154 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000012-000009 --seed=12285357985 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000012-000009 --seed=13309137816 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000012-000009 --seed=14332917647 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000012-000009 --seed=15356697478 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000012-000009 --seed=16380477309 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000012-000009 --seed=17404257140 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000012-000009 --seed=18428036971 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 11:59:47] selfplay finished: 31.117 seconds
[2019-06-18 11:59:47] selfplay mn: 31.138 seconds
[2019-06-18 11:59:47] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-13-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779844 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559675 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339506 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119337 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899168 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142678999 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458830 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238661 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018492 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798323 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578154 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285357985 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137816 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917647 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697478 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477309 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257140 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036971 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816802 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596633 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376464 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156295 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000012-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golde
[2019-06-18 11:59:48] train finished: 44.092 seconds
:::MLL 1560880749.746376 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880749.747277 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880749.748121 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:09.829631 47460684497792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:59:09.830698 47460684497792 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpz7iayxy2
I0618 11:59:09.831783 47460684497792 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpz7iayxy2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2a95d3cdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:09.832251 47460684497792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880749.752933 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880749.753662 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880749.754353 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:09.832129 48011562132352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:59:09.833245 48011562132352 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp97y43r82
I0618 11:59:09.834440 48011562132352 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp97y43r82', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2baad8b16e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:09.834889 48011562132352 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:09.837244 47460684497792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:09.840256 48011562132352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:09.857156 47460684497792 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880749.789977 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880749.790796 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880749.791554 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:09.862387 47403843048320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560880749.776150 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880749.777041 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880749.777876 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:09.862573 47003644994432 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:59:09.863095 48011562132352 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:09.863429 47403843048320 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp61zkz0vb
W0618 11:59:09.863595 47003644994432 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpyoen56l9
I0618 11:59:09.864493 47403843048320 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp61zkz0vb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1d59d01e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:09.864640 47003644994432 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpyoen56l9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac02c267e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:09.864923 47403843048320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:09.865062 47003644994432 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:09.870047 47403843048320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:09.870134 47003644994432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880749.789297 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880749.790216 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880749.790959 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:09.873941 46950828385152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560880749.793253 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880749.793981 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880749.794634 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:09.874264 46921447981952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:59:09.875001 46950828385152 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp7u1wwigm
W0618 11:59:09.875265 46921447981952 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpf_s0ua27
I0618 11:59:09.875991 46950828385152 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp7u1wwigm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab3e008fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:09.876249 46921447981952 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpf_s0ua27', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aad08d38e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:09.876389 46950828385152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:09.876636 46921447981952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:09.881279 46950828385152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:09.881407 46921447981952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880749.806185 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880749.807068 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880749.807927 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:09.890108 47218045010816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560880749.817029 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880749.817779 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880749.818443 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:09.890084 47823300113280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:59:09.891095 47823300113280 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp49c775u9
W0618 11:59:09.891120 47218045010816 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp4esab5h5
I0618 11:59:09.892129 47823300113280 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp49c775u9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7f03670e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:09.892139 47218045010816 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp4esab5h5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af217631e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:09.892547 47218045010816 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:09.892546 47823300113280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:09.892430 47003644994432 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:09.893168 47403843048320 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880749.837312 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880749.837834 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880749.838211 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:09.892765 47711479817088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560880749.836904 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880749.837358 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880749.837810 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:09.893254 47223225107328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:59:09.893815 47711479817088 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpge31a8lr
I0618 11:59:09.894805 47711479817088 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpge31a8lr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b64fa64ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:59:09.894244 47223225107328 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp32q17o6b
I0618 11:59:09.895205 47711479817088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:09.895215 47223225107328 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp32q17o6b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af34c251dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:09.895609 47223225107328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:09.897611 47218045010816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:09.897621 47823300113280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:09.899920 47711479817088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:09.900268 47223225107328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880749.833788 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880749.834597 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880749.835347 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:09.900025 47762777723776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:59:09.900963 46950828385152 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880749.813275 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880749.814214 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880749.815076 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:09.900931 47878860968832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:59:09.901082 46921447981952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880749.810616 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880749.811519 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880749.812335 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:09.900731 47765003608960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560880749.826575 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880749.827318 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880749.828069 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:09.900769 47451681649536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:59:09.901135 47762777723776 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpmezn89d_
I0618 11:59:09.902248 47762777723776 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpmezn89d_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b70ebfc9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:09.902716 47762777723776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:09.902006 47878860968832 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpmqwun_0a
W0618 11:59:09.901776 47765003608960 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpts83l5t5
W0618 11:59:09.901804 47451681649536 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp0y48jije
I0618 11:59:09.903125 47878860968832 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpmqwun_0a', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8bf3166e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:09.902780 47765003608960 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpts83l5t5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7170a8fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:09.902799 47451681649536 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp0y48jije', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b287d372e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:09.903572 47878860968832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:09.903182 47765003608960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:09.903194 47451681649536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:09.905490 47460684497792 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:59:09.907983 47762777723776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:09.908205 47451681649536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:09.908201 47765003608960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:09.908652 47878860968832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:09.909781 47460684497792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:59:09.914836 47460684497792 estimator.py:1111] Calling model_fn.
W0618 11:59:09.914947 47460684497792 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:59:09.917231 47823300113280 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:09.917782 47218045010816 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:09.916297 47460684497792 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:59:09.916397 48011562132352 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:59:09.919260 47711479817088 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:09.919769 47223225107328 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:09.921262 48011562132352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880749.866843 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880749.867276 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880749.867780 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:09.923156 47346947376000 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560880749.868660 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880749.869044 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880749.869399 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:09.923490 47345290666880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:59:09.924133 47346947376000 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp6g60knm6
I0618 11:59:09.925100 47346947376000 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp6g60knm6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b101a911e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:59:09.924424 47345290666880 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp3lkvbnul
I0618 11:59:09.925394 47345290666880 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp3lkvbnul', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0fb7d19e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:09.925506 47346947376000 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:09.925791 47345290666880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:09.927218 48011562132352 estimator.py:1111] Calling model_fn.
W0618 11:59:09.927342 48011562132352 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:59:09.927938 47765003608960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:09.928744 48011562132352 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:59:09.928009 47451681649536 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:09.930240 47346947376000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:09.930553 47345290666880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:09.930058 47762777723776 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:09.930594 47878860968832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880749.876014 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880749.876401 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880749.876722 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:09.931158 47586434966400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560880749.878541 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880749.879022 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880749.879426 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:09.931659 47302716097408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:59:09.932164 47586434966400 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpe6vwehyg
I0618 11:59:09.933149 47586434966400 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpe6vwehyg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b47dd23be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:59:09.932602 47302716097408 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpvcanqs50
I0618 11:59:09.933556 47586434966400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:09.933559 47302716097408 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpvcanqs50', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b05ce2d5dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:09.933955 47302716097408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880749.882940 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880749.883363 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880749.883721 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:09.937316 47917262148480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560880749.878283 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880749.878934 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880749.879361 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:09.937400 47669626479488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:59:09.938197 47586434966400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:09.938509 47302716097408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:09.938310 47917262148480 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp346_gaxn
W0618 11:59:09.938382 47669626479488 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpv4j2kt7t
I0618 11:59:09.939291 47917262148480 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp346_gaxn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b94e3f9edd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:09.939357 47669626479488 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpv4j2kt7t', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5b3bbd6dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:09.939684 47917262148480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:09.939753 47669626479488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:09.944408 47669626479488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:09.944420 47917262148480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:09.945163 47003644994432 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:59:09.946031 47403843048320 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:59:09.949649 47346947376000 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:09.948935 46950828385152 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:59:09.949790 47003644994432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:59:09.949172 46921447981952 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880749.896259 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880749.896740 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880749.897135 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:09.951073 46933222081408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:59:09.950042 47345290666880 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:09.950662 47403843048320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880749.900376 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880749.900823 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880749.901209 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:09.952439 47667775939456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:59:09.952070 46933222081408 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpb2f9qtp1
I0618 11:59:09.953060 46933222081408 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpb2f9qtp1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aafc69dedd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880749.893259 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880749.893755 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880749.894123 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:09.950525 47972418847616 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_0_0
I0618 11:59:09.953458 46933222081408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:09.953382 47667775939456 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp5payacmr
I0618 11:59:09.954366 47667775939456 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp5payacmr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5acd707e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880749.896264 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880749.896766 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880749.897154 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:09.951880 47298707379072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:59:09.951533 47972418847616 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpgtmyqzvn
I0618 11:59:09.954805 47667775939456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:09.952600 47972418847616 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpgtmyqzvn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba1bb925e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:59:09.953216 46950828385152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:59:09.953027 47972418847616 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:09.953495 46921447981952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:59:09.952970 47298707379072 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb330/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b04df3d2d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:09.954113 47298707379072 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:09.955291 47003644994432 estimator.py:1111] Calling model_fn.
W0618 11:59:09.955404 47003644994432 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:59:09.956116 47403843048320 estimator.py:1111] Calling model_fn.
W0618 11:59:09.956231 47403843048320 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:59:09.956862 47003644994432 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:59:09.958191 46933222081408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use[2019-06-18 11:59:50] divide_golden_chunk finished: 3.433 seconds
[2019-06-18 11:59:50] generate golden chunk: 3.448 seconds
[2019-06-18 11:59:50] moving /lfs/lfs12/gma_akey/results/epb330/models/000012-000010.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb330/models/000012-000011.data-00000-of-00001
[2019-06-18 11:59:50] moving /lfs/lfs12/gma_akey/results/epb330/models/000012-000010.pb --> /lfs/lfs12/gma_akey/results/epb330/models/000012-000011.pb
[2019-06-18 11:59:50] moving /lfs/lfs12/gma_akey/results/epb330/models/000012-000010.meta --> /lfs/lfs12/gma_akey/results/epb330/models/000012-000011.meta
[2019-06-18 11:59:50] moving /lfs/lfs12/gma_akey/results/epb330/models/000012-000010.index --> /lfs/lfs12/gma_akey/results/epb330/models/000012-000011.index
[2019-06-18 11:59:50] iteration time 11: 50.099 seconds
2019-06-18 11:59:51.322923: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880790.552914 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 12}}
[2019-06-18 11:59:54] minmax time: 3.243 seconds
2019-06-18 11:59:54.576153: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:59:54.581387: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:59:54.585805: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880794.596540 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 11}}
[2019-06-18 11:59:54] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000013-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000013-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000013-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000013-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000013-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000013-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000013-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000013-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000013-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000013-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000013-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 11:59:54] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-13-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000012-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000012-000011 --seed=13 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000012-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000012-000011 --seed=1023779844 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000012-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000012-000011 --seed=2047559675 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000012-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000012-000011 --seed=3071339506 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000012-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000012-000011 --seed=4095119337 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000012-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000012-000011 --seed=5118899168 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000012-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000012-000011 --seed=6142678999 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000012-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000012-000011 --seed=7166458830 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000012-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000012-000011 --seed=8190238661 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000012-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000012-000011 --seed=9214018492 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000012-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000012-000011 --seed=10237798323 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000012-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000012-000011 --seed=11261578154 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000012-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000012-000011 --seed=12285357985 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000012-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000012-000011 --seed=13309137816 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000012-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000012-000011 --seed=14332917647 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000012-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000012-000011 --seed=15356697478 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000012-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000012-000011 --seed=16380477309 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000012-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000012-000011 --seed=17404257140 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000012-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000012-000011 --seed=18428036971 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000012-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000012-000011 --seed=19451816802 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000012-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000012-000011 --seed=20475596633 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:00:05] eval finished: 10.732 seconds
[2019-06-18 12:00:05] Win rate 000012-000011 vs 000011-000010: 0.370
:::MLL 1560880805.397948 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 11}}
[2019-06-18 12:00:05] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-14-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000013-000010 --seed=14 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000013-000010 --seed=1023779845 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000013-000010 --seed=2047559676 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000013-000010 --seed=3071339507 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000013-000010 --seed=4095119338 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000013-000010 --seed=5118899169 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000013-000010 --seed=6142679000 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000013-000010 --seed=7166458831 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000013-000010 --seed=8190238662 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000013-000010 --seed=9214018493 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000013-000010 --seed=10237798324 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000013-000010 --seed=11261578155 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000013-000010 --seed=12285357986 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000013-000010 --seed=13309137817 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000013-000010 --seed=14332917648 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000013-000010 --seed=15356697479 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000013-000010 --seed=16380477310 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000013-000010 --seed=17404257141 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000013-000010 --seed=18428036972 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:00:35] selfplay finished: 30.357 seconds
[2019-06-18 12:00:35] selfplay mn: 30.374 seconds
[2019-06-18 12:00:35] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-14-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779845 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559676 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339507 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119338 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899169 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142679000 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458831 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238662 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018493 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798324 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578155 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285357986 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137817 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917648 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697479 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477310 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257141 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036972 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816803 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596634 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376465 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156296 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000013-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golde
[2019-06-18 12:00:38] train finished: 43.856 seconds
:::MLL 1560880799.883556 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880799.884298 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880799.884974 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:59.962801 46918642676608 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560880799.876135 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880799.877002 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880799.877870 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:59.962934 47492112937856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 11:59:59.963830 46918642676608 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpb1cdt159
W0618 11:59:59.963895 47492112937856 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp0px9mu79
I0618 11:59:59.964838 46918642676608 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpb1cdt159', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aac619dde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:59.964895 47492112937856 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp0px9mu79', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b31e71bce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:59.965272 46918642676608 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:59.965314 47492112937856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:59.970346 46918642676608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:59.970346 47492112937856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880799.892134 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880799.892884 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880799.893628 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:59.977205 47617117254528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560880799.894150 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880799.894885 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880799.895601 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:59.977265 47754013029248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 11:59:59.978207 47617117254528 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpru9ojk8z
W0618 11:59:59.978239 47754013029248 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpewaust96
I0618 11:59:59.979189 47617117254528 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpru9ojk8z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4f01f24e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:59.979217 47754013029248 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpewaust96', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6ee1920e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:59.979580 47617117254528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:59.979619 47754013029248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:59.984494 47617117254528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:59.984515 47754013029248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880799.892999 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880799.893756 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880799.894546 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:59.986787 47051648631680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560880799.894933 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880799.895691 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880799.896407 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:59.987113 47804673586048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 11:59:59.987833 47051648631680 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpcrpweedv
W0618 11:59:59.988067 47804673586048 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpsm4mebo7
I0618 11:59:59.988836 47051648631680 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpcrpweedv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acb5963be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:59.989078 47804673586048 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpsm4mebo7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7aad2cce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:59:59.989936 46918642676608 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:59.989938 47492112937856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:59:59.989238 47051648631680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:59.989526 47804673586048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:59.994221 47051648631680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:59.994423 47804673586048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880799.909651 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880799.910388 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880799.911108 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:59.996826 47015725671296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560880799.907304 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880799.908015 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880799.908727 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:59.996987 47241326252928 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 11:59:59.997837 47015725671296 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpds_1zvxj
W0618 11:59:59.997971 47241326252928 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpi76fcy5o
I0618 11:59:59.998817 47015725671296 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpds_1zvxj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac2fc36fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:59.998966 47241326252928 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpi76fcy5o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af7830eae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:59.999228 47015725671296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:59.999373 47241326252928 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:00.004070 47754013029248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:00.004173 47617117254528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:00.004072 47015725671296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:00.004266 47241326252928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:00.013783 47051648631680 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:00.014485 47804673586048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880799.965004 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880799.965438 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880799.965805 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:00.022242 47828212806528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560880799.967050 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880799.967471 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880799.967847 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:00.023433 47508633895808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 12:00:00.023249 47828212806528 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpzqkd5mll
I0618 12:00:00.024217 47828212806528 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpzqkd5mll', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b802838ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:00.024621 47828212806528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:00.024348 47508633895808 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp7m4i58gy
I0618 12:00:00.025300 47508633895808 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp7m4i58gy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b35bfd59e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:00.025685 47508633895808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:00.023734 47015725671296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:00.024401 47241326252928 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880799.967116 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880799.967519 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880799.968045 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:00.024971 47540315816832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560880799.968245 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880799.968618 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880799.968955 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:00.025155 47618409112448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560880799.943850 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880799.944628 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880799.945329 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:00.025701 47843787969408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560880799.942081 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880799.942788 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880799.943601 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:00.025744 47040579036032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 12:00:00.026074 47540315816832 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpafj2qpuf
W0618 12:00:00.026151 47618409112448 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp17c7s8at
I0618 12:00:00.027050 47540315816832 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpafj2qpuf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3d20395e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:00.027114 47618409112448 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp17c7s8at', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4f4ef27e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:00:00.026844 47843787969408 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpl0d3s_ej
W0618 12:00:00.026876 47040579036032 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpl08v6tyt
I0618 12:00:00.027441 47540315816832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:00.027503 47618409112448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:00.027958 47843787969408 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpl0d3s_ej', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b83c892ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:00.027966 47040579036032 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpl08v6tyt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac8c5973e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:00:00.029281 47828212806528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:00:00.028403 47040579036032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:00.028410 47843787969408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:00.030268 47508633895808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880799.971929 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880799.972445 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880799.972884 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:00.029023 47317926462336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 12:00:00.030080 47317926462336 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp9unlya01
I0618 12:00:00.031105 47317926462336 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp9unlya01', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0958c91e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:00:00.032250 47540315816832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:00:00.031506 47317926462336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:00.032291 47618409112448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:00.033812 47843787969408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:00.033827 47040579036032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880799.976421 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880799.976881 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880799.977269 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:00.032673 47820447249280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_0_0
I0618 12:00:00.033666 47820447249280 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb330/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7e595bbd30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:00.034773 47820447249280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:00.036199 47317926462336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:00.037853 47492112937856 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:00.038217 46918642676608 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:00.039288 47820447249280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:00.042149 47492112937856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:00.042534 46918642676608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:00.048640 47828212806528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:00:00.047218 47492112937856 estimator.py:1111] Calling model_fn.
W0618 12:00:00.047324 47492112937856 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:00:00.047639 46918642676608 estimator.py:1111] Calling model_fn.
W0618 12:00:00.047752 46918642676608 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:00:00.049445 47508633895808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:00.048675 47492112937856 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560880799.989376 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880799.989871 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880799.990317 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:00.048491 47914003809152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 12:00:00.049127 46918642676608 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560880799.993151 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880799.993580 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880799.993969 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:00.049565 47934616077184 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 12:00:00.049500 47914003809152 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpe_hp5gli
W0618 12:00:00.052129 47754013029248 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:00.052136 47617117254528 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:00:00.050472 47914003809152 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpe_hp5gli', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9421c38e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:00.050871 47914003809152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:00.050516 47934616077184 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp97756i9m
W0618 12:00:00.051591 47540315816832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:00.051829 47618409112448 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:00:00.051469 47934616077184 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp97756i9m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b98ee59de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:00.051863 47934616077184 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:00.056467 47754013029248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:00.056437 47617117254528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:00.056075 47040579036032 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:00.056174 47843787969408 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:00.055512 47914003809152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:00.055584 47317926462336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:00.056442 47934616077184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:00.058611 47820447249280 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:00:00.061520 47617117254528 estimator.py:1111] Calling model_fn.
I0618 12:00:00.061592 47754013029248 estimator.py:1111] Calling model_fn.
W0618 12:00:00.061631 47617117254528 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:00:00.061699 47754013029248 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:00:00.062976 47617117254528 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:00:00.063054 47754013029248 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:00:00.061000 47051648631680 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:00.061547 47804673586048 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:00.065272 47051648631680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:00.065829 47804673586048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:00:00.070322 47051648631680 estimator.py:1111] Calling model_fn.
W0618 12:00:00.070439 47051648631680 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:00:00.070893 47804673586048 estimator.py:1111] Calling model_fn.
W0618 12:00:00.071001 47804673586048 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:00:00.071459 47015725671296 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:00.072154 47241326252928 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:00.071787 47051648631680 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:00:00.072329 47804673586048 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:00:00.074911 47914003809152 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:00.075725 47934616077184 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:00.075743 47015725671296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:00.076425 47241326252928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880799.982910 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880799.983707 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880799.984396 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:00.079764 47595805045632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560880799.980356 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880799.981114 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880799.981861 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:00.080211 47613871080320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560880800.024385 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880800.024782 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880800.025123 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:00.081372 47033582498688 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560880800.023896 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880800.024304 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880800.024641 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:00.081447 47122272191360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000003-000001.tfrecord.zz_0_0
I0618 12:00:00.080829 47015725671296 estimator.py:1111] Calling model_fn.
W0618 12:00:00.080941 47015725671296 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:00:00.081485 47241326252928 estimator.py:1111] Calling model_fn.
W0618 12:00:00.081593 47241326252928 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:00:00.080935 47595805045632 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpzr788iwo
W0618 12:00:00.081269 47613871080320 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpuq7nmiy5
I0618 12:00:00.082099 47595805045632 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpzr788iwo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4a0ba3cdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:00:00.082350 47033582498688 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpv8332qid
W0618 12:00:00.082296 47015725671296 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:00:00.082355 47613871080320 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpuq7nmiy5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4e40759e48>, '_task_type': 'worker', '_task_id': 0,[2019-06-18 12:00:39] divide_golden_chunk finished: 3.366 seconds
[2019-06-18 12:00:39] generate golden chunk: 3.380 seconds
[2019-06-18 12:00:39] iteration time 12: 48.601 seconds
2019-06-18 12:00:39.995653: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880839.153600 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 13}}
[2019-06-18 12:00:43] minmax time: 3.236 seconds
2019-06-18 12:00:43.241997: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:00:43.247473: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:00:43.252076: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880843.264649 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 12}}
[2019-06-18 12:00:43] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000014-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000014-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000014-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000014-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000014-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000014-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000014-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000014-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000014-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000014-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000014-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:00:43] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-14-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000013-000011 --seed=14 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000013-000011 --seed=1023779845 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000013-000011 --seed=2047559676 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000013-000011 --seed=3071339507 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000013-000011 --seed=4095119338 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000013-000011 --seed=5118899169 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000013-000011 --seed=6142679000 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000013-000011 --seed=7166458831 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000013-000011 --seed=8190238662 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000013-000011 --seed=9214018493 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000013-000011 --seed=10237798324 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000013-000011 --seed=11261578155 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000013-000011 --seed=12285357986 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000013-000011 --seed=13309137817 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000013-000011 --seed=14332917648 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000013-000011 --seed=15356697479 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000013-000011 --seed=16380477310 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000013-000011 --seed=17404257141 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000013-000011 --seed=18428036972 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000013-000011 --seed=19451816803 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000013-000011 --seed=20475596634 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:00:53] eval finished: 10.638 seconds
[2019-06-18 12:00:53] Win rate 000013-000011 vs 000011-000010: 0.490
:::MLL 1560880853.971606 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 12}}
[2019-06-18 12:00:53] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-15-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000014-000010 --seed=15 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000014-000010 --seed=1023779846 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000014-000010 --seed=2047559677 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000014-000010 --seed=3071339508 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000014-000010 --seed=4095119339 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000014-000010 --seed=5118899170 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000014-000010 --seed=6142679001 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000014-000010 --seed=7166458832 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000014-000010 --seed=8190238663 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000014-000010 --seed=9214018494 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000014-000010 --seed=10237798325 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000014-000010 --seed=11261578156 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000014-000010 --seed=12285357987 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000014-000010 --seed=13309137818 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000014-000010 --seed=14332917649 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000014-000010 --seed=15356697480 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000014-000010 --seed=16380477311 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000014-000010 --seed=17404257142 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000014-000010 --seed=18428036973 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:01:24] selfplay finished: 30.559 seconds
[2019-06-18 12:01:24] selfplay mn: 30.577 seconds
[2019-06-18 12:01:24] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-15-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779846 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559677 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339508 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119339 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899170 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142679001 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458832 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238663 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018494 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798325 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578156 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285357987 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137818 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917649 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697480 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477311 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257142 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036973 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816804 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596635 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376466 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156297 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000014-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golde
[2019-06-18 12:01:26] train finished: 43.584 seconds
:::MLL 1560880848.511694 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880848.512550 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880848.513313 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:48.598876 47276649923456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_0_0
:::MLL 1560880848.515972 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880848.516683 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880848.517349 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:48.598902 47829401944960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_0_0
W0618 12:00:48.599925 47276649923456 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpbnbdqijf
W0618 12:00:48.599954 47829401944960 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp7wvd9ye_
I0618 12:00:48.600998 47276649923456 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpbnbdqijf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2affbc831e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:48.601000 47829401944960 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp7wvd9ye_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b806f198e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:48.601426 47276649923456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:48.601425 47829401944960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:48.606540 47829401944960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:48.606552 47276649923456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:48.626397 47829401944960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:48.626539 47276649923456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880848.564294 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880848.565207 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880848.566060 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:48.650799 47424035550080 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_0_0
:::MLL 1560880848.568652 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880848.569390 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880848.570076 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:48.650982 47683999339392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_0_0
W0618 12:00:48.651818 47424035550080 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp7gt3jrhj
W0618 12:00:48.651944 47683999339392 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpa7k03r5m
I0618 12:00:48.652827 47424035550080 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp7gt3jrhj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b220d614e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:48.652981 47683999339392 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpa7k03r5m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5e946dee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:48.653259 47424035550080 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:48.653430 47683999339392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:48.658552 47424035550080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:48.658721 47683999339392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880848.598291 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880848.598658 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880848.598981 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:48.661059 47202503627648 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_0_0
:::MLL 1560880848.596981 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880848.597415 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880848.597734 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:48.661123 47360941491072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_0_0
W0618 12:00:48.662041 47202503627648 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpwpx2zuvn
W0618 12:00:48.662087 47360941491072 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpcq23xm3u
I0618 12:00:48.663009 47202503627648 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpwpx2zuvn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aee790c5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:48.663069 47360941491072 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpcq23xm3u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b135cae5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:48.663403 47202503627648 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:48.663457 47360941491072 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:48.668051 47202503627648 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:48.668113 47360941491072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880848.567827 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880848.568712 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880848.569534 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:48.671674 47416965051264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_0_0
:::MLL 1560880848.568920 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880848.569781 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880848.570488 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:48.671819 47743165047680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_0_0
:::MLL 1560880848.590831 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880848.591569 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880848.592284 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:48.673539 47179735073664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_0_0
W0618 12:00:48.672691 47416965051264 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpg525tqnc
:::MLL 1560880848.588832 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880848.589594 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880848.590376 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:48.673722 47770328552320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_0_0
W0618 12:00:48.672815 47743165047680 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp4awd0dwr
I0618 12:00:48.673699 47416965051264 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpg525tqnc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2067f20dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:48.673796 47743165047680 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp4awd0dwr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6c5afaedd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:00:48.674781 47829401944960 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:00:48.674101 47416965051264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:48.674189 47743165047680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:48.675134 47276649923456 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:48.674529 47179735073664 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpl59qqauy
W0618 12:00:48.674704 47770328552320 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp6n_k_5op
I0618 12:00:48.675512 47179735073664 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpl59qqauy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae92befddd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:48.675691 47770328552320 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp6n_k_5op', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b72ae0d2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:48.675909 47179735073664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:48.676090 47770328552320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:48.679099 47829401944960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:48.679462 47276649923456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:48.678951 47743165047680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:48.679136 47416965051264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:48.680794 47424035550080 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:48.680872 47683999339392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:48.680785 47179735073664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:48.680866 47770328552320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:00:48.684128 47829401944960 estimator.py:1111] Calling model_fn.
W0618 12:00:48.684236 47829401944960 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:00:48.684541 47276649923456 estimator.py:1111] Calling model_fn.
W0618 12:00:48.684652 47276649923456 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:00:48.685599 47829401944960 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:00:48.686020 47276649923456 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:00:48.687294 47202503627648 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:48.687616 47360941491072 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880848.617120 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880848.617916 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880848.618668 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:48.695982 47657571541888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_0_0
:::MLL 1560880848.602902 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880848.603834 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880848.604715 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:48.696325 47634179330944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_0_0
W0618 12:00:48.697079 47657571541888 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpaegoclia
W0618 12:00:48.697354 47634179330944 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp2lbx0p9k
I0618 12:00:48.698102 47657571541888 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpaegoclia', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b586d35be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:48.698356 47634179330944 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp2lbx0p9k', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b52faecee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:48.698515 47657571541888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:48.698757 47634179330944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880848.626034 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880848.626846 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880848.627595 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:48.697333 47802787087232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_0_0
:::MLL 1560880848.612245 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880848.613214 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880848.614115 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:48.697400 47348679594880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_0_0
W0618 12:00:48.698453 47802787087232 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmphmww9n3f
W0618 12:00:48.698485 47348679594880 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpmz39pf3o
W0618 12:00:48.699006 47743165047680 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:00:48.699585 47802787087232 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmphmww9n3f', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7a3cbb1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:48.699585 47348679594880 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpmz39pf3o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1081d0ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:00:48.699299 47416965051264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:00:48.700026 47802787087232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:48.700030 47348679594880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:48.700542 47179735073664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:48.700659 47770328552320 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:48.703283 47657571541888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:48.703501 47634179330944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:48.705404 47802787087232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:48.705414 47348679594880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880848.649556 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880848.649935 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880848.650310 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:48.709900 47166277297024 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_0_0
:::MLL 1560880848.650440 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880848.650816 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880848.651142 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:48.710148 47942408803200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_0_0
:::MLL 1560880848.632404 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880848.632864 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880848.633259 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:48.709824 47998797394816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_0_0
:::MLL 1560880848.629130 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880848.629653 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880848.630055 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:48.709818 47192244614016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_0_0
W0618 12:00:48.710961 47166277297024 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpjqgbcbge
W0618 12:00:48.711160 47942408803200 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpz_wndx0h
I0618 12:00:48.711938 47166277297024 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpjqgbcbge', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae609ca7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:48.712132 47942408803200 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpz_wndx0h', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9abed56da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:48.712341 47166277297024 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:48.712524 47942408803200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:48.710793 47192244614016 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp5nuj62y6
I0618 12:00:48.710909 47998797394816 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb330/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba7dfdafd30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:48.711776 47192244614016 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp5nuj62y6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aec15904e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:48.712035 47998797394816 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:48.712168 47192244614016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:48.716955 47166277297024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:48.717077 47942408803200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:48.716701 47998797394816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:48.716790 47192244614016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:48.723188 47657571541888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:48.723501 47634179330944 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880848.667171 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880848.667623 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880848.668027 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:48.726737 47590303826816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_0_0
:::MLL 1560880848.667973 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880848.668403 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880848.668772 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:48.727210 47440241251200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_0_0
W0618 12:00:48.727748 47802787087232 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:48.727823 47348679594880 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:48.727739 47590303826816 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp00bhx7m6
I0618 12:00:48.728708 47590303826816 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp00bhx7m6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b48c3bdddd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:00:48.728159 47440241251200 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpy7uk__aq
I0618 12:00:48.729108 47590303826816 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:48.729119 47440241251200 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpy7uk__aq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b25d350ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:48.729510 47440241251200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:48.730418 47424035550080 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:48.730566 47683999339392 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:48.733847 47590303826816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:48.734723 47424035550080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:48.734093 47440241251200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:48.734862 47683999339392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:48.734679 47202503627648 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:48.735404 47360941491072 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:48.736296 47166277297024 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:48.736342 47942408803200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:48.735944 47998797394816 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:48.736202 47192244614016 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:48.738989 47202503627648 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:00:48.739773 47424035550080 estimator.py:1111] Calling model_fn.
W0618 12:00:48.739883 47424035550080 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:00:48.739886 47683999339392 estimator.py:1111] Calling model_fn.
W0618 12:00:48.739993 47683999339392 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:00:48.739753 47360941491072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:48.741240 47424035550080 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:00:48.741352 47683999339392 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:00:48.744019 47202503627648 estimator.py:1111] Calling model_fn.
W0618 12:00:48.744124 47202503627648 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:00:48.744858 47360941491072 estimator.py:1111] Calling model_fn.
W0618 12:00:48.744970 47360941491072 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:00:48.745486 47202503627648 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:00:48.746336 47360941491072 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560880848.688838 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880848.689291 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880848.689748 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:48.749011 47937134449536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_0_0
:::MLL 1560880848.689241 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880848.689763 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880848.690118 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:48.749241 47926916428672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_0_0
W0618 12:00:48.747082 47416965051264 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:48.747149 47743165047680 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:48.748542 47179735073664 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880848.689540 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880848.689922 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880848.690246 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:48.748486 47462240162688 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_0_0
:::MLL 1560880848.690816 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880848.691188 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880848.691669 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:48.748723 47073322304384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000004-000002.tfrecord.zz_0_0
W0618 12:00:48.750026 47937134449536 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpi6a673sf
W0618 12:00:48.748971 47770328552320 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:48.750212 47926916428672 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpgd10wmz8
I0618 12:00:48.750995 47937134449536 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpi6a673sf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9984752e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:48.751193 47926916428672 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpgd10wmz8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b97236a7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:48.751394 47937134449536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:48.751589 47926916428672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:48.749475 47462240162688 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp5t5lo2bo
W0618 12:00:48.749699 47073322304384 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp0t_qmckh
I0618 12:00:48.750442 47462240162688 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp5t5lo2bo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2af28d6dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:48.750658 47073322304384 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp0t_qmckh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad0653dddd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:48.750838 47462240162688 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:48.751047 47073322304384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:48.751397 47416965051264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:48.751502 47743165047680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:48.752847 47179735073664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:48.753333 47770328552320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for .[2019-06-18 12:01:27] divide_golden_chunk finished: 3.443 seconds
[2019-06-18 12:01:28] generate golden chunk: 3.458 seconds
[2019-06-18 12:01:28] moving /lfs/lfs12/gma_akey/results/epb330/models/000014-000011.meta --> /lfs/lfs12/gma_akey/results/epb330/models/000014-000012.meta
[2019-06-18 12:01:28] moving /lfs/lfs12/gma_akey/results/epb330/models/000014-000011.pb --> /lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb
[2019-06-18 12:01:28] moving /lfs/lfs12/gma_akey/results/epb330/models/000014-000011.index --> /lfs/lfs12/gma_akey/results/epb330/models/000014-000012.index
[2019-06-18 12:01:28] moving /lfs/lfs12/gma_akey/results/epb330/models/000014-000011.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb330/models/000014-000012.data-00000-of-00001
[2019-06-18 12:01:28] iteration time 13: 48.901 seconds
2019-06-18 12:01:28.934247: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880888.054327 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 14}}
[2019-06-18 12:01:32] minmax time: 3.275 seconds
2019-06-18 12:01:32.219825: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:01:32.225319: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:01:32.229915: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880892.240782 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 13}}
[2019-06-18 12:01:32] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000015-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000015-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000015-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000015-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000015-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000015-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000015-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000015-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000015-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000015-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000015-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:01:32] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-15-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000014-000012 --seed=15 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000014-000012 --seed=1023779846 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000014-000012 --seed=2047559677 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000014-000012 --seed=3071339508 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000014-000012 --seed=4095119339 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000014-000012 --seed=5118899170 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000014-000012 --seed=6142679001 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000014-000012 --seed=7166458832 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000014-000012 --seed=8190238663 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000014-000012 --seed=9214018494 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000014-000012 --seed=10237798325 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000014-000012 --seed=11261578156 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000014-000012 --seed=12285357987 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000014-000012 --seed=13309137818 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000014-000012 --seed=14332917649 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000014-000012 --seed=15356697480 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000014-000012 --seed=16380477311 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000014-000012 --seed=17404257142 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000014-000012 --seed=18428036973 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000014-000012 --seed=19451816804 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000014-000012 --seed=20475596635 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:01:44] eval finished: 11.836 seconds
[2019-06-18 12:01:44] Win rate 000014-000012 vs 000013-000011: 0.780
:::MLL 1560880904.146753 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 13}}
[2019-06-18 12:01:44] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-16-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000015-000011 --seed=16 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000015-000011 --seed=1023779847 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000015-000011 --seed=2047559678 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000015-000011 --seed=3071339509 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000015-000011 --seed=4095119340 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000015-000011 --seed=5118899171 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000015-000011 --seed=6142679002 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000015-000011 --seed=7166458833 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000015-000011 --seed=8190238664 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000015-000011 --seed=9214018495 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000015-000011 --seed=10237798326 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000015-000011 --seed=11261578157 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000015-000011 --seed=12285357988 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000015-000011 --seed=13309137819 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000015-000011 --seed=14332917650 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000015-000011 --seed=15356697481 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000015-000011 --seed=16380477312 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000015-000011 --seed=17404257143 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000015-000011 --seed=18428036974 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:02:14] selfplay finished: 30.201 seconds
[2019-06-18 12:02:14] selfplay mn: 30.218 seconds
[2019-06-18 12:02:14] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-16-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779847 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559678 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339509 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119340 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899171 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142679002 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458833 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238664 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018495 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798326 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578157 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285357988 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137819 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917650 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697481 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477312 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257143 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036974 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816805 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596636 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376467 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156298 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000015-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golde
[2019-06-18 12:02:15] train finished: 43.441 seconds
:::MLL 1560880897.529281 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880897.529997 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880897.530746 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:37.614496 47993839354752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_0_0
:::MLL 1560880897.512858 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880897.513795 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880897.514654 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:37.615673 47428548125568 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_0_0
W0618 12:01:37.615581 47993839354752 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpp_pdgkyk
I0618 12:01:37.616647 47993839354752 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpp_pdgkyk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba6b8554e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:37.617083 47993839354752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:37.616709 47428548125568 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp3hb8d75k
I0618 12:01:37.617760 47428548125568 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp3hb8d75k', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b231a59be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:37.618174 47428548125568 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:37.622183 47993839354752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:37.623064 47428548125568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880897.540420 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880897.541181 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880897.541882 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:37.627527 47622428124032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_0_0
:::MLL 1560880897.532760 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880897.533678 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880897.534526 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:37.627798 47888333390720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_0_0
:::MLL 1560880897.516140 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880897.516882 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880897.517602 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:37.627646 47587774616448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_0_0
:::MLL 1560880897.518109 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880897.518833 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880897.519525 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:37.627709 47770682344320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_0_0
W0618 12:01:37.628642 47622428124032 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpmzsqj788
W0618 12:01:37.628889 47888333390720 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpplz88rsu
I0618 12:01:37.629739 47622428124032 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpmzsqj788', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b503e7fbda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:01:37.628709 47587774616448 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpcz8h2ro8
W0618 12:01:37.628750 47770682344320 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpzix1kics
I0618 12:01:37.630026 47888333390720 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpplz88rsu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8e27b01e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:37.629820 47587774616448 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpcz8h2ro8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b482cfd1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:37.630191 47622428124032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:01:37.629856 47770682344320 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpzix1kics', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b72c3238e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:37.630509 47888333390720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:01:37.630263 47587774616448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:01:37.630298 47770682344320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:37.635388 47622428124032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:37.635425 47587774616448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:37.635425 47770682344320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:37.635873 47888333390720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:37.641868 47993839354752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:37.642626 47428548125568 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880897.554137 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880897.554980 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880897.555828 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:37.645632 47494880699264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_0_0
:::MLL 1560880897.554288 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880897.555181 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880897.556001 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:37.645823 47657063670656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_0_0
W0618 12:01:37.646637 47494880699264 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp7jgw9tw9
W0618 12:01:37.646767 47657063670656 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp259cr0in
I0618 12:01:37.647640 47494880699264 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp7jgw9tw9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b328c147e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:37.647752 47657063670656 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp259cr0in', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b584ef03e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:37.648043 47494880699264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:01:37.648145 47657063670656 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:37.652976 47494880699264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:37.653060 47657063670656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:37.655253 47770682344320 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:37.655335 47587774616448 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:37.657486 47622428124032 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:37.658422 47888333390720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880897.557590 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880897.558507 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880897.559383 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:37.664968 46929909080960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_0_0
:::MLL 1560880897.558362 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880897.559279 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880897.560005 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:37.665031 47529626874752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_0_0
W0618 12:01:37.666095 47529626874752 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp_ir9upnb
:::MLL 1560880897.580307 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880897.580845 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880897.581319 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:37.665295 47266645009280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_0_0
W0618 12:01:37.666070 46929909080960 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpr0fknwu3
I0618 12:01:37.667050 46929909080960 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpr0fknwu3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aaf0125be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:37.667075 47529626874752 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp_ir9upnb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3aa31d0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:37.667446 46929909080960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880897.586884 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880897.587344 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880897.587758 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:37.665896 47714605130624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_0_0
I0618 12:01:37.667483 47529626874752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:37.666335 47266645009280 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpqphtwzee
I0618 12:01:37.667319 47266645009280 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpqphtwzee', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afd682c3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:01:37.666877 47714605130624 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp09u0b9p8
I0618 12:01:37.667715 47266645009280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:01:37.667852 47714605130624 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp09u0b9p8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b65b4ad2dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880897.602291 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880897.602961 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880897.603385 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:37.667008 47111831335808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_0_0
:::MLL 1560880897.602280 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880897.602979 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880897.603407 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:37.667131 47569920512896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_0_0
I0618 12:01:37.668247 47714605130624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:01:37.668062 47111831335808 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb330/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad95c8efd30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:01:37.668143 47569920512896 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp9_8g4cw3
I0618 12:01:37.669123 47569920512896 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp9_8g4cw3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4404cd1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:37.669170 47111831335808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:01:37.669521 47569920512896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:37.672357 47529626874752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:37.672380 46929909080960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:37.672443 47266645009280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:37.672777 47714605130624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:37.672576 47494880699264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:37.672648 47657063670656 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:37.673884 47111831335808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:37.674183 47569920512896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880897.600830 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880897.601576 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880897.602339 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:37.675238 47607511298944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_0_0
:::MLL 1560880897.587105 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880897.588029 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880897.588936 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:37.675740 47474647810944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_0_0
W0618 12:01:37.676269 47607511298944 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp0835s8n1
:::MLL 1560880897.616829 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880897.617218 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880897.617542 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:37.677526 47226709394304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_0_0
:::MLL 1560880897.615337 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880897.615721 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880897.616051 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:37.677521 47704980796288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_0_0
I0618 12:01:37.677253 47607511298944 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp0835s8n1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4cc562fdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:01:37.676718 47474647810944 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpqxff23h_
I0618 12:01:37.677647 47607511298944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:01:37.677713 47474647810944 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpqxff23h_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2dd61b1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:37.678118 47474647810944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:37.678541 47226709394304 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpp4s_ns4k
W0618 12:01:37.678513 47704980796288 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpyog4x71z
I0618 12:01:37.679498 47226709394304 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpp4s_ns4k', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af41bd31e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:37.679500 47704980796288 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpyog4x71z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6377058da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:37.679886 47226709394304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:01:37.679894 47704980796288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:37.682751 47607511298944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:37.683328 47474647810944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:37.684616 47226709394304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:37.684677 47704980796288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:37.692154 47529626874752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:37.692358 46929909080960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:37.690358 47428548125568 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:01:37.690472 47993839354752 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:01:37.691856 47266645009280 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:37.692118 47714605130624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:37.693375 47111831335808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:37.693470 47569920512896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:37.694671 47428548125568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:01:37.694813 47993839354752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880897.635736 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880897.636183 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880897.636534 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:37.698266 47431900627840 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_0_0
:::MLL 1560880897.637971 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880897.638381 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880897.638740 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:37.699731 46920241881984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_0_0
W0618 12:01:37.699261 47431900627840 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpogisck39
I0618 12:01:37.699736 47428548125568 estimator.py:1111] Calling model_fn.
I0618 12:01:37.700241 47431900627840 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpogisck39', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b23e22cde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:01:37.699843 47428548125568 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:01:37.699918 47993839354752 estimator.py:1111] Calling model_fn.
W0618 12:01:37.700031 47993839354752 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:01:37.700635 47431900627840 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:37.700673 46920241881984 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpibn3z819
W0618 12:01:37.701205 47428548125568 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:01:37.701654 46920241881984 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpibn3z819', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aacc0efedd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:01:37.701413 47993839354752 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:01:37.702048 46920241881984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:37.703174 47770682344320 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:01:37.703434 47587774616448 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:01:37.703928 47226709394304 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:37.704060 47704980796288 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880897.631847 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880897.632385 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880897.632828 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:37.706245 47997116228480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_0_0
:::MLL 1560880897.630376 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880897.630891 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880897.631283 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:37.706243 47900506428288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000005-000003.tfrecord.zz_0_0
W0618 12:01:37.704819 47607511298944 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:37.705305 47431900627840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:37.706155 47474647810944 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:37.707318 47997116228480 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpvr47rk34
W0618 12:01:37.707288 47900506428288 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpncxrqnll
I0618 12:01:37.708253 47900506428288 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpncxrqnll', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b90fd41de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:37.708286 47997116228480 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpvr47rk34', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba77ba67e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:01:37.706552 46920241881984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:01:37.708651 47900506428288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:01:37.708687 47997116228480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:37.707468 47770682344320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:01:37.707739 47587774616448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:01:37.709035 47622428124032 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:01:37.709451 47888333390720 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:01:37.713371 47900506428288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:37.713416 47997116228480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:01:37.712480 47770682344320 estimator.py:1111] Calling model_fn.
W0618 12:01:37.712589 47770682344320 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:01:37.712749 47587774616448 estimator.py:1111] Calling model_fn.
W0618 12:01:37.712862 47587774616448 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:01:37.713662 47622428124032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:01:37.714063 47888333390720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:01:37.713950 47770682344320 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:01:37.714222 47587774616448 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:01:37.719132 47622428124032 estimator.py:1111] Calling model_fn.
W0618 12:01:37.719248 47622428124032 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:01:37.719499 47888333390720 estimator.py:1111] Calling model_fn.
W0618 12:01:37.719614 47888333390720 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:01:37.720705 47622428124032 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:01:37.721057 47888333390720 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for [2019-06-18 12:02:17] divide_golden_chunk finished: 3.255 seconds
[2019-06-18 12:02:17] generate golden chunk: 3.270 seconds
[2019-06-18 12:02:17] moving /lfs/lfs12/gma_akey/results/epb330/models/000015-000012.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb330/models/000015-000013.data-00000-of-00001
[2019-06-18 12:02:17] moving /lfs/lfs12/gma_akey/results/epb330/models/000015-000012.pb --> /lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb
[2019-06-18 12:02:17] moving /lfs/lfs12/gma_akey/results/epb330/models/000015-000012.meta --> /lfs/lfs12/gma_akey/results/epb330/models/000015-000013.meta
[2019-06-18 12:02:17] moving /lfs/lfs12/gma_akey/results/epb330/models/000015-000012.index --> /lfs/lfs12/gma_akey/results/epb330/models/000015-000013.index
[2019-06-18 12:02:17] iteration time 14: 49.623 seconds
2019-06-18 12:02:18.605716: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880937.677468 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 15}}
[2019-06-18 12:02:21] minmax time: 3.247 seconds
2019-06-18 12:02:21.862480: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:02:21.867874: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:02:21.872275: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880941.882807 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 14}}
[2019-06-18 12:02:21] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000016-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000016-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000016-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000016-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000016-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000016-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000016-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000016-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000016-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000016-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000016-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:02:21] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-16-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000015-000013 --seed=16 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000015-000013 --seed=1023779847 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000015-000013 --seed=2047559678 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000015-000013 --seed=3071339509 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000015-000013 --seed=4095119340 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000015-000013 --seed=5118899171 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000015-000013 --seed=6142679002 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000015-000013 --seed=7166458833 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000015-000013 --seed=8190238664 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000015-000013 --seed=9214018495 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000015-000013 --seed=10237798326 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000015-000013 --seed=11261578157 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000015-000013 --seed=12285357988 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000015-000013 --seed=13309137819 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000015-000013 --seed=14332917650 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000015-000013 --seed=15356697481 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000015-000013 --seed=16380477312 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000015-000013 --seed=17404257143 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000015-000013 --seed=18428036974 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000015-000013 --seed=19451816805 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000015-000013 --seed=20475596636 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:02:32] eval finished: 10.939 seconds
[2019-06-18 12:02:32] Win rate 000015-000013 vs 000014-000012: 0.720
:::MLL 1560880952.893110 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 14}}
[2019-06-18 12:02:32] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-17-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000016-000012 --seed=17 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000016-000012 --seed=1023779848 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000016-000012 --seed=2047559679 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000016-000012 --seed=3071339510 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000016-000012 --seed=4095119341 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000016-000012 --seed=5118899172 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000016-000012 --seed=6142679003 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000016-000012 --seed=7166458834 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000016-000012 --seed=8190238665 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000016-000012 --seed=9214018496 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000016-000012 --seed=10237798327 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000016-000012 --seed=11261578158 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000016-000012 --seed=12285357989 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000016-000012 --seed=13309137820 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000016-000012 --seed=14332917651 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000016-000012 --seed=15356697482 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000016-000012 --seed=16380477313 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000016-000012 --seed=17404257144 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000016-000012 --seed=18428036975 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:03:03] selfplay finished: 30.553 seconds
[2019-06-18 12:03:03] selfplay mn: 30.571 seconds
[2019-06-18 12:03:03] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-17-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779848 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559679 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339510 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119341 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899172 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142679003 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458834 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238665 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018496 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798327 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578158 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285357989 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137820 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917651 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697482 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477313 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257144 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036975 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816806 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596637 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376468 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156299 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000016-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golde
[2019-06-18 12:03:05] train finished: 43.775 seconds
:::MLL 1560880947.177299 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880947.178169 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880947.178916 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:27.264306 47222457840512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_0_0
:::MLL 1560880947.181453 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880947.182209 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880947.182895 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:27.264497 47195299373952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_0_0
W0618 12:02:27.265403 47222457840512 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpmyo9tg8z
W0618 12:02:27.265539 47195299373952 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmppwr2aphm
I0618 12:02:27.266466 47222457840512 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpmyo9tg8z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af31e697e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:27.266613 47195299373952 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmppwr2aphm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeccba40e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:27.266891 47222457840512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:02:27.267009 47195299373952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:27.271703 47195299373952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:27.271715 47222457840512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:27.291369 47222457840512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:27.291383 47195299373952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880947.213797 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880947.214530 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880947.215202 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:27.303636 47809748132736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_0_0
:::MLL 1560880947.209547 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880947.210440 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880947.211172 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:27.303784 47857851208576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_0_0
W0618 12:02:27.304722 47809748132736 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp8d4rl684
W0618 12:02:27.304779 47857851208576 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp721of2z9
I0618 12:02:27.305790 47809748132736 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp8d4rl684', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7bdba43e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:27.305824 47857851208576 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp721of2z9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b870eceee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:27.306188 47809748132736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:02:27.306211 47857851208576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880947.207972 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880947.208862 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880947.209697 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:27.303819 47881739752320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_0_0
:::MLL 1560880947.215290 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880947.216057 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880947.216801 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:27.304098 47924310856576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_0_0
W0618 12:02:27.304829 47881739752320 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpht0d5ej3
W0618 12:02:27.305094 47924310856576 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpq1n5jv7b
I0618 12:02:27.305826 47881739752320 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpht0d5ej3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8c9ead2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:27.306105 47924310856576 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpq1n5jv7b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b96881cae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:27.306226 47881739752320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:02:27.306504 47924310856576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:27.310872 47809748132736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:27.310875 47857851208576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:27.310926 47881739752320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:27.311159 47924310856576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880947.230647 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880947.231406 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880947.232113 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:27.313369 47433519281024 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_0_0
:::MLL 1560880947.221281 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880947.222220 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880947.223017 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:27.313411 47095763624832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_0_0
W0618 12:02:27.314583 47095763624832 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp54rtwrks
W0618 12:02:27.314615 47433519281024 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp_8w8icye
I0618 12:02:27.315709 47095763624832 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp54rtwrks', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad59ed93e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:27.315736 47433519281024 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp_8w8icye', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2442a78da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880947.223279 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880947.224100 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880947.224807 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:27.315011 47593791538048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_0_0
:::MLL 1560880947.221970 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880947.222828 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880947.223606 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:27.315061 47966077371264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_0_0
I0618 12:02:27.316140 47095763624832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:02:27.316173 47433519281024 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880947.219462 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880947.220233 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880947.220894 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:27.316104 47996489888640 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_0_0
:::MLL 1560880947.217932 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880947.218673 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880947.219513 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:27.316108 47525780571008 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_0_0
W0618 12:02:27.316081 47593791538048 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpt78th9eq
W0618 12:02:27.316115 47966077371264 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp_ai5ysuw
I0618 12:02:27.317163 47593791538048 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpt78th9eq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4993a01e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:27.317184 47966077371264 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp_ai5ysuw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba041971e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:27.317556 47593791538048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:02:27.317573 47966077371264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:27.317196 47996489888640 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpqki5x0ht
W0618 12:02:27.317233 47525780571008 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmppayqqqld
I0618 12:02:27.318309 47996489888640 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpqki5x0ht', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba756514e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:27.318325 47525780571008 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmppayqqqld', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b39bddb1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:27.318757 47996489888640 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:02:27.318767 47525780571008 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:27.321533 47095763624832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:27.321574 47433519281024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:27.322565 47966077371264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:27.322578 47593791538048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:27.324005 47996489888640 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:27.324108 47525780571008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880947.262339 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880947.262754 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880947.263224 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:27.326548 47228193543040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_0_0
:::MLL 1560880947.261506 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880947.261946 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880947.262351 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:27.326644 47775395726208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_0_0
W0618 12:02:27.327545 47228193543040 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpdp9w1q51
W0618 12:02:27.327632 47775395726208 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpirxnai75
I0618 12:02:27.328527 47228193543040 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpdp9w1q51', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af474496e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:27.328618 47775395726208 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpirxnai75', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b73dc141dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:27.328927 47228193543040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:02:27.329025 47775395726208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:27.330301 47857851208576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:27.330368 47809748132736 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:27.330139 47881739752320 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:27.330639 47924310856576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:27.333565 47775395726208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:27.333565 47228193543040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:27.339557 47222457840512 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:02:27.339727 47195299373952 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:02:27.342105 47966077371264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:27.342120 47593791538048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:27.343538 47095763624832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:27.343881 47433519281024 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:27.343851 47222457840512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:02:27.344021 47195299373952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:02:27.346175 47525780571008 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:27.346342 47996489888640 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:02:27.348906 47222457840512 estimator.py:1111] Calling model_fn.
W0618 12:02:27.349014 47222457840512 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:02:27.349074 47195299373952 estimator.py:1111] Calling model_fn.
W0618 12:02:27.349186 47195299373952 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:02:27.350389 47222457840512 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:02:27.350550 47195299373952 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:02:27.352746 47228193543040 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:27.352781 47775395726208 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880947.294976 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880947.295393 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880947.295747 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:27.360609 47970455491456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_0_0
:::MLL 1560880947.293414 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880947.293816 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880947.294174 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:27.360661 47298158887808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_0_0
W0618 12:02:27.361612 47970455491456 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp6idinnrz
W0618 12:02:27.361641 47298158887808 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp1f7qmh8y
I0618 12:02:27.362604 47970455491456 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp6idinnrz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba1468bee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:27.362618 47298158887808 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp1f7qmh8y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b04be8bde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:27.363003 47970455491456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:02:27.363014 47298158887808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880947.297860 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880947.298282 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880947.298654 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:27.364427 47910283883392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_0_0
:::MLL 1560880947.299599 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880947.300009 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880947.300357 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:27.365015 46983519691648 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_0_0
I0618 12:02:27.365463 47910283883392 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb330/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b93440a0d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880947.304375 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880947.304895 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880947.305283 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:27.368393 47252513227648 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_0_0
I0618 12:02:27.366568 47910283883392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:27.366024 46983519691648 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpzmrpou36
I0618 12:02:27.366997 46983519691648 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpzmrpou36', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abb7c96be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880947.305550 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880947.306008 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880947.306339 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:27.369135 47042763035520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_0_0
W0618 12:02:27.367655 47970455491456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:27.367665 47298158887808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:02:27.367391 46983519691648 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:27.369400 47252513227648 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpckkmqx2l
I0618 12:02:27.370388 47252513227648 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpckkmqx2l', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afa1dda5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880947.306684 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880947.307182 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880947.307603 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:27.368638 47255875105664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_0_0
I0618 12:02:27.370801 47252513227648 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:27.370117 47042763035520 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp5puwkeum
I0618 12:02:27.371098 47042763035520 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp5puwkeum', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac947c43e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:27.371503 47042763035520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:27.369706 47255875105664 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp9vafhove
I0618 12:02:27.370720 47255875105664 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp9vafhove', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afae63c8dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:27.371108 47255875105664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:27.371208 47910283883392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:27.371886 46983519691648 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880947.308823 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880947.309277 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880947.309648 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:27.372913 47552073704320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_0_0
W0618 12:02:27.375388 47252513227648 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:27.373898 47552073704320 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp0up5jdzb
:::MLL 1560880947.313426 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880947.313870 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880947.314269 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:27.373868 47497029907328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_0_0
:::MLL 1560880947.312823 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880947.313298 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880947.313700 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:27.374721 47491353858944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000006-000004.tfrecord.zz_0_0
I0618 12:02:27.374895 47552073704320 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp0up5jdzb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3fdd0c7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:02:27.376042 47042763035520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:02:27.375300 47552073704320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:27.374814 47497029907328 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp75s7gq4h
W0618 12:02:27.375693 47491353858944 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpk0fdjivq
I0618 12:02:27.375787 47497029907328 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp75s7gq4h', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b330c2ebe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:02:27.375789 47255875105664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:02:27.376669 47491353858944 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpk0fdjivq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b31b9dd2e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:27.376188 47497029907328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:02:27.377066 47491353858944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:27.378115 47857851208576 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:02:27.378561 47809748132736 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:02:27.377938 47881739752320 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:02:27.378428 47924310856576 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:02:27.379901 47552073704320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:27.382408 47857851208576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:02:27.380809 47497029907328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:27.381642 47491353858944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:27.382893 47809748132736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:02:27.382227 47881739752320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:02:27.382757 47924310856576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:02:27.387451 47857851208576 estimator.py:1111] Calling model_fn.
W0618 12:02:27.387560 47857851208576 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:02:27.387969 47809748132736 estimator.py:1111] Calling model_fn.
W0618 12:02:27.388078 47809748132736 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) i[2019-06-18 12:03:06] divide_golden_chunk finished: 3.351 seconds
[2019-06-18 12:03:06] generate golden chunk: 3.365 seconds
[2019-06-18 12:03:06] moving /lfs/lfs12/gma_akey/results/epb330/models/000016-000013.meta --> /lfs/lfs12/gma_akey/results/epb330/models/000016-000014.meta
[2019-06-18 12:03:06] moving /lfs/lfs12/gma_akey/results/epb330/models/000016-000013.index --> /lfs/lfs12/gma_akey/results/epb330/models/000016-000014.index
[2019-06-18 12:03:06] moving /lfs/lfs12/gma_akey/results/epb330/models/000016-000013.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb330/models/000016-000014.data-00000-of-00001
[2019-06-18 12:03:06] moving /lfs/lfs12/gma_akey/results/epb330/models/000016-000013.pb --> /lfs/lfs12/gma_akey/results/epb330/models/000016-000014.pb
[2019-06-18 12:03:06] iteration time 15: 49.201 seconds
2019-06-18 12:03:07.812334: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880986.878295 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 16}}
[2019-06-18 12:03:11] minmax time: 3.230 seconds
2019-06-18 12:03:11.051441: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:03:11.056789: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:03:11.061314: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880991.071625 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 15}}
[2019-06-18 12:03:11] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000017-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000017-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000017-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000017-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000017-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000017-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000017-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000017-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000017-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000017-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000017-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:03:11] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-17-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000016-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000016-000014 --seed=17 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000016-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000016-000014 --seed=1023779848 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000016-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000016-000014 --seed=2047559679 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000016-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000016-000014 --seed=3071339510 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000016-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000016-000014 --seed=4095119341 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000016-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000016-000014 --seed=5118899172 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000016-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000016-000014 --seed=6142679003 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000016-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000016-000014 --seed=7166458834 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000016-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000016-000014 --seed=8190238665 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000016-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000016-000014 --seed=9214018496 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000016-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000016-000014 --seed=10237798327 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000016-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000016-000014 --seed=11261578158 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000016-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000016-000014 --seed=12285357989 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000016-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000016-000014 --seed=13309137820 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000016-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000016-000014 --seed=14332917651 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000016-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000016-000014 --seed=15356697482 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000016-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000016-000014 --seed=16380477313 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000016-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000016-000014 --seed=17404257144 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000016-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000016-000014 --seed=18428036975 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000016-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000016-000014 --seed=19451816806 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000016-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000016-000014 --seed=20475596637 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:03:21] eval finished: 10.672 seconds
[2019-06-18 12:03:21] Win rate 000016-000014 vs 000015-000013: 0.470
:::MLL 1560881001.812634 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 15}}
[2019-06-18 12:03:21] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-18-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000017-000013 --seed=18 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000017-000013 --seed=1023779849 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000017-000013 --seed=2047559680 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000017-000013 --seed=3071339511 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000017-000013 --seed=4095119342 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000017-000013 --seed=5118899173 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000017-000013 --seed=6142679004 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000017-000013 --seed=7166458835 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000017-000013 --seed=8190238666 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000017-000013 --seed=9214018497 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000017-000013 --seed=10237798328 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000017-000013 --seed=11261578159 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000017-000013 --seed=12285357990 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000017-000013 --seed=13309137821 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000017-000013 --seed=14332917652 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000017-000013 --seed=15356697483 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000017-000013 --seed=16380477314 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000017-000013 --seed=17404257145 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000017-000013 --seed=18428036976 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:03:51] selfplay finished: 30.072 seconds
[2019-06-18 12:03:51] selfplay mn: 30.091 seconds
[2019-06-18 12:03:51] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-18-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779849 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559680 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339511 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119342 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899173 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142679004 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458835 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238666 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018497 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798328 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578159 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285357990 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137821 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917652 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697483 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477314 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257145 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036976 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816807 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596638 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376469 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156300 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000017-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golde
[2019-06-18 12:03:55] train finished: 44.150 seconds
:::MLL 1560880996.363195 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880996.363923 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880996.364562 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:16.453582 47298502824832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_0_0
:::MLL 1560880996.356431 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880996.357319 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880996.358158 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:16.453557 47347825468288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_0_0
W0618 12:03:16.454566 47298502824832 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp3xj2i55h
W0618 12:03:16.454597 47347825468288 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpboqthts6
I0618 12:03:16.455557 47298502824832 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp3xj2i55h', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b04d30bde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:16.455576 47347825468288 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpboqthts6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b104ee7be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:16.455959 47298502824832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:16.455976 47347825468288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:16.460786 47347825468288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:16.460807 47298502824832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880996.382643 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880996.383558 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880996.384469 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:16.478660 47733960643456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_0_0
:::MLL 1560880996.387962 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880996.388719 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880996.389422 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:16.478802 47266929292160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_0_0
W0618 12:03:16.480088 47298502824832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:16.480194 47347825468288 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:16.479786 47733960643456 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp208ttsoy
W0618 12:03:16.479871 47266929292160 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp5_vwhvak
I0618 12:03:16.480861 47733960643456 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp208ttsoy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6a365aee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:16.480967 47266929292160 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp5_vwhvak', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afd791e0e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:16.481310 47733960643456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:16.481424 47266929292160 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:16.486521 47733960643456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:16.486605 47266929292160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880996.427562 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880996.428287 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880996.428999 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:16.508706 47503857083264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_0_0
:::MLL 1560880996.407620 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880996.408572 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880996.409481 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:16.508776 47991853495168 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_0_0
W0618 12:03:16.508426 47733960643456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880996.413288 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880996.414072 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880996.414796 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:16.507361 46958001312640 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_0_0
:::MLL 1560880996.399327 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880996.400213 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880996.401088 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:16.507566 47082819629952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_0_0
W0618 12:03:16.508887 47266929292160 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:16.509775 47503857083264 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpl4fbbjr6
W0618 12:03:16.509803 47991853495168 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp_4z_zfo8
I0618 12:03:16.510800 47503857083264 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpl4fbbjr6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b34a31d2dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:16.510873 47991853495168 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp_4z_zfo8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba641f78e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880996.442070 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880996.442486 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880996.442841 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:16.509382 47869501535104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_0_0
:::MLL 1560880996.443493 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880996.443907 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880996.444258 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:16.509553 47797451678592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_0_0
I0618 12:03:16.511216 47503857083264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:16.511298 47991853495168 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:16.508402 46958001312640 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpqbsyrbsl
W0618 12:03:16.508558 47082819629952 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp8soe9vex
I0618 12:03:16.509419 46958001312640 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpqbsyrbsl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab58b931e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880996.404866 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880996.405611 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880996.406278 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:16.509701 47590744830848 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_0_0
I0618 12:03:16.509541 47082819629952 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp8soe9vex', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad29b538dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880996.403236 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880996.403990 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880996.404793 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:16.509928 47569175511936 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_0_0
I0618 12:03:16.509829 46958001312640 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:16.509941 47082819629952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:16.510400 47869501535104 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpwennkouq
W0618 12:03:16.510542 47797451678592 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp0mauao82
I0618 12:03:16.511374 47869501535104 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpwennkouq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b89c538be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:16.511507 47797451678592 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp0mauao82', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b78feb73e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:16.511773 47869501535104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:16.511900 47797451678592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:16.510834 47590744830848 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpicwp6t1j
W0618 12:03:16.511047 47569175511936 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpyia743c8
I0618 12:03:16.511934 47590744830848 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpicwp6t1j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b48de06fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:16.512159 47569175511936 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpyia743c8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b43d8655dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:16.512387 47590744830848 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:16.512614 47569175511936 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:16.515984 47991853495168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:16.515994 47503857083264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:16.514732 47082819629952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:16.514751 46958001312640 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:16.516323 47869501535104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:16.516492 47797451678592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:16.517679 47590744830848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:16.517934 47569175511936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880996.414283 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880996.415171 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880996.416009 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:16.527280 47468260365184 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_0_0
W0618 12:03:16.528177 47298502824832 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880996.415277 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880996.416173 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880996.416849 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:16.527766 46976436061056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_0_0
W0618 12:03:16.528308 47347825468288 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:03:16.528296 47468260365184 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpha5haf28
I0618 12:03:16.529277 47468260365184 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpha5haf28', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2c59625dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:03:16.528774 46976436061056 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpcujj43vc
I0618 12:03:16.529672 47468260365184 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:16.529782 46976436061056 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpcujj43vc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab9d65f0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:16.530193 46976436061056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:16.532473 47298502824832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:03:16.532604 47347825468288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:03:16.535485 47503857083264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:16.535572 47991853495168 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880996.468204 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880996.468680 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880996.469014 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:16.534961 47457206727552 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_0_0
:::MLL 1560880996.468799 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880996.469193 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880996.469511 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:16.535001 47247186817920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_0_0
W0618 12:03:16.534525 47468260365184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:16.534183 46958001312640 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:16.534199 47082819629952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:16.535053 46976436061056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:16.535376 47869501535104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:16.535717 47797451678592 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:16.536062 47457206727552 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp462feg5e
W0618 12:03:16.536090 47247186817920 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmptzus2nk8
I0618 12:03:16.537070 47457206727552 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp462feg5e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b29c6894e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:16.537083 47247186817920 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmptzus2nk8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af8e05fce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:16.537471 47457206727552 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:16.537480 47247186817920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:16.537534 47298502824832 estimator.py:1111] Calling model_fn.
W0618 12:03:16.537643 47298502824832 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:03:16.537623 47347825468288 estimator.py:1111] Calling model_fn.
W0618 12:03:16.537733 47347825468288 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:03:16.539015 47298502824832 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:03:16.539095 47347825468288 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:03:16.539973 47590744830848 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:16.540555 47569175511936 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:16.542127 47457206727552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:16.542119 47247186817920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:16.553874 47468260365184 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880996.475586 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880996.476047 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880996.476475 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:16.553993 47872650462080 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_0_0
:::MLL 1560880996.475533 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880996.475990 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880996.476417 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:16.554063 47069216494464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_0_0
W0618 12:03:16.554680 46976436061056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:16.554996 47872650462080 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpqcebyzf8
W0618 12:03:16.555038 47069216494464 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpvs10z0to
I0618 12:03:16.555979 47872650462080 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpqcebyzf8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8a80e98e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:16.556019 47069216494464 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpvs10z0to', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acf70842e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:16.556387 47872650462080 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:16.556427 47069216494464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880996.475562 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880996.476063 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880996.476562 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:16.555954 47166869443456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_0_0
:::MLL 1560880996.476765 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880996.477249 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880996.477678 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:16.556000 47852516291456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_0_0
I0618 12:03:16.556994 47852516291456 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb330/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b85d0d28d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:03:16.556965 47166869443456 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp9gd_g0qc
I0618 12:03:16.557928 47166869443456 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp9gd_g0qc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae62d15de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:16.558110 47852516291456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:16.558319 47166869443456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:16.560438 47733960643456 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:03:16.560593 47266929292160 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:03:16.561191 47457206727552 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:16.561285 47247186817920 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:16.561110 47872650462080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:16.561124 47069216494464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880996.496217 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880996.496660 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880996.497040 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:16.563035 47805857788800 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_0_0
:::MLL 1560880996.498101 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880996.498537 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880996.498901 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:16.564032 47985619465088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_0_0
W0618 12:03:16.564064 47805857788800 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpew_bnd6g
W0618 12:03:16.562786 47852516291456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:16.562850 47166869443456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:03:16.565052 47805857788800 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpew_bnd6g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7af3c24e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:16.565450 47805857788800 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:16.565008 47985619465088 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp7gqi3o3k
I0618 12:03:16.565979 47985619465088 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp7gqi3o3k', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba4ce63ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:03:16.565073 47733960643456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:03:16.565203 47266929292160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:03:16.566377 47985619465088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:16.570053 47805857788800 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:16.570844 47985619465088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:03:16.570526 47733960643456 estimator.py:1111] Calling model_fn.
W0618 12:03:16.570639 47733960643456 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:03:16.570659 47266929292160 estimator.py:1111] Calling model_fn.
W0618 12:03:16.570771 47266929292160 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560880996.485760 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880996.486208 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880996.486584 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:16.571103 47019879121792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_0_0
:::MLL 1560880996.482974 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880996.483442 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880996.483832 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:16.571167 47450387420032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000007-000004.tfrecord.zz_0_0
W0618 12:03:16.572102 47733960643456 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:03:16.572241 47266929292160 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:03:16.572112 47019879121792 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpev8u6l46
W0618 12:03:16.572160 47450387420032 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp03puv7wy
I0618 12:03:16.573101 47019879121792 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpev8u6l46', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac3f3c79e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:16.573133 47450387420032 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp03puv7wy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b283012de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:16.573494 47019879121792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:16.573520 47450387420032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:16.578097 47019879121792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:16.578108 47450387420032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:16.580260 47872650462080 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:16.580454 47069216494464 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:16.583604 47991853495168 deprecation.py:323] From .[2019-06-18 12:03:55] divide_golden_chunk finished: 3.427 seconds
[2019-06-18 12:03:55] generate golden chunk: 3.441 seconds
[2019-06-18 12:03:55] iteration time 16: 48.468 seconds
2019-06-18 12:03:56.323968: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
Got 343572 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000009.tfrecord.zz: 13.656 seconds
Got 377723 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000004.tfrecord.zz: 0.312 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000004.tfrecord.zz: 15.987 seconds
Got 380569 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000005.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000005.tfrecord.zz: 14.825 seconds
Got 347010 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000006.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000006.tfrecord.zz: 11.699 seconds
Got 391566 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000000.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000000.tfrecord.zz: 14.278 seconds
Got 383377 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000002.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000002.tfrecord.zz: 13.368 seconds
Got 348127 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000007.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000007.tfrecord.zz: 13.196 seconds
Got 346341 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000008.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000008.tfrecord.zz: 13.564 seconds
Got 389066 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000003.tfrecord.zz: 0.309 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000003.tfrecord.zz: 13.435 seconds
Got 387780 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000001.tfrecord.zz: 0.317 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000000-000001.tfrecord.zz: 15.319 seconds
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/checkpoint_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/checkpointlog.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000001-000001_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000001-000001log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000002-000002_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000002-000002log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000003-000003_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000003-000003log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000004-000004_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000004-000004log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000005-000005_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000005-000005log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000006-000005_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000006-000005log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000007-000006_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000007-000006log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000008-000007_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000008-000007log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000009-000008_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000009-000008log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000010-000009_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000010-000009log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000011-000010_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000011-000010log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000012-000011_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000012-000011log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000013-000011_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000013-000011log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000014-000012_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000014-000012log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000015-000013_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000015-000013log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000016-000014_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000016-000014log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000017-000014_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000017-000014log.txt['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881035.346396 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 17}}
[2019-06-18 12:03:59] minmax time: 3.252 seconds
2019-06-18 12:03:59.585978: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:03:59.591364: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:03:59.596117: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881039.608540 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 16}}
[2019-06-18 12:03:59] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000018-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000018-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000018-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000018-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000018-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000018-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000018-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000018-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000018-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000018-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000018-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:03:59] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-18-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000017-000014 --seed=18 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000017-000014 --seed=1023779849 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000017-000014 --seed=2047559680 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000017-000014 --seed=3071339511 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000017-000014 --seed=4095119342 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000017-000014 --seed=5118899173 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000017-000014 --seed=6142679004 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000017-000014 --seed=7166458835 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000017-000014 --seed=8190238666 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000017-000014 --seed=9214018497 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000017-000014 --seed=10237798328 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000017-000014 --seed=11261578159 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000017-000014 --seed=12285357990 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000017-000014 --seed=13309137821 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000017-000014 --seed=14332917652 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000017-000014 --seed=15356697483 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000017-000014 --seed=16380477314 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000017-000014 --seed=17404257145 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000017-000014 --seed=18428036976 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000017-000014 --seed=19451816807 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000017-000014 --seed=20475596638 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:04:10] eval finished: 10.426 seconds
[2019-06-18 12:04:10] Win rate 000017-000014 vs 000015-000013: 0.770
:::MLL 1560881050.106372 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 16}}
[2019-06-18 12:04:10] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-19-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000018-000013 --seed=19 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000018-000013 --seed=1023779850 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000018-000013 --seed=2047559681 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000018-000013 --seed=3071339512 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000018-000013 --seed=4095119343 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000018-000013 --seed=5118899174 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000018-000013 --seed=6142679005 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000018-000013 --seed=7166458836 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000018-000013 --seed=8190238667 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000018-000013 --seed=9214018498 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000018-000013 --seed=10237798329 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000018-000013 --seed=11261578160 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000018-000013 --seed=12285357991 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000018-000013 --seed=13309137822 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000018-000013 --seed=14332917653 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000018-000013 --seed=15356697484 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000018-000013 --seed=16380477315 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000018-000013 --seed=17404257146 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000018-000013 --seed=18428036977 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:04:39] selfplay finished: 29.197 seconds
[2019-06-18 12:04:39] selfplay mn: 29.218 seconds
[2019-06-18 12:04:39] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-19-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779850 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559681 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339512 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119343 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899174 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142679005 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458836 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238667 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018498 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798329 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578160 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285357991 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137822 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917653 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697484 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477315 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257146 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036977 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816808 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596639 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376470 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156301 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000018-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golde
[2019-06-18 12:04:42] divide_golden_chunk finished: 3.329 seconds
[2019-06-18 12:04:42] generate golden chunk: 3.344 seconds
[2019-06-18 12:04:43] train finished: 43.757 seconds
:::MLL 1560881044.901557 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881044.902292 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881044.902968 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:04.984258 47141279433600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_0_0
:::MLL 1560881044.888445 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881044.889320 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881044.890166 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:04.984272 47806785176448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_0_0
W0618 12:04:04.985313 47141279433600 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmptvvvu92j
W0618 12:04:04.985345 47806785176448 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpveng6ej3
I0618 12:04:04.986310 47141279433600 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmptvvvu92j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae037cd4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:04.986339 47806785176448 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpveng6ej3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7b2b08fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:04.986714 47141279433600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:04.986742 47806785176448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:04.991598 47141279433600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:04.991612 47806785176448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881044.894714 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881044.895591 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881044.896398 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:04.998572 47677013279616 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_0_0
:::MLL 1560881044.908173 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881044.908857 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881044.909549 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:04.998794 48009773228928 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_0_0
W0618 12:04:04.999605 47677013279616 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpvvn1cgb3
W0618 12:04:04.999766 48009773228928 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp2tguy04q
I0618 12:04:05.000597 47677013279616 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpvvn1cgb3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5cf4071e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:05.000773 48009773228928 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp2tguy04q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2baa6e10edd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:05.000997 47677013279616 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:05.001169 48009773228928 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:05.005925 47677013279616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:05.006078 48009773228928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:05.010820 47141279433600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:05.016496 47806785176448 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:05.024920 47677013279616 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:05.025604 48009773228928 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881044.940580 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881044.941352 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881044.942042 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:05.036102 47008922166144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_0_0
:::MLL 1560881044.943199 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881044.943956 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881044.944652 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:05.036109 47836680229760 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_0_0
W0618 12:04:05.037178 47008922166144 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpdo0uk66l
W0618 12:04:05.037202 47836680229760 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp0fkadc3f
I0618 12:04:05.038184 47008922166144 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpdo0uk66l', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac166b1be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:05.038201 47836680229760 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp0fkadc3f', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8220eb5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:05.038585 47008922166144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:05.038600 47836680229760 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:05.043662 47008922166144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:05.043724 47836680229760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881044.978501 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881044.978924 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881044.979327 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:05.047824 47364104721280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_0_0
:::MLL 1560881044.980000 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881044.980420 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881044.980778 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:05.048054 47433771336576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_0_0
W0618 12:04:05.048850 47364104721280 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpm3br1x08
W0618 12:04:05.049018 47433771336576 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp7vc7l22c
I0618 12:04:05.049819 47364104721280 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpm3br1x08', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1419396e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:05.050029 47433771336576 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp7vc7l22c', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2451ad9dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881044.963853 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881044.964403 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881044.964867 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:05.049049 47225653764992 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_0_0
I0618 12:04:05.050211 47364104721280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881044.969941 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881044.970431 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881044.970856 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:05.049244 47566490370944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_0_0
I0618 12:04:05.050430 47433771336576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881044.946274 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881044.947168 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881044.948012 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:05.051127 47870218507136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_0_0
:::MLL 1560881044.954936 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881044.955730 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881044.956428 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:05.051398 47027072549760 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_0_0
W0618 12:04:05.050085 47225653764992 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp267bac2s
I0618 12:04:05.050271 47566490370944 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb330/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4338594d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:05.051081 47225653764992 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp267bac2s', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af3dce77e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:05.051388 47566490370944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:05.051483 47225653764992 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:05.052281 47870218507136 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmppa938nl3
W0618 12:04:05.052528 47027072549760 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmps9bj4ebd
I0618 12:04:05.053414 47870218507136 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmppa938nl3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b89eff4ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:05.053687 47027072549760 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmps9bj4ebd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac5a08a8e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:05.053875 47870218507136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:05.054180 47027072549760 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:05.054858 47364104721280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:05.055016 47433771336576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:05.056124 47566490370944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:05.056147 47225653764992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:05.059244 47870218507136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:05.059456 47027072549760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:05.059363 47141279433600 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881044.959989 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881044.960967 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881044.961815 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:05.061449 47829394969472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_0_0
:::MLL 1560881044.977269 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881044.978004 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881044.978685 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:05.061693 47685426930560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_0_0
W0618 12:04:05.062460 47829394969472 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpw7171zcl
W0618 12:04:05.062684 47685426930560 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpqh2g925_
I0618 12:04:05.063523 47829394969472 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpw7171zcl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b806eaf2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:05.063778 47685426930560 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpqh2g925_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5ee9852dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:05.063981 47829394969472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:05.064216 47685426930560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:05.063028 47008922166144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:05.063137 47836680229760 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:05.063685 47141279433600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:04:05.064956 47806785176448 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:04:05.068812 47829394969472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:05.068902 47685426930560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:04:05.068786 47141279433600 estimator.py:1111] Calling model_fn.
W0618 12:04:05.068905 47141279433600 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:04:05.069293 47806785176448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:04:05.070261 47141279433600 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:04:05.072518 47677013279616 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:04:05.073887 47364104721280 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:05.073259 48009773228928 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:04:05.074279 47433771336576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:04:05.074447 47806785176448 estimator.py:1111] Calling model_fn.
W0618 12:04:05.074562 47806785176448 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:04:05.075952 47806785176448 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:04:05.075308 47566490370944 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:05.075531 47225653764992 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:05.076836 47677013279616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:04:05.077564 48009773228928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:04:05.081245 47870218507136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:05.081750 47027072549760 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:04:05.082135 47677013279616 estimator.py:1111] Calling model_fn.
W0618 12:04:05.082244 47677013279616 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:04:05.082849 48009773228928 estimator.py:1111] Calling model_fn.
W0618 12:04:05.082958 48009773228928 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:04:05.083595 47677013279616 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:04:05.084314 48009773228928 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:04:05.087846 47829394969472 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:05.088194 47685426930560 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881044.992852 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881044.993596 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881044.994422 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:05.087897 47397967328128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_0_0
:::MLL 1560881044.994696 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881044.995412 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881044.996097 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:05.087999 47009409966976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_0_0
W0618 12:04:05.089010 47397967328128 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpcigvt0ys
W0618 12:04:05.089083 47009409966976 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp_vrxaeb_
I0618 12:04:05.090135 47397967328128 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpcigvt0ys', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1bfb97ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:05.090324 47009409966976 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp_vrxaeb_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac183c4edd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881045.020300 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881045.020806 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881045.021237 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:05.090358 46987373982592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_0_0
I0618 12:04:05.090594 47397967328128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:05.090775 47009409966976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:05.091332 46987373982592 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpddwu7yuv
:::MLL 1560881045.023837 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881045.024284 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881045.024670 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:05.092072 47339387794304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_0_0
I0618 12:04:05.092318 46987373982592 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpddwu7yuv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abc62528dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:05.092712 46987373982592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:05.093060 47339387794304 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp0mmc_ff2
I0618 12:04:05.094038 47339387794304 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp0mmc_ff2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0e57fafe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:05.094429 47339387794304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:05.095944 47009409966976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:05.096042 47397967328128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:05.097364 46987373982592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:05.099031 47339387794304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881045.035664 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881045.036047 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881045.036361 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:05.104830 47755110974336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_0_0
:::MLL 1560881045.034947 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881045.035462 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881045.035801 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:05.104845 47557435372416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_0_0
W0618 12:04:05.105839 47755110974336 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpxm_33n46
W0618 12:04:05.105870 47557435372416 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp9vt98rr2
I0618 12:04:05.106829 47755110974336 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpxm_33n46', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6f23034e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:05.106858 47557435372416 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp9vt98rr2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b411ca0ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881045.042375 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881045.042915 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881045.043402 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:05.107756 47474728846208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_0_0
I0618 12:04:05.107229 47755110974336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:05.107259 47557435372416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:05.108794 47474728846208 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp1t7k4kw9
I0618 12:04:05.109794 47474728846208 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp1t7k4kw9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2ddaef9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:05.110186 47474728846208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:05.111864 47755110974336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:05.111938 47557435372416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:05.111622 47836680229760 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:04:05.111730 47008922166144 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:04:05.114951 47474728846208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881045.052387 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881045.052820 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881045.053214 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:05.116307 47923916092288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000008-000005.tfrecord.zz_0_0
W0618 12:04:05.115919 47836680229760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:04:05.116072 47008922166144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:04:05.116324 46987373982592 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:05.117304 47923916092288 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpkntpbmzv
I0618 12:04:05.118283 47923916092288 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpkntpbmzv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9670950dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:05.118690 47923916092288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:05.117624 47009409966976 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:05.118113 47397967328128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:05.118147 47339387794304 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:04:05.120965 47836680229760 estimator.py:1111] Calling model_fn.
W0618 12:04:05.121077 47836680229760 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:04:05.121379 47364104721280 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:04:05.121184 47008922166144 estimator.py:1111] Calling model_fn.
W0618 12:04:05.121295 47008922166144 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:04:05.121967 47433771336576 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function ta[2019-06-18 12:04:43] moving /lfs/lfs12/gma_akey/results/epb330/models/000018-000014.index --> /lfs/lfs12/gma_akey/results/epb330/models/000018-000015.index
[2019-06-18 12:04:43] moving /lfs/lfs12/gma_akey/results/epb330/models/000018-000014.meta --> /lfs/lfs12/gma_akey/results/epb330/models/000018-000015.meta
[2019-06-18 12:04:43] moving /lfs/lfs12/gma_akey/results/epb330/models/000018-000014.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb330/models/000018-000015.data-00000-of-00001
[2019-06-18 12:04:43] moving /lfs/lfs12/gma_akey/results/epb330/models/000018-000014.pb --> /lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb
[2019-06-18 12:04:43] iteration time 17: 48.087 seconds
2019-06-18 12:04:44.454874: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881083.433076 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 18}}
[2019-06-18 12:04:47] minmax time: 3.263 seconds
2019-06-18 12:04:47.727890: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:04:47.733251: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:04:47.737568: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881087.748277 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 17}}
[2019-06-18 12:04:47] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000019-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000019-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000019-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000019-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000019-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000019-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000019-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000019-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000019-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000019-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000019-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:04:47] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-19-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000018-000015 --seed=19 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000018-000015 --seed=1023779850 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000018-000015 --seed=2047559681 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000018-000015 --seed=3071339512 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000018-000015 --seed=4095119343 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000018-000015 --seed=5118899174 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000018-000015 --seed=6142679005 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000018-000015 --seed=7166458836 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000018-000015 --seed=8190238667 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000018-000015 --seed=9214018498 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000018-000015 --seed=10237798329 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000018-000015 --seed=11261578160 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000018-000015 --seed=12285357991 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000018-000015 --seed=13309137822 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000018-000015 --seed=14332917653 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000018-000015 --seed=15356697484 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000018-000015 --seed=16380477315 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000018-000015 --seed=17404257146 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000018-000015 --seed=18428036977 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000018-000015 --seed=19451816808 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000018-000015 --seed=20475596639 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:04:58] eval finished: 10.328 seconds
[2019-06-18 12:04:58] Win rate 000018-000015 vs 000017-000014: 0.570
:::MLL 1560881098.148506 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 17}}
[2019-06-18 12:04:58] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-20-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000019-000014 --seed=20 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000019-000014 --seed=1023779851 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000019-000014 --seed=2047559682 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000019-000014 --seed=3071339513 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000019-000014 --seed=4095119344 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000019-000014 --seed=5118899175 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000019-000014 --seed=6142679006 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000019-000014 --seed=7166458837 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000019-000014 --seed=8190238668 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000019-000014 --seed=9214018499 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000019-000014 --seed=10237798330 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000019-000014 --seed=11261578161 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000019-000014 --seed=12285357992 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000019-000014 --seed=13309137823 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000019-000014 --seed=14332917654 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000019-000014 --seed=15356697485 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000019-000014 --seed=16380477316 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000019-000014 --seed=17404257147 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000019-000014 --seed=18428036978 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:05:28] selfplay finished: 30.240 seconds
[2019-06-18 12:05:28] selfplay mn: 30.259 seconds
[2019-06-18 12:05:28] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-20-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779851 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559682 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339513 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119344 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899175 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142679006 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458837 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238668 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018499 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798330 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578161 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285357992 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137823 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917654 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697485 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477316 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257147 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036978 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816809 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596640 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376471 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156302 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000019-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golde
[2019-06-18 12:05:31] train finished: 43.258 seconds
:::MLL 1560881093.029964 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881093.030694 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881093.031334 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:53.124231 47072682890112 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_0_0
:::MLL 1560881093.024832 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881093.025635 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881093.026454 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:53.124852 46914217837440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_0_0
W0618 12:04:53.125357 47072682890112 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmppbxz4pzt
I0618 12:04:53.126446 47072682890112 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmppbxz4pzt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad03f212dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:04:53.125976 46914217837440 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpz62bmst6
I0618 12:04:53.126844 47072682890112 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:53.126993 46914217837440 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpz62bmst6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aab59e05e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:53.127408 46914217837440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:53.131609 47072682890112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:53.132217 46914217837440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:53.150919 47072682890112 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:53.152082 46914217837440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881093.082446 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881093.083205 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881093.083924 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:53.168615 47184271455104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_0_0
:::MLL 1560881093.068877 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881093.069778 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881093.070601 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:53.168638 47925718426496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_0_0
W0618 12:04:53.169738 47184271455104 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpfnv9__hi
W0618 12:04:53.169770 47925718426496 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp_f4nifqa
I0618 12:04:53.170866 47184271455104 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpfnv9__hi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aea3a537e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:53.170896 47925718426496 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp_f4nifqa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b96dc027e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:53.171266 47184271455104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:53.171290 47925718426496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:53.176071 47184271455104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:53.176074 47925718426496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881093.107275 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881093.107775 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881093.108198 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:53.181308 47908907213696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_0_0
W0618 12:04:53.182344 47908907213696 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp26n2c3fw
I0618 12:04:53.183377 47908907213696 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp26n2c3fw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b92f1fbbe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:53.183807 47908907213696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881093.089968 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881093.090809 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881093.091602 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:53.185807 47825225778048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_0_0
:::MLL 1560881093.089854 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881093.090683 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881093.091447 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:53.185759 47933774381952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_0_0
W0618 12:04:53.186841 47933774381952 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpqom_h12t
W0618 12:04:53.186872 47825225778048 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpk1h3hunf
I0618 12:04:53.187916 47933774381952 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpqom_h12t', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b98bc2e9e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:53.187967 47825225778048 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpk1h3hunf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7f762e5e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:53.188370 47933774381952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:53.188415 47825225778048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:53.188548 47908907213696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881093.111305 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881093.111709 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881093.112061 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:53.189880 47001518330752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_0_0
W0618 12:04:53.190870 47001518330752 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpu00rkqx9
I0618 12:04:53.191852 47001518330752 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpu00rkqx9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abfad642e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:53.192257 47001518330752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:53.193669 47933774381952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:53.193719 47825225778048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:53.195308 47184271455104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:53.195293 47925718426496 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:53.196781 47001518330752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:53.198940 47072682890112 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:04:53.200173 46914217837440 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881093.105951 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881093.106728 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881093.107562 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:53.199576 47295983010688 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_0_0
:::MLL 1560881093.107689 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881093.108505 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881093.109178 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:53.199663 47364553991040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_0_0
W0618 12:04:53.200689 47295983010688 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpjghe58au
W0618 12:04:53.200741 47364553991040 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp0h8m7agf
I0618 12:04:53.201796 47295983010688 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpjghe58au', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b043cda8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:53.201872 47364553991040 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp0h8m7agf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b143400be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:53.202242 47295983010688 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:53.202330 47364553991040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:53.203233 47072682890112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:04:53.204503 46914217837440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:04:53.207657 47908907213696 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:53.207376 47295983010688 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:53.207463 47364553991040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:04:53.208307 47072682890112 estimator.py:1111] Calling model_fn.
W0618 12:04:53.208420 47072682890112 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:04:53.209625 46914217837440 estimator.py:1111] Calling model_fn.
W0618 12:04:53.209735 46914217837440 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:04:53.209784 47072682890112 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:04:53.211108 46914217837440 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560881093.110918 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881093.111820 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881093.112669 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:53.213851 47062504776576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_0_0
:::MLL 1560881093.111103 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881093.111994 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881093.112835 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:53.214607 47098694882176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_0_0
W0618 12:04:53.214993 47062504776576 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpk3skje61
I0618 12:04:53.215983 47062504776576 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpk3skje61', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acde0776e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:04:53.215338 47933774381952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:53.215615 47098694882176 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpsk20vho1
I0618 12:04:53.216384 47062504776576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:53.215493 47825225778048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:04:53.216611 47098694882176 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpsk20vho1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad64d90ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:53.217000 47098694882176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:53.215880 47001518330752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:53.221727 47062504776576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:53.221865 47098694882176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881093.150665 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881093.151149 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881093.151542 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:53.224430 47831261168512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_0_0
:::MLL 1560881093.150201 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881093.150677 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881093.151098 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:53.224471 47205643588480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_0_0
W0618 12:04:53.225464 47205643588480 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpeg21nvk4
I0618 12:04:53.225466 47831261168512 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb330/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b80ddeb1d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:53.226463 47205643588480 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpeg21nvk4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aef34346dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:53.226593 47831261168512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:53.226870 47205643588480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:53.228695 47295983010688 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:53.229589 47364553991040 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:53.231263 47831261168512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:53.231410 47205643588480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881093.161564 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881093.161977 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881093.162345 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:53.234473 46945483924352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_0_0
:::MLL 1560881093.159603 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881093.160022 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881093.160461 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:53.234886 47239936918400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_0_0
W0618 12:04:53.235486 46945483924352 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp7n8pywcn
I0618 12:04:53.236487 46945483924352 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp7n8pywcn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab2a17afe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:04:53.235869 47239936918400 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpj_dt9mn2
I0618 12:04:53.236854 47239936918400 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpj_dt9mn2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af7303f1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:53.236884 46945483924352 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:53.237262 47239936918400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:53.241071 47062504776576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:53.241308 47098694882176 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881093.124585 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881093.125307 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881093.126014 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:53.239678 47167121236864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_0_0
:::MLL 1560881093.121367 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881093.122165 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881093.122810 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:53.239931 47452456682368 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_0_0
W0618 12:04:53.241508 46945483924352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:53.241879 47239936918400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:53.240704 47167121236864 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpe4vh7ieo
W0618 12:04:53.240926 47452456682368 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpx8c4gm8m
I0618 12:04:53.241708 47167121236864 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpe4vh7ieo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae63c17fdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:53.241915 47452456682368 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpx8c4gm8m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b28ab695e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:53.242116 47167121236864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:53.242314 47452456682368 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:53.243357 47184271455104 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:04:53.243445 47925718426496 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:04:53.247339 47452456682368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:53.247350 47167121236864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:53.247691 47184271455104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:04:53.247782 47925718426496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:04:53.250378 47831261168512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:53.250546 47205643588480 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:04:53.252821 47184271455104 estimator.py:1111] Calling model_fn.
I0618 12:04:53.252907 47925718426496 estimator.py:1111] Calling model_fn.
W0618 12:04:53.252930 47184271455104 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:04:53.253014 47925718426496 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:04:53.254310 47184271455104 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:04:53.254385 47925718426496 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560881093.183144 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881093.183525 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881093.183843 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:53.254538 47585982559104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_0_0
:::MLL 1560881093.184350 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881093.184726 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881093.185045 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:53.254702 47022862377856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_0_0
W0618 12:04:53.255559 47908907213696 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:04:53.255542 47585982559104 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp19n_qvuw
W0618 12:04:53.255704 47022862377856 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpmx40lhpg
I0618 12:04:53.256517 47585982559104 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp19n_qvuw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b47c22c7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:53.256683 47022862377856 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpmx40lhpg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac4a5986e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:53.256917 47585982559104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:53.257079 47022862377856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:53.259877 47908907213696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:04:53.260645 46945483924352 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:53.261295 47239936918400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:53.261547 47585982559104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:53.261636 47022862377856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881093.182778 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881093.183343 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881093.183829 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:53.263960 47686657741696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_0_0
W0618 12:04:53.262941 47001518330752 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881093.189690 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881093.190187 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881093.190623 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:53.264163 47961851106176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000009-000006.tfrecord.zz_0_0
W0618 12:04:53.263423 47933774381952 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:04:53.263746 47825225778048 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:04:53.264979 47686657741696 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpod3spvlm
W0618 12:04:53.265131 47961851106176 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpxdc7as29
I0618 12:04:53.265980 47686657741696 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpod3spvlm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5f32e1ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:53.266123 47961851106176 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpxdc7as29', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9f45af5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:53.264993 47908907213696 estimator.py:1111] Calling model_fn.
I0618 12:04:53.266383 47686657741696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:53.265105 47908907213696 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:04:53.266520 47961851106176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:53.266474 47908907213696 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:04:53.266466 47452456682368 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:53.266686 47167121236864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:53.267231 47001518330752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your in[2019-06-18 12:05:31] divide_golden_chunk finished: 3.347 seconds
[2019-06-18 12:05:31] generate golden chunk: 3.361 seconds
[2019-06-18 12:05:31] moving /lfs/lfs12/gma_akey/results/epb330/models/000019-000015.pb --> /lfs/lfs12/gma_akey/results/epb330/models/000019-000016.pb
[2019-06-18 12:05:31] moving /lfs/lfs12/gma_akey/results/epb330/models/000019-000015.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb330/models/000019-000016.data-00000-of-00001
[2019-06-18 12:05:31] moving /lfs/lfs12/gma_akey/results/epb330/models/000019-000015.index --> /lfs/lfs12/gma_akey/results/epb330/models/000019-000016.index
[2019-06-18 12:05:31] moving /lfs/lfs12/gma_akey/results/epb330/models/000019-000015.meta --> /lfs/lfs12/gma_akey/results/epb330/models/000019-000016.meta
[2019-06-18 12:05:31] iteration time 18: 48.377 seconds
2019-06-18 12:05:32.940200: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881131.810473 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 19}}
[2019-06-18 12:05:36] minmax time: 3.274 seconds
2019-06-18 12:05:36.224249: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:05:36.229578: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:05:36.234187: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881136.245227 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 18}}
[2019-06-18 12:05:36] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000020-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000020-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000020-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000020-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000020-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000020-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000020-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000020-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000020-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000020-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000020-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:05:36] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-20-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000019-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000019-000016 --seed=20 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000019-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000019-000016 --seed=1023779851 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000019-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000019-000016 --seed=2047559682 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000019-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000019-000016 --seed=3071339513 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000019-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000019-000016 --seed=4095119344 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000019-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000019-000016 --seed=5118899175 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000019-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000019-000016 --seed=6142679006 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000019-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000019-000016 --seed=7166458837 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000019-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000019-000016 --seed=8190238668 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000019-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000019-000016 --seed=9214018499 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000019-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000019-000016 --seed=10237798330 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000019-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000019-000016 --seed=11261578161 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000019-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000019-000016 --seed=12285357992 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000019-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000019-000016 --seed=13309137823 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000019-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000019-000016 --seed=14332917654 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000019-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000019-000016 --seed=15356697485 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000019-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000019-000016 --seed=16380477316 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000019-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000019-000016 --seed=17404257147 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000019-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000019-000016 --seed=18428036978 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000019-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000019-000016 --seed=19451816809 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000019-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000019-000016 --seed=20475596640 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:05:46] eval finished: 10.671 seconds
[2019-06-18 12:05:46] Win rate 000019-000016 vs 000018-000015: 0.350
:::MLL 1560881146.987475 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 18}}
[2019-06-18 12:05:46] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-21-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000020-000015 --seed=21 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000020-000015 --seed=1023779852 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000020-000015 --seed=2047559683 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000020-000015 --seed=3071339514 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000020-000015 --seed=4095119345 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000020-000015 --seed=5118899176 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000020-000015 --seed=6142679007 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000020-000015 --seed=7166458838 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000020-000015 --seed=8190238669 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000020-000015 --seed=9214018500 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000020-000015 --seed=10237798331 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000020-000015 --seed=11261578162 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000020-000015 --seed=12285357993 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000020-000015 --seed=13309137824 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000020-000015 --seed=14332917655 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000020-000015 --seed=15356697486 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000020-000015 --seed=16380477317 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000020-000015 --seed=17404257148 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000020-000015 --seed=18428036979 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:06:17] selfplay finished: 30.729 seconds
[2019-06-18 12:06:17] selfplay mn: 30.750 seconds
[2019-06-18 12:06:17] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-21-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779852 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559683 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339514 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119345 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899176 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142679007 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458838 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238669 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018500 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798331 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578162 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285357993 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137824 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917655 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697486 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477317 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257148 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036979 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816810 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596641 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376472 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156303 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000020-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golde
[2019-06-18 12:06:19] train finished: 43.215 seconds
:::MLL 1560881141.534143 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881141.534858 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881141.535520 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:41.629880 47509759382400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_0_0
:::MLL 1560881141.530747 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881141.531545 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881141.532228 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:41.629909 47278118253440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_0_0
W0618 12:05:41.630889 47509759382400 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpadxa70x5
W0618 12:05:41.630943 47278118253440 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpuryngo8k
I0618 12:05:41.631986 47509759382400 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpadxa70x5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3602eb0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:41.632086 47278118253440 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpuryngo8k', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0014080e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:41.632415 47509759382400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:05:41.632560 47278118253440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:41.637454 47509759382400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:41.637484 47278118253440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:41.657069 47509759382400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:41.657499 47278118253440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881141.558508 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881141.559389 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881141.560082 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:41.658474 47039392084864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_0_0
:::MLL 1560881141.557836 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881141.558681 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881141.559472 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:41.658541 47956745249664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_0_0
W0618 12:05:41.659549 47039392084864 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmppedkdfd3
W0618 12:05:41.659649 47956745249664 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp37rk_0za
I0618 12:05:41.660653 47039392084864 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmppedkdfd3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac87ed7be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:41.660773 47956745249664 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp37rk_0za', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9e155a3dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:41.661102 47039392084864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:05:41.661238 47956745249664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:41.665917 47039392084864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:41.666002 47956745249664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881141.568055 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881141.568790 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881141.569491 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:41.670531 47685180330880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_0_0
:::MLL 1560881141.565880 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881141.566594 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881141.567322 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:41.670646 47280298255232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_0_0
W0618 12:05:41.671550 47685180330880 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpo7r1aa4w
W0618 12:05:41.671629 47280298255232 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmplv716k0q
I0618 12:05:41.672659 47685180330880 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpo7r1aa4w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5edad24e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:41.672761 47280298255232 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmplv716k0q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0095f83e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:41.673120 47685180330880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:05:41.673219 47280298255232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:41.677940 47280298255232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:41.677948 47685180330880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881141.583491 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881141.584241 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881141.584932 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:41.684386 47027697234816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_0_0
:::MLL 1560881141.585794 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881141.586527 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881141.587223 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:41.684483 47631600509824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_0_0
W0618 12:05:41.685457 47027697234816 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpcytm87jr
W0618 12:05:41.685548 47631600509824 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpt4j52x6k
I0618 12:05:41.686576 47027697234816 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpcytm87jr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac5c5c68e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:41.686662 47631600509824 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpt4j52x6k', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5261372e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:41.687016 47027697234816 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:05:41.687074 47631600509824 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:41.685289 47039392084864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:41.685691 47956745249664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:41.691804 47631600509824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:41.691846 47027697234816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:41.697281 47685180330880 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:41.697268 47280298255232 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881141.606185 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881141.606950 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881141.607671 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:41.703321 47276430001024 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_0_0
:::MLL 1560881141.609215 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881141.609974 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881141.610683 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:41.703544 47036117889920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_0_0
:::MLL 1560881141.609746 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881141.610263 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881141.610722 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:41.703542 47490539746176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_0_0
:::MLL 1560881141.620686 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881141.621064 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881141.621382 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:41.704422 46988954162048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_0_0
W0618 12:05:41.704459 47276430001024 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpsq97674x
W0618 12:05:41.704556 47490539746176 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpwnu419kg
I0618 12:05:41.705571 47276430001024 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpsq97674x', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2affaf675e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:05:41.704623 47036117889920 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpw2_huqp1
I0618 12:05:41.705542 47490539746176 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpwnu419kg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b318956ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:41.705910 47036117889920 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpw2_huqp1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac7bbaf8da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:41.706025 47276430001024 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:05:41.705944 47490539746176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:05:41.706367 47036117889920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:41.705415 46988954162048 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmprr7d93w4
I0618 12:05:41.706395 46988954162048 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmprr7d93w4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abcc0822e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:05:41.706343 47509759382400 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:05:41.706795 46988954162048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:41.707066 47278118253440 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:05:41.711059 47631600509824 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:41.711266 47027697234816 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:41.710587 47490539746176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:41.710644 47509759382400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:05:41.711313 47276430001024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:41.711586 47036117889920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:41.711369 46988954162048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:41.711381 47278118253440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560881141.624468 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881141.624959 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881141.625383 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:41.713302 47464175866752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_0_0
:::MLL 1560881141.618981 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881141.619512 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881141.619996 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:41.713331 47726386389888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_0_0
I0618 12:05:41.715705 47509759382400 estimator.py:1111] Calling model_fn.
W0618 12:05:41.715826 47509759382400 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:05:41.714330 47464175866752 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb330/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2b65eddd30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:05:41.714341 47726386389888 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpozz4bl8t
I0618 12:05:41.715320 47726386389888 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpozz4bl8t', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6872e4ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881141.614936 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881141.615841 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881141.616635 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:41.715467 47819086488448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_0_0
I0618 12:05:41.715445 47464175866752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:05:41.716443 47278118253440 estimator.py:1111] Calling model_fn.
:::MLL 1560881141.614585 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881141.615503 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881141.616318 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:41.715889 47302316594048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_0_0
I0618 12:05:41.715726 47726386389888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:41.716555 47278118253440 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:05:41.717187 47509759382400 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:05:41.716589 47819086488448 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpywtu823v
W0618 12:05:41.717916 47278118253440 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:05:41.717690 47819086488448 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpywtu823v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7e08403dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:05:41.716980 47302316594048 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpm3qer3ka
I0618 12:05:41.718067 47302316594048 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpm3qer3ka', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b05b65d6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:41.718142 47819086488448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:05:41.718513 47302316594048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:41.720108 47464175866752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:41.720374 47726386389888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881141.650593 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881141.651106 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881141.651543 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:41.722299 47068158006144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_0_0
W0618 12:05:41.723444 47819086488448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:41.723693 47302316594048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:41.723364 47068158006144 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpquloc5ad
I0618 12:05:41.724406 47068158006144 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpquloc5ad', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acf316cddd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:41.724846 47068158006144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:41.729656 47490539746176 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881141.659526 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881141.659987 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881141.660383 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:41.729602 47481344058240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_0_0
W0618 12:05:41.729896 47068158006144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:41.730587 46988954162048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:41.730623 47481344058240 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpepdwzief
I0618 12:05:41.731650 47481344058240 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpepdwzief', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2f653badd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:41.732071 47481344058240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:41.733313 47276430001024 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:41.733794 47036117889920 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:41.733265 47956745249664 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:05:41.733668 47039392084864 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881141.659009 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881141.659557 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881141.660046 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:41.736727 47693721064320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_0_0
:::MLL 1560881141.664708 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881141.665133 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881141.665522 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:41.738243 47371144913792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_0_0
W0618 12:05:41.736958 47481344058240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:41.737795 47693721064320 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp38nmm5k5
I0618 12:05:41.738840 47693721064320 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp38nmm5k5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b60d7e39dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:41.739269 47693721064320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:41.737549 47956745249664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:05:41.738002 47039392084864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:05:41.739278 47371144913792 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmplrbfvn42
I0618 12:05:41.740294 47371144913792 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmplrbfvn42', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b15bcda3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:41.740722 47371144913792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:41.739193 47464175866752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:41.739548 47726386389888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:41.744193 47693721064320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:05:41.742577 47956745249664 estimator.py:1111] Calling model_fn.
W0618 12:05:41.742688 47956745249664 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:05:41.743117 47039392084864 estimator.py:1111] Calling model_fn.
W0618 12:05:41.743226 47039392084864 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:05:41.745600 47371144913792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:41.744041 47956745249664 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:05:41.744607 47039392084864 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:05:41.745156 47685180330880 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:05:41.745346 47280298255232 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:05:41.745252 47819086488448 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:41.745930 47302316594048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:41.749440 47685180330880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:05:41.749629 47280298255232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:05:41.750745 47068158006144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:05:41.754490 47685180330880 estimator.py:1111] Calling model_fn.
W0618 12:05:41.754603 47685180330880 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:05:41.754691 47280298255232 estimator.py:1111] Calling model_fn.
W0618 12:05:41.754801 47280298255232 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:05:41.755980 47685180330880 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:05:41.756158 47280298255232 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560881141.683008 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881141.683394 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881141.683721 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:41.756855 47069066843008 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_0_0
:::MLL 1560881141.684757 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881141.685140 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881141.685467 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:41.757221 47546008171392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000010-000007.tfrecord.zz_0_0
W0618 12:05:41.758475 47631600509824 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:05:41.759138 47027697234816 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:05:41.757597 47481344058240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:41.757864 47069066843008 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp2jx40_2u
I0618 12:05:41.758850 47069066843008 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp2jx40_2u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acf6798ada0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:05:41.758205 47546008171392 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpbiph1aaz
I0618 12:05:41.759177 47546008171392 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpbiph1aaz', '_tf_random_seed': None, '_[2019-06-18 12:06:21] divide_golden_chunk finished: 3.351 seconds
[2019-06-18 12:06:21] generate golden chunk: 3.366 seconds
[2019-06-18 12:06:21] iteration time 19: 49.295 seconds
2019-06-18 12:06:22.211790: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881181.105314 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 20}}
[2019-06-18 12:06:25] minmax time: 3.266 seconds
2019-06-18 12:06:25.487091: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:06:25.492433: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:06:25.496863: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881185.509212 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 19}}
[2019-06-18 12:06:25] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000021-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000021-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000021-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000021-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000021-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000021-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000021-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000021-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000021-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000021-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000021-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:06:25] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-21-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000020-000016 --seed=21 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000020-000016 --seed=1023779852 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000020-000016 --seed=2047559683 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000020-000016 --seed=3071339514 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000020-000016 --seed=4095119345 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000020-000016 --seed=5118899176 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000020-000016 --seed=6142679007 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000020-000016 --seed=7166458838 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000020-000016 --seed=8190238669 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000020-000016 --seed=9214018500 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000020-000016 --seed=10237798331 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000020-000016 --seed=11261578162 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000020-000016 --seed=12285357993 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000020-000016 --seed=13309137824 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000020-000016 --seed=14332917655 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000020-000016 --seed=15356697486 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000020-000016 --seed=16380477317 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000020-000016 --seed=17404257148 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000020-000016 --seed=18428036979 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000020-000016 --seed=19451816810 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000018-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000020-000016 --seed=20475596641 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:06:35] eval finished: 10.224 seconds
[2019-06-18 12:06:35] Win rate 000020-000016 vs 000018-000015: 0.560
:::MLL 1560881195.805811 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 19}}
[2019-06-18 12:06:35] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-22-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000021-000015 --seed=22 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000021-000015 --seed=1023779853 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000021-000015 --seed=2047559684 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000021-000015 --seed=3071339515 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000021-000015 --seed=4095119346 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000021-000015 --seed=5118899177 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000021-000015 --seed=6142679008 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000021-000015 --seed=7166458839 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000021-000015 --seed=8190238670 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000021-000015 --seed=9214018501 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000021-000015 --seed=10237798332 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000021-000015 --seed=11261578163 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000021-000015 --seed=12285357994 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000021-000015 --seed=13309137825 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000021-000015 --seed=14332917656 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000021-000015 --seed=15356697487 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000021-000015 --seed=16380477318 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000021-000015 --seed=17404257149 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000021-000015 --seed=18428036980 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:07:05] selfplay finished: 29.327 seconds
[2019-06-18 12:07:05] selfplay mn: 29.347 seconds
[2019-06-18 12:07:05] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-22-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779853 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559684 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339515 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119346 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899177 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142679008 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458839 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238670 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018501 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798332 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578163 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285357994 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137825 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917656 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697487 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477318 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257149 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036980 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816811 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596642 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376473 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156304 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000021-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golde
[2019-06-18 12:07:08] divide_golden_chunk finished: 3.283 seconds
[2019-06-18 12:07:08] generate golden chunk: 3.297 seconds
[2019-06-18 12:07:09] train finished: 43.879 seconds
:::MLL 1560881190.818115 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881190.818830 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881190.819495 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:30.908607 47189942883200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_0_0
:::MLL 1560881190.807664 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881190.808576 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881190.809425 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:30.908694 47269196727168 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_0_0
W0618 12:06:30.909749 47269196727168 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpba36ig4j
W0618 12:06:30.909718 47189942883200 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmple8rk35p
I0618 12:06:30.910839 47269196727168 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpba36ig4j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afe00445e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:30.910861 47189942883200 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmple8rk35p', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeb8c5eae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:30.911283 47269196727168 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:30.911318 47189942883200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:30.916079 47269196727168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:30.916181 47189942883200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:30.935374 47269196727168 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:30.936608 47189942883200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881190.843199 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881190.843931 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881190.844641 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:30.940715 47884533306240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_0_0
:::MLL 1560881190.837647 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881190.838559 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881190.839445 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:30.941610 47884110865280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_0_0
W0618 12:06:30.941810 47884533306240 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpw_d7m79g
I0618 12:06:30.942921 47884533306240 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpw_d7m79g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8d452f5e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:30.943386 47884533306240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:30.942677 47884110865280 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpxxy3xlch
I0618 12:06:30.943786 47884110865280 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpxxy3xlch', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8d2c017e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:30.944242 47884110865280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881190.825819 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881190.826709 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881190.827584 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:30.943734 47820089926528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_0_0
:::MLL 1560881190.841610 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881190.842358 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881190.843056 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:30.943852 47500346065792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_0_0
W0618 12:06:30.944759 47820089926528 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpkfdsn9wq
W0618 12:06:30.944858 47500346065792 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpkj67pq2v
I0618 12:06:30.945765 47820089926528 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpkfdsn9wq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7e440f7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:30.945854 47500346065792 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpkj67pq2v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b33d1d75e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:30.946167 47820089926528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:30.946257 47500346065792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:30.948763 47884533306240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:30.949500 47884110865280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:30.951042 47820089926528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:30.951061 47500346065792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881190.865759 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881190.866607 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881190.867460 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:30.967771 47445699335040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_0_0
:::MLL 1560881190.866234 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881190.867160 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881190.867907 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:30.967746 47792585823104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_0_0
W0618 12:06:30.968796 47445699335040 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpqj50age6
W0618 12:06:30.968770 47792585823104 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpe_klpk0z
I0618 12:06:30.969792 47445699335040 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpqj50age6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2718a46e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:30.969792 47792585823104 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpe_klpk0z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b77dcb02e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:06:30.970640 47884533306240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:06:30.970201 47445699335040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:30.970199 47792585823104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:30.971567 47884110865280 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:30.970768 47500346065792 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:30.970858 47820089926528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:30.975211 47445699335040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:30.975362 47792585823104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881190.877105 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881190.877845 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881190.878544 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:30.981452 47867452289920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_0_0
:::MLL 1560881190.869831 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881190.870784 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881190.871682 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:30.981983 47381600674688 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_0_0
W0618 12:06:30.982515 47867452289920 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpz45fvo7d
I0618 12:06:30.983520 47867452289920 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpz45fvo7d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b894b13be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:06:30.982945 47381600674688 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp8888z2f8
I0618 12:06:30.983928 47867452289920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:30.983942 47381600674688 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp8888z2f8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b182c106e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:30.984344 47381600674688 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:30.984129 47269196727168 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881190.893816 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881190.894283 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881190.894669 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:30.984534 47390093370240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_0_0
:::MLL 1560881190.894330 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881190.894779 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881190.895155 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:30.984541 47407999673216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_0_0
W0618 12:06:30.985560 47390093370240 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpra94lp_l
W0618 12:06:30.985532 47407999673216 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmplipveyio
W0618 12:06:30.986225 47189942883200 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:06:30.986516 47407999673216 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmplipveyio', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1e51913e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:30.986538 47390093370240 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpra94lp_l', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1a2644bdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:30.986922 47407999673216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:30.986942 47390093370240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:30.988830 47867452289920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:30.989105 47381600674688 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:30.988503 47269196727168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:06:30.990706 47189942883200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:06:30.991668 47407999673216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:30.991725 47390093370240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:06:30.993599 47269196727168 estimator.py:1111] Calling model_fn.
W0618 12:06:30.993712 47269196727168 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560881190.916396 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881190.916816 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881190.917177 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:30.993818 47018886923136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_0_0
:::MLL 1560881190.915700 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881190.916141 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881190.916510 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:30.994374 47918302081920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_0_0
W0618 12:06:30.994495 47445699335040 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:30.995078 47269196727168 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:06:30.994738 47792585823104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:30.994817 47018886923136 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpul7a7icw
I0618 12:06:30.995863 47018886923136 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpul7a7icw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac3b8a3de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:30.995843 47189942883200 estimator.py:1111] Calling model_fn.
W0618 12:06:30.995375 47918302081920 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpppp8ysop
W0618 12:06:30.995956 47189942883200 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:06:30.996303 47018886923136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:30.996412 47918302081920 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpppp8ysop', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9521f60e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:30.996805 47918302081920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:30.997321 47189942883200 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560881190.906924 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881190.907401 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881190.907803 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:30.997951 47990001750912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_0_0
:::MLL 1560881190.900094 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881190.900652 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881190.901130 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:30.998017 47544420283264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_0_0
I0618 12:06:30.998986 47990001750912 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb330/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba5d3982d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:06:30.999016 47544420283264 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpgootuerq
W0618 12:06:31.000954 47018886923136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:06:30.999973 47544420283264 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpgootuerq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3e14de6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:31.000107 47990001750912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:31.001392 47918302081920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:06:31.000372 47544420283264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881190.880044 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881190.880944 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881190.881802 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:31.001348 47949433901952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_0_0
:::MLL 1560881190.880956 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881190.881854 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881190.882549 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:31.001417 47268436280192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_0_0
W0618 12:06:31.002470 47949433901952 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpiyjj2ng6
W0618 12:06:31.002504 47268436280192 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpma6qa0sr
I0618 12:06:31.003595 47949433901952 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpiyjj2ng6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9c618fee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:31.003620 47268436280192 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpma6qa0sr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afdd2f0de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:31.004055 47268436280192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:31.004059 47949433901952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:31.004807 47990001750912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:31.004948 47544420283264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:31.008455 47867452289920 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:31.008481 47381600674688 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:31.009405 47268436280192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:31.009475 47949433901952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:31.010766 47407999673216 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:31.011040 47390093370240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:31.020040 47018886923136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:31.019036 47500346065792 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:06:31.020171 47884533306240 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:06:31.019082 47820089926528 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:06:31.020410 47884110865280 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:06:31.020687 47918302081920 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881190.943391 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881190.943863 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881190.944273 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:31.023353 47750702056320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_0_0
:::MLL 1560881190.940727 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881190.941200 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881190.941603 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:31.023648 47404371002240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_0_0
W0618 12:06:31.023380 47500346065792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:06:31.023376 47820089926528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:06:31.024502 47884533306240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:06:31.024731 47884110865280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:06:31.023887 47544420283264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:31.024033 47990001750912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:31.024354 47750702056320 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpgjdmqst8
I0618 12:06:31.025328 47750702056320 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpgjdmqst8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6e1c389e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:06:31.024626 47404371002240 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpli77yzhy
I0618 12:06:31.025603 47404371002240 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpli77yzhy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1d79481e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:31.025728 47750702056320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:31.026006 47404371002240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:31.028472 47500346065792 estimator.py:1111] Calling model_fn.
I0618 12:06:31.028455 47820089926528 estimator.py:1111] Calling model_fn.
W0618 12:06:31.028567 47820089926528 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:06:31.029600 47884533306240 estimator.py:1111] Calling model_fn.
W0618 12:06:31.028578 47500346065792 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:06:31.029709 47884533306240 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:06:31.029845 47884110865280 estimator.py:1111] Calling model_fn.
W0618 12:06:31.029955 47884110865280 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:06:31.029967 47500346065792 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:06:31.031083 47884533306240 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:06:31.030402 47750702056320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:31.029941 47820089926528 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:06:31.030540 47404371002240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:31.031347 47884110865280 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:06:31.031321 47268436280192 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:31.031835 47949433901952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881190.956219 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881190.956711 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881190.957132 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:31.036110 47606539453312 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_0_0
:::MLL 1560881190.951175 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881190.951720 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881190.952206 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:31.036403 47682404311936 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000011-000008.tfrecord.zz_0_0
W0618 12:06:31.037245 47606539453312 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpwb3y0z5q
W0618 12:06:31.037549 47682404311936 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpoov62uxg
I0618 12:06:31.038308 47606539453312 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpwb3y0z5q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4c8b75cdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:31.038594 47682404311936 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpoov62uxg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5e355bbe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:31.038753 47606539453312 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:31.039016 47682404311936 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:31.043503 47606539453312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:31.043774 47682404311936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value[2019-06-18 12:07:09] moving /lfs/lfs12/gma_akey/results/epb330/models/000021-000016.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb330/models/000021-000017.data-00000-of-00001
[2019-06-18 12:07:09] moving /lfs/lfs12/gma_akey/results/epb330/models/000021-000016.pb --> /lfs/lfs12/gma_akey/results/epb330/models/000021-000017.pb
[2019-06-18 12:07:09] moving /lfs/lfs12/gma_akey/results/epb330/models/000021-000016.meta --> /lfs/lfs12/gma_akey/results/epb330/models/000021-000017.meta
[2019-06-18 12:07:09] moving /lfs/lfs12/gma_akey/results/epb330/models/000021-000016.index --> /lfs/lfs12/gma_akey/results/epb330/models/000021-000017.index
[2019-06-18 12:07:09] iteration time 20: 48.352 seconds
2019-06-18 12:07:10.745395: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881229.457094 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 21}}
[2019-06-18 12:07:13] minmax time: 3.201 seconds
2019-06-18 12:07:13.956568: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:07:13.962013: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:07:13.966498: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881233.977376 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 20}}
[2019-06-18 12:07:13] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000022-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000022-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000022-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000022-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000022-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000022-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000022-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000022-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000022-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000022-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000022-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:07:14] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-22-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000021-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000021-000017 --seed=22 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000021-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000021-000017 --seed=1023779853 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000021-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000021-000017 --seed=2047559684 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000021-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000021-000017 --seed=3071339515 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000021-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000021-000017 --seed=4095119346 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000021-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000021-000017 --seed=5118899177 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000021-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000021-000017 --seed=6142679008 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000021-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000021-000017 --seed=7166458839 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000021-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000021-000017 --seed=8190238670 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000021-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000021-000017 --seed=9214018501 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000021-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000021-000017 --seed=10237798332 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000021-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000021-000017 --seed=11261578163 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000021-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000021-000017 --seed=12285357994 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000021-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000021-000017 --seed=13309137825 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000021-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000021-000017 --seed=14332917656 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000021-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000021-000017 --seed=15356697487 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000021-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000021-000017 --seed=16380477318 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000021-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000021-000017 --seed=17404257149 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000021-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000021-000017 --seed=18428036980 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000021-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000021-000017 --seed=19451816811 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000021-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000021-000017 --seed=20475596642 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:07:24] eval finished: 10.303 seconds
[2019-06-18 12:07:24] Win rate 000021-000017 vs 000020-000016: 0.380
:::MLL 1560881244.353597 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 20}}
[2019-06-18 12:07:24] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-23-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000022-000016 --seed=23 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000022-000016 --seed=1023779854 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000022-000016 --seed=2047559685 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000022-000016 --seed=3071339516 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000022-000016 --seed=4095119347 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000022-000016 --seed=5118899178 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000022-000016 --seed=6142679009 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000022-000016 --seed=7166458840 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000022-000016 --seed=8190238671 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000022-000016 --seed=9214018502 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000022-000016 --seed=10237798333 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000022-000016 --seed=11261578164 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000022-000016 --seed=12285357995 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000022-000016 --seed=13309137826 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000022-000016 --seed=14332917657 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000022-000016 --seed=15356697488 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000022-000016 --seed=16380477319 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000022-000016 --seed=17404257150 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000022-000016 --seed=18428036981 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:07:54] selfplay finished: 30.171 seconds
[2019-06-18 12:07:54] selfplay mn: 30.189 seconds
[2019-06-18 12:07:54] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-23-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=23 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779854 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559685 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339516 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119347 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899178 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142679009 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458840 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238671 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018502 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798333 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578164 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285357995 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137826 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917657 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697488 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477319 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257150 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036981 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816812 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596643 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376474 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156305 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000022-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golde
[2019-06-18 12:07:57] train finished: 43.071 seconds
:::MLL 1560881239.242935 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881239.243680 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881239.244361 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:19.330305 47499175736192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_0_0
:::MLL 1560881239.227528 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881239.228398 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881239.229302 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:19.330415 47339627635584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_0_0
W0618 12:07:19.331358 47499175736192 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpxtzokq7x
W0618 12:07:19.331430 47339627635584 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmppaltdn48
I0618 12:07:19.332362 47499175736192 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpxtzokq7x', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b338c157e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:19.332440 47339627635584 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmppaltdn48', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0e6646be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:19.332754 47499175736192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:07:19.332845 47339627635584 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:19.337470 47499175736192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:19.337474 47339627635584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:19.356838 47499175736192 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:19.356936 47339627635584 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881239.289346 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881239.290098 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881239.290772 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:19.380887 46956349678464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_0_0
:::MLL 1560881239.277951 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881239.278843 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881239.279699 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:19.381068 47374918853504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_0_0
W0618 12:07:19.382070 46956349678464 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpdbdmxlit
W0618 12:07:19.382175 47374918853504 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp528qg6yy
I0618 12:07:19.383172 46956349678464 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpdbdmxlit', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab529212e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:19.383266 47374918853504 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp528qg6yy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b169dcbfda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:19.383635 46956349678464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:07:19.383695 47374918853504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:19.388922 47374918853504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:19.388960 46956349678464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881239.286635 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881239.287425 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881239.288168 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:19.394562 46920053109632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_0_0
:::MLL 1560881239.288267 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881239.289028 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881239.289728 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:19.394773 46960072872832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_0_0
W0618 12:07:19.395644 46920053109632 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmplfkdl2d4
W0618 12:07:19.395805 46960072872832 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpujum3njq
I0618 12:07:19.396642 46920053109632 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmplfkdl2d4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aacb5af6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:19.396802 46960072872832 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpujum3njq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab6070cae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:19.397047 46920053109632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:07:19.397205 46960072872832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881239.299988 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881239.300790 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881239.301584 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:19.402240 47697977529216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_0_0
:::MLL 1560881239.301439 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881239.302170 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881239.302855 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:19.402187 47595864544128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_0_0
W0618 12:07:19.402000 46920053109632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:19.402032 46960072872832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:19.403262 47697977529216 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpuhjd0pch
W0618 12:07:19.403233 47595864544128 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpklsbf1s_
I0618 12:07:19.404255 47595864544128 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpklsbf1s_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4a0f2fae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:19.404270 47697977529216 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpuhjd0pch', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b61d5981e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881239.305439 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881239.306146 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881239.306801 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:19.402581 47970704462720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_0_0
:::MLL 1560881239.321915 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881239.322379 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881239.322772 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:19.403084 47311723053952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_0_0
:::MLL 1560881239.285087 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881239.285976 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881239.286834 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:19.402833 47398526559104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_0_0
I0618 12:07:19.404673 47697977529216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:07:19.404670 47595864544128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881239.326063 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881239.326517 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881239.326917 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:19.404172 46934705329024 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_0_0
W0618 12:07:19.404115 47311723053952 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpbnq7u0go
W0618 12:07:19.403749 47970704462720 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpr_f4gw8s
I0618 12:07:19.405097 47311723053952 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpbnq7u0go', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b07e7089e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:07:19.405080 47339627635584 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:07:19.403913 47398526559104 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp7rzi9t04
W0618 12:07:19.405117 47499175736192 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:07:19.404893 47970704462720 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpr_f4gw8s', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba15562de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:19.404999 47398526559104 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp7rzi9t04', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1c1cecfe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:19.405496 47311723053952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:07:19.405366 47970704462720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:07:19.405444 47398526559104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:19.405166 46934705329024 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpytl9h3gv
I0618 12:07:19.406162 46934705329024 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpytl9h3gv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab01f06ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:19.406559 46934705329024 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:19.409834 47697977529216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:19.409841 47595864544128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:19.409353 47339627635584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:07:19.409430 47499175736192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:07:19.410229 47311723053952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:19.410707 47374918853504 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:19.411109 46956349678464 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:19.411175 46934705329024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:19.410726 47398526559104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:19.410727 47970704462720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:07:19.414390 47339627635584 estimator.py:1111] Calling model_fn.
I0618 12:07:19.414471 47499175736192 estimator.py:1111] Calling model_fn.
W0618 12:07:19.414501 47339627635584 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:07:19.414582 47499175736192 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:07:19.415870 47339627635584 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:07:19.415935 47499175736192 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:07:19.421479 46920053109632 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:19.421475 46960072872832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:19.429224 47697977529216 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:19.429326 47595864544128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:19.429375 47311723053952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:19.430345 46934705329024 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881239.300682 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881239.301587 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881239.302432 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:19.429730 47486020129664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_0_0
:::MLL 1560881239.301530 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881239.302408 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881239.303135 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:19.430112 47365103805312 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_0_0
W0618 12:07:19.430742 47486020129664 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp3djco7k5
I0618 12:07:19.431727 47486020129664 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp3djco7k5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b307bf2ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:07:19.431082 47365103805312 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpmxrlw2s_
I0618 12:07:19.432064 47365103805312 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpmxrlw2s_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1454c62e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:19.432122 47486020129664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:19.432527 47398526559104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:07:19.432465 47365103805312 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:19.432833 47970704462720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:19.436878 47486020129664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:19.437157 47365103805312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881239.369603 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881239.369994 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881239.370347 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:19.448861 47849812087680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_0_0
:::MLL 1560881239.370406 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881239.370779 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881239.371103 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:19.449226 47505747833728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_0_0
W0618 12:07:19.449879 47849812087680 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp9udjy2lf
W0618 12:07:19.450179 47505747833728 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpvgyenqed
I0618 12:07:19.450884 47849812087680 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp9udjy2lf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b852fa3ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:19.451158 47505747833728 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpvgyenqed', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3513cfce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:19.451289 47849812087680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:07:19.451553 47505747833728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881239.364699 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881239.365174 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881239.365600 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:19.451004 47325557134208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_0_0
:::MLL 1560881239.366477 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881239.366952 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881239.367357 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:19.451155 47789646041984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_0_0
W0618 12:07:19.452016 47325557134208 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpmg_5i_f9
W0618 12:07:19.452171 47789646041984 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp1kidiiy7
I0618 12:07:19.453008 47325557134208 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpmg_5i_f9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0b1f9bee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:19.453148 47789646041984 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp1kidiiy7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b772d769e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:19.453401 47325557134208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:07:19.453546 47789646041984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:19.455901 47849812087680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:19.456134 47505747833728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:19.456112 47486020129664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881239.376117 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881239.376671 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881239.377149 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:19.458149 47053634601856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_0_0
W0618 12:07:19.456615 47365103805312 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881239.380023 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881239.380472 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881239.380848 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:19.458557 47341108654976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_0_0
W0618 12:07:19.457994 47325557134208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:19.458102 47789646041984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:19.459168 47053634601856 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpyw15hyac
I0618 12:07:19.460152 47053634601856 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpyw15hyac', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acbcfc35e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881239.381188 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881239.381636 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881239.382014 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:19.458358 47870376145792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_0_0
W0618 12:07:19.459518 47341108654976 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpuhtyxey1
I0618 12:07:19.460502 47341108654976 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpuhtyxey1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0ebe8d3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:19.460558 47053634601856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:07:19.460901 47341108654976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:19.459375 47870376145792 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpyxq9jhcx
I0618 12:07:19.460372 47870376145792 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpyxq9jhcx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b89f95a3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:19.460777 47870376145792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881239.385005 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881239.385415 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881239.385775 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:19.461309 47791404811136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000012-000009.tfrecord.zz_0_0
W0618 12:07:19.463169 46956349678464 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:07:19.463403 47374918853504 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:07:19.462278 47791404811136 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpetup0o75
I0618 12:07:19.463262 47791404811136 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpetup0o75', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b77964b4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:19.463667 47791404811136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:19.465194 47053634601856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:19.465462 47341108654976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:19.465419 47870376145792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:19.467783 46956349678464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:07:19.468049 47374918853504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:07:19.468201 47791404811136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:19.469786 46960072872832 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:07:19.470151 46920053109632 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:07:19.473247 46956349678464 estimator.py:1111] Calling model_fn.
W0618 12:07:19.473363 46956349678464 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:07:19.473496 47374918853504 estimator.py:1111] Calling model_fn.
W0618 12:07:19.473613 47374918853504 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:07:19.474826 46956349678464 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:07:19.474088 46960072872832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:07:19.474840 47849812087680 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:19.475072 47374918853504 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:07:19.474511 46920053109632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:07:19.475122 47505747833728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:19.477038 47697977529216 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:07:19.477754 47595864544128 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:07:19.476927 47311723053952 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable u[2019-06-18 12:07:57] divide_golden_chunk finished: 3.345 seconds
[2019-06-18 12:07:57] generate golden chunk: 3.360 seconds
[2019-06-18 12:07:57] iteration time 21: 48.447 seconds
2019-06-18 12:07:59.147315: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881277.903901 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 22}}
[2019-06-18 12:08:02] minmax time: 3.256 seconds
2019-06-18 12:08:02.415146: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:08:02.420599: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:08:02.425235: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881282.437790 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 21}}
[2019-06-18 12:08:02] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000023-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000023-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000023-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000023-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000023-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000023-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000023-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000023-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000023-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000023-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000023-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:08:02] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-23-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000022-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000022-000017 --seed=23 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000022-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000022-000017 --seed=1023779854 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000022-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000022-000017 --seed=2047559685 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000022-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000022-000017 --seed=3071339516 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000022-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000022-000017 --seed=4095119347 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000022-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000022-000017 --seed=5118899178 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000022-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000022-000017 --seed=6142679009 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000022-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000022-000017 --seed=7166458840 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000022-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000022-000017 --seed=8190238671 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000022-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000022-000017 --seed=9214018502 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000022-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000022-000017 --seed=10237798333 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000022-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000022-000017 --seed=11261578164 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000022-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000022-000017 --seed=12285357995 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000022-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000022-000017 --seed=13309137826 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000022-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000022-000017 --seed=14332917657 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000022-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000022-000017 --seed=15356697488 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000022-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000022-000017 --seed=16380477319 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000022-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000022-000017 --seed=17404257150 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000022-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000022-000017 --seed=18428036981 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000022-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000022-000017 --seed=19451816812 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000022-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000022-000017 --seed=20475596643 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:08:13] eval finished: 10.790 seconds
[2019-06-18 12:08:13] Win rate 000022-000017 vs 000020-000016: 0.450
:::MLL 1560881293.300547 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 21}}
[2019-06-18 12:08:13] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-24-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000023-000016 --seed=24 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000023-000016 --seed=1023779855 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000023-000016 --seed=2047559686 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000023-000016 --seed=3071339517 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000023-000016 --seed=4095119348 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000023-000016 --seed=5118899179 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000023-000016 --seed=6142679010 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000023-000016 --seed=7166458841 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000023-000016 --seed=8190238672 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000023-000016 --seed=9214018503 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000023-000016 --seed=10237798334 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000023-000016 --seed=11261578165 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000023-000016 --seed=12285357996 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000023-000016 --seed=13309137827 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000023-000016 --seed=14332917658 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000023-000016 --seed=15356697489 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000023-000016 --seed=16380477320 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000023-000016 --seed=17404257151 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000023-000016 --seed=18428036982 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:08:43] selfplay finished: 29.879 seconds
[2019-06-18 12:08:43] selfplay mn: 29.900 seconds
[2019-06-18 12:08:43] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-24-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=24 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779855 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559686 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339517 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119348 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899179 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142679010 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458841 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238672 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018503 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798334 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578165 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285357996 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137827 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917658 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697489 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477320 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257151 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036982 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816813 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596644 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376475 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156306 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000023-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golde
[2019-06-18 12:08:45] train finished: 43.049 seconds
:::MLL 1560881287.714088 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881287.714967 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881287.715822 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:07.823092 47027227333504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_0_0
:::MLL 1560881287.720209 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881287.720950 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881287.721653 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:07.823097 47942886892416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_0_0
W0618 12:08:07.824186 47027227333504 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpxfxdslvo
W0618 12:08:07.824216 47942886892416 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpbdrq7u77
I0618 12:08:07.825191 47027227333504 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpxfxdslvo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac5a9c44e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:07.825205 47942886892416 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpbdrq7u77', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9adb546e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:07.825598 47027227333504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:07.825604 47942886892416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:07.830655 47942886892416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:07.830798 47027227333504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881287.730998 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881287.731707 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881287.732422 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:07.834137 47972037206912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_0_0
:::MLL 1560881287.728432 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881287.729161 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881287.729839 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:07.834433 47670279385984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_0_0
W0618 12:08:07.835196 47972037206912 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpg0fmielx
W0618 12:08:07.835455 47670279385984 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmproy1r_22
I0618 12:08:07.836196 47972037206912 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpg0fmielx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba1a4d2ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:07.836467 47670279385984 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmproy1r_22', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5b62a80dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:07.836596 47972037206912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:07.836877 47670279385984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:07.841516 47972037206912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:07.841755 47670279385984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:07.850044 47942886892416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:07.850193 47027227333504 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881287.736526 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881287.737448 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881287.738301 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:07.852468 47282991608704 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_0_0
:::MLL 1560881287.748455 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881287.749196 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881287.749863 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:07.852718 47850411176832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_0_0
W0618 12:08:07.853516 47282991608704 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpbmpunj51
W0618 12:08:07.853727 47850411176832 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpslcs_amj
I0618 12:08:07.854516 47282991608704 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpbmpunj51', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0136818e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:07.854714 47850411176832 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpslcs_amj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8553590dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:07.854919 47282991608704 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:07.855108 47850411176832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:07.859943 47282991608704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:07.859976 47850411176832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:07.861057 47972037206912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:07.861588 47670279385984 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:07.879409 47850411176832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:07.879835 47282991608704 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881287.800204 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881287.800720 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881287.801156 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:07.881001 47332076323712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_0_0
W0618 12:08:07.882013 47332076323712 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp4jf14bpi
I0618 12:08:07.882984 47332076323712 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp4jf14bpi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0ca42ece48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881287.804718 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881287.805166 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881287.805549 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:07.883007 47846150751104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_0_0
I0618 12:08:07.883385 47332076323712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:07.884002 47846150751104 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpzdd8_del
I0618 12:08:07.884995 47846150751104 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpzdd8_del', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8455681e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:07.885390 47846150751104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:07.888003 47332076323712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:07.889988 47846150751104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:07.898313 47942886892416 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:07.899053 47027227333504 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881287.769978 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881287.770822 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881287.771622 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:07.899912 47785911214976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_0_0
:::MLL 1560881287.770436 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881287.771339 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881287.772107 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:07.900216 47800697049984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_0_0
:::MLL 1560881287.819922 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881287.820347 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881287.820707 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:07.901100 47281671324544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_0_0
:::MLL 1560881287.821765 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881287.822183 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881287.822504 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:07.901597 47267230106496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_0_0
W0618 12:08:07.901060 47785911214976 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpva6lpapt
W0618 12:08:07.901302 47800697049984 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpkpb1c697
I0618 12:08:07.902202 47785911214976 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpva6lpapt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b764ed9ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:08:07.902636 47942886892416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:08:07.902393 47800697049984 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpkpb1c697', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b79c0279e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:07.902689 47785911214976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:07.902099 47281671324544 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpa38zv1fl
I0618 12:08:07.902846 47800697049984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:07.903384 47027227333504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:08:07.903088 47281671324544 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpa38zv1fl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b00e7cf9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:08:07.902570 47267230106496 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp1qmq0o6z
I0618 12:08:07.903480 47281671324544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:07.903536 47267230106496 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp1qmq0o6z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afd8b0c0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:07.903939 47267230106496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:07.907018 47332076323712 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:08:07.907719 47942886892416 estimator.py:1111] Calling model_fn.
W0618 12:08:07.907839 47942886892416 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560881287.819304 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881287.819789 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881287.820189 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:07.908690 47390711817088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_0_0
:::MLL 1560881287.818642 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881287.819158 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881287.819587 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:07.909017 47376836440960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_0_0
I0618 12:08:07.908464 47027227333504 estimator.py:1111] Calling model_fn.
W0618 12:08:07.908058 47281671324544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:07.908572 47027227333504 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:08:07.908084 47800697049984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:07.908121 47785911214976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:07.908433 47267230106496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:07.909192 47942886892416 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:08:07.909229 47846150751104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:07.909790 47390711817088 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpevl7h4fp
W0618 12:08:07.910057 47376836440960 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp7u079o53
I0618 12:08:07.910777 47390711817088 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpevl7h4fp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1a4b217e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:07.911017 47376836440960 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp7u079o53', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1710180e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:08:07.909921 47027227333504 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:08:07.911176 47390711817088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:07.911418 47376836440960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:07.909830 47670279385984 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:07.909850 47972037206912 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:07.914140 47670279385984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:08:07.914210 47972037206912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:08:07.915763 47390711817088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:07.915957 47376836440960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:08:07.919220 47670279385984 estimator.py:1111] Calling model_fn.
W0618 12:08:07.919333 47670279385984 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:08:07.919330 47972037206912 estimator.py:1111] Calling model_fn.
W0618 12:08:07.919440 47972037206912 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:08:07.920707 47670279385984 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:08:07.920801 47972037206912 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560881287.745100 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881287.746008 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881287.746854 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:07.924834 47942153876352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_0_0
W0618 12:08:07.927486 47282991608704 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:07.927567 47850411176832 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:07.925904 47942153876352 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp7c8rk9nz
I0618 12:08:07.926911 47942153876352 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp7c8rk9nz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9aafa38e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:08:07.927251 47281671324544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:07.927611 47267230106496 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:08:07.927320 47942153876352 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:07.929738 47800697049984 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:07.930298 47785911214976 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:07.931780 47282991608704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:08:07.931884 47850411176832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:08:07.932328 47942153876352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881287.752618 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881287.753338 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881287.754013 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:07.932562 47078283486080 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_0_0
W0618 12:08:07.934851 47390711817088 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:07.934958 47376836440960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:07.933584 47078283486080 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpdasttx7m
I0618 12:08:07.934582 47078283486080 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpdasttx7m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad18cf36e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:07.934983 47078283486080 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:07.936820 47282991608704 estimator.py:1111] Calling model_fn.
W0618 12:08:07.936934 47282991608704 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:08:07.936939 47850411176832 estimator.py:1111] Calling model_fn.
W0618 12:08:07.937048 47850411176832 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:08:07.938284 47282991608704 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:08:07.938404 47850411176832 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:08:07.939720 47078283486080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881287.843531 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881287.843946 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881287.844317 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:07.946369 47332900402048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_0_0
:::MLL 1560881287.838798 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881287.839302 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881287.839745 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:07.946331 47436653396864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_0_0
W0618 12:08:07.947369 47436653396864 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpr7jctccw
W0618 12:08:07.947400 47332900402048 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpf0uyjxqo
I0618 12:08:07.948472 47436653396864 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpr7jctccw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b24fd765e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:07.948499 47332900402048 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpf0uyjxqo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0cd54d3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:07.948894 47436653396864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:07.948923 47332900402048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:07.951941 47942153876352 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:07.953567 47332900402048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:07.953564 47436653396864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:07.954557 47332076323712 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881287.762198 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881287.763099 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881287.763947 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:07.956878 47411642819456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_0_0
:::MLL 1560881287.762306 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881287.763201 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881287.764067 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:07.956911 47335009473408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_0_0
W0618 12:08:07.957118 47846150751104 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:07.958009 47411642819456 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmptirqbluy
W0618 12:08:07.958047 47335009473408 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpa93128uq
I0618 12:08:07.959090 47411642819456 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmptirqbluy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1f2ab73e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:07.959141 47335009473408 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpa93128uq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0d53032e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:08:07.958869 47332076323712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:08:07.959534 47411642819456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:07.959601 47335009473408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:07.959134 47078283486080 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:07.961471 47846150751104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:08:07.963901 47332076323712 estimator.py:1111] Calling model_fn.
W0618 12:08:07.964010 47332076323712 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:08:07.964535 47411642819456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:07.964564 47335009473408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:07.965368 47332076323712 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560881287.812445 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881287.813001 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881287.813431 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:07.965423 47741144871808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_0_0
:::MLL 1560881287.808242 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881287.808776 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881287.809251 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:07.965423 47199219704704 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000022-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000013-000010.tfrecord.zz_0_0
I0618 12:08:07.966570 47846150751104 estimator.py:1111] Calling model_fn.
W0618 12:08:07.966680 478461507[2019-06-18 12:08:46] divide_golden_chunk finished: 3.269 seconds
[2019-06-18 12:08:46] generate golden chunk: 3.284 seconds
[2019-06-18 12:08:46] iteration time 22: 48.582 seconds
2019-06-18 12:08:47.717124: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881326.485879 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 23}}
[2019-06-18 12:08:50] minmax time: 3.241 seconds
2019-06-18 12:08:50.968627: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:08:50.974227: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:08:50.978839: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881330.991374 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 22}}
[2019-06-18 12:08:51] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000024-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000024-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000024-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000024-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000024-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000024-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000024-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000024-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000024-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000024-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000024-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:08:51] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-24-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000023-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000023-000017 --seed=24 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000023-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000023-000017 --seed=1023779855 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000023-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000023-000017 --seed=2047559686 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000023-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000023-000017 --seed=3071339517 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000023-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000023-000017 --seed=4095119348 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000023-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000023-000017 --seed=5118899179 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000023-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000023-000017 --seed=6142679010 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000023-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000023-000017 --seed=7166458841 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000023-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000023-000017 --seed=8190238672 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000023-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000023-000017 --seed=9214018503 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000023-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000023-000017 --seed=10237798334 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000023-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000023-000017 --seed=11261578165 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000023-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000023-000017 --seed=12285357996 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000023-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000023-000017 --seed=13309137827 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000023-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000023-000017 --seed=14332917658 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000023-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000023-000017 --seed=15356697489 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000023-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000023-000017 --seed=16380477320 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000023-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000023-000017 --seed=17404257151 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000023-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000023-000017 --seed=18428036982 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000023-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000023-000017 --seed=19451816813 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000023-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000023-000017 --seed=20475596644 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:09:01] eval finished: 10.172 seconds
[2019-06-18 12:09:01] Win rate 000023-000017 vs 000020-000016: 0.360
:::MLL 1560881341.236241 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 22}}
[2019-06-18 12:09:01] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-25-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000024-000016 --seed=25 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000024-000016 --seed=1023779856 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000024-000016 --seed=2047559687 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000024-000016 --seed=3071339518 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000024-000016 --seed=4095119349 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000024-000016 --seed=5118899180 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000024-000016 --seed=6142679011 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000024-000016 --seed=7166458842 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000024-000016 --seed=8190238673 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000024-000016 --seed=9214018504 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000024-000016 --seed=10237798335 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000024-000016 --seed=11261578166 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000024-000016 --seed=12285357997 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000024-000016 --seed=13309137828 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000024-000016 --seed=14332917659 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000024-000016 --seed=15356697490 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000024-000016 --seed=16380477321 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000024-000016 --seed=17404257152 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000024-000016 --seed=18428036983 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:09:31] selfplay finished: 29.946 seconds
[2019-06-18 12:09:31] selfplay mn: 29.966 seconds
[2019-06-18 12:09:31] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-25-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=25 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779856 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559687 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339518 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119349 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899180 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142679011 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458842 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238673 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018504 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798335 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578166 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285357997 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137828 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917659 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697490 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477321 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257152 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036983 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816814 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596645 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376476 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156307 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000024-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golde
[2019-06-18 12:09:34] train finished: 43.357 seconds
:::MLL 1560881336.305654 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881336.306425 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881336.307112 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:56.409829 46983683277696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_0_0
:::MLL 1560881336.298262 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881336.299164 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881336.300015 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:56.409895 47051498865536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_0_0
W0618 12:08:56.410872 46983683277696 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp94ont5k3
W0618 12:08:56.410931 47051498865536 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp45o6y39j
I0618 12:08:56.412038 46983683277696 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp94ont5k3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abb8656ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:56.412039 47051498865536 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp45o6y39j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acb50768e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:56.412470 46983683277696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:56.412472 47051498865536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:56.417224 46983683277696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:56.417228 47051498865536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881336.325130 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881336.325796 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881336.326530 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:56.421150 47408880296832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_0_0
:::MLL 1560881336.314364 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881336.315285 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881336.316119 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:56.421283 47808943448960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_0_0
W0618 12:08:56.422197 47408880296832 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp8m6hdxre
W0618 12:08:56.422273 47808943448960 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpj90bv6cb
I0618 12:08:56.423197 47408880296832 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp8m6hdxre', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1e860e7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:56.423263 47808943448960 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpj90bv6cb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7babadbdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:56.423597 47408880296832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:56.423665 47808943448960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:56.428540 47808943448960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:56.428555 47408880296832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:56.436563 46983683277696 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:56.436660 47051498865536 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881336.326335 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881336.327064 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881336.327751 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:56.441699 47703466845056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_0_0
:::MLL 1560881336.321255 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881336.322196 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881336.323083 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:56.442154 47379090203520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_0_0
W0618 12:08:56.442876 47703466845056 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmptrmshdgc
I0618 12:08:56.443992 47703466845056 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmptrmshdgc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b631cc87e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:08:56.443261 47379090203520 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpb2i5wwe1
I0618 12:08:56.444366 47379090203520 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpb2i5wwe1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b17966dbe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:56.444443 47703466845056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:56.444822 47379090203520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:56.447944 47808943448960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:56.448059 47408880296832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:56.449756 47703466845056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:56.450065 47379090203520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881336.339982 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881336.340899 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881336.341779 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:56.464298 47367367422848 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_0_0
:::MLL 1560881336.340848 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881336.341805 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881336.342555 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:56.464963 47496590476160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_0_0
W0618 12:08:56.465409 47367367422848 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmppuxn_gah
I0618 12:08:56.466506 47367367422848 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmppuxn_gah', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b14dbb24e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:08:56.466075 47496590476160 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpk23x1png
I0618 12:08:56.466949 47367367422848 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:56.467189 47496590476160 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpk23x1png', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b32f1fd8e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:56.467640 47496590476160 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:56.472270 47367367422848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:56.471629 47703466845056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:56.472894 47496590476160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:56.472391 47379090203520 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881336.391270 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881336.391704 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881336.392082 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:56.474154 46931083301760 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_0_0
:::MLL 1560881336.389582 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881336.390025 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881336.390398 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:56.474624 47129444389760 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_0_0
W0618 12:08:56.475172 46931083301760 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp8goyww_j
I0618 12:08:56.476155 46931083301760 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp8goyww_j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aaf4722ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:08:56.475616 47129444389760 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpsl_8aeuv
I0618 12:08:56.476553 46931083301760 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:56.476594 47129444389760 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpsl_8aeuv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2add7660ddd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:56.476988 47129444389760 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881336.369352 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881336.370315 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881336.371195 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:56.479007 47579154170752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_0_0
:::MLL 1560881336.376696 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881336.377464 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881336.378139 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:56.479123 47379374818176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_0_0
W0618 12:08:56.480103 47579154170752 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp17w2iigg
W0618 12:08:56.480181 47379374818176 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpofgzl1yl
I0618 12:08:56.481106 47579154170752 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp17w2iigg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b462b2b9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:56.481153 47379374818176 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpofgzl1yl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b17a7649e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:56.481528 47579154170752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:56.481549 47379374818176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:56.481140 46931083301760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:56.481585 47129444389760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:56.484899 46983683277696 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:56.485333 47051498865536 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:56.486339 47379374818176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:56.486361 47579154170752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881336.402142 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881336.402578 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881336.402955 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:56.486830 47344687985536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_0_0
:::MLL 1560881336.404770 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881336.405208 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881336.405578 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:56.488400 47965189079936 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_0_0
W0618 12:08:56.487857 47344687985536 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpybub_w1_
I0618 12:08:56.488837 47344687985536 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpybub_w1_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0f93e57e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:08:56.489196 46983683277696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:08:56.489245 47344687985536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:56.489642 47051498865536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:08:56.489371 47965189079936 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpz_s5pe1y
I0618 12:08:56.490344 47965189079936 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpz_s5pe1y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba00ca4de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:56.490731 47965189079936 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:56.493932 47367367422848 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:56.493842 47344687985536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:08:56.494280 46983683277696 estimator.py:1111] Calling model_fn.
W0618 12:08:56.494390 46983683277696 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:08:56.494930 47496590476160 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:08:56.494773 47051498865536 estimator.py:1111] Calling model_fn.
W0618 12:08:56.494889 47051498865536 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:08:56.495248 47965189079936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:56.495759 46983683277696 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:08:56.496249 47051498865536 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:08:56.495974 47808943448960 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:56.496395 47408880296832 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881336.404921 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881336.405351 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881336.405720 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:56.496313 47907763143552 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_0_0
:::MLL 1560881336.401475 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881336.401956 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881336.402404 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:56.496505 47029676987264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_0_0
W0618 12:08:56.497348 47907763143552 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpi93ngelb
W0618 12:08:56.497487 47029676987264 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpzsm725cv
I0618 12:08:56.498339 47907763143552 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpi93ngelb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b92adca7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:56.498453 47029676987264 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpzsm725cv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac63bc72e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:56.498745 47907763143552 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:56.498848 47029676987264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:56.500148 46931083301760 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:56.500253 47808943448960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:08:56.500752 47129444389760 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:56.500729 47408880296832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:08:56.503416 47907763143552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:56.503424 47029676987264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:56.506036 47579154170752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:56.506140 47379374818176 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:08:56.505357 47808943448960 estimator.py:1111] Calling model_fn.
W0618 12:08:56.505465 47808943448960 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:08:56.505876 47408880296832 estimator.py:1111] Calling model_fn.
W0618 12:08:56.505984 47408880296832 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:08:56.506829 47808943448960 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:08:56.507368 47408880296832 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560881336.343327 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881336.344230 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881336.345098 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:56.506911 46981950268288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_0_0
W0618 12:08:56.507957 46981950268288 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpoz1crqey
I0618 12:08:56.508985 46981950268288 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpoz1crqey', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abb1f0b1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881336.349716 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881336.350461 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881336.351147 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:56.509118 47564346569600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_0_0
I0618 12:08:56.509394 46981950268288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:56.510080 47564346569600 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmppnev6hb3
I0618 12:08:56.511085 47564346569600 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmppnev6hb3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b42b8918e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:56.511494 47564346569600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:56.512856 47344687985536 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:56.514311 47965189079936 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:56.514404 46981950268288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881336.416726 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881336.417146 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881336.417501 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:56.515833 47918362780544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_0_0
:::MLL 1560881336.412731 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881336.413227 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881336.413663 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:56.516067 47789926687616 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_0_0
W0618 12:08:56.516326 47564346569600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:56.516841 47918362780544 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpdy5qo1ca
W0618 12:08:56.517040 47789926687616 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp1b_b00rw
I0618 12:08:56.517825 47918362780544 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpdy5qo1ca', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9525943e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:56.518021 47789926687616 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp1b_b00rw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b773e30fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:56.518218 47918362780544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:56.518423 47789926687616 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:56.520959 47703466845056 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:56.521053 47379090203520 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:56.522838 47918362780544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:56.522932 47789926687616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:56.522516 47029676987264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:56.522569 47907763143552 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:56.525294 47703466845056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:08:56.525366 47379090203520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:08:56.530413 47703466845056 estimator.py:1111] Calling model_fn.
I0618 12:08:56.530465 47379090203520 estimator.py:1111] Calling model_fn.
W0618 12:08:56.530525 47703466845056 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:08:56.530576 47379090203520 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:08:56.531909 47379090203520 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:08:56.531894 47703466845056 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:08:56.533880 46981950268288 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:56.535990 47564346569600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:56.541982 47918362780544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:56.542111 47789926687616 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:56.542385 47367367422848 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:56.542873 47496590476160 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881336.461115 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881336.461629 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881336.462002 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:56.546428 46956374889344 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000023-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000014-000010.tfrecord.zz_0_0
W0618 12:08:56.546682 47367367422848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560881336.464289 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881336.464678 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881336.465048 opt_learning_rate_decay_b[2019-06-18 12:09:34] divide_golden_chunk finished: 3.436 seconds
[2019-06-18 12:09:34] generate golden chunk: 3.450 seconds
[2019-06-18 12:09:34] iteration time 23: 48.168 seconds
2019-06-18 12:09:35.959582: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881374.654138 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 24}}
[2019-06-18 12:09:39] minmax time: 3.244 seconds
2019-06-18 12:09:39.213438: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:09:39.218925: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:09:39.223493: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881379.236233 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 23}}
[2019-06-18 12:09:39] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000025-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000025-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000025-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000025-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000025-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000025-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000025-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000025-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000025-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000025-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000025-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:09:39] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-25-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000024-000017 --seed=25 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000024-000017 --seed=1023779856 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000024-000017 --seed=2047559687 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000024-000017 --seed=3071339518 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000024-000017 --seed=4095119349 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000024-000017 --seed=5118899180 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000024-000017 --seed=6142679011 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000024-000017 --seed=7166458842 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000024-000017 --seed=8190238673 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000024-000017 --seed=9214018504 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000024-000017 --seed=10237798335 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000024-000017 --seed=11261578166 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000024-000017 --seed=12285357997 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000024-000017 --seed=13309137828 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000024-000017 --seed=14332917659 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000024-000017 --seed=15356697490 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000024-000017 --seed=16380477321 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000024-000017 --seed=17404257152 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000024-000017 --seed=18428036983 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000024-000017 --seed=19451816814 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000020-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000024-000017 --seed=20475596645 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:09:49] eval finished: 10.097 seconds
[2019-06-18 12:09:49] Win rate 000024-000017 vs 000020-000016: 0.570
:::MLL 1560881389.404272 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 23}}
[2019-06-18 12:09:49] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-26-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000025-000016 --seed=26 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000025-000016 --seed=1023779857 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000025-000016 --seed=2047559688 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000025-000016 --seed=3071339519 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000025-000016 --seed=4095119350 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000025-000016 --seed=5118899181 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000025-000016 --seed=6142679012 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000025-000016 --seed=7166458843 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000025-000016 --seed=8190238674 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000025-000016 --seed=9214018505 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000025-000016 --seed=10237798336 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000025-000016 --seed=11261578167 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000025-000016 --seed=12285357998 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000025-000016 --seed=13309137829 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000025-000016 --seed=14332917660 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000025-000016 --seed=15356697491 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000025-000016 --seed=16380477322 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000025-000016 --seed=17404257153 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000025-000016 --seed=18428036984 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:10:19] selfplay finished: 29.997 seconds
[2019-06-18 12:10:19] selfplay mn: 30.019 seconds
[2019-06-18 12:10:19] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-26-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=26 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779857 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559688 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339519 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119350 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899181 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142679012 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458843 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238674 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018505 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798336 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578167 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285357998 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137829 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917660 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697491 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477322 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257153 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036984 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816815 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596646 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376477 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156308 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000025-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golde
[2019-06-18 12:10:22] divide_golden_chunk finished: 3.423 seconds
[2019-06-18 12:10:22] generate golden chunk: 3.438 seconds
[2019-06-18 12:10:23] train finished: 43.967 seconds
:::MLL 1560881384.533069 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881384.533787 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881384.534446 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:44.639240 46954901336960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_0_0
W0618 12:09:44.640269 46954901336960 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpptinaual
I0618 12:09:44.641273 46954901336960 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpptinaual', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab4d2cd3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:44.641676 46954901336960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:44.646624 46954901336960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881384.530876 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881384.531647 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881384.532393 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:44.654005 47912804017024 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_0_0
:::MLL 1560881384.515467 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881384.516342 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881384.517194 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:44.654474 47135781720960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_0_0
:::MLL 1560881384.521770 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881384.522507 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881384.523172 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:44.654777 47572565611392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_0_0
:::MLL 1560881384.544506 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881384.545225 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881384.545911 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:44.656898 47571450151808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_0_0
W0618 12:09:44.655030 47912804017024 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpyz41p40v
:::MLL 1560881384.541936 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881384.542648 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881384.543309 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:44.657076 47761120244608 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_0_0
W0618 12:09:44.655608 47135781720960 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp7tlla6ze
I0618 12:09:44.656028 47912804017024 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpyz41p40v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b93da402e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:09:44.655837 47572565611392 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpuk5jb42i
I0618 12:09:44.656595 47135781720960 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp7tlla6ze', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adef01cee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:44.656831 47572565611392 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpuk5jb42i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b44a2762e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:44.656425 47912804017024 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:44.657000 47135781720960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:44.657226 47572565611392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:44.658028 47571450151808 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpxuhc18p3
W0618 12:09:44.658111 47761120244608 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpxi53b4aj
I0618 12:09:44.659036 47571450151808 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpxuhc18p3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b445ff99dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:44.659127 47761120244608 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpxi53b4aj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7089318dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:44.659449 47571450151808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:44.659532 47761120244608 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:44.661064 47912804017024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:44.661756 47135781720960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:44.661930 47572565611392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:44.664188 47571450151808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:44.664204 47761120244608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:44.665780 46954901336960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881384.558833 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881384.559607 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881384.560312 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:44.678540 47393817133952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_0_0
:::MLL 1560881384.552793 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881384.553694 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881384.554541 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:44.678703 47740673028992 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_0_0
W0618 12:09:44.679684 47393817133952 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp9ea5xlmu
W0618 12:09:44.679761 47740673028992 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmppsmktgqt
W0618 12:09:44.680090 47912804017024 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:09:44.680819 47393817133952 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp9ea5xlmu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1b0438ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:44.680852 47740673028992 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmppsmktgqt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6bc671ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:44.681274 47393817133952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:44.680962 47135781720960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:09:44.681306 47740673028992 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:44.681436 47572565611392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:44.683398 47571450151808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:44.683436 47761120244608 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:44.686600 47740673028992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:44.686633 47393817133952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881384.601198 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881384.601669 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881384.602079 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:44.690233 46978932364160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_0_0
:::MLL 1560881384.603615 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881384.604099 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881384.604516 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:44.690545 47334926390144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_0_0
W0618 12:09:44.691249 46978932364160 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpx1pgdsrs
W0618 12:09:44.691526 47334926390144 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpl714i78e
I0618 12:09:44.692309 46978932364160 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpx1pgdsrs', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aba6b299e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:44.692581 47334926390144 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpl714i78e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0d4e0f6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:44.692722 46978932364160 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:44.693016 47334926390144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:44.697372 46978932364160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:44.697545 47334926390144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881384.567680 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881384.568583 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881384.569460 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:44.698654 47096177632128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_0_0
:::MLL 1560881384.567687 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881384.568606 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881384.569467 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:44.699303 47164735071104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_0_0
W0618 12:09:44.699800 47096177632128 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpri3jtmxa
I0618 12:09:44.700906 47096177632128 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpri3jtmxa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad5b7867e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:09:44.700399 47164735071104 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpz8j8etqv
I0618 12:09:44.701347 47096177632128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:44.701531 47164735071104 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpz8j8etqv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae5adddde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:44.701990 47164735071104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881384.555993 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881384.556716 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881384.557431 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:44.702729 47704336176000 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_0_0
:::MLL 1560881384.546385 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881384.547310 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881384.548169 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:44.703115 47012961661824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_0_0
W0618 12:09:44.703782 47704336176000 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmps9xetinu
I0618 12:09:44.704790 47704336176000 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmps9xetinu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6350996e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:09:44.704144 47012961661824 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpjn04iqve
I0618 12:09:44.705131 47012961661824 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpjn04iqve', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac257778e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:44.705186 47704336176000 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:44.705533 47012961661824 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:44.706593 47096177632128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:44.707212 47164735071104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:44.708673 47393817133952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:44.708751 47740673028992 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:44.710048 47704336176000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:44.710212 47012961661824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:44.713513 46954901336960 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881384.625545 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881384.626048 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881384.626416 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:44.715018 47639985632128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_0_0
:::MLL 1560881384.628620 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881384.629097 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881384.629548 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:44.715562 47295053910912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_0_0
W0618 12:09:44.716198 46978932364160 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:44.716656 47334926390144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881384.633205 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881384.633691 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881384.634138 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:44.717705 47305032962944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_0_0
W0618 12:09:44.716040 47639985632128 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpjecx1uj0
I0618 12:09:44.717033 47639985632128 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpjecx1uj0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b545501ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:09:44.716555 47295053910912 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpicupq0ek
I0618 12:09:44.717430 47639985632128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:44.717563 47295053910912 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpicupq0ek', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b040579ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:09:44.717844 46954901336960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:09:44.717969 47295053910912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:44.718822 47305032962944 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpn6rdm3t1
I0618 12:09:44.719875 47305032962944 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpn6rdm3t1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b065845ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:44.720306 47305032962944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881384.638263 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881384.638717 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881384.639112 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:44.722352 47375787512704 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_0_0
W0618 12:09:44.722058 47639985632128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:44.722517 47295053910912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:44.723364 47375787512704 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmppb0060ne
I0618 12:09:44.722930 46954901336960 estimator.py:1111] Calling model_fn.
W0618 12:09:44.723042 46954901336960 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:09:44.724431 47375787512704 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmppb0060ne', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b16d1929e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:44.724860 47375787512704 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:44.725318 47305032962944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:44.724415 46954901336960 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:09:44.727286 47912804017024 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:09:44.729542 47375787512704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:44.728543 47135781720960 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:09:44.728321 47096177632128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:44.728914 47572565611392 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:09:44.729382 47164735071104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:44.729141 47704336176000 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:44.729469 47012961661824 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:44.731414 47571450151808 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:09:44.731428 47761120244608 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:09:44.731593 47912804017024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:09:44.732824 47135781720960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:09:44.733224 47572565611392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:09:44.735699 47571450151808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:09:44.735720 47761120244608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560881384.637652 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881384.638068 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881384.638495 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:44.736755 47166187946880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_0_0
:::MLL 1560881384.636681 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881384.637124 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881384.637537 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:44.736729 47506613404544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_0_0
I0618 12:09:44.736608 47912804017024 estimator.py:1111] Calling model_fn.
W0618 12:09:44.736734 47912804017024 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:09:44.737872 47135781720960 estimator.py:1111] Calling model_fn.
W0618 12:09:44.737977 47135781720960 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:09:44.738277 47572565611392 estimator.py:1111] Calling model_fn.
W0618 12:09:44.738386 47572565611392 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:09:44.737830 47166187946880 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpy4ca7aya
W0618 12:09:44.737801 47506613404544 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp5p_iy87l
I0618 12:09:44.738791 47506613404544 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp5p_iy87l', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3547675da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:09:44.738108 47912804017024 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:09:44.738813 47166187946880 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpy4ca7aya', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae604770da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:44.739197 47506613404544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:44.739216 47166187946880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:44.739335 47135781720960 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:09:44.739743 47572565611392 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:09:44.740732 47571450151808 estimator.py:1111] Calling model_fn.
I0618 12:09:44.740755 47761120244608 estimator.py:1111] Calling model_fn.
W0618 12:09:44.740845 47571450151808 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:09:44.740860 47761120244608 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:09:44.742198 47571450151808 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:09:44.742210 47761120244608 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:09:44.741008 47639985632128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:44.741563 47295053910912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:44.744666 47305032962944 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:44.743879 47166187946880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:44.743919 47506613404544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:44.748446 47375787512704 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881384.640168 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881384.640654 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881384.641086 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:44.751016 47999081345920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_0_0
:::MLL 1560881384.645467 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881384.645886 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881384.646262 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:44.751467 47738824725376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_0_0
W0618 12:09:44.752050 47999081345920 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp_y_msivc
I0618 12:09:44.753030 47999081345920 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp_y_msivc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba7f0c7ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:09:44.752452 47738824725376 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpsc7avc54
I0618 12:09:44.753432 47999081345920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:44.753431 47738824725376 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpsc7avc54', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6b5846ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:44.753830 47738824725376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881384.629927 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881384.630465 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881384.630929 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:44.754051 47586604241792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000024-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000015-000011.tfrecord.zz_0_0
:::MLL 1560881384.629949 global_batch_si[2019-06-18 12:10:23] moving /lfs/lfs12/gma_akey/results/epb330/models/000025-000017.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb330/models/000025-000018.data-00000-of-00001
[2019-06-18 12:10:23] moving /lfs/lfs12/gma_akey/results/epb330/models/000025-000017.pb --> /lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb
[2019-06-18 12:10:23] moving /lfs/lfs12/gma_akey/results/epb330/models/000025-000017.meta --> /lfs/lfs12/gma_akey/results/epb330/models/000025-000018.meta
[2019-06-18 12:10:23] moving /lfs/lfs12/gma_akey/results/epb330/models/000025-000017.index --> /lfs/lfs12/gma_akey/results/epb330/models/000025-000018.index
[2019-06-18 12:10:23] iteration time 24: 48.618 seconds
2019-06-18 12:10:24.642051: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881423.271898 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 25}}
[2019-06-18 12:10:27] minmax time: 3.263 seconds
2019-06-18 12:10:27.915713: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:10:27.921105: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:10:27.925646: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881427.937097 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 24}}
[2019-06-18 12:10:27] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000026-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000026-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000026-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000026-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000026-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000026-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000026-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000026-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000026-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000026-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000026-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:10:27] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-26-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000025-000018 --seed=26 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000025-000018 --seed=1023779857 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000025-000018 --seed=2047559688 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000025-000018 --seed=3071339519 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000025-000018 --seed=4095119350 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000025-000018 --seed=5118899181 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000025-000018 --seed=6142679012 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000025-000018 --seed=7166458843 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000025-000018 --seed=8190238674 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000025-000018 --seed=9214018505 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000025-000018 --seed=10237798336 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000025-000018 --seed=11261578167 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000025-000018 --seed=12285357998 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000025-000018 --seed=13309137829 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000025-000018 --seed=14332917660 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000025-000018 --seed=15356697491 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000025-000018 --seed=16380477322 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000025-000018 --seed=17404257153 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000025-000018 --seed=18428036984 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000025-000018 --seed=19451816815 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000024-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000025-000018 --seed=20475596646 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:10:38] eval finished: 10.796 seconds
[2019-06-18 12:10:38] Win rate 000025-000018 vs 000024-000017: 0.600
:::MLL 1560881438.806934 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 24}}
[2019-06-18 12:10:38] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-27-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000026-000017 --seed=27 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000026-000017 --seed=1023779858 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000026-000017 --seed=2047559689 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000026-000017 --seed=3071339520 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000026-000017 --seed=4095119351 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000026-000017 --seed=5118899182 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000026-000017 --seed=6142679013 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000026-000017 --seed=7166458844 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000026-000017 --seed=8190238675 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000026-000017 --seed=9214018506 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000026-000017 --seed=10237798337 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000026-000017 --seed=11261578168 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000026-000017 --seed=12285357999 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000026-000017 --seed=13309137830 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000026-000017 --seed=14332917661 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000026-000017 --seed=15356697492 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000026-000017 --seed=16380477323 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000026-000017 --seed=17404257154 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000026-000017 --seed=18428036985 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:11:08] selfplay finished: 30.146 seconds
[2019-06-18 12:11:08] selfplay mn: 30.165 seconds
[2019-06-18 12:11:08] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-27-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=27 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779858 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559689 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339520 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119351 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899182 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142679013 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458844 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238675 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018506 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798337 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578168 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285357999 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137830 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917661 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697492 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477323 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257154 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036985 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816816 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596647 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376478 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156309 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000026-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golde
[2019-06-18 12:11:12] train finished: 44.239 seconds
:::MLL 1560881433.243263 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881433.244002 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881433.244704 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:33.346816 47391276069760 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_0_0
:::MLL 1560881433.233538 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881433.234451 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881433.235301 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:33.346770 47776913892224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_0_0
W0618 12:10:33.347839 47391276069760 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpame85oa7
W0618 12:10:33.347799 47776913892224 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpvwvc2_nu
I0618 12:10:33.348809 47776913892224 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpvwvc2_nu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7436917e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:33.348838 47391276069760 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpame85oa7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1a6cc33e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:33.349211 47776913892224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:10:33.349244 47391276069760 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:33.354256 47391276069760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:33.354249 47776913892224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881433.260384 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881433.261098 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881433.261738 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:33.367303 47980967650176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_0_0
:::MLL 1560881433.255021 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881433.255925 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881433.256746 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:33.367367 47928182379392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_0_0
W0618 12:10:33.368363 47980967650176 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmplf08ipwe
W0618 12:10:33.368398 47928182379392 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp75mhuqd3
I0618 12:10:33.369364 47980967650176 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmplf08ipwe', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba3b91eae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:33.369405 47928182379392 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp75mhuqd3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b976edf6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:33.369767 47980967650176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:10:33.369815 47928182379392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:33.373713 47776913892224 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:33.374717 47980967650176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:33.373905 47391276069760 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:33.375082 47928182379392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881433.258545 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881433.259476 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881433.260343 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:33.382672 47068201091968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_0_0
:::MLL 1560881433.272143 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881433.272885 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881433.273576 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:33.382733 47678105289600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_0_0
W0618 12:10:33.383760 47068201091968 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpq2sdf3ec
W0618 12:10:33.383792 47678105289600 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpl9q2t87g
I0618 12:10:33.384767 47068201091968 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpq2sdf3ec', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acf33fe5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:33.384801 47678105289600 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpl9q2t87g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5d351dde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:33.385177 47068201091968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:10:33.385206 47678105289600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:33.390199 47068201091968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:33.390224 47678105289600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:33.393887 47980967650176 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:33.394343 47928182379392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:33.409368 47068201091968 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:33.409566 47678105289600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881433.312787 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881433.313298 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881433.313764 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:33.412488 47257831031680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_0_0
W0618 12:10:33.413521 47257831031680 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpd5zu9az1
I0618 12:10:33.414504 47257831031680 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpd5zu9az1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afb5ad18e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:33.414911 47257831031680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881433.313449 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881433.313948 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881433.314345 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:33.416452 47272076841856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_0_0
I0618 12:10:33.417463 47272076841856 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb330/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afeabef5cc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:33.418584 47272076841856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:33.419575 47257831031680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:33.422176 47776913892224 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:10:33.422780 47391276069760 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:10:33.423213 47272076841856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:33.426485 47776913892224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:10:33.427158 47391276069760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:10:33.431561 47776913892224 estimator.py:1111] Calling model_fn.
W0618 12:10:33.431672 47776913892224 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:10:33.432282 47391276069760 estimator.py:1111] Calling model_fn.
W0618 12:10:33.432399 47391276069760 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:10:33.433028 47776913892224 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:10:33.433774 47391276069760 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560881433.346063 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881433.346502 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881433.346872 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:33.436321 47373405606784 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_0_0
:::MLL 1560881433.346711 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881433.347135 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881433.347485 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:33.436441 47922431275904 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_0_0
W0618 12:10:33.437357 47373405606784 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp76z_8yjw
W0618 12:10:33.437471 47922431275904 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmps671_dfw
I0618 12:10:33.438348 47373405606784 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp76z_8yjw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1643999e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:33.438439 47922431275904 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmps671_dfw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9618148dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:33.438745 47373405606784 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:10:33.438830 47922431275904 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:33.438645 47257831031680 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881433.280504 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881433.281238 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881433.281907 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:33.441950 47504399713152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_0_0
W0618 12:10:33.442278 47980967650176 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:10:33.442768 47928182379392 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:10:33.442424 47272076841856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:33.443371 47373405606784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:33.443465 47922431275904 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:33.443118 47504399713152 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp_7qe6d67
I0618 12:10:33.444267 47504399713152 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp_7qe6d67', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b34c3751e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:33.444743 47504399713152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:33.446639 47980967650176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:10:33.447086 47928182379392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560881433.273894 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881433.274803 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881433.275679 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:33.447846 47990071640960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_0_0
W0618 12:10:33.448957 47990071640960 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpvux89wm5
I0618 12:10:33.450047 47990071640960 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpvux89wm5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba5d7c29e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:10:33.450237 47504399713152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:10:33.450487 47990071640960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881433.359268 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881433.359708 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881433.360110 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:33.449761 47106809488256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_0_0
:::MLL 1560881433.360490 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881433.360931 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881433.361302 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:33.450171 47303557546880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_0_0
I0618 12:10:33.451785 47980967650176 estimator.py:1111] Calling model_fn.
W0618 12:10:33.451905 47980967650176 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:10:33.450803 47106809488256 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp3tojomx6
I0618 12:10:33.452145 47928182379392 estimator.py:1111] Calling model_fn.
I0618 12:10:33.451775 47106809488256 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp3tojomx6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad8313bae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:10:33.452255 47928182379392 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:10:33.451179 47303557546880 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp8l2x9i_i
I0618 12:10:33.452148 47303557546880 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp8l2x9i_i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b060054de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:33.452183 47106809488256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:10:33.452544 47303557546880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:33.453270 47980967650176 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:10:33.453620 47928182379392 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:10:33.455736 47990071640960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:33.456874 47106809488256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:33.457129 47303557546880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:33.457553 47068201091968 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:10:33.458141 47678105289600 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:10:33.461858 47068201091968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:10:33.462343 47373405606784 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:33.462622 47922431275904 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:33.462500 47678105289600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:10:33.466900 47068201091968 estimator.py:1111] Calling model_fn.
W0618 12:10:33.467011 47068201091968 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:10:33.467605 47678105289600 estimator.py:1111] Calling model_fn.
W0618 12:10:33.467714 47678105289600 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:10:33.468388 47068201091968 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:10:33.469087 47678105289600 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560881433.307971 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881433.308709 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881433.309412 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:33.470677 46968995799936 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_0_0
:::MLL 1560881433.300556 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881433.301444 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881433.302350 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:33.470725 47459045315456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_0_0
W0618 12:10:33.472239 47504399713152 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:33.471849 46968995799936 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpd5ua5v75
W0618 12:10:33.471880 47459045315456 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpdzhkwyyr
I0618 12:10:33.472966 46968995799936 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpd5ua5v75', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab81ae58e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:33.472971 47459045315456 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpdzhkwyyr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2a341fee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:33.473421 46968995799936 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:10:33.473469 47459045315456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881433.292261 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881433.293183 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881433.294036 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:33.475727 47798129845120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_0_0
W0618 12:10:33.475903 47106809488256 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:33.476277 47303557546880 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:33.476878 47798129845120 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp3a6zwsqa
W0618 12:10:33.476991 47990071640960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:10:33.477939 47798129845120 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp3a6zwsqa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7927233e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:33.478343 47798129845120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:33.478812 46968995799936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:33.478821 47459045315456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881433.298273 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881433.298985 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881433.299658 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:33.482672 47513031082880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_0_0
W0618 12:10:33.483106 47798129845120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:33.483661 47513031082880 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp0h9pilxl
I0618 12:10:33.484726 47513031082880 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp0h9pilxl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b36c5ed4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:33.485174 47513031082880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:33.486182 47257831031680 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:10:33.489884 47513031082880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881433.357180 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881433.357614 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881433.357972 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:33.489637 47085260002176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_0_0
:::MLL 1560881433.353649 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881433.354159 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881433.354587 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:33.489817 47488142173056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000025-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000016-000012.tfrecord.zz_0_0
W0618 12:10:33.490145 47272076841856 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:10:33.490680 47085260002176 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpd5v0ae4r
W0618 12:10:33.490785 47488142173056 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpaiaduq0g
W0618 12:10:33.490506 47257831031680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:10:33.491650 47085260002176 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpd5v0ae4r', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad32cc89da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:33.491753 47488142173056 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpaiaduq0g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b30fa6ebe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:33.492053 47085260002176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:10:33.492150 47488142173056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:33.494498 47272076841856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:10:33.495574 47257831031680 estimator.py:1111] Calling model_fn.
W0618 12:10:33.495683 47257831031680 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:10:33.496705 47085260002176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:33.496801 47488142173056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:33.497032 47257831031680 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:10:33.499580 47272076841856 estimator.py:1111] Calling model_fn.
W0618 12:10:33.499687 47272076841856 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:10:33.500480 46968995799936 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:33.500927 47459045315456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:33.502405 47798129845120 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:33.501043 47272076841856 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:10:33.509171 47513031082880 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be re[2019-06-18 12:11:12] divide_golden_chunk finished: 3.314 seconds
[2019-06-18 12:11:12] generate golden chunk: 3.328 seconds
[2019-06-18 12:11:12] moving /lfs/lfs12/gma_akey/results/epb330/models/000026-000018.meta --> /lfs/lfs12/gma_akey/results/epb330/models/000026-000019.meta
[2019-06-18 12:11:12] moving /lfs/lfs12/gma_akey/results/epb330/models/000026-000018.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb330/models/000026-000019.data-00000-of-00001
[2019-06-18 12:11:12] moving /lfs/lfs12/gma_akey/results/epb330/models/000026-000018.pb --> /lfs/lfs12/gma_akey/results/epb330/models/000026-000019.pb
[2019-06-18 12:11:12] moving /lfs/lfs12/gma_akey/results/epb330/models/000026-000018.index --> /lfs/lfs12/gma_akey/results/epb330/models/000026-000019.index
[2019-06-18 12:11:12] iteration time 25: 49.078 seconds
2019-06-18 12:11:13.727308: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881472.350405 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 26}}
[2019-06-18 12:11:16] minmax time: 3.256 seconds
2019-06-18 12:11:16.993332: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:11:16.998655: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:11:17.003222: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881477.014396 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 25}}
[2019-06-18 12:11:17] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000027-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000027-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000027-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000027-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000027-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000027-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000027-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000027-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000027-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000027-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000027-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:11:17] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-27-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000026-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000026-000019 --seed=27 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000026-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000026-000019 --seed=1023779858 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000026-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000026-000019 --seed=2047559689 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000026-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000026-000019 --seed=3071339520 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000026-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000026-000019 --seed=4095119351 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000026-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000026-000019 --seed=5118899182 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000026-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000026-000019 --seed=6142679013 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000026-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000026-000019 --seed=7166458844 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000026-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000026-000019 --seed=8190238675 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000026-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000026-000019 --seed=9214018506 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000026-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000026-000019 --seed=10237798337 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000026-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000026-000019 --seed=11261578168 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000026-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000026-000019 --seed=12285357999 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000026-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000026-000019 --seed=13309137830 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000026-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000026-000019 --seed=14332917661 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000026-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000026-000019 --seed=15356697492 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000026-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000026-000019 --seed=16380477323 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000026-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000026-000019 --seed=17404257154 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000026-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000026-000019 --seed=18428036985 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000026-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000026-000019 --seed=19451816816 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000026-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000026-000019 --seed=20475596647 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:11:27] eval finished: 10.565 seconds
[2019-06-18 12:11:27] Win rate 000026-000019 vs 000025-000018: 0.260
:::MLL 1560881487.654017 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 25}}
[2019-06-18 12:11:27] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-28-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000027-000018 --seed=28 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000027-000018 --seed=1023779859 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000027-000018 --seed=2047559690 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000027-000018 --seed=3071339521 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000027-000018 --seed=4095119352 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000027-000018 --seed=5118899183 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000027-000018 --seed=6142679014 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000027-000018 --seed=7166458845 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000027-000018 --seed=8190238676 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000027-000018 --seed=9214018507 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000027-000018 --seed=10237798338 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000027-000018 --seed=11261578169 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000027-000018 --seed=12285358000 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000027-000018 --seed=13309137831 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000027-000018 --seed=14332917662 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000027-000018 --seed=15356697493 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000027-000018 --seed=16380477324 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000027-000018 --seed=17404257155 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000027-000018 --seed=18428036986 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:11:57] selfplay finished: 30.309 seconds
[2019-06-18 12:11:57] selfplay mn: 30.327 seconds
[2019-06-18 12:11:57] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-28-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=28 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779859 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559690 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339521 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119352 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899183 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142679014 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458845 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238676 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018507 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798338 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578169 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285358000 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137831 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917662 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697493 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477324 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257155 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036986 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816817 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596648 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376479 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156310 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000027-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golde
[2019-06-18 12:12:00] train finished: 43.851 seconds
:::MLL 1560881482.295999 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881482.296931 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881482.297779 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:22.412738 46923553895296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_0_0
:::MLL 1560881482.306356 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881482.307094 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881482.307779 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:22.414197 47913857549184 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_0_0
W0618 12:11:22.413829 46923553895296 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpfqlkwlar
I0618 12:11:22.414838 46923553895296 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpfqlkwlar', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aad86594e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:22.415248 46923553895296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:22.415165 47913857549184 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpcm6f5vy6
I0618 12:11:22.416317 47913857549184 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpcm6f5vy6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b94190bde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:22.416762 47913857549184 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:22.420253 46923553895296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:22.421426 47913857549184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881482.306106 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881482.306958 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881482.307822 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:22.432004 47597169091456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_0_0
:::MLL 1560881482.323489 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881482.324207 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881482.324903 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:22.432158 48003412681600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_0_0
W0618 12:11:22.433103 47597169091456 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpt20umysb
W0618 12:11:22.433229 48003412681600 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpibudx79z
I0618 12:11:22.434182 47597169091456 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpt20umysb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4a5cf17e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:22.434327 48003412681600 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpibudx79z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba8f2f2ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:22.434638 47597169091456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:11:22.434763 48003412681600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:22.439558 46923553895296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:22.439939 48003412681600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:22.439945 47597169091456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:22.440798 47913857549184 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:22.461603 48003412681600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:22.461653 47597169091456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881482.329377 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881482.330313 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881482.331184 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:22.475344 47454752437120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_0_0
W0618 12:11:22.476424 47454752437120 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpi4z17d6z
I0618 12:11:22.477426 47454752437120 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpi4z17d6z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b29343fae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:22.477831 47454752437120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881482.338200 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881482.338886 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881482.339602 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:22.479218 47233906791296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_0_0
W0618 12:11:22.480299 47233906791296 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpmvo_i4zb
I0618 12:11:22.481292 47233906791296 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpmvo_i4zb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af5c8d28dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:22.481686 47233906791296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:22.482850 47454752437120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881482.386464 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881482.386949 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881482.387354 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:22.486123 47641463329664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_0_0
:::MLL 1560881482.385640 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881482.386159 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881482.386584 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:22.486105 47591487480704 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_0_0
W0618 12:11:22.486299 47233906791296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:22.487155 47641463329664 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpk9lkudcu
W0618 12:11:22.487122 47591487480704 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpgkby6c1n
I0618 12:11:22.488106 47591487480704 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpgkby6c1n', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b490a4afe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:22.488136 47641463329664 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpk9lkudcu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b54ad15de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:11:22.488116 46923553895296 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:11:22.488500 47591487480704 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:11:22.488532 47641463329664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:22.489164 47913857549184 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:11:22.492434 46923553895296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:11:22.493191 47641463329664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:22.493208 47591487480704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881482.395259 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881482.395673 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881482.396023 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:22.492709 47629871162240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_0_0
:::MLL 1560881482.397562 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881482.397968 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881482.398322 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:22.492711 47056510178176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_0_0
W0618 12:11:22.493488 47913857549184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560881482.381363 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881482.382117 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881482.382813 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:22.494287 47535292126080 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_0_0
:::MLL 1560881482.371405 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881482.372311 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881482.373166 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:22.494516 47832631411584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_0_0
W0618 12:11:22.493749 47629871162240 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpqea_6dzb
W0618 12:11:22.493777 47056510178176 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpdu3azs6r
W0618 12:11:22.495356 47535292126080 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp4s1b1p6u
I0618 12:11:22.494743 47629871162240 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpqea_6dzb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b51fa237e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:22.494750 47056510178176 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpdu3azs6r', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acc7b292e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:11:22.495523 47832631411584 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpz_ps0dp8
I0618 12:11:22.496356 47535292126080 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp4s1b1p6u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3bf4c9de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:22.495143 47056510178176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:11:22.495150 47629871162240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:11:22.496698 47832631411584 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpz_ps0dp8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b812f975e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:22.496842 47535292126080 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:11:22.497177 47832631411584 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:11:22.497493 46923553895296 estimator.py:1111] Calling model_fn.
W0618 12:11:22.497607 46923553895296 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:11:22.498539 47913857549184 estimator.py:1111] Calling model_fn.
W0618 12:11:22.498647 47913857549184 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:11:22.498971 46923553895296 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560881482.337063 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881482.337995 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881482.338867 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:22.498958 47796280812416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_0_0
W0618 12:11:22.500010 47913857549184 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:11:22.499850 47629871162240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:22.499845 47056510178176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:22.500106 47796280812416 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpdw8ub_ym
:::MLL 1560881482.342205 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881482.342911 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881482.343644 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:22.500819 47788693406592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_0_0
W0618 12:11:22.501710 47535292126080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:22.501876 47832631411584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:11:22.501219 47796280812416 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpdw8ub_ym', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b78b8ed3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:22.501665 47796280812416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:22.501909 47788693406592 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpdug46ia1
W0618 12:11:22.502309 47454752437120 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:11:22.503026 47788693406592 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpdug46ia1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b76f4ae9e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:22.503508 47788693406592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:22.505788 47233906791296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:22.506977 47796280812416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:22.508773 47788693406592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:22.511216 48003412681600 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:11:22.511244 47597169091456 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:11:22.512358 47591487480704 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:22.512438 47641463329664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:22.515544 48003412681600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:11:22.515580 47597169091456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:11:22.518748 47056510178176 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:22.518891 47629871162240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:22.521096 47535292126080 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:22.521385 47832631411584 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:11:22.520653 48003412681600 estimator.py:1111] Calling model_fn.
I0618 12:11:22.520712 47597169091456 estimator.py:1111] Calling model_fn.
W0618 12:11:22.520761 48003412681600 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:11:22.520825 47597169091456 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:11:22.522117 48003412681600 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:11:22.522186 47597169091456 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:11:22.528524 47796280812416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881482.402632 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881482.403171 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881482.403651 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:22.530012 47142527284096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_0_0
W0618 12:11:22.531064 47788693406592 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881482.408062 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881482.408528 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881482.408940 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:22.530435 47292298109824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_0_0
W0618 12:11:22.531022 47142527284096 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmptaxu_1fm
I0618 12:11:22.532022 47142527284096 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmptaxu_1fm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae0822e0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:11:22.531433 47292298109824 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpzbj7707z
I0618 12:11:22.532414 47142527284096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:11:22.532399 47292298109824 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpzbj7707z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0361377dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:22.532795 47292298109824 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:22.537046 47142527284096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:22.537372 47292298109824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881482.414039 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881482.414445 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881482.414809 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:22.547354 47465573073792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_0_0
:::MLL 1560881482.411901 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881482.412321 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881482.412673 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:22.547347 47303715300224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_0_0
W0618 12:11:22.548422 47465573073792 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpc8jleo5v
W0618 12:11:22.548389 47303715300224 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp1ksgm67r
I0618 12:11:22.549377 47303715300224 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp1ksgm67r', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0609bbfe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:22.549402 47465573073792 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpc8jleo5v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2bb9359e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:22.549771 47303715300224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:11:22.549799 47465573073792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:22.550791 47454752437120 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:11:22.553436 47233906791296 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:11:22.554468 47465573073792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:22.554474 47303715300224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:22.555113 47454752437120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:11:22.556027 47142527284096 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:22.556596 47292298109824 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:22.557767 47233906791296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560881482.468084 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881482.468562 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881482.468965 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:22.560110 47513166668672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_0_0
:::MLL 1560881482.468906 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881482.469334 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881482.469684 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:22.560509 47491373208448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000026-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000017-000013.tfrecord.zz_0_0
W0618 12:11:22.560227 47591487480704 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:11:22.560547 47641463329664 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:11:22.560180 47454752437120 estimator.py:1111] Calling model_fn.
W0618 12:11:22.560290 47454752437120 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:11:22.561136 47513166668672 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpzxkzc3mj
I0618 12:11:22.562121 47513166668672 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpzxkzc3mj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b36ce022e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:11:22.561492 47491373208448 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpo590jbf9
I0618 12:11:22.562465 47491373208448 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpo590jbf9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b31bb046e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:22.562531 47513166668672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:11:22.562867 47491373208448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:22.561655 47454752437120 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:11:22.562846 47233906791296 estimator.py:1111] Calling model_fn.
W0618 12:11:22.562959 47233906791296 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:11:22.564551 47591487480704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:11:22.564301 47233906791296 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:11:22.564900 47641463329664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:11:22.567203 47513166668672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:22.567515 47491373208448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:22.566162 47056510178176 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:11:22.566608 47629871162240 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:11:22.569271 47535292126080 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarr[2019-06-18 12:12:01] divide_golden_chunk finished: 3.320 seconds
[2019-06-18 12:12:01] generate golden chunk: 3.335 seconds
[2019-06-18 12:12:01] iteration time 26: 48.967 seconds
2019-06-18 12:12:02.780407: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881521.317683 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 27}}
[2019-06-18 12:12:06] minmax time: 3.272 seconds
2019-06-18 12:12:06.062218: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:12:06.067795: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:12:06.072476: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881526.085719 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 26}}
[2019-06-18 12:12:06] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000028-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000028-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000028-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000028-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000028-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000028-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000028-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000028-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000028-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000028-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000028-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:12:06] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-28-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000027-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000027-000019 --seed=28 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000027-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000027-000019 --seed=1023779859 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000027-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000027-000019 --seed=2047559690 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000027-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000027-000019 --seed=3071339521 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000027-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000027-000019 --seed=4095119352 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000027-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000027-000019 --seed=5118899183 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000027-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000027-000019 --seed=6142679014 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000027-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000027-000019 --seed=7166458845 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000027-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000027-000019 --seed=8190238676 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000027-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000027-000019 --seed=9214018507 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000027-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000027-000019 --seed=10237798338 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000027-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000027-000019 --seed=11261578169 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000027-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000027-000019 --seed=12285358000 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000027-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000027-000019 --seed=13309137831 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000027-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000027-000019 --seed=14332917662 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000027-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000027-000019 --seed=15356697493 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000027-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000027-000019 --seed=16380477324 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000027-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000027-000019 --seed=17404257155 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000027-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000027-000019 --seed=18428036986 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000027-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000027-000019 --seed=19451816817 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000027-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000027-000019 --seed=20475596648 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:12:16] eval finished: 10.571 seconds
[2019-06-18 12:12:16] Win rate 000027-000019 vs 000025-000018: 0.380
:::MLL 1560881536.728881 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 26}}
[2019-06-18 12:12:16] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-29-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000028-000018 --seed=29 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000028-000018 --seed=1023779860 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000028-000018 --seed=2047559691 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000028-000018 --seed=3071339522 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000028-000018 --seed=4095119353 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000028-000018 --seed=5118899184 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000028-000018 --seed=6142679015 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000028-000018 --seed=7166458846 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000028-000018 --seed=8190238677 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000028-000018 --seed=9214018508 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000028-000018 --seed=10237798339 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000028-000018 --seed=11261578170 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000028-000018 --seed=12285358001 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000028-000018 --seed=13309137832 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000028-000018 --seed=14332917663 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000028-000018 --seed=15356697494 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000028-000018 --seed=16380477325 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000028-000018 --seed=17404257156 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000028-000018 --seed=18428036987 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:12:46] selfplay finished: 29.987 seconds
[2019-06-18 12:12:46] selfplay mn: 30.005 seconds
[2019-06-18 12:12:46] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-29-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=29 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779860 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559691 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339522 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119353 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899184 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142679015 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458846 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238677 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018508 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798339 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578170 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285358001 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137832 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917663 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697494 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477325 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257156 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036987 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816818 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596649 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376480 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156311 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000028-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golde
[2019-06-18 12:12:50] divide_golden_chunk finished: 3.316 seconds
[2019-06-18 12:12:50] generate golden chunk: 3.331 seconds
[2019-06-18 12:12:50] train finished: 44.046 seconds
:::MLL 1560881531.378487 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881531.379371 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881531.380203 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:11.499680 47577708135296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_0_0
:::MLL 1560881531.386403 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881531.387170 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881531.387875 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:11.499943 47511515775872 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_0_0
W0618 12:12:11.500719 47577708135296 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpkcwn2u1x
W0618 12:12:11.500948 47511515775872 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpk9d47whg
I0618 12:12:11.501729 47577708135296 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpkcwn2u1x', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b45d4face48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:11.501945 47511515775872 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpk9d47whg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b366b9b8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:11.502139 47577708135296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:12:11.502345 47511515775872 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:11.507088 47577708135296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:11.507272 47511515775872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881531.397473 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881531.398369 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881531.399206 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:11.518516 47266044171136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_0_0
:::MLL 1560881531.407590 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881531.408339 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881531.409009 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:11.518703 47540865741696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_0_0
W0618 12:12:11.519648 47266044171136 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpcygzmr_9
W0618 12:12:11.519808 47540865741696 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp8excft48
I0618 12:12:11.520754 47266044171136 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpcygzmr_9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afd445c1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:11.520893 47540865741696 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp8excft48', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3d41006e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:11.521198 47266044171136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:12:11.521358 47540865741696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:11.526536 47577708135296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:11.526579 47511515775872 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:11.526489 47266044171136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:11.526689 47540865741696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:11.548343 47266044171136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:11.548938 47540865741696 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881531.469008 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881531.469471 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881531.469898 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:11.566556 47712268817280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_0_0
:::MLL 1560881531.458244 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881531.458820 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881531.459303 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:11.566524 47820143432576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_0_0
W0618 12:12:11.567601 47712268817280 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpuo45lyr9
W0618 12:12:11.567630 47820143432576 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp8s3q2y65
I0618 12:12:11.568613 47712268817280 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpuo45lyr9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b65296bde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:11.568629 47820143432576 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp8s3q2y65', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7e473fde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:11.569015 47712268817280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:12:11.569041 47820143432576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:11.573728 47820143432576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:11.573743 47712268817280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881531.444389 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881531.445144 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881531.445862 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:11.574584 47250275677056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_0_0
:::MLL 1560881531.447162 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881531.447908 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881531.448580 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:11.574819 47899110658944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_0_0
W0618 12:12:11.575241 47577708135296 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:12:11.575521 47511515775872 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:12:11.575632 47250275677056 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpjnwmvzte
W0618 12:12:11.575785 47899110658944 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmplwc8a_bh
I0618 12:12:11.576647 47250275677056 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpjnwmvzte', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af9987c0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:11.576781 47899110658944 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmplwc8a_bh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b90aa102e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:11.577048 47250275677056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:12:11.577182 47899110658944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:11.579554 47577708135296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:12:11.579829 47511515775872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560881531.485096 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881531.485561 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881531.485915 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:11.580390 47312542143360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_0_0
:::MLL 1560881531.483682 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881531.484099 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881531.484587 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:11.580505 47527453795200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_0_0
W0618 12:12:11.581972 47250275677056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:11.581991 47899110658944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:11.581437 47312542143360 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpwm1pydkd
W0618 12:12:11.581512 47527453795200 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp_u86dc4z
I0618 12:12:11.582437 47312542143360 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpwm1pydkd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0817daee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:11.582489 47527453795200 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp_u86dc4z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3a21967e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:11.582845 47312542143360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:12:11.582888 47527453795200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:12:11.584635 47577708135296 estimator.py:1111] Calling model_fn.
W0618 12:12:11.584743 47577708135296 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:12:11.584892 47511515775872 estimator.py:1111] Calling model_fn.
W0618 12:12:11.585000 47511515775872 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:12:11.586111 47577708135296 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:12:11.586365 47511515775872 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:12:11.587594 47527453795200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:11.587596 47312542143360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:11.592682 47820143432576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:11.592865 47712268817280 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881531.428688 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881531.429563 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881531.430410 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:11.598271 47952987542400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_0_0
W0618 12:12:11.599356 47952987542400 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpa2sqax4r
:::MLL 1560881531.444361 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881531.445221 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881531.446103 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:11.601628 47198641931136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_0_0
I0618 12:12:11.600358 47952987542400 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpa2sqax4r', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9d35601e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881531.445092 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881531.446040 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881531.446745 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:11.602003 47407362757504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_0_0
W0618 12:12:11.600943 47266044171136 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:12:11.600845 47952987542400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:11.601265 47250275677056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:11.601356 47899110658944 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:11.601360 47540865741696 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:12:11.602667 47198641931136 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpe4we41zz
I0618 12:12:11.603669 47198641931136 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpe4we41zz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aed92df8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:12:11.603012 47407362757504 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmprahpen75
I0618 12:12:11.604004 47407362757504 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmprahpen75', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1e2b9a7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:11.604075 47198641931136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:12:11.604405 47407362757504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:11.605601 47266044171136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:12:11.606038 47540865741696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:12:11.605929 47952987542400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:11.606626 47312542143360 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:11.606688 47527453795200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:11.608862 47198641931136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:11.609169 47407362757504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:12:11.611069 47266044171136 estimator.py:1111] Calling model_fn.
W0618 12:12:11.611185 47266044171136 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:12:11.611578 47540865741696 estimator.py:1111] Calling model_fn.
W0618 12:12:11.611695 47540865741696 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:12:11.612663 47266044171136 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:12:11.613174 47540865741696 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560881531.429674 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881531.430539 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881531.431245 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:11.621904 47688076268416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_0_0
W0618 12:12:11.622899 47688076268416 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpamyavvem
I0618 12:12:11.623901 47688076268416 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpamyavvem', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5f876eee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:11.624300 47688076268416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:11.626364 47952987542400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:11.628247 47198641931136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:11.628581 47407362757504 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:11.629251 47688076268416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881531.529172 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881531.529731 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881531.530165 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:11.636370 47665751700352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_0_0
W0618 12:12:11.637413 47665751700352 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpakmefv62
I0618 12:12:11.638404 47665751700352 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpakmefv62', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5a54c90e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:11.638818 47665751700352 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:11.640281 47820143432576 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:12:11.640620 47712268817280 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881531.435904 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881531.436601 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881531.437277 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:11.643368 47261054710656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_0_0
:::MLL 1560881531.432996 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881531.433730 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881531.434433 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:11.643968 47817709011840 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_0_0
W0618 12:12:11.643589 47665751700352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:11.644573 47820143432576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:12:11.644933 47712268817280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:12:11.644504 47261054710656 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpnmktvim2
I0618 12:12:11.645609 47261054710656 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpnmktvim2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afc1af70e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:12:11.645085 47817709011840 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpvlkm8veh
I0618 12:12:11.646065 47261054710656 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:12:11.646170 47817709011840 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpvlkm8veh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7db6257e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:11.646647 47817709011840 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:12:11.649637 47820143432576 estimator.py:1111] Calling model_fn.
W0618 12:12:11.649751 47820143432576 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:12:11.648954 47688076268416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:11.649467 47250275677056 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:12:11.649994 47712268817280 estimator.py:1111] Calling model_fn.
W0618 12:12:11.650104 47712268817280 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:12:11.649665 47899110658944 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:12:11.651122 47820143432576 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:12:11.651414 47261054710656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:11.651447 47712268817280 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:12:11.651965 47817709011840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:11.653778 47250275677056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:12:11.653984 47899110658944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:12:11.654184 47312542143360 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:12:11.654630 47527453795200 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881531.528628 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881531.529223 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881531.529700 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:11.657566 46938889741184 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_0_0
:::MLL 1560881531.524651 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881531.525135 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881531.525551 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:11.659003 47348117824384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_0_0
:::MLL 1560881531.521163 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881531.521701 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881531.522111 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:11.658952 47171509240704 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_0_0
W0618 12:12:11.658501 47312542143360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:12:11.658862 47250275677056 estimator.py:1111] Calling model_fn.
W0618 12:12:11.658972 47250275677056 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:12:11.658941 47527453795200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:12:11.659038 47899110658944 estimator.py:1111] Calling model_fn.
W0618 12:12:11.659143 47899110658944 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:12:11.658539 46938889741184 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp1xcy35jw
:::MLL 1560881531.496285 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881531.496803 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881531.497224 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:11.658804 47443980919680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_0_0
W0618 12:12:11.660040 47348117824384 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpw4qcoywe
I0618 12:12:11.659512 46938889741184 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp1xcy35jw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab1186fadd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881531.495965 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881531.496470 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881531.496908 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:11.658847 47840094540672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000027-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000018-000013.tfrecord.zz_0_0
W0618 12:12:11.660012 47171509240704 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp1fkdpva4
I0618 12:12:11.660997 47171509240704 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp1fkdpva4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae741a38e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:11.661028 47348117824384 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpw4qcoywe', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0[2019-06-18 12:12:50] iteration time 27: 48.835 seconds
2019-06-18 12:12:51.629829: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881570.152780 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 28}}
[2019-06-18 12:12:54] minmax time: 3.233 seconds
2019-06-18 12:12:54.872742: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:12:54.878337: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:12:54.883032: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881574.896567 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 27}}
[2019-06-18 12:12:54] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000029-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000029-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000029-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000029-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000029-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000029-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000029-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000029-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000029-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000029-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000029-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:12:54] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-29-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000028-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000028-000019 --seed=29 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000028-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000028-000019 --seed=1023779860 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000028-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000028-000019 --seed=2047559691 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000028-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000028-000019 --seed=3071339522 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000028-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000028-000019 --seed=4095119353 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000028-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000028-000019 --seed=5118899184 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000028-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000028-000019 --seed=6142679015 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000028-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000028-000019 --seed=7166458846 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000028-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000028-000019 --seed=8190238677 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000028-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000028-000019 --seed=9214018508 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000028-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000028-000019 --seed=10237798339 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000028-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000028-000019 --seed=11261578170 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000028-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000028-000019 --seed=12285358001 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000028-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000028-000019 --seed=13309137832 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000028-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000028-000019 --seed=14332917663 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000028-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000028-000019 --seed=15356697494 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000028-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000028-000019 --seed=16380477325 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000028-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000028-000019 --seed=17404257156 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000028-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000028-000019 --seed=18428036987 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000028-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000028-000019 --seed=19451816818 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000028-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000028-000019 --seed=20475596649 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:13:05] eval finished: 10.553 seconds
[2019-06-18 12:13:05] Win rate 000028-000019 vs 000025-000018: 0.430
:::MLL 1560881585.524104 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 27}}
[2019-06-18 12:13:05] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-30-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000029-000018 --seed=30 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000029-000018 --seed=1023779861 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000029-000018 --seed=2047559692 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000029-000018 --seed=3071339523 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000029-000018 --seed=4095119354 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000029-000018 --seed=5118899185 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000029-000018 --seed=6142679016 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000029-000018 --seed=7166458847 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000029-000018 --seed=8190238678 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000029-000018 --seed=9214018509 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000029-000018 --seed=10237798340 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000029-000018 --seed=11261578171 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000029-000018 --seed=12285358002 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000029-000018 --seed=13309137833 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000029-000018 --seed=14332917664 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000029-000018 --seed=15356697495 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000029-000018 --seed=16380477326 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000029-000018 --seed=17404257157 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000029-000018 --seed=18428036988 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:13:35] selfplay finished: 29.768 seconds
[2019-06-18 12:13:35] selfplay mn: 29.790 seconds
[2019-06-18 12:13:35] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-30-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=30 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779861 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559692 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339523 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119354 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899185 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142679016 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458847 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238678 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018509 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798340 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578171 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285358002 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137833 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917664 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697495 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477326 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257157 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036988 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816819 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596650 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376481 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156312 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000029-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golde
[2019-06-18 12:13:38] divide_golden_chunk finished: 3.270 seconds
[2019-06-18 12:13:38] generate golden chunk: 3.285 seconds
[2019-06-18 12:13:38] train finished: 43.771 seconds
:::MLL 1560881580.196043 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881580.196780 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881580.197429 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:00.310937 47602783298432 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_0_0
:::MLL 1560881580.185987 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881580.186883 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881580.187714 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:00.311006 47935720715136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_0_0
W0618 12:13:00.312049 47602783298432 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp63lxh6fk
W0618 12:13:00.312077 47935720715136 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpjbv64650
I0618 12:13:00.313072 47602783298432 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp63lxh6fk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4bab937dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:13:00.313072 47935720715136 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpjbv64650', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9930314e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:13:00.313471 47602783298432 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:13:00.313470 47935720715136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:13:00.318337 47602783298432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:13:00.318359 47935720715136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881580.196135 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881580.197076 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881580.197946 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:00.319363 47065949029248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_0_0
:::MLL 1560881580.208552 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881580.209307 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881580.210002 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:00.319583 47151393047424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_0_0
W0618 12:13:00.320508 47065949029248 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpe695q5nt
W0618 12:13:00.320683 47151393047424 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpk8azz_eb
I0618 12:13:00.321586 47065949029248 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpe695q5nt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aceadc29e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:13:00.321762 47151393047424 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpk8azz_eb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae2929ede48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:13:00.322015 47065949029248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:13:00.322189 47151393047424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:13:00.327336 47065949029248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:13:00.327414 47151393047424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881580.185660 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881580.186388 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881580.187114 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:00.329798 46985168040832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_0_0
:::MLL 1560881580.179259 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881580.180146 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881580.181007 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:00.329853 47328582345600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_0_0
W0618 12:13:00.330922 46985168040832 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpo7rlbiai
W0618 12:13:00.330950 47328582345600 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpikhl005r
I0618 12:13:00.331990 46985168040832 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpo7rlbiai', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abbded68e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881580.210651 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881580.211591 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881580.212451 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:00.332468 48008290362240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_0_0
I0618 12:13:00.332007 47328582345600 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpikhl005r', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0bd3ecfe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:13:00.332420 46985168040832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:13:00.332439 47328582345600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:13:00.333536 48008290362240 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp95uavih5
I0618 12:13:00.334606 48008290362240 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp95uavih5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2baa15ae3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:13:00.335035 48008290362240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:13:00.337773 47328582345600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:13:00.337810 46985168040832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:13:00.337835 47935720715136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:13:00.337978 47602783298432 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:13:00.340105 48008290362240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881580.170638 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881580.171385 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881580.172197 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:00.339529 47024359834496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_0_0
W0618 12:13:00.340676 47024359834496 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpn08qe0_y
I0618 12:13:00.341713 47024359834496 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpn08qe0_y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac4fed9de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:13:00.342128 47024359834496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881580.172243 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881580.172990 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881580.173679 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:00.346354 47846618768256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_0_0
W0618 12:13:00.347036 47024359834496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:13:00.347330 47846618768256 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpvh_8hihl
I0618 12:13:00.348318 47846618768256 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpvh_8hihl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b84714d7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:13:00.348709 47846618768256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:13:00.349371 47065949029248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:13:00.349568 47151393047424 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:13:00.353640 47846618768256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:13:00.359566 48008290362240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:13:00.359420 47328582345600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:13:00.359593 46985168040832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:13:00.366896 47024359834496 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881580.248337 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881580.249188 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881580.250009 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:00.370959 46952927773568 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_0_0
:::MLL 1560881580.279931 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881580.280497 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881580.281014 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:00.371356 47220325421952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_0_0
W0618 12:13:00.371988 46952927773568 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmplb9dy1ek
I0618 12:13:00.372978 46952927773568 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmplb9dy1ek', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab45d2afe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:13:00.373395 46952927773568 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:13:00.372976 47846618768256 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:13:00.372396 47220325421952 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp8j8_efjj
I0618 12:13:00.373451 47220325421952 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp8j8_efjj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af29f4f6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:13:00.373883 47220325421952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:13:00.377994 46952927773568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:13:00.378877 47220325421952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881580.289155 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881580.289694 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881580.290153 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:00.381381 47978480264064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_0_0
W0618 12:13:00.382419 47978480264064 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp11ws2cz0
I0618 12:13:00.383431 47978480264064 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp11ws2cz0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba324dc3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881580.297846 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881580.298302 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881580.298692 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:00.383402 47345021621120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_0_0
I0618 12:13:00.383832 47978480264064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:13:00.384392 47345021621120 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpu6x94bwc
I0618 12:13:00.385375 47345021621120 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpu6x94bwc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0fa7c85dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:13:00.385776 47345021621120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:13:00.386013 47935720715136 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:13:00.386303 47602783298432 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881580.257365 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881580.257903 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881580.258394 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:00.388061 47888618476416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_0_0
:::MLL 1560881580.269578 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881580.269998 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881580.270363 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:00.388129 47214158189440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_0_0
:::MLL 1560881580.299325 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881580.299747 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881580.300111 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:00.387656 47573776614272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_0_0
W0618 12:13:00.388485 47978480264064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:13:00.389118 47888618476416 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp5z7wxbfk
W0618 12:13:00.389149 47214158189440 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpfd8dpxue
W0618 12:13:00.388648 47573776614272 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpxelg7eqi
I0618 12:13:00.390138 47888618476416 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp5z7wxbfk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8e38ae2e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:13:00.390140 47214158189440 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpfd8dpxue', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af12fb6ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:13:00.389634 47573776614272 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpxelg7eqi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b44eaa48dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:13:00.390537 47888618476416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:13:00.390543 47214158189440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:13:00.390029 47573776614272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:13:00.390304 47345021621120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:13:00.390359 47935720715136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:13:00.390653 47602783298432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560881580.241212 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881580.241748 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881580.242248 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:00.393726 47538306995072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_0_0
:::MLL 1560881580.249856 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881580.250306 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881580.250697 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:00.394068 47574964810624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_0_0
W0618 12:13:00.394582 47573776614272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:13:00.395292 47888618476416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:13:00.395274 47214158189440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:13:00.394759 47538306995072 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpjbutwvbq
I0618 12:13:00.395758 47538306995072 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpjbutwvbq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3ca87d2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:13:00.395061 47574964810624 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpvcqyu7i1
I0618 12:13:00.395476 47935720715136 estimator.py:1111] Calling model_fn.
I0618 12:13:00.396051 47574964810624 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpvcqyu7i1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4531770dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:13:00.395587 47935720715136 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:13:00.396179 47538306995072 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:13:00.395784 47602783298432 estimator.py:1111] Calling model_fn.
W0618 12:13:00.395900 47602783298432 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:13:00.396451 47574964810624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:13:00.397871 46952927773568 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:13:00.396956 47935720715136 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:13:00.397274 47602783298432 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:13:00.398098 47220325421952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:13:00.399809 47065949029248 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:13:00.400166 47151393047424 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:13:00.400787 47538306995072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:13:00.401060 47574964810624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:13:00.404260 47065949029248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:13:00.404648 47151393047424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:13:00.407788 48008290362240 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:13:00.407999 46985168040832 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:13:00.407443 47978480264064 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:13:00.408206 47328582345600 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:13:00.409306 47345021621120 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:13:00.409580 47065949029248 estimator.py:1111] Calling model_fn.
W0618 12:13:00.409707 47065949029248 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:13:00.410004 47151393047424 estimator.py:1111] Calling model_fn.
W0618 12:13:00.410121 47151393047424 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:13:00.412193 48008290362240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:13:00.411154 47065949029248 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:13:00.411584 47151393047424 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:13:00.412348 46985168040832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:13:00.412595 47328582345600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:13:00.413689 47573776614272 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:13:00.414456 47888618476416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:13:00.414431 47214158189440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:13:00.415186 47024359834496 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:13:00.417262 48008290362240 estimator.py:1111] Calling model_fn.
W0618 12:13:00.417380 48008290362240 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:13:00.417484 46985168040832 estimator.py:1111] Calling model_fn.
W0618 12:13:00.417612 46985168040832 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:13:00.417789 47328582345600 estimator.py:1111] Calling model_fn.
W0618 12:13:00.417906 47328582345600 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:13:00.418736 48008290362240 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:13:00.419042 46985168040832 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:13:00.419323 47328582345600 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:13:00.419512 47024359834496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:13:00.419660 47538306995072 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:13:00.420108 47846618768256 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:13:00.420308 47574964810624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:13:00.424400 47846618768256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:13:00.424598 47024359834496 estimator.py:1111] Calling model_fn.
W0618 12:13:00.424708 47024359834496 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:13:00.426084 47024359834496 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560881580.313373 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881580.313891 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881580.314368 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:00.428170 46985048540032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_0_0
:::MLL 1560881580.319237 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881580.319695 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881580.320091 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:00.428319 47477258924928 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000028-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000019-000014.tfrecord.zz_0_0
W0618 12:13:00.429200 46985048540032 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpihb1blfo
W0618 12:13:00.429327 47477258924928 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp3fsd185a
I0618 12:13:00.430192 46985048540032 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpihb1blfo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abbd7b71e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:13:00.430319 47477258924928 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp3fsd185a', '_tf_random_seed': None, '_s[2019-06-18 12:13:38] iteration time 28: 48.538 seconds
2019-06-18 12:13:40.244223: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881618.690864 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 29}}
[2019-06-18 12:13:43] minmax time: 3.219 seconds
2019-06-18 12:13:43.473158: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:13:43.478545: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:13:43.483066: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881623.496222 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 28}}
[2019-06-18 12:13:43] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:13:43] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-30-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000029-000019 --seed=30 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000029-000019 --seed=1023779861 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000029-000019 --seed=2047559692 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000029-000019 --seed=3071339523 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000029-000019 --seed=4095119354 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000029-000019 --seed=5118899185 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000029-000019 --seed=6142679016 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000029-000019 --seed=7166458847 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000029-000019 --seed=8190238678 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000029-000019 --seed=9214018509 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000029-000019 --seed=10237798340 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000029-000019 --seed=11261578171 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000029-000019 --seed=12285358002 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000029-000019 --seed=13309137833 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000029-000019 --seed=14332917664 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000029-000019 --seed=15356697495 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000029-000019 --seed=16380477326 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000029-000019 --seed=17404257157 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000029-000019 --seed=18428036988 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000029-000019 --seed=19451816819 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000025-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000029-000019 --seed=20475596650 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:13:55] eval finished: 11.876 seconds
[2019-06-18 12:13:55] Win rate 000029-000019 vs 000025-000018: 0.560
:::MLL 1560881635.444337 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 28}}
[2019-06-18 12:13:55] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-31-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000030-000018 --seed=31 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000030-000018 --seed=1023779862 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000030-000018 --seed=2047559693 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000030-000018 --seed=3071339524 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000030-000018 --seed=4095119355 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000030-000018 --seed=5118899186 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000030-000018 --seed=6142679017 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000030-000018 --seed=7166458848 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000030-000018 --seed=8190238679 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000030-000018 --seed=9214018510 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000030-000018 --seed=10237798341 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000030-000018 --seed=11261578172 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000030-000018 --seed=12285358003 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000030-000018 --seed=13309137834 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000030-000018 --seed=14332917665 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000030-000018 --seed=15356697496 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000030-000018 --seed=16380477327 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000030-000018 --seed=17404257158 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000030-000018 --seed=18428036989 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:14:24] selfplay finished: 29.533 seconds
[2019-06-18 12:14:24] selfplay mn: 29.552 seconds
[2019-06-18 12:14:24] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-31-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=31 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779862 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559693 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339524 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119355 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899186 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142679017 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458848 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238679 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018510 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798341 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578172 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285358003 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137834 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917665 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697496 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477327 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257158 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036989 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816820 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596651 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376482 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156313 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golde
[2019-06-18 12:14:27] train finished: 43.800 seconds
:::MLL 1560881628.719051 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881628.719946 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881628.720800 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:48.837530 47908946711424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_0_0
W0618 12:13:48.838649 47908946711424 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp69b_zaqj
I0618 12:13:48.839684 47908946711424 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp69b_zaqj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b92f4566e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:13:48.840180 47908946711424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:13:48.845058 47908946711424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881628.752474 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881628.753270 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881628.754017 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:48.845253 47408441312128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_0_0
W0618 12:13:48.846260 47408441312128 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp1zfiuqq7
I0618 12:13:48.847304 47408441312128 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp1zfiuqq7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1e6be41e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:13:48.847750 47408441312128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:13:48.852360 47408441312128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:13:48.864653 47908946711424 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:13:48.871748 47408441312128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881628.785039 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881628.785737 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881628.786426 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:48.902264 47910631330688 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_0_0
:::MLL 1560881628.788165 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881628.788920 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881628.789614 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:48.902411 46993165804416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_0_0
W0618 12:13:48.903309 47910631330688 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp_t4m6x0e
W0618 12:13:48.903403 46993165804416 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp47a9hcjo
I0618 12:13:48.904336 47910631330688 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp_t4m6x0e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9358bfae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:13:48.904397 46993165804416 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp47a9hcjo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abdbb8abdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:13:48.904748 47910631330688 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:13:48.904801 46993165804416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:13:48.909700 47910631330688 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:13:48.909722 46993165804416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881628.796602 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881628.797320 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881628.798016 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:48.911395 47868978262912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_0_0
W0618 12:13:48.913101 47908946711424 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881628.764641 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881628.765367 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881628.766032 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:48.913941 47333361103744 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_0_0
W0618 12:13:48.912592 47868978262912 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpumm8pond
:::MLL 1560881628.767199 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881628.767895 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881628.768578 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:48.914110 47933669659520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_0_0
I0618 12:13:48.913736 47868978262912 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpumm8pond', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b89a6083e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:13:48.914172 47868978262912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881628.799293 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881628.800026 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881628.800690 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:48.914274 47620417213312 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_0_0
W0618 12:13:48.915054 47333361103744 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmps74roop1
W0618 12:13:48.915168 47933669659520 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp89tk187n
I0618 12:13:48.916184 47333361103744 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmps74roop1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0cf0c30e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:13:48.916292 47933669659520 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp89tk187n', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b98b5f09da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:13:48.916627 47333361103744 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:13:48.916724 47933669659520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:13:48.915329 47620417213312 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpxrlkd66r
I0618 12:13:48.916450 47620417213312 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpxrlkd66r', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4fc6a3ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:13:48.916912 47620417213312 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:13:48.917432 47908946711424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:13:48.919489 47408441312128 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881628.820072 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881628.820535 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881628.820939 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:48.919486 46978114827136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_0_0
W0618 12:13:48.919347 47868978262912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:13:48.920515 46978114827136 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp30zjgl2q
I0618 12:13:48.921512 46978114827136 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp30zjgl2q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aba3a6f0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:13:48.921905 47933669659520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:13:48.921923 47333361103744 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:13:48.921955 46978114827136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:13:48.921869 47620417213312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:13:48.922667 47908946711424 estimator.py:1111] Calling model_fn.
W0618 12:13:48.922779 47908946711424 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:13:48.923775 47408441312128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:13:48.924159 47908946711424 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560881628.820198 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881628.820654 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881628.821053 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:48.926261 47082064384896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_0_0
W0618 12:13:48.926736 46978114827136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:13:48.927241 47082064384896 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp3rm_99ld
W0618 12:13:48.928786 47910631330688 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:13:48.928225 47082064384896 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp3rm_99ld', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad26e4f6dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:13:48.929088 46993165804416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:13:48.928617 47082064384896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:13:48.928852 47408441312128 estimator.py:1111] Calling model_fn.
W0618 12:13:48.928964 47408441312128 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:13:48.930318 47408441312128 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:13:48.933163 47082064384896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:13:48.940675 47868978262912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:13:48.943193 47333361103744 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:13:48.943295 47933669659520 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:13:48.943745 47620417213312 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:13:48.946007 46978114827136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:13:48.952303 47082064384896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881628.841597 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881628.842059 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881628.842468 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:48.970207 47806198236032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_0_0
:::MLL 1560881628.841749 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881628.842216 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881628.842609 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:48.970533 47234098938752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_0_0
W0618 12:13:48.971217 47806198236032 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp73nd124o
I0618 12:13:48.972207 47806198236032 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp73nd124o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7b080d1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:13:48.971514 47234098938752 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmppp1kh78u
I0618 12:13:48.972501 47234098938752 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmppp1kh78u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af5d4469e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:13:48.972608 47806198236032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:13:48.972900 47234098938752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:13:48.976657 47910631330688 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:13:48.977356 46993165804416 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:13:48.977205 47806198236032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:13:48.977445 47234098938752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881628.820123 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881628.821064 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881628.821926 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:48.976855 46916365362048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_0_0
:::MLL 1560881628.826792 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881628.827515 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881628.828177 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:48.977057 47229566006144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_0_0
:::MLL 1560881628.882353 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881628.882759 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881628.883107 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:48.979853 47841181463424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_0_0
:::MLL 1560881628.880040 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881628.880455 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881628.880802 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:48.979800 47454369780608 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_0_0
W0618 12:13:48.977983 46916365362048 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpz3zbh6gt
W0618 12:13:48.978147 47229566006144 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpkuqfgndz
:::MLL 1560881628.803373 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881628.804284 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881628.804994 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:48.979184 47326907483008 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_0_0
I0618 12:13:48.979080 46916365362048 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpz3zbh6gt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aabd9e0fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:13:48.979214 47229566006144 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpkuqfgndz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af4c6178e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:13:48.980982 47910631330688 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:13:48.979482 46916365362048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:13:48.979620 47229566006144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:13:48.980850 47841181463424 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp137iloa9
W0618 12:13:48.980801 47454369780608 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp2kykg2i5
W0618 12:13:48.981690 46993165804416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:13:48.981806 47454369780608 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp2kykg2i5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b291d70ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:13:48.981830 47841181463424 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp137iloa9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b832d36ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:13:48.982203 47454369780608 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:13:48.980233 47326907483008 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpq2djink_
I0618 12:13:48.982231 47841181463424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:13:48.981234 47326907483008 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpq2djink_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0b70188e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881628.802490 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881628.803371 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881628.804206 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:48.981294 48009323438976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_0_0
I0618 12:13:48.981646 47326907483008 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881628.886653 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881628.887038 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881628.887368 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:48.982438 47073064235904 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_0_0
W0618 12:13:48.982303 48009323438976 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpod5u38zl
I0618 12:13:48.983300 48009323438976 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpod5u38zl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2baa5341ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:13:48.983697 48009323438976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881628.888304 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881628.888933 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881628.889254 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:13:48.983966 47174687634304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000029-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000020-000015.tfrecord.zz_0_0
W0618 12:13:48.983467 47073064235904 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpb7699obn
I0618 12:13:48.984444 47073064235904 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpb7699obn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad055dbfe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:13:48.984229 46916365362048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:13:48.984236 47229566006144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:13:48.984840 47073064235904 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:13:48.986094 47910631330688 estimator.py:1111] Calling model_fn.
W0618 12:13:48.986207 47910631330688 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:13:48.986875 47841181463424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:13:48.984965 47174687634304 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp75jvdugw
W0618 12:13:48.986847 47454369780608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:13:48.986860 46993165804416 estimator.py:1111] Calling model_fn.
W0618 12:13:48.986970 46993165804416 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:13:48.985952 47174687634304 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp75jvdugw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae7ff15de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:13:48.987576 47910631330688 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:13:48.986352 47174687634304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:13:48.986690 47326907483008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:13:48.988348 46993165804416 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:13:48.988766 48009323438976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:13:48.989480 47073064235904 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:13:48.991296 47933669659520 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:13:48.990778 47868978262912 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:13:48.991619 47333361103744 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:13:48.990935 47174687634304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:13:48.993376 47620417213312 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:13:48.994085 46978114827136 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:13:48.995567 47933669659520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:13:48.995145 47868978262912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:13:48.995946 47333361103744 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:13:48.996238 47806198236032 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:13:48.996532 47234098938752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:13:48.997756 47620417213312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:13:48.998431 46978114827136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:13:48.999108 47082064384896 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:13:49.000648 47933669659520 estimator.py:1111] Calling model_fn.
W0618 12:13:49.000763 47933669659520 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:13:49.000208 47868978262912 estimator.py:1111] Calling model_fn.
W0618 12:13:49.000322 47868978262912 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:13:49.001060 47333361103744 estimator.py:1111] Calling model_fn.
W0618 12:13:49.001168 47333361103744 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:13:49.002125 47933669659520 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:13:49.001672 47868978262912 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:13:49.002528 47333361103744 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:13:49.002830 47620417213312 estimator.py:1111] Calling model_fn.
W0618 12:13:49.002941 47620417213312 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:13:49.003384 47082064384896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort,[2019-06-18 12:14:28] divide_golden_chunk finished: 3.301 seconds
[2019-06-18 12:14:28] generate golden chunk: 3.316 seconds
[2019-06-18 12:14:28] moving /lfs/lfs12/gma_akey/results/epb330/models/000030-000019.index --> /lfs/lfs12/gma_akey/results/epb330/models/000030-000020.index
[2019-06-18 12:14:28] moving /lfs/lfs12/gma_akey/results/epb330/models/000030-000019.pb --> /lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb
[2019-06-18 12:14:28] moving /lfs/lfs12/gma_akey/results/epb330/models/000030-000019.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb330/models/000030-000020.data-00000-of-00001
[2019-06-18 12:14:28] moving /lfs/lfs12/gma_akey/results/epb330/models/000030-000019.meta --> /lfs/lfs12/gma_akey/results/epb330/models/000030-000020.meta
[2019-06-18 12:14:28] iteration time 29: 49.665 seconds
2019-06-18 12:14:29.908479: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881668.356193 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 30}}
[2019-06-18 12:14:33] minmax time: 3.264 seconds
2019-06-18 12:14:33.182535: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:14:33.188000: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:14:33.192668: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881673.204226 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 29}}
[2019-06-18 12:14:33] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000031-000020 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000031-000020 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000031-000020 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb103 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000031-000020 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000031-000020 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000031-000020 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000031-000020 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb105 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000031-000020 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000031-000020 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000031-000020 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb330/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb330/models/000031-000020 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb108 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:14:33] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-eval-31-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000030-000020 --seed=31 : \
-host epb255 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000030-000020 --seed=1023779862 : \
-host epb288 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000030-000020 --seed=2047559693 : \
-host epb286 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000030-000020 --seed=3071339524 : \
-host epb158 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000030-000020 --seed=4095119355 : \
-host epb282 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000030-000020 --seed=5118899186 : \
-host epb280 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000030-000020 --seed=6142679017 : \
-host epb137 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000030-000020 --seed=7166458848 : \
-host epb164 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000030-000020 --seed=8190238679 : \
-host epb159 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000030-000020 --seed=9214018510 : \
-host epb331 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000030-000020 --seed=10237798341 : \
-host epb295 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000030-000020 --seed=11261578172 : \
-host epb150 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000030-000020 --seed=12285358003 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000030-000020 --seed=13309137834 : \
-host epb289 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000030-000020 --seed=14332917665 : \
-host epb297 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000030-000020 --seed=15356697496 : \
-host epb285 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000030-000020 --seed=16380477327 : \
-host epb281 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000030-000020 --seed=17404257158 : \
-host epb294 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000030-000020 --seed=18428036989 : \
-host epb290 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000030-000020 --seed=19451816820 : \
-host epb115 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/000030-000020 --seed=20475596651 : \
-host epb296 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:14:44] eval finished: 11.603 seconds
[2019-06-18 12:14:44] Win rate 000030-000020 vs 000029-000019: 0.600
:::MLL 1560881684.879618 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 29}}
[2019-06-18 12:14:44] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-selfplay-32-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb330 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000031-000019 --seed=32 : \
-host epb255 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000031-000019 --seed=1023779863 : \
-host epb288 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000031-000019 --seed=2047559694 : \
-host epb286 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000031-000019 --seed=3071339525 : \
-host epb158 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000031-000019 --seed=4095119356 : \
-host epb282 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000031-000019 --seed=5118899187 : \
-host epb280 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000031-000019 --seed=6142679018 : \
-host epb137 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000031-000019 --seed=7166458849 : \
-host epb164 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000031-000019 --seed=8190238680 : \
-host epb159 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000031-000019 --seed=9214018511 : \
-host epb331 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000031-000019 --seed=10237798342 : \
-host epb295 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000031-000019 --seed=11261578173 : \
-host epb150 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000031-000019 --seed=12285358004 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000031-000019 --seed=13309137835 : \
-host epb289 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000031-000019 --seed=14332917666 : \
-host epb297 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000031-000019 --seed=15356697497 : \
-host epb285 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000031-000019 --seed=16380477328 : \
-host epb281 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000031-000019 --seed=17404257159 : \
-host epb294 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb330/data/holdout/000031-000019 --seed=18428036990 : \
-host epb290 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb330/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000030-000020.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb33
[2019-06-18 12:15:14] selfplay finished: 29.128 seconds
[2019-06-18 12:15:14] selfplay mn: 29.150 seconds
[2019-06-18 12:15:14] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb330/mpi/out-divide_golden_chunk-32-%r.txt \
-host epb330 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=32 : \
-host epb255 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=1023779863 : \
-host epb288 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=2047559694 : \
-host epb286 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=3071339525 : \
-host epb158 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=4095119356 : \
-host epb282 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=5118899187 : \
-host epb280 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=6142679018 : \
-host epb137 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=7166458849 : \
-host epb164 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=8190238680 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=9214018511 : \
-host epb331 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=10237798342 : \
-host epb295 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=11261578173 : \
-host epb150 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=12285358004 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=13309137835 : \
-host epb289 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=14332917666 : \
-host epb297 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=15356697497 : \
-host epb285 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=16380477328 : \
-host epb281 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=17404257159 : \
-host epb294 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=18428036990 : \
-host epb290 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=19451816821 : \
-host epb115 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=20475596652 : \
-host epb296 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=21499376483 : \
-host epb117 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb330 --seed=22523156314 : \
-host epb293 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb330/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb330/data/golde
[2019-06-18 12:15:17] divide_golden_chunk finished: 3.271 seconds
[2019-06-18 12:15:17] generate golden chunk: 3.285 seconds
[2019-06-18 12:15:17] train finished: 44.176 seconds
:::MLL 1560881678.488982 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881678.489873 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881678.490728 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:14:38.642850 47026237076352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_0_0
W0618 12:14:38.643930 47026237076352 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpyz04wtur
I0618 12:14:38.644957 47026237076352 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpyz04wtur', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac56ebe4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:14:38.645381 47026237076352 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881678.494109 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881678.494853 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881678.495519 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:14:38.649682 47139553715072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_0_0
W0618 12:14:38.650468 47026237076352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:14:38.650655 47139553715072 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpqlks06ik
I0618 12:14:38.651641 47139553715072 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpqlks06ik', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adfd0f0ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:14:38.652038 47139553715072 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881678.507808 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881678.508526 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881678.509264 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:14:38.656280 47774945682304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_0_0
W0618 12:14:38.656919 47139553715072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881678.496764 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881678.497638 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881678.498517 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:14:38.657393 47555585315712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_0_0
W0618 12:14:38.657439 47774945682304 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpukydyguh
I0618 12:14:38.658560 47774945682304 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpukydyguh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b73c140ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:14:38.659012 47774945682304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:14:38.658529 47555585315712 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpolm4lpcu
I0618 12:14:38.659659 47555585315712 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpolm4lpcu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b40ae5b4dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:14:38.660119 47555585315712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:14:38.664378 47774945682304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:14:38.665446 47555585315712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:14:38.670287 47026237076352 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881678.499128 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881678.500015 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881678.500819 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:14:38.673825 47495956325248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_0_0
:::MLL 1560881678.500176 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881678.501040 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881678.501761 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:14:38.674042 47063071216512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_0_0
W0618 12:14:38.674935 47495956325248 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpm0u03brm
W0618 12:14:38.675147 47063071216512 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpf7y_erfm
I0618 12:14:38.676069 47495956325248 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpm0u03brm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b32cc313e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:14:38.676254 47063071216512 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpf7y_erfm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ace023aada0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:14:38.676521 47495956325248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:14:38.676703 47063071216512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:14:38.676554 47139553715072 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:14:38.681851 47063071216512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:14:38.681848 47495956325248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881678.530588 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881678.531481 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881678.532341 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:14:38.681687 47276670944128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_0_0
W0618 12:14:38.682802 47276670944128 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpfi6f5bad
I0618 12:14:38.683805 47276670944128 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpfi6f5bad', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2affbdc3ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:14:38.684217 47276670944128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:14:38.686115 47774945682304 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:14:38.687801 47555585315712 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:14:38.689206 47276670944128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881678.531831 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881678.532677 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881678.533431 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:14:38.695264 47949110559616 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_0_0
W0618 12:14:38.696294 47949110559616 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpu8coa2zp
I0618 12:14:38.697284 47949110559616 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpu8coa2zp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9c4e4a1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:14:38.697682 47949110559616 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:14:38.702544 47949110559616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:14:38.703560 47063071216512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:14:38.703750 47495956325248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881678.560707 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881678.561247 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881678.561688 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:14:38.707288 47276568363904 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_0_0
:::MLL 1560881678.560480 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881678.560994 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881678.561442 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:14:38.707604 48010034684800 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_0_0
W0618 12:14:38.708441 47276670944128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:14:38.708327 47276568363904 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpm7mdz6qa
W0618 12:14:38.708586 48010034684800 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp4996f3nh
I0618 12:14:38.709318 47276568363904 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpm7mdz6qa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2affb7a69e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:14:38.709575 48010034684800 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp4996f3nh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2baa7da66dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:14:38.709724 47276568363904 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:14:38.709978 48010034684800 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:14:38.714343 47276568363904 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:14:38.714546 48010034684800 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881678.582416 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881678.582896 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881678.583378 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:14:38.714213 47655498539904 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_0_0
:::MLL 1560881678.582932 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881678.583803 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881678.584661 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:14:38.714164 47108884923264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_0_0
:::MLL 1560881678.588601 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881678.589353 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881678.590068 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:14:38.714478 47062675440512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_0_0
:::MLL 1560881678.589509 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881678.589936 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881678.590307 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:14:38.714981 47722409710464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_0_0
W0618 12:14:38.715258 47655498539904 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpwzn9wvxr
I0618 12:14:38.716252 47655498539904 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpwzn9wvxr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b57f1a63e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:14:38.715204 47108884923264 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp2gw94rbe
W0618 12:14:38.715487 47062675440512 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpstf0el7q
I0618 12:14:38.716236 47108884923264 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp2gw94rbe', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad8acf05dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:14:38.716652 47655498539904 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:14:38.715975 47722409710464 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmprldzc6xv
I0618 12:14:38.716533 47062675440512 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpstf0el7q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acdeaa38e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:14:38.716966 47722409710464 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmprldzc6xv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6785ddae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:14:38.716715 47108884923264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:14:38.716983 47062675440512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:14:38.717362 47722409710464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:14:38.718404 47026237076352 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:14:38.721292 47655498539904 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:14:38.721912 47722409710464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:14:38.721954 47949110559616 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:14:38.721618 47108884923264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:14:38.721764 47062675440512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:14:38.722705 47026237076352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:14:38.724361 47139553715072 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881678.580420 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881678.581012 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881678.581456 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:14:38.727032 47932432462720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_0_0
I0618 12:14:38.727759 47026237076352 estimator.py:1111] Calling model_fn.
W0618 12:14:38.727878 47026237076352 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:14:38.728039 47932432462720 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpserb34zf
W0618 12:14:38.728700 47139553715072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560881678.583755 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881678.584187 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881678.584564 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:14:38.728777 47398512518016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_0_0
I0618 12:14:38.729041 47932432462720 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpserb34zf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b986c328e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:14:38.729443 47932432462720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:14:38.729241 47026237076352 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:14:38.729756 47398512518016 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpueq62kcc
I0618 12:14:38.730744 47398512518016 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpueq62kcc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1c1c16ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:14:38.731148 47398512518016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:14:38.733168 47276568363904 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:14:38.733470 48010034684800 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:14:38.733816 47139553715072 estimator.py:1111] Calling model_fn.
W0618 12:14:38.733928 47139553715072 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:14:38.734095 47932432462720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:14:38.735291 47139553715072 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:14:38.735707 47398512518016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:14:38.735678 47774945682304 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:14:38.736418 47555585315712 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:14:38.739994 47774945682304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:14:38.740139 47655498539904 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:14:38.740719 47555585315712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:14:38.740888 47722409710464 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:14:38.741007 47108884923264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:14:38.741090 47062675440512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:14:38.745102 47774945682304 estimator.py:1111] Calling model_fn.
W0618 12:14:38.745210 47774945682304 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:14:38.745773 47555585315712 estimator.py:1111] Calling model_fn.
W0618 12:14:38.745881 47555585315712 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:14:38.746597 47774945682304 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:14:38.747249 47555585315712 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:14:38.752866 47932432462720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881678.610472 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881678.611121 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881678.611663 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:14:38.753163 47032008881024 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_0_0
W0618 12:14:38.754786 47398512518016 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:14:38.754243 47032008881024 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmper3myhbe
I0618 12:14:38.755301 47032008881024 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmper3myhbe', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac6c6c4fdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:14:38.755732 47032008881024 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881678.630883 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881678.631344 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881678.631740 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:14:38.755637 47502832702336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_0_0
W0618 12:14:38.756061 47276670944128 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:14:38.756883 47063071216512 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:14:38.757310 47495956325248 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:14:38.756658 47502832702336 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp4mvcbqbc
I0618 12:14:38.757692 47502832702336 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp4mvcbqbc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b34660e6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:14:38.758103 47502832702336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:14:38.760359 47276670944128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:14:38.760545 47032008881024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:14:38.761758 47063071216512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:14:38.762251 47495956325248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:14:38.762664 47502832702336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:14:38.765420 47276670944128 estimator.py:1111] Calling model_fn.
W0618 12:14:38.765531 47276670944128 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:14:38.766900 47276670944128 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:14:38.767473 47063071216512 estimator.py:1111] Calling model_fn.
W0618 12:14:38.767593 47063071216512 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560881678.533219 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881678.534049 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881678.534740 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:14:38.768043 47918177272704 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_0_0
:::MLL 1560881678.536859 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881678.537563 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881678.538248 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:14:38.768062 47304576848768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/000021-000015.tfrecord.zz_0_0
I0618 12:14:38.768029 47495956325248 estimator.py:1111] Calling model_fn.
W0618 12:14:38.768150 47495956325248 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:14:38.769126 47063071216512 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:14:38.769126 47918177272704 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmpdsbk0dqs
W0618 12:14:38.769159 47304576848768 estimator.py:1760] Using temporary folder as model directory: /tmp/96733.tmpdir/tmp_bn71r3c
I0618 12:14:38.770212 47918177272704 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmpdsbk0dqs', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b951a859e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:14:38.769685 47495956325248 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:14:38.770237 47304576848768 estimator.py:201] Using config: {'_model_dir': '/tmp/96733.tmpdir/tmp_bn71r3c', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b063d162e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:14:38.769215 47949110559616 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:14:38.770665 47918177272704 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:14:38.770680 47304576848768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:14:38.773506 47949110559616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:14:38.775477 47918177272704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:14:38.775510 47304576848768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:14:38.778545 47949110559616 estimator.py:1111] Calling model_fn.
W0618 12:14:38.778656 47949110559616 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:14:38.779384 47032008881024 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:14:38.780148 47276568363904 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy[2019-06-18 12:15:17] moving /lfs/lfs12/gma_akey/results/epb330/models/000031-000020.index --> /lfs/lfs12/gma_akey/results/epb330/models/000031-000021.index
[2019-06-18 12:15:17] moving /lfs/lfs12/gma_akey/results/epb330/models/000031-000020.pb --> /lfs/lfs12/gma_akey/results/epb330/models/000031-000021.pb
[2019-06-18 12:15:17] moving /lfs/lfs12/gma_akey/results/epb330/models/000031-000020.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb330/models/000031-000021.data-00000-of-00001
[2019-06-18 12:15:17] moving /lfs/lfs12/gma_akey/results/epb330/models/000031-000020.meta --> /lfs/lfs12/gma_akey/results/epb330/models/000031-000021.meta
[2019-06-18 12:15:17] iteration time 30: 49.095 seconds
:::MLL 1560881717.451001 epoch_stop: {"value": null, "metadata": {'lineno': 737, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 30}}
[2019-06-18 12:15:17] Total time: 1702.847 seconds

numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000018-000015_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000018-000015log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000019-000016_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000019-000016log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000020-000016_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000020-000016log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000021-000017_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000021-000017log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000022-000017_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000022-000017log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000023-000017_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000023-000017log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000024-000017_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000024-000017log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000025-000018_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000025-000018log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000026-000019_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000026-000019log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000027-000019_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000027-000019log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000028-000019_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000028-000019log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000029-000019_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000029-000019log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb330/models/000030-000020_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb330/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb330/models/000030-000020log.txt
:::MLL 1560881720.064995 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 0}}
I0618 12:15:20.065937 47046246794112 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/target --seed=1
I0618 12:15:46.858528 47046246794112 utils.py:86] eval finished: 26.791 seconds
I0618 12:15:46.862032 47046246794112 reference_implementation.py:563] Win rate 000001-000001 vs target: 0.040
:::MLL 1560881746.862717 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 0}}
:::MLL 1560881746.863053 eval_accuracy: {"value": 0.04, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 0}}
:::MLL 1560881746.863389 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 1}}
I0618 12:15:46.863689 47046246794112 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/target --seed=2
I0618 12:16:14.474520 47046246794112 utils.py:86] eval finished: 27.611 seconds
I0618 12:16:14.477409 47046246794112 reference_implementation.py:563] Win rate 000002-000002 vs target: 0.070
:::MLL 1560881774.478454 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 1}}
:::MLL 1560881774.478822 eval_accuracy: {"value": 0.07, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 1}}
:::MLL 1560881774.479155 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 2}}
I0618 12:16:14.479480 47046246794112 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/target --seed=3
I0618 12:16:41.286719 47046246794112 utils.py:86] eval finished: 26.807 seconds
I0618 12:16:41.289611 47046246794112 reference_implementation.py:563] Win rate 000003-000003 vs target: 0.050
:::MLL 1560881801.290305 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 2}}
:::MLL 1560881801.290633 eval_accuracy: {"value": 0.05, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 2}}
:::MLL 1560881801.290970 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 3}}
I0618 12:16:41.291267 47046246794112 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000004-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/target --seed=4
I0618 12:17:08.940639 47046246794112 utils.py:86] eval finished: 27.649 seconds
I0618 12:17:08.943521 47046246794112 reference_implementation.py:563] Win rate 000004-000004 vs target: 0.070
:::MLL 1560881828.944209 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 3}}
:::MLL 1560881828.944536 eval_accuracy: {"value": 0.07, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 3}}
:::MLL 1560881828.944870 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 4}}
I0618 12:17:08.945161 47046246794112 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000005-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/target --seed=5
I0618 12:17:37.030372 47046246794112 utils.py:86] eval finished: 28.085 seconds
I0618 12:17:37.033211 47046246794112 reference_implementation.py:563] Win rate 000005-000005 vs target: 0.050
:::MLL 1560881857.037987 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 4}}
:::MLL 1560881857.038325 eval_accuracy: {"value": 0.05, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 4}}
:::MLL 1560881857.038668 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 5}}
I0618 12:17:37.039021 47046246794112 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000006-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/target --seed=6
I0618 12:18:03.059465 47046246794112 utils.py:86] eval finished: 26.020 seconds
I0618 12:18:03.062430 47046246794112 reference_implementation.py:563] Win rate 000006-000005 vs target: 0.050
:::MLL 1560881883.063078 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 5}}
:::MLL 1560881883.063390 eval_accuracy: {"value": 0.05, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 5}}
:::MLL 1560881883.063696 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 6}}
I0618 12:18:03.064037 47046246794112 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000007-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/target --seed=7
I0618 12:18:32.613374 47046246794112 utils.py:86] eval finished: 29.549 seconds
I0618 12:18:32.616277 47046246794112 reference_implementation.py:563] Win rate 000007-000006 vs target: 0.120
:::MLL 1560881912.624473 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 6}}
:::MLL 1560881912.624820 eval_accuracy: {"value": 0.12, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 6}}
:::MLL 1560881912.625146 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 7}}
I0618 12:18:32.625459 47046246794112 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000008-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/target --seed=8
I0618 12:18:58.004825 47046246794112 utils.py:86] eval finished: 25.379 seconds
I0618 12:18:58.007742 47046246794112 reference_implementation.py:563] Win rate 000008-000007 vs target: 0.180
:::MLL 1560881938.012646 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 7}}
:::MLL 1560881938.012993 eval_accuracy: {"value": 0.18, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 7}}
:::MLL 1560881938.013317 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 8}}
I0618 12:18:58.013633 47046246794112 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000009-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/target --seed=9
I0618 12:19:25.295759 47046246794112 utils.py:86] eval finished: 27.282 seconds
I0618 12:19:25.298569 47046246794112 reference_implementation.py:563] Win rate 000009-000008 vs target: 0.220
:::MLL 1560881965.299234 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 8}}
:::MLL 1560881965.299544 eval_accuracy: {"value": 0.22, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 8}}
:::MLL 1560881965.299870 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 9}}
I0618 12:19:25.300179 47046246794112 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000010-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/target --seed=10
I0618 12:19:52.220423 47046246794112 utils.py:86] eval finished: 26.920 seconds
I0618 12:19:52.223380 47046246794112 reference_implementation.py:563] Win rate 000010-000009 vs target: 0.160
:::MLL 1560881992.224046 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 9}}
:::MLL 1560881992.224357 eval_accuracy: {"value": 0.16, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 9}}
:::MLL 1560881992.224661 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 10}}
I0618 12:19:52.224971 47046246794112 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000011-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/target --seed=11
I0618 12:20:19.822020 47046246794112 utils.py:86] eval finished: 27.597 seconds
I0618 12:20:19.824875 47046246794112 reference_implementation.py:563] Win rate 000011-000010 vs target: 0.090
:::MLL 1560882019.825788 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 10}}
:::MLL 1560882019.826118 eval_accuracy: {"value": 0.09, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 10}}
:::MLL 1560882019.826436 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 11}}
I0618 12:20:19.826744 47046246794112 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000012-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/target --seed=12
I0618 12:20:44.678289 47046246794112 utils.py:86] eval finished: 24.851 seconds
I0618 12:20:44.681150 47046246794112 reference_implementation.py:563] Win rate 000012-000011 vs target: 0.140
:::MLL 1560882044.682128 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 11}}
:::MLL 1560882044.682467 eval_accuracy: {"value": 0.14, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 11}}
:::MLL 1560882044.682803 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 12}}
I0618 12:20:44.683127 47046246794112 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000013-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/target --seed=13
I0618 12:21:12.429467 47046246794112 utils.py:86] eval finished: 27.746 seconds
I0618 12:21:12.432358 47046246794112 reference_implementation.py:563] Win rate 000013-000011 vs target: 0.150
:::MLL 1560882072.433048 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 12}}
:::MLL 1560882072.433385 eval_accuracy: {"value": 0.15, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 12}}
:::MLL 1560882072.433713 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 13}}
I0618 12:21:12.434041 47046246794112 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000014-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/target --seed=14
I0618 12:21:40.227221 47046246794112 utils.py:86] eval finished: 27.793 seconds
I0618 12:21:40.230074 47046246794112 reference_implementation.py:563] Win rate 000014-000012 vs target: 0.300
:::MLL 1560882100.230987 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 13}}
:::MLL 1560882100.231320 eval_accuracy: {"value": 0.3, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 13}}
:::MLL 1560882100.231638 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 14}}
I0618 12:21:40.231945 47046246794112 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000015-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/target --seed=15
I0618 12:22:04.235293 47046246794112 utils.py:86] eval finished: 24.003 seconds
I0618 12:22:04.238169 47046246794112 reference_implementation.py:563] Win rate 000015-000013 vs target: 0.400
:::MLL 1560882124.238831 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 14}}
:::MLL 1560882124.239158 eval_accuracy: {"value": 0.4, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 14}}
:::MLL 1560882124.239486 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 15}}
I0618 12:22:04.239796 47046246794112 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000016-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/target --seed=16
I0618 12:22:28.359572 47046246794112 utils.py:86] eval finished: 24.120 seconds
I0618 12:22:28.362630 47046246794112 reference_implementation.py:563] Win rate 000016-000014 vs target: 0.360
:::MLL 1560882148.363314 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 15}}
:::MLL 1560882148.363641 eval_accuracy: {"value": 0.36, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 15}}
:::MLL 1560882148.363969 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 16}}
I0618 12:22:28.364274 47046246794112 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb330/models/000017-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb330/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb330/sgf/eval/target --seed=17
I0618 12:22:50.636454 47046246794112 utils.py:86] eval finished: 22.272 seconds
I0618 12:22:50.639377 47046246794112 reference_implementation.py:563] Win rate 000017-000014 vs target: 0.550
:::MLL 1560882170.640225 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 16}}
:::MLL 1560882170.640554 eval_accuracy: {"value": 0.55, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 16}}
:::MLL 1560882170.640896 eval_result: {"value": null, "metadata": {'lineno': 52, 'file': 'ml_perf/eval_models.py', 'iteration': 16, 'timestamp': 850.193}}
:::MLL 1560882170.641199 run_stop: {"value": null, "metadata": {'lineno': 53, 'file': 'ml_perf/eval_models.py', 'status': 'success'}}
Model 000017-000014 beat target after 850.193s
~/submission/benchmarks/minigo/clx-8260l-2s-x32
