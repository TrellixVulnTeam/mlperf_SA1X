:::MLL 1560874143.560618169 submission_org: {"value": "Intel_Corp", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560874143.562291518 submission_platform: {"value": "32xCLX-8260L_CPUs", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560874143.563679376 submission_division: {"value": "closed", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560874143.565107011 submission_status: {"value": "onprem", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560874143.566462184 submission_benchmark: {"value": "minigo", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560874143.567706663 submission_poc_name: {"value": "Guokai Ma, Letian Kang, Christine Cheng, Mingxiao Huang", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560874143.569018459 submission_poc_email: {"value": "guokai.ma@intel.com, letian.kang@intel.com, christine.cheng@intel.com, mingxiao.huang@intel.com", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560874143.570473142 submission_entry: {"value": {"framework": "TensorFlow 1.13.1", "power": "none", "notes": "none", "interconnect": "OPA", "os": "Oracle Linux Server 7.6", "libraries": "MKLDNN (v0.18), MKL (v2019.0.3.20190220), IntelMPI (2018.1.163)", "compilers": "GCC6.3", "nodes": [{"num_nodes": 32, "cpu": "Intel(R) Xeon(R) Platinum 8260L CPU @ 2.40GHz", "num_cores": 48, "num_vcpus": "NA", "accelerator": "NA", "num_accelerators": 0, "sys_mem_size": "192G", "sys_storage_type": "SSD", "sys_storage_size": "800G", "cpu_accel_interconnect": "100Gb OPA", "network_card": "100Gb OPA", "num_network_cards": 1, "notes": "NA"}]}, "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560874165.473595376 cache_clear: {value: true, metadata: {lineno: 0, file: manual}}
~/submission/benchmarks/minigo/implementations/tensorflow ~/submission/benchmarks/minigo/clx-8260l-2s-x32
Physical cores = 48
Virtual cores = 96
NUMA cores = 24
KMP_HW_SUBSET = 2T
Output to /lfs/lfs12/gma_akey
./run_mn.sh: line 20: ulimit: max user processes: cannot modify limit: Operation not permitted
Wiping dir /lfs/lfs12/gma_akey/results/epb074
:::MLL 1560874172.901772 init_start: {"value": null, "metadata": {'lineno': 742, 'file': 'ml_perf/reference_implementation.py'}}
Making dir /lfs/lfs12/gma_akey/results/epb074/models
Making dir /lfs/lfs12/gma_akey/results/epb074/data/selfplay
Making dir /lfs/lfs12/gma_akey/results/epb074/data/holdout
Making dir /lfs/lfs12/gma_akey/results/epb074/sgf/eval
Making dir /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks
Making dir /lfs/lfs12/gma_akey/results/epb074/work_dir
Making dir /lfs/lfs12/gma_akey/results/epb074/mpi
[2019-06-18 10:09:32] Selfplay nodes = ['epb074', 'epb087', 'epb155', 'epb230', 'epb079', 'epb287', 'epb076', 'epb233', 'epb133', 'epb140', 'epb263', 'epb239', 'epb156', 'epb077', 'epb078', 'epb101', 'epb252', 'epb231', 'epb050', 'epb171', 'epb100', 'epb237', 'epb235', 'epb159', 'epb158', 'epb234']
[2019-06-18 10:09:32] Train nodes = ['epb311', 'epb130', 'epb073', 'epb153', 'epb152', 'epb232']
[2019-06-18 10:09:32] Eval nodes = ['epb074', 'epb087', 'epb155', 'epb230', 'epb079', 'epb287', 'epb076', 'epb233', 'epb133', 'epb140', 'epb263', 'epb239', 'epb156', 'epb077', 'epb078', 'epb101', 'epb252', 'epb231', 'epb050', 'epb171', 'epb100', 'epb237', 'epb235', 'epb159', 'epb158', 'epb234']
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.53s/it]
[2019-06-18 10:12:21] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/tools/strip_unused_lib.py:86: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
[2019-06-18 10:12:21] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/tools/optimize_for_inference_lib.py:113: remove_training_nodes (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.remove_training_nodes`
2019-06-18 10:12:21.515570: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX512F
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2019-06-18 10:12:21.528288: I tensorflow/core/common_runtime/process_util.cc:113] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
[2019-06-18 10:12:21] From ./quantize_graph.py:351: quantize_v2 (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.
Instructions for updating:
`tf.quantize_v2` is deprecated, please use `tf.quantization.quantize` instead.
2019-06-18 10:12:21.858363: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
[2019-06-18 10:12:21] From ./dual_net.py:679: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.gfile.GFile.
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_99']
Reading tf_records from 1 inputs
[2019-06-18 10:12:25] minmax time: 3.828 seconds
2019-06-18 10:12:25.696547: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:12:25.701819: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:12:25.706504: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874345.829856 init_stop: {"value": null, "metadata": {'lineno': 614, 'file': 'ml_perf/reference_implementation.py'}}
:::MLL 1560874345.830236 run_start: {"value": null, "metadata": {'lineno': 615, 'file': 'ml_perf/reference_implementation.py'}}
:::MLL 1560874345.830633 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 0}}
[2019-06-18 10:12:25] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir 
[2019-06-18 10:12:25] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-2-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000001-000000 --seed=2 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000001-000000 --seed=1023779833 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000001-000000 --seed=2047559664 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000001-000000 --seed=3071339495 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000001-000000 --seed=4095119326 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000001-000000 --seed=5118899157 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000001-000000 --seed=6142678988 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000001-000000 --seed=7166458819 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000001-000000 --seed=8190238650 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000001-000000 --seed=9214018481 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000001-000000 --seed=10237798312 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000001-000000 --seed=11261578143 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000001-000000 --seed=12285357974 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000001-000000 --seed=13309137805 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000001-000000 --seed=14332917636 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000001-000000 --seed=15356697467 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000001-000000 --seed=16380477298 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000001-000000 --seed=17404257129 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000001-000000 --seed=18428036960 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000001-000000 --seed=19451816791 : \
-host epb1
[2019-06-18 10:13:02] selfplay finished: 36.140 seconds
[2019-06-18 10:13:02] selfplay mn: 36.162 seconds
[2019-06-18 10:13:02] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-2-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779833 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559664 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339495 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119326 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899157 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142678988 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458819 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238650 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018481 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798312 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578143 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285357974 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137805 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917636 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697467 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477298 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257129 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036960 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816791 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596622 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376453 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156284 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_
[2019-06-18 10:13:17] divide_golden_chunk finished: 15.736 seconds
[2019-06-18 10:13:17] generate golden chunk: 15.752 seconds
[2019-06-18 10:13:20] train finished: 55.080 seconds
:::MLL 1560874361.137138 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874361.138069 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874361.138931 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:41.727912 47569855996800 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560874361.137134 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874361.138074 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874361.138931 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:41.727912 47262976082816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560874361.186272 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874361.186686 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874361.187040 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:41.728091 47777504183168 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560874361.188035 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874361.188484 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874361.188858 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:41.728141 47412596343680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560874361.208168 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874361.208553 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874361.208920 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:41.728381 47649233597312 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560874361.209104 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874361.209473 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874361.209792 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:41.728358 47852462654336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560874361.144456 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874361.145223 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874361.145908 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:41.728614 47966170919808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560874361.139959 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874361.140838 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874361.141673 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:41.728684 47591254909824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560874361.211975 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874361.212409 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874361.212817 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:41.730693 47392222491520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560874361.216880 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874361.217230 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874361.217557 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:41.730679 47092264846208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560874361.146324 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874361.147226 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874361.148069 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:41.730752 47959327994752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560874361.160357 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874361.161153 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874361.161881 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:41.730774 47572925256576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 10:12:41.729893 47649233597312 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpn7tiwelu
I0618 10:12:41.730966 47649233597312 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpn7tiwelu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b567c3abe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:41.731389 47649233597312 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:12:41.731914 47392222491520 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpsf1g7fxj
W0618 10:12:41.731940 47262976082816 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp78i112f6
I0618 10:12:41.732654 47392222491520 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpsf1g7fxj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1aa52c8e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:12:41.732171 47569855996800 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpia2hz7v4
W0618 10:12:41.732347 47092264846208 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp1thqj2w7
I0618 10:12:41.733070 47262976082816 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp78i112f6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afc8d7cae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:12:41.732434 47777504183168 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp6dnyxek5
I0618 10:12:41.732999 47392222491520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:12:41.732460 47412596343680 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpt0vh556v
I0618 10:12:41.733067 47092264846208 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp1thqj2w7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad4ce4e0e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:41.733283 47569855996800 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpia2hz7v4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4400f4bda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:41.733513 47777504183168 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp6dnyxek5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7459c09e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:41.733527 47262976082816 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:12:41.733525 47412596343680 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpt0vh556v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1f638cde10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:41.733403 47092264846208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:12:41.733748 47569855996800 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:12:41.732765 47959327994752 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp5i94rxbl
W0618 10:12:41.732791 47572925256576 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpt3xiu1jo
I0618 10:12:41.733952 47412596343680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:12:41.733947 47777504183168 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:12:41.733854 47959327994752 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp5i94rxbl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9eaf4bbe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:41.733863 47572925256576 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpt3xiu1jo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b44b7e5ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:41.734298 47959327994752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:12:41.734297 47572925256576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:12:41.733091 47852462654336 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpy4efohe1
I0618 10:12:41.734096 47852462654336 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpy4efohe1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b85cda00e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:12:41.733542 47966170919808 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpjtnvxh8u
W0618 10:12:41.733567 47591254909824 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp0ud2rbvg
I0618 10:12:41.734550 47852462654336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:12:41.734624 47966170919808 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpjtnvxh8u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba0472a7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:41.734635 47591254909824 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp0ud2rbvg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b48fc6e3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:41.735077 47591254909824 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:12:41.735081 47966170919808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:12:41.741068 47852462654336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:41.741971 47092264846208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:41.741127 47966170919808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:41.742018 47392222491520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:41.741124 47649233597312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:41.741166 47591254909824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:41.742117 47959327994752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:41.742172 47572925256576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:41.742526 47412596343680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:41.742548 47777504183168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:41.742600 47569855996800 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:41.742641 47262976082816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:41.762690 47092264846208 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:41.762181 47852462654336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:41.763143 47392222491520 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:41.763422 47569855996800 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:41.762433 47649233597312 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:41.763567 47412596343680 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:41.763612 47777504183168 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:41.763581 47262976082816 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:41.763383 47966170919808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:41.764271 47959327994752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:41.763637 47591254909824 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:41.764606 47572925256576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874361.211367 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874361.211717 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874361.212067 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:41.769802 47080792773504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560874361.212337 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874361.212677 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874361.213003 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:41.769816 47344124494720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560874361.166659 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874361.167417 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874361.168125 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:41.770118 47045247841152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560874361.162133 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874361.163070 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874361.163933 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:41.770109 47202237997952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 10:12:41.770438 47080792773504 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpmczd7g8g
W0618 10:12:41.770463 47344124494720 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmprmmdh4ev
I0618 10:12:41.771140 47080792773504 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpmczd7g8g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad222842e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:41.771143 47344124494720 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmprmmdh4ev', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0f724f5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:41.771458 47080792773504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:12:41.771457 47344124494720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:12:41.771238 47045247841152 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpc19620qg
W0618 10:12:41.771212 47202237997952 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpbvlo3jiy
I0618 10:12:41.772310 47202237997952 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpbvlo3jiy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aee69373e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:41.772316 47045247841152 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpc19620qg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac9dbdf8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:41.772754 47045247841152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:12:41.772755 47202237997952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874361.194508 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874361.195276 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874361.195962 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:41.776613 47512343974784 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560874361.187140 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874361.188065 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874361.188914 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:41.776600 47658187436928 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560874361.241872 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874361.242259 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874361.242590 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:41.776619 47194558100352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560874361.244473 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874361.244854 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874361.245184 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:41.776657 47907905377152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000000.tfrecord.zz_0
I0618 10:12:41.777640 47512343974784 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb074/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b369cf8dd68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:12:41.777970 47658187436928 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpwwhekf3o
I0618 10:12:41.778898 47512343974784 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:12:41.779058 47658187436928 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpwwhekf3o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5891eb7e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:12:41.778407 47194558100352 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp8hyxwap7
I0618 10:12:41.779494 47658187436928 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:12:41.779482 47194558100352 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp8hyxwap7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aec9f754e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:12:41.778731 47907905377152 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp6lmez6za
I0618 10:12:41.779776 47907905377152 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp6lmez6za', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b92b644ee80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:41.779917 47194558100352 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:12:41.780194 47907905377152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874361.252790 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874361.253205 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874361.253557 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:41.782218 47907610825600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560874361.250563 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874361.250977 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874361.251322 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:41.782209 47388549739392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560874361.194454 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874361.195379 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874361.196272 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:41.782245 47117130171264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560874361.202778 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874361.203566 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874361.204336 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:12:41.782309 47842042483584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 10:12:41.784427 47202237997952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:41.784539 47045247841152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:41.786544 47080792773504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:41.786417 47117130171264 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmppdajhjt6
W0618 10:12:41.786648 47388549739392 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpiscra2bh
I0618 10:12:41.787450 47117130171264 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmppdajhjt6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ada9864de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:12:41.787654 47512343974784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:12:41.787738 47388549739392 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpiscra2bh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b19ca42ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:12:41.787652 47658187436928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:41.787080 47842042483584 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpulnbiqba
W0618 10:12:41.787688 47907905377152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:41.787054 47907610825600 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpamo8wpvb
W0618 10:12:41.787776 47194558100352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:12:41.787864 47117130171264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:12:41.788057 47842042483584 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpulnbiqba', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b836088ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:41.788145 47907610825600 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpamo8wpvb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b92a4b66e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:12:41.788180 47388549739392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:12:41.788470 47842042483584 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:12:41.788786 47344124494720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:12:41.788598 47907610825600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:12:41.796090 47842042483584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:41.796244 47117130171264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:41.796261 47907610825600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:41.796279 47388549739392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:12:41.805623 47202237997952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:41.805844 47045247841152 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:41.805911 47080792773504 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:41.807471 47658187436928 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:41.807777 47344124494720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:41.807565 47512343974784 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:41.807659 47907905377152 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:41.807963 47194558100352 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:41.815875 47842042483584 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:41.816107 47117130171264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:41.817334 47907610825600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:41.817465 47388549739392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:12:41.820029 47092264846208 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:12:41.820225 47392222491520 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:12:41.819519 47852462654336 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:12:41.819621 47649233597312 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:12:41.820142 47966170919808 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:12:41.820367 47591254909824 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:12:41.821234 47959327994752 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:12:41.821379 47572925256576 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:12:41.821766 47412596343680 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:12:41.821880 47777504183168 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:12:41.824282 47092264846208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:12:41.824545 47392222491520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:12:41.823848 47852462654336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:12:41.823963 47649233597312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:12:41.824893 47966170919808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:12:41.825180 47591254909824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:12:41.826182 47412596343680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:12:41.826348 47777504183168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:12:41.826094 47959327994752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:12:41.826317 47572925256576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:12:41.826808 47262976082816 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two[2019-06-18 10:13:20] iteration time 0: 55.109 seconds
2019-06-18 10:13:21.316797: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874400.939702 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 1}}
[2019-06-18 10:13:24] minmax time: 3.250 seconds
2019-06-18 10:13:24.576792: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:13:24.582009: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:13:24.586667: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874404.597055 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 0}}
[2019-06-18 10:13:24] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir 
[2019-06-18 10:13:24] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-2-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000001-000001 --seed=2 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000001-000001 --seed=1023779833 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000001-000001 --seed=2047559664 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000001-000001 --seed=3071339495 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000001-000001 --seed=4095119326 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000001-000001 --seed=5118899157 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000001-000001 --seed=6142678988 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000001-000001 --seed=7166458819 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000001-000001 --seed=8190238650 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000001-000001 --seed=9214018481 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000001-000001 --seed=10237798312 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000001-000001 --seed=11261578143 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000001-000001 --seed=12285357974 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000001-000001 --seed=13309137805 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000001-000001 --seed=14332917636 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000001-000001 --seed=15356697467 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000001-000001 --seed=16380477298 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000001-000001 --seed=17404257129 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000001-000001 --seed=18428036960 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000001-000001 --seed=19451816791 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000001-000001 --seed=20475596622 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_
[2019-06-18 10:13:37] eval finished: 12.852 seconds
[2019-06-18 10:13:37] Win rate 000001-000001 vs checkpoint: 0.480
:::MLL 1560874417.524693 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 0}}
[2019-06-18 10:13:37] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-3-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000002-000000 --seed=3 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000002-000000 --seed=1023779834 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000002-000000 --seed=2047559665 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000002-000000 --seed=3071339496 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000002-000000 --seed=4095119327 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000002-000000 --seed=5118899158 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000002-000000 --seed=6142678989 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000002-000000 --seed=7166458820 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000002-000000 --seed=8190238651 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000002-000000 --seed=9214018482 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000002-000000 --seed=10237798313 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000002-000000 --seed=11261578144 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000002-000000 --seed=12285357975 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000002-000000 --seed=13309137806 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000002-000000 --seed=14332917637 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000002-000000 --seed=15356697468 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000002-000000 --seed=16380477299 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000002-000000 --seed=17404257130 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000002-000000 --seed=18428036961 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000002-000000 --seed=19451816792 : \
-host epb1
[2019-06-18 10:14:07] selfplay finished: 29.562 seconds
[2019-06-18 10:14:07] selfplay mn: 29.579 seconds
[2019-06-18 10:14:07] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-3-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779834 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559665 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339496 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119327 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899158 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142678989 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458820 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238651 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018482 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798313 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578144 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285357975 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137806 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917637 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697468 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477299 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257130 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036961 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816792 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596623 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376454 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156285 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_
[2019-06-18 10:14:09] train finished: 44.448 seconds
:::MLL 1560874409.851321 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874409.852131 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874409.852808 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:29.918778 47033973363584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560874409.850013 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874409.850891 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874409.851668 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:29.918944 47563821409152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 10:13:29.919909 47033973363584 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpth1oc83b
W0618 10:13:29.920017 47563821409152 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpslgdl9yv
I0618 10:13:29.920949 47033973363584 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpth1oc83b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac73bdcae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:29.921046 47563821409152 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpslgdl9yv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4299443dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:29.921345 47033973363584 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:13:29.921442 47563821409152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:13:29.926204 47563821409152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:29.926243 47033973363584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874409.864585 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874409.865434 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874409.866141 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:29.946403 47643541689216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560874409.863656 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874409.864506 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874409.865292 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:29.946524 47508832613248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 10:13:29.947476 47643541689216 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp0uew49q4
W0618 10:13:29.947574 47508832613248 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpiug56ok0
W0618 10:13:29.948716 47033973363584 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:13:29.948552 47643541689216 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp0uew49q4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5528f72e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:29.948666 47508832613248 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpiug56ok0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b35cbadce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:13:29.948943 47563821409152 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:13:29.948988 47643541689216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:13:29.949101 47508832613248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:13:29.954296 47643541689216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:29.954314 47508832613248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874409.925912 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874409.926350 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874409.926734 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:29.956231 47261414282112 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560874409.925899 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874409.926336 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874409.926721 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:29.956382 47938977493888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 10:13:29.957324 47261414282112 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpm_fisqsv
W0618 10:13:29.957400 47938977493888 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpqt0v4j8i
I0618 10:13:29.958398 47261414282112 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpm_fisqsv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afc3065add8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:29.958472 47938977493888 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpqt0v4j8i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b99f24fce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:29.958833 47261414282112 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:13:29.958911 47938977493888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874409.915237 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874409.915720 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874409.916105 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:29.960796 46914968871808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560874409.919069 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874409.919456 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874409.919786 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:29.961154 47007209345920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 10:13:29.962197 46914968871808 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpddo97tl6
W0618 10:13:29.962224 47007209345920 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpap_bdjop
I0618 10:13:29.963296 46914968871808 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpddo97tl6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aab86a43e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:29.963298 47007209345920 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpap_bdjop', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac1009a2da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560874409.904248 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874409.905031 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874409.905747 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:29.963556 47657935467392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560874409.899901 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874409.900792 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874409.901619 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:29.963624 47739489514368 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000001.tfrecord.zz_0
I0618 10:13:29.963692 47007209345920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:13:29.963701 46914968871808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:13:29.963917 47261414282112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:29.963942 47938977493888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:29.964570 47657935467392 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpirix8p1w
W0618 10:13:29.964622 47739489514368 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpg7iwz9wa
I0618 10:13:29.965582 47657935467392 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpirix8p1w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5882e6be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:29.965621 47739489514368 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpg7iwz9wa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6b7fe6cda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:29.965998 47657935467392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:13:29.966028 47739489514368 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:13:29.968495 46914968871808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:29.968529 47007209345920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:29.970935 47739489514368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:29.970945 47657935467392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:29.975955 47508832613248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:13:29.975999 47643541689216 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:13:29.985097 47938977493888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:13:29.985133 47261414282112 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:13:29.988325 46914968871808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:13:29.988354 47007209345920 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:13:29.990936 47657935467392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:13:29.991033 47739489514368 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874409.962727 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874409.963151 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874409.963506 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:29.992022 47370200548224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560874409.964128 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874409.964549 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874409.964941 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:29.992959 47523298288512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 10:13:29.993172 47370200548224 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpuzvb58eh
I0618 10:13:29.994267 47370200548224 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpuzvb58eh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1584905e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:29.994682 47370200548224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:13:29.993993 47523298288512 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp39lkeqev
I0618 10:13:29.995003 47523298288512 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp39lkeqev', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3929e67e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:29.995413 47523298288512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874409.931020 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874409.931780 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874409.932526 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:29.995899 47987035812736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560874409.933167 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874409.933890 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874409.934597 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:29.995897 47585950536576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 10:13:29.996930 47987035812736 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpq9nagplg
W0618 10:13:29.996970 47585950536576 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpinbq8h4m
I0618 10:13:29.997988 47987035812736 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpq9nagplg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba522cf8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:29.998065 47585950536576 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpinbq8h4m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b47c043edd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:29.998423 47987035812736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:13:29.998510 47585950536576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:13:29.999606 47370200548224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:29.999611 47563821409152 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:13:30.000017 47033973363584 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:13:30.000242 47523298288512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:30.004190 47563821409152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:13:30.004653 47033973363584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:13:30.003690 47987035812736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:30.003804 47585950536576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:13:30.009498 47563821409152 estimator.py:1111] Calling model_fn.
W0618 10:13:30.009625 47563821409152 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:13:30.010034 47033973363584 estimator.py:1111] Calling model_fn.
W0618 10:13:30.010146 47033973363584 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:13:30.011078 47563821409152 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:13:30.011597 47033973363584 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560874409.953863 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874409.954749 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874409.955636 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:30.018524 47478194938752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560874409.958942 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874409.959663 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874409.960301 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:30.018567 47177336333184 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 10:13:30.019592 47478194938752 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp7av378zm
I0618 10:13:30.019670 47177336333184 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb074/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae89cf5ed68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:30.020666 47478194938752 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp7av378zm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2ea987fe80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:13:30.021025 47370200548224 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:13:30.020880 47177336333184 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:13:30.021090 47478194938752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:13:30.021427 47523298288512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874409.996709 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874409.997155 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874409.997533 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:30.024195 47884024755072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 10:13:30.026216 47478194938752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:30.026240 47177336333184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:30.025178 47884024755072 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpz_yfr3b_
W0618 10:13:30.026113 47987035812736 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:13:30.026145 47884024755072 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpz_yfr3b_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8d26df8dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:13:30.027081 47643541689216 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:13:30.027148 47508832613248 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:13:30.026513 47585950536576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:13:30.026535 47884024755072 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874410.002024 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874410.002511 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874410.002969 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:30.027593 47586532369280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 10:13:30.028560 47586532369280 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpcx8m8i0_
I0618 10:13:30.029574 47586532369280 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpcx8m8i0_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b47e2f1ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:30.029958 47586532369280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:13:30.031732 47643541689216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:13:30.031809 47508832613248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:13:30.031345 47884024755072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:30.034755 47938977493888 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:13:30.034949 47261414282112 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:13:30.034444 47586532369280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:13:30.036072 46914968871808 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:13:30.036174 47007209345920 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:13:30.037171 47643541689216 estimator.py:1111] Calling model_fn.
W0618 10:13:30.037289 47643541689216 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:13:30.037294 47508832613248 estimator.py:1111] Calling model_fn.
W0618 10:13:30.037409 47508832613248 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:13:30.038522 47739489514368 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:13:30.038639 47657935467392 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560874410.013781 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874410.014232 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874410.014698 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:30.038514 47217295537024 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 10:13:30.038752 47643541689216 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:13:30.038873 47508832613248 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:13:30.039112 47938977493888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:13:30.039272 47261414282112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:13:30.039661 47217295537024 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpyzdq2wxo
W0618 10:13:30.040397 46914968871808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:13:30.040500 47007209345920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:13:30.040661 47217295537024 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpyzdq2wxo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af1eab70e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:13:30.041039 47217295537024 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:13:30.042794 47739489514368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:13:30.042955 47657935467392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:13:30.044175 47938977493888 estimator.py:1111] Calling model_fn.
W0618 10:13:30.044284 47938977493888 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:13:30.044344 47261414282112 estimator.py:1111] Calling model_fn.
W0618 10:13:30.044454 47261414282112 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:13:30.045644 47938977493888 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:13:30.045804 47261414282112 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:13:30.045478 46914968871808 estimator.py:1111] Calling model_fn.
W0618 10:13:30.045592 46914968871808 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:13:30.045578 47217295537024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:13:30.045591 47007209345920 estimator.py:1111] Calling model_fn.
W0618 10:13:30.045702 47007209345920 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560874410.018344 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874410.018764 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874410.019117 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:13:30.045740 47084665389952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 10:13:30.046951 46914968871808 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:13:30.047068 47007209345920 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:13:30.046709 47084665389952 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpzotfbtcy
I0618 10:13:30.047863 47739489514368 estimator.py:1111] Calling model_fn.
I0618 10:13:30.047725 47084665389952 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdi[2019-06-18 10:14:10] divide_golden_chunk finished: 3.360 seconds
[2019-06-18 10:14:10] generate golden chunk: 3.375 seconds
[2019-06-18 10:14:10] iteration time 1: 49.541 seconds
2019-06-18 10:14:10.996406: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874450.480510 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 2}}
[2019-06-18 10:14:14] minmax time: 3.237 seconds
2019-06-18 10:14:14.243105: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:14:14.248604: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:14:14.253301: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874454.264053 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 1}}
[2019-06-18 10:14:14] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000003-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000003-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000003-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000003-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000003-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000003-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000003-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000003-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000003-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000003-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000003-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir 
[2019-06-18 10:14:14] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-3-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000002-000001 --seed=3 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000002-000001 --seed=1023779834 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000002-000001 --seed=2047559665 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000002-000001 --seed=3071339496 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000002-000001 --seed=4095119327 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000002-000001 --seed=5118899158 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000002-000001 --seed=6142678989 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000002-000001 --seed=7166458820 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000002-000001 --seed=8190238651 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000002-000001 --seed=9214018482 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000002-000001 --seed=10237798313 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000002-000001 --seed=11261578144 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000002-000001 --seed=12285357975 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000002-000001 --seed=13309137806 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000002-000001 --seed=14332917637 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000002-000001 --seed=15356697468 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000002-000001 --seed=16380477299 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000002-000001 --seed=17404257130 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000002-000001 --seed=18428036961 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000002-000001 --seed=19451816792 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000002-000001 --seed=20475596623 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_
[2019-06-18 10:14:26] eval finished: 11.880 seconds
[2019-06-18 10:14:26] Win rate 000002-000001 vs checkpoint: 0.750
:::MLL 1560874466.221731 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 1}}
[2019-06-18 10:14:26] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-4-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000003-000000 --seed=4 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000003-000000 --seed=1023779835 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000003-000000 --seed=2047559666 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000003-000000 --seed=3071339497 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000003-000000 --seed=4095119328 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000003-000000 --seed=5118899159 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000003-000000 --seed=6142678990 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000003-000000 --seed=7166458821 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000003-000000 --seed=8190238652 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000003-000000 --seed=9214018483 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000003-000000 --seed=10237798314 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000003-000000 --seed=11261578145 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000003-000000 --seed=12285357976 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000003-000000 --seed=13309137807 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000003-000000 --seed=14332917638 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000003-000000 --seed=15356697469 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000003-000000 --seed=16380477300 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000003-000000 --seed=17404257131 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000003-000000 --seed=18428036962 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/
[2019-06-18 10:14:55] selfplay finished: 29.639 seconds
[2019-06-18 10:14:55] selfplay mn: 29.657 seconds
[2019-06-18 10:14:55] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-4-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779835 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559666 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339497 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119328 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899159 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142678990 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458821 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238652 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018483 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798314 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578145 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285357976 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137807 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917638 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697469 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477300 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257131 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036962 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816793 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596624 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376455 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156286 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_
[2019-06-18 10:14:58] train finished: 44.350 seconds
:::MLL 1560874459.538972 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874459.539654 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874459.540255 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:19.607216 47772442645376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560874459.537071 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874459.537818 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874459.538613 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:19.607340 47272668525440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 10:14:19.608270 47772442645376 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpimjuunlt
W0618 10:14:19.608379 47272668525440 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpccm1_uu6
I0618 10:14:19.609339 47772442645376 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpimjuunlt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b732c0fada0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:19.609438 47272668525440 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpccm1_uu6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afecf33ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:19.609780 47772442645376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:14:19.609867 47272668525440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:14:19.615070 47272668525440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:19.615163 47772442645376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874459.548328 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874459.549195 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874459.550024 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:19.619867 47564960424832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560874459.554045 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874459.554778 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874459.555477 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:19.619879 47135160959872 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 10:14:19.620910 47564960424832 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpm_sb1601
W0618 10:14:19.620880 47135160959872 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp4kyajs3x
I0618 10:14:19.621865 47135160959872 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp4kyajs3x', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adecb1cce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:19.621893 47564960424832 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpm_sb1601', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b42dd282e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:19.622254 47135160959872 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:14:19.622290 47564960424832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874459.554987 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874459.555903 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874459.556737 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:19.625218 47620112724864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560874459.560322 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874459.561054 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874459.561749 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:19.625292 47230445724544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 10:14:19.627087 47564960424832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:19.627115 47135160959872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:19.626334 47620112724864 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmphc7og3er
W0618 10:14:19.626379 47230445724544 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmplly8i_oi
I0618 10:14:19.627424 47620112724864 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmphc7og3er', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4fb47d8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:19.627458 47230445724544 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmplly8i_oi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af4fa86edd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:19.627892 47620112724864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:14:19.627903 47230445724544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:14:19.633297 47230445724544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:19.633342 47620112724864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:19.637791 47272668525440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:14:19.638410 47772442645376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874459.592281 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874459.592808 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874459.593268 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:19.640147 47257328747392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 10:14:19.641203 47257328747392 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpc0rz39hg
I0618 10:14:19.642285 47257328747392 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpc0rz39hg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afb3ce15e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:19.642717 47257328747392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874459.602290 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874459.602803 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874459.603219 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:19.642959 47145893815168 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 10:14:19.643987 47145893815168 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp1o6e3rge
I0618 10:14:19.645048 47145893815168 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp1o6e3rge', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae14ad70e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:19.645493 47145893815168 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874459.611032 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874459.611466 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874459.611879 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:19.645642 47482377581440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560874459.611016 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874459.611447 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874459.611858 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:19.645693 47169678873472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 10:14:19.647103 47564960424832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:14:19.647372 47135160959872 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:14:19.646741 47482377581440 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpe8s59p9x
W0618 10:14:19.647821 47257328747392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:19.646771 47169678873472 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpkj4pcze6
I0618 10:14:19.647839 47482377581440 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpe8s59p9x', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2fa2d60e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:19.647856 47169678873472 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpkj4pcze6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae6d48a6e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:19.648282 47482377581440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:14:19.648284 47169678873472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874459.573087 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874459.573966 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874459.574784 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:19.649798 47471939752832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560874459.581765 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874459.582546 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874459.583335 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:19.649862 47413179782016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 10:14:19.650555 47145893815168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:19.650852 47471939752832 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpbpvl109n
W0618 10:14:19.650942 47413179782016 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp9p0n9alp
I0618 10:14:19.651937 47471939752832 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpbpvl109n', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2d34b16e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:19.652034 47413179782016 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp9p0n9alp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1f86536e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:19.652382 47471939752832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:14:19.652470 47413179782016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:14:19.653451 47482377581440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:19.653470 47169678873472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:19.656050 47230445724544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:14:19.656533 47620112724864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:14:19.657629 47471939752832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:19.657649 47413179782016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874459.626678 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874459.627059 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874459.627377 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:19.660851 46940491096960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560874459.628103 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874459.628579 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874459.628970 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:19.661494 46917881951104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 10:14:19.661892 46940491096960 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp0f4n_n97
I0618 10:14:19.662919 46940491096960 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp0f4n_n97', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab177e27e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:14:19.662499 46917881951104 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpeecyewih
I0618 10:14:19.663332 46940491096960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:14:19.663530 46917881951104 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpeecyewih', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aac34464e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:19.663980 46917881951104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:14:19.669262 47257328747392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:14:19.668399 46940491096960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:19.668902 46917881951104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874459.602581 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874459.603495 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874459.604255 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:19.670225 47750166528896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560874459.601822 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874459.602715 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874459.603577 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:19.670368 47146464211840 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 10:14:19.671819 47145893815168 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:14:19.671457 47146464211840 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb074/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae16cd6cd68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:14:19.671581 47750166528896 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpfkijs1id
I0618 10:14:19.672602 47146464211840 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:14:19.672610 47750166528896 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpfkijs1id', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6dfc4d1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:19.673030 47750166528896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:14:19.673435 47482377581440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:14:19.673447 47169678873472 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874459.635794 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874459.636377 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874459.636730 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:19.673584 47906414592896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560874459.638863 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874459.639275 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874459.639618 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:19.674972 47377773835136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 10:14:19.674608 47906414592896 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpmd7rmgca
I0618 10:14:19.675655 47906414592896 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpmd7rmgca', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b925d695e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:19.676074 47906414592896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:14:19.675972 47377773835136 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpd4gn3gyi
I0618 10:14:19.677010 47377773835136 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpd4gn3gyi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1747f78e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:19.677425 47377773835136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:14:19.677618 47146464211840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:19.677858 47750166528896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:19.679949 47471939752832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:14:19.680191 47413179782016 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:14:19.681087 47906414592896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:19.682335 47377773835136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:19.689418 47272668525440 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:14:19.689814 47772442645376 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:14:19.689416 46940491096960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:14:19.689873 46917881951104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:14:19.694063 47272668525440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:14:19.694454 47772442645376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:14:19.694821 47564960424832 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:14:19.695098 47135160959872 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:14:19.699116 47564960424832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:14:19.699430 47135160959872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:14:19.699551 47272668525440 estimator.py:1111] Calling model_fn.
W0618 10:14:19.699664 47272668525440 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:14:19.699901 47772442645376 estimator.py:1111] Calling model_fn.
W0618 10:14:19.700016 47772442645376 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:14:19.700181 47146464211840 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:14:19.700316 47750166528896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:14:19.701122 47272668525440 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:14:19.701463 47772442645376 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:14:19.702304 47906414592896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:14:19.703585 47377773835136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:14:19.704204 47564960424832 estimator.py:1111] Calling model_fn.
W0618 10:14:19.704311 47564960424832 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:14:19.704528 47135160959872 estimator.py:1111] Calling model_fn.
W0618 10:14:19.704636 47135160959872 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:14:19.705658 47564960424832 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560874459.635895 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874459.636839 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874459.637715 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:19.705399 47311450841984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560874459.645496 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874459.646270 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874459.647054 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:19.705429 47204899873664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 10:14:19.705995 47135160959872 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:14:19.705171 47620112724864 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:14:19.705443 47230445724544 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:14:19.706486 47311450841984 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpml0rt818
W0618 10:14:19.706521 47204899873664 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp1sswqh_k
I0618 10:14:19.707585 47311450841984 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpml0rt818', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b07d6cefe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:19.707632 47204899873664 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp1sswqh_k', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aef07e03e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:19.708031 47311450841984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:14:19.708072 47204899873664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:14:19.709450 47620112724864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:14:19.709793 47230445724544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560874459.676928 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874459.677416 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874459.677837 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:19.711695 47628506870656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560874459.676921 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874459.677406 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874459.677828 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:14:19.711774 47603074171776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 10:14:19.713299 47311450841984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:19.713313 47204899873664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:19.712746 47628506870656 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmph4qxbw1x
W0618 10:14:19.712917 47603074171776 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpfjbh4sfc
I0618 10:14:19.713809 47628506870656 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmph4qxbw1x', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b51a8d1ee80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:19.713991 47603074171776 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpfjbh4sfc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4bbce9de80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:14:19.714231 47628506870656 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:14:19.714416 47603074171776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:14:19.714552 47620112724864 estimator.py:1111] Calling model_fn.
W0618 10:14:19.714662 47620112724864 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:14:19.714874 47230445724544 estimator.py:1111] Calling model_fn.
W0618 10:14:19.714983 47230445724544 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:14:19.716017 47620112724864 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:14:19.716336 47230445724544 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:14:19.719119 47628506870656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:19.719192 47603074171776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:14:19.719989 47257328747392 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:14:19.720833 47482377581440 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:14:19.721296 47169678873472 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:14:19.722394 47145893815168 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:14:19.724655 47257328747392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:14:19.725118 47482377581440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:14:19.725611 47169678873472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:14:19.727036 47145893815168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:14:19.730184 47257328747392 estimator.py:1111] Calling model_fn.
W0618 10:14:19.730318 47257328747392 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:14:19.730221 47482377581440 estimator.py:1111] Calling model_fn.
W0618 10:14:19.730327 47482377581440 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:14:19.730720 47169678873472 estimator.py:1111] Calling model_fn.
W0618 10:14:19.730830 47169678873472 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:14:19.731519 47471939752832 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:14:19.731789 47257328747392 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructio[2019-06-18 10:14:59] divide_golden_chunk finished: 3.324 seconds
[2019-06-18 10:14:59] generate golden chunk: 3.338 seconds
[2019-06-18 10:14:59] moving /lfs/lfs12/gma_akey/results/epb074/models/000003-000001.pb --> /lfs/lfs12/gma_akey/results/epb074/models/000003-000002.pb
[2019-06-18 10:14:59] moving /lfs/lfs12/gma_akey/results/epb074/models/000003-000001.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb074/models/000003-000002.data-00000-of-00001
[2019-06-18 10:14:59] moving /lfs/lfs12/gma_akey/results/epb074/models/000003-000001.index --> /lfs/lfs12/gma_akey/results/epb074/models/000003-000002.index
[2019-06-18 10:14:59] moving /lfs/lfs12/gma_akey/results/epb074/models/000003-000001.meta --> /lfs/lfs12/gma_akey/results/epb074/models/000003-000002.meta
[2019-06-18 10:14:59] iteration time 2: 48.784 seconds
2019-06-18 10:14:59.702707: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874499.264691 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 3}}
[2019-06-18 10:15:02] minmax time: 3.247 seconds
2019-06-18 10:15:02.959913: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:15:02.965469: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:15:02.969926: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874502.979305 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 2}}
[2019-06-18 10:15:02] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir 
[2019-06-18 10:15:03] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-4-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000003-000002 --seed=4 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000003-000002 --seed=1023779835 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000003-000002 --seed=2047559666 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000003-000002 --seed=3071339497 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000003-000002 --seed=4095119328 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000003-000002 --seed=5118899159 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000003-000002 --seed=6142678990 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000003-000002 --seed=7166458821 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000003-000002 --seed=8190238652 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000003-000002 --seed=9214018483 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000003-000002 --seed=10237798314 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000003-000002 --seed=11261578145 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000003-000002 --seed=12285357976 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000003-000002 --seed=13309137807 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000003-000002 --seed=14332917638 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000003-000002 --seed=15356697469 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000003-000002 --seed=16380477300 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000003-000002 --seed=17404257131 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000003-000002 --seed=18428036962 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000003-000002 --seed=19451816793 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000003-000002 --seed=20475596624 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 10:15:13] eval finished: 10.481 seconds
[2019-06-18 10:15:13] Win rate 000003-000002 vs 000002-000001: 0.280
:::MLL 1560874513.534491 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 2}}
[2019-06-18 10:15:13] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-5-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000004-000001 --seed=5 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000004-000001 --seed=1023779836 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000004-000001 --seed=2047559667 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000004-000001 --seed=3071339498 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000004-000001 --seed=4095119329 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000004-000001 --seed=5118899160 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000004-000001 --seed=6142678991 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000004-000001 --seed=7166458822 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000004-000001 --seed=8190238653 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000004-000001 --seed=9214018484 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000004-000001 --seed=10237798315 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000004-000001 --seed=11261578146 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000004-000001 --seed=12285357977 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000004-000001 --seed=13309137808 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000004-000001 --seed=14332917639 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000004-000001 --seed=15356697470 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000004-000001 --seed=16380477301 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000004-000001 --seed=17404257132 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000004-000001 --seed=18428036963 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/
[2019-06-18 10:15:42] selfplay finished: 29.370 seconds
[2019-06-18 10:15:42] selfplay mn: 29.387 seconds
[2019-06-18 10:15:42] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-5-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779836 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559667 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339498 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119329 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899160 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142678991 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458822 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238653 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018484 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798315 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578146 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285357977 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137808 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917639 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697470 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477301 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257132 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036963 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816794 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596625 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376456 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156287 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_
[2019-06-18 10:15:46] divide_golden_chunk finished: 3.343 seconds
[2019-06-18 10:15:46] generate golden chunk: 3.358 seconds
[2019-06-18 10:15:47] train finished: 44.266 seconds
:::MLL 1560874508.224841 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874508.225602 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874508.226325 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:08.295375 47211326280576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560874508.226855 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874508.227580 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874508.228239 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:08.295378 47942701355904 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 10:15:08.296471 47211326280576 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp69s8qhuq
W0618 10:15:08.296499 47942701355904 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpnoexuoc2
I0618 10:15:08.297566 47211326280576 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp69s8qhuq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af086eb6e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:08.297582 47942701355904 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpnoexuoc2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9ad0456e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:08.298000 47211326280576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:08.298017 47942701355904 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:08.303249 47211326280576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:08.303272 47942701355904 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874508.245361 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874508.246220 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874508.247065 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:08.314752 47837207331712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560874508.253623 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874508.254373 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874508.255067 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:08.314771 47697780835200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 10:15:08.315888 47697780835200 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp2wnh4rzn
W0618 10:15:08.315914 47837207331712 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpk6i707ha
I0618 10:15:08.316985 47697780835200 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp2wnh4rzn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b61c9dede10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:08.316985 47837207331712 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpk6i707ha', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8240565e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:08.317426 47837207331712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:08.317429 47697780835200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:08.322394 47697780835200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:08.322400 47837207331712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:08.325796 47211326280576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:08.325825 47942701355904 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874508.291262 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874508.291854 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874508.292231 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:08.328170 47999847682944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 10:15:08.329243 47999847682944 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp810jra0c
:::MLL 1560874508.294587 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874508.295017 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874508.295384 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:08.330001 47851254334336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000003.tfrecord.zz_0
I0618 10:15:08.330302 47999847682944 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp810jra0c', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba81e752e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:08.330687 47999847682944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:08.330981 47851254334336 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpmuswx6l2
I0618 10:15:08.332042 47851254334336 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpmuswx6l2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b85859a9e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:08.332472 47851254334336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:08.335518 47999847682944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:08.337136 47851254334336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874508.268162 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874508.269040 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874508.269896 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:08.339429 47855154205568 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560874508.268209 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874508.269096 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874508.269913 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:08.339500 47422158304128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 10:15:08.340495 47855154205568 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp_svqkmuc
W0618 10:15:08.340592 47422158304128 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp6c3zd5wc
I0618 10:15:08.341595 47855154205568 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp_svqkmuc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b866e0dee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:15:08.342647 47837207331712 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:15:08.341760 47422158304128 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp6c3zd5wc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b219d7cce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:15:08.342887 47697780835200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:15:08.342041 47855154205568 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:08.342218 47422158304128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:08.347247 47855154205568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:08.347520 47422158304128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874508.277041 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874508.277811 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874508.278575 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:08.350503 47768700973952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560874508.279075 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874508.279819 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874508.280515 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:08.350552 47434411787136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 10:15:08.351642 47768700973952 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmposc8h2b1
W0618 10:15:08.351683 47434411787136 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpp52579hb
I0618 10:15:08.352757 47768700973952 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmposc8h2b1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b724d0a4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:08.352816 47434411787136 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpp52579hb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2477da1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:08.353221 47768700973952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:08.353283 47434411787136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874508.316009 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874508.316450 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874508.316824 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:08.355308 47092790137728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 10:15:08.355531 47999847682944 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:08.356863 47851254334336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:08.356375 47092790137728 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp_tp9tq3_
I0618 10:15:08.357435 47092790137728 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp_tp9tq3_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad4ed9d6e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:08.357869 47092790137728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:08.358892 47434411787136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:08.358893 47768700973952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874508.317303 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874508.317805 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874508.318208 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:08.359146 47590572082048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 10:15:08.360174 47590572082048 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp757kgj81
I0618 10:15:08.361198 47590572082048 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp757kgj81', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b48d3bb1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:08.361619 47590572082048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:08.362906 47092790137728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:08.366367 47590572082048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:08.369924 47855154205568 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:08.370379 47422158304128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874508.334267 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874508.334659 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874508.335004 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:08.370378 47034497622912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560874508.334148 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874508.334546 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874508.334902 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:08.370380 47867443856256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 10:15:08.371498 47867443856256 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpaufhp677
W0618 10:15:08.371529 47034497622912 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpimmew3hd
I0618 10:15:08.372521 47867443856256 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpaufhp677', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b894a931e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:08.372560 47034497622912 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpimmew3hd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac75b1c3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:08.372937 47867443856256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:08.372980 47034497622912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874508.340425 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874508.340800 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874508.341125 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:08.376327 47542461584256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560874508.342537 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874508.342963 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874508.343347 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:08.377459 47103432737664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 10:15:08.377390 47542461584256 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpwtmoiuc_
I0618 10:15:08.378428 47542461584256 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpwtmoiuc_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3da01f1dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:08.378844 47542461584256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:08.377883 47867443856256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:08.377915 47034497622912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:08.378445 47103432737664 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpq40go4vv
I0618 10:15:08.379461 47103432737664 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpq40go4vv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad767f69e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:15:08.379394 47211326280576 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:15:08.379426 47942701355904 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:15:08.379873 47103432737664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:08.381592 47768700973952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:08.381622 47434411787136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:08.383677 47542461584256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874508.318758 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874508.319484 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874508.320201 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:08.383587 47394560942976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560874508.312451 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874508.313382 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874508.314240 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:08.383578 47714084275072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 10:15:08.384101 47092790137728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:08.384562 47103432737664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:08.384257 47211326280576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:15:08.384331 47942701355904 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:15:08.384728 47394560942976 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp8mlwza9m
W0618 10:15:08.384762 47714084275072 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp0yvrv46i
I0618 10:15:08.385813 47394560942976 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp8mlwza9m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1b308e7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:08.385826 47714084275072 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp0yvrv46i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6595a19e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:08.386230 47394560942976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:08.386239 47714084275072 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:08.387578 47590572082048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874508.313112 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874508.313999 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874508.314877 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:08.389389 47810844787584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560874508.321545 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874508.322304 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874508.322964 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:08.389568 47735516730240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000003.tfrecord.zz_0
I0618 10:15:08.389960 47211326280576 estimator.py:1111] Calling model_fn.
I0618 10:15:08.390044 47942701355904 estimator.py:1111] Calling model_fn.
W0618 10:15:08.390079 47211326280576 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:15:08.390168 47942701355904 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:15:08.390659 47837207331712 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:15:08.390931 47697780835200 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:15:08.390488 47810844787584 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp3qp19pad
W0618 10:15:08.391393 47394560942976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:15:08.390695 47735516730240 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb074/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6a931aed68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:15:08.391397 47714084275072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:15:08.391565 47810844787584 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp3qp19pad', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7c1d01de80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:15:08.391603 47211326280576 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:15:08.391686 47942701355904 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:15:08.391949 47735516730240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:08.392007 47810844787584 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:08.394973 47837207331712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:15:08.395267 47697780835200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:15:08.397272 47810844787584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:08.397398 47735516730240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:08.398781 47867443856256 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:08.398885 47034497622912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:15:08.400004 47837207331712 estimator.py:1111] Calling model_fn.
W0618 10:15:08.400112 47837207331712 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:15:08.400344 47697780835200 estimator.py:1111] Calling model_fn.
W0618 10:15:08.400460 47697780835200 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:15:08.401462 47837207331712 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:15:08.401825 47697780835200 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:15:08.403370 47542461584256 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:08.403204 47999847682944 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:15:08.404288 47103432737664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:08.404256 47851254334336 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:15:08.407521 47999847682944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:15:08.408593 47851254334336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:15:08.411724 47394560942976 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:08.411747 47714084275072 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:15:08.412608 47999847682944 estimator.py:1111] Calling model_fn.
W0618 10:15:08.412718 47999847682944 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:15:08.413662 47851254334336 estimator.py:1111] Calling model_fn.
W0618 10:15:08.413771 47851254334336 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:15:08.414078 47999847682944 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:15:08.415126 47851254334336 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560874508.381386 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874508.381760 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874508.382076 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:08.417201 47018005312384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 10:15:08.418275 47018005312384 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpn8hg637x
I0618 10:15:08.419285 47018005312384 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpn8hg637x', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac384178e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560874508.383439 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874508.383824 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874508.384217 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:08.419258 47497145750400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 10:15:08.419589 47810844787584 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:15:08.419680 47018005312384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:08.420109 47735516730240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:08.420208 47497145750400 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp9j2pyk2e
:::MLL 1560874508.384303 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874508.384751 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874508.385185 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:08.420761 47885773587328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560874508.384653 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874508.385149 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874508.385522 o[2019-06-18 10:15:47] iteration time 3: 48.002 seconds
2019-06-18 10:15:47.744190: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874547.266552 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 4}}
[2019-06-18 10:15:51] minmax time: 3.257 seconds
2019-06-18 10:15:51.011117: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:15:51.016353: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:15:51.020634: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874551.031851 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 3}}
[2019-06-18 10:15:51] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000005-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000005-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000005-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000005-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000005-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000005-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000005-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000005-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000005-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000005-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000005-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir 
[2019-06-18 10:15:51] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-5-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000004-000002 --seed=5 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000004-000002 --seed=1023779836 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000004-000002 --seed=2047559667 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000004-000002 --seed=3071339498 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000004-000002 --seed=4095119329 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000004-000002 --seed=5118899160 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000004-000002 --seed=6142678991 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000004-000002 --seed=7166458822 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000004-000002 --seed=8190238653 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000004-000002 --seed=9214018484 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000004-000002 --seed=10237798315 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000004-000002 --seed=11261578146 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000004-000002 --seed=12285357977 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000004-000002 --seed=13309137808 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000004-000002 --seed=14332917639 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000004-000002 --seed=15356697470 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000004-000002 --seed=16380477301 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000004-000002 --seed=17404257132 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000004-000002 --seed=18428036963 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000004-000002 --seed=19451816794 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000004-000002 --seed=20475596625 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 10:16:02] eval finished: 11.810 seconds
[2019-06-18 10:16:02] Win rate 000004-000002 vs 000002-000001: 0.440
:::MLL 1560874562.918466 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 3}}
[2019-06-18 10:16:02] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-6-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000005-000001 --seed=6 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000005-000001 --seed=1023779837 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000005-000001 --seed=2047559668 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000005-000001 --seed=3071339499 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000005-000001 --seed=4095119330 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000005-000001 --seed=5118899161 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000005-000001 --seed=6142678992 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000005-000001 --seed=7166458823 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000005-000001 --seed=8190238654 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000005-000001 --seed=9214018485 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000005-000001 --seed=10237798316 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000005-000001 --seed=11261578147 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000005-000001 --seed=12285357978 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000005-000001 --seed=13309137809 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000005-000001 --seed=14332917640 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000005-000001 --seed=15356697471 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000005-000001 --seed=16380477302 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000005-000001 --seed=17404257133 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000005-000001 --seed=18428036964 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/
[2019-06-18 10:16:32] selfplay finished: 29.859 seconds
[2019-06-18 10:16:32] selfplay mn: 29.876 seconds
[2019-06-18 10:16:32] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-6-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779837 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559668 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339499 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119330 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899161 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142678992 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458823 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238654 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018485 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798316 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578147 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285357978 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137809 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917640 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697471 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477302 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257133 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036964 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816795 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596626 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376457 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156288 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_
[2019-06-18 10:16:35] train finished: 44.436 seconds
:::MLL 1560874556.277851 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874556.278663 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874556.279468 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:56.334691 47727116583808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560874556.260914 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874556.261788 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874556.262658 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:56.334753 47411290915712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 10:15:56.335727 47727116583808 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpj5klijft
W0618 10:15:56.335779 47411290915712 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpkbk53c1y
I0618 10:15:56.336815 47727116583808 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpj5klijft', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b689e6ade48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:56.336854 47411290915712 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpkbk53c1y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1f15bd9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:56.337253 47727116583808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:56.337285 47411290915712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:56.342481 47411290915712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:56.342488 47727116583808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:56.364956 47411290915712 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:56.365061 47727116583808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874556.303012 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874556.303765 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874556.304418 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:56.368823 47579352834944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560874556.289771 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874556.290630 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874556.291492 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:56.368932 47236580725632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560874556.313142 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874556.313953 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874556.314680 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:56.368775 47452283016064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560874556.291363 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874556.292256 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874556.293100 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:56.368877 47850747630464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 10:15:56.369935 47579352834944 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp4tce1qqe
W0618 10:15:56.370015 47236580725632 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpw8ioa5of
I0618 10:15:56.370980 47579352834944 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp4tce1qqe', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b463702ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:56.371060 47236580725632 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpw8ioa5of', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af66833ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:56.371427 47579352834944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:56.371522 47236580725632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:56.369805 47452283016064 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpa0twmunw
W0618 10:15:56.369873 47850747630464 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp4hxvcn_5
I0618 10:15:56.370873 47452283016064 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpa0twmunw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b28a10f6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:56.370902 47850747630464 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp4hxvcn_5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b856766ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:56.371292 47452283016064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:56.371321 47850747630464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:56.376627 47579352834944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:56.376687 47236580725632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874556.340455 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874556.340874 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874556.341234 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:56.377399 46984851379072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560874556.341096 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874556.341481 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874556.341815 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:56.377394 47261120172928 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 10:15:56.376734 47452283016064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:56.376737 47850747630464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:56.378440 46984851379072 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpx2tc0s2o
W0618 10:15:56.378468 47261120172928 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpv3h9gh05
I0618 10:15:56.379430 46984851379072 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpx2tc0s2o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abbcbf6ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:56.379442 47261120172928 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpv3h9gh05', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afc1eddde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:56.379826 46984851379072 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:56.379833 47261120172928 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:56.384661 46984851379072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:56.384664 47261120172928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874556.357918 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874556.358359 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874556.358744 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:56.394794 47287632593792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560874556.351678 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874556.352230 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874556.352768 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:56.394975 47259253740416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560874556.329512 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874556.330261 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874556.330911 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:56.395471 47356102976384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560874556.318015 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874556.318932 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874556.319741 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:56.395530 47563515233152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560874556.322826 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874556.323716 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874556.324377 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:56.395767 47791213351808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560874556.326373 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874556.327202 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874556.327889 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:56.395782 47974262858624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 10:15:56.395838 47287632593792 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp46t6j42d
W0618 10:15:56.395996 47259253740416 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmptuytnxbk
I0618 10:15:56.396873 47287632593792 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp46t6j42d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b024b215e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:15:56.396851 47236580725632 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:56.396862 47579352834944 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:15:56.397003 47259253740416 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmptuytnxbk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afbaf9e5e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:56.397285 47287632593792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:56.397422 47259253740416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:56.396582 47356102976384 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb074/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b123c487d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:15:56.396625 47563515233152 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpm9010m7q
I0618 10:15:56.397719 47563515233152 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpm9010m7q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4287045e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:15:56.396928 47974262858624 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpkqmgh9fi
W0618 10:15:56.396957 47791213351808 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpcpu0_nc7
I0618 10:15:56.397813 47356102976384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:56.398028 47974262858624 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpkqmgh9fi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba2297bada0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:56.398035 47791213351808 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpcpu0_nc7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b778ae1ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:56.398161 47563515233152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:56.398475 47974262858624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:56.398476 47791213351808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:56.399009 47452283016064 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:56.399063 47850747630464 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:56.402232 47287632593792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:56.402259 47259253740416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:56.403126 47356102976384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:56.403299 47563515233152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:56.403748 47791213351808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:56.403826 47974262858624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:56.404316 46984851379072 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:56.404286 47261120172928 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874556.369032 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874556.369406 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874556.369727 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:56.405528 47130526016384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560874556.370670 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874556.371096 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874556.371472 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:56.406337 47758251750272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 10:15:56.406513 47130526016384 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpnd1ozroh
I0618 10:15:56.407562 47130526016384 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpnd1ozroh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2addb6d93e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:56.407983 47130526016384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:56.407379 47758251750272 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp41rl4ez3
I0618 10:15:56.408413 47758251750272 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp41rl4ez3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6fde37ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:56.408809 47758251750272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:56.412739 47130526016384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:56.413499 47758251750272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:56.415291 47727116583808 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:15:56.415354 47411290915712 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:15:56.419598 47727116583808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:15:56.419682 47411290915712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:15:56.421701 47259253740416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:56.421875 47287632593792 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:15:56.424666 47727116583808 estimator.py:1111] Calling model_fn.
W0618 10:15:56.424772 47727116583808 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:15:56.424756 47411290915712 estimator.py:1111] Calling model_fn.
W0618 10:15:56.424868 47411290915712 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:15:56.425400 47356102976384 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:56.425485 47563515233152 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:56.426136 47727116583808 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:15:56.426234 47411290915712 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:15:56.426021 47791213351808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874556.389046 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874556.389421 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874556.389767 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:56.425964 47399670350720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560874556.389959 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874556.390341 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874556.390664 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:56.426162 47534662652800 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 10:15:56.426542 47974262858624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:56.427024 47399670350720 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpyuuxwjg8
W0618 10:15:56.427193 47534662652800 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmppla8fwvr
I0618 10:15:56.428099 47399670350720 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpyuuxwjg8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1c6119de80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:56.428238 47534662652800 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmppla8fwvr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3bcf44ee80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:56.428534 47399670350720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:56.428666 47534662652800 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874556.393811 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874556.394186 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874556.394506 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:56.430227 47781455664000 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560874556.395329 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874556.395714 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874556.396040 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:56.430689 47669269619584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 10:15:56.431201 47781455664000 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpjcw5h_i3
I0618 10:15:56.432174 47781455664000 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpjcw5h_i3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7545476da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:15:56.431645 47669269619584 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpkpgeewrg
I0618 10:15:56.432562 47781455664000 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:56.432616 47669269619584 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpkpgeewrg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5b26783e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:56.433012 47669269619584 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:56.432492 47130526016384 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:56.433520 47399670350720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:56.433570 47534662652800 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:56.433044 47758251750272 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:56.437364 47781455664000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:56.437726 47669269619584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:56.444665 47579352834944 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:15:56.444884 47236580725632 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560874556.389360 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874556.390175 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874556.390938 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:56.445461 47685355824000 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560874556.375524 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874556.376448 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874556.377285 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:15:56.445525 47035023246208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 10:15:56.446478 47685355824000 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmply6i00_r
W0618 10:15:56.446509 47035023246208 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp2veg3rgh
I0618 10:15:56.447494 47685355824000 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmply6i00_r', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5ee5482dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:56.447519 47035023246208 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp2veg3rgh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac77a709dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:15:56.447915 47685355824000 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:15:56.447941 47035023246208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:15:56.447659 47850747630464 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:15:56.447842 47452283016064 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:15:56.448969 47579352834944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:15:56.449196 47236580725632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:15:56.452127 47261120172928 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:15:56.452181 46984851379072 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:15:56.451965 47850747630464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:15:56.452147 47452283016064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:15:56.452954 47685355824000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:56.452975 47035023246208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:15:56.453139 47399670350720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:15:56.453223 47534662652800 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:15:56.454007 47579352834944 estimator.py:1111] Calling model_fn.
W0618 10:15:56.454116 47579352834944 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:15:56.454255 47236580725632 estimator.py:1111] Calling model_fn.
W0618 10:15:56.454362 47236580725632 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:15:56.455462 47579352834944 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:15:56.455730 47236580725632 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future vers[2019-06-18 10:16:36] divide_golden_chunk finished: 3.348 seconds
[2019-06-18 10:16:36] generate golden chunk: 3.362 seconds
[2019-06-18 10:16:36] iteration time 4: 48.892 seconds
2019-06-18 10:16:36.680510: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874596.158676 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 5}}
[2019-06-18 10:16:39] minmax time: 3.254 seconds
2019-06-18 10:16:39.943853: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:16:39.949175: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:16:39.953568: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874599.964587 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 4}}
[2019-06-18 10:16:39] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000006-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000006-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000006-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000006-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000006-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000006-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000006-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000006-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000006-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000006-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000006-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir 
[2019-06-18 10:16:40] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-6-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000005-000002 --seed=6 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000005-000002 --seed=1023779837 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000005-000002 --seed=2047559668 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000005-000002 --seed=3071339499 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000005-000002 --seed=4095119330 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000005-000002 --seed=5118899161 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000005-000002 --seed=6142678992 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000005-000002 --seed=7166458823 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000005-000002 --seed=8190238654 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000005-000002 --seed=9214018485 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000005-000002 --seed=10237798316 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000005-000002 --seed=11261578147 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000005-000002 --seed=12285357978 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000005-000002 --seed=13309137809 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000005-000002 --seed=14332917640 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000005-000002 --seed=15356697471 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000005-000002 --seed=16380477302 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000005-000002 --seed=17404257133 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000005-000002 --seed=18428036964 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000005-000002 --seed=19451816795 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000005-000002 --seed=20475596626 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 10:16:52] eval finished: 12.539 seconds
[2019-06-18 10:16:52] Win rate 000005-000002 vs 000002-000001: 0.560
:::MLL 1560874612.587172 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 4}}
[2019-06-18 10:16:52] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-7-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000006-000001 --seed=7 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000006-000001 --seed=1023779838 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000006-000001 --seed=2047559669 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000006-000001 --seed=3071339500 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000006-000001 --seed=4095119331 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000006-000001 --seed=5118899162 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000006-000001 --seed=6142678993 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000006-000001 --seed=7166458824 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000006-000001 --seed=8190238655 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000006-000001 --seed=9214018486 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000006-000001 --seed=10237798317 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000006-000001 --seed=11261578148 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000006-000001 --seed=12285357979 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000006-000001 --seed=13309137810 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000006-000001 --seed=14332917641 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000006-000001 --seed=15356697472 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000006-000001 --seed=16380477303 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000006-000001 --seed=17404257134 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000006-000001 --seed=18428036965 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/
[2019-06-18 10:17:21] selfplay finished: 28.971 seconds
[2019-06-18 10:17:21] selfplay mn: 28.987 seconds
[2019-06-18 10:17:21] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-7-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779838 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559669 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339500 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119331 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899162 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142678993 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458824 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238655 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018486 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798317 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578148 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285357979 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137810 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917641 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697472 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477303 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257134 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036965 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816796 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596627 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376458 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156289 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000006-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_
[2019-06-18 10:17:23] train finished: 43.538 seconds
:::MLL 1560874605.255046 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874605.255832 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874605.256510 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:45.327375 47393396298624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560874605.253564 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874605.254332 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874605.255157 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:45.327385 47686299915136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 10:16:45.328421 47686299915136 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpwvyxi3n6
W0618 10:16:45.328452 47393396298624 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpcm0n052v
I0618 10:16:45.329529 47686299915136 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpwvyxi3n6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5f1d8dee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:45.329556 47393396298624 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpcm0n052v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1aeb236e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:45.329986 47686299915136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:16:45.330011 47393396298624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:16:45.335364 47686299915136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:45.335433 47393396298624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874605.257334 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874605.258219 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874605.259030 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:45.342231 46935403168640 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560874605.265222 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874605.265955 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874605.266658 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:45.342456 47955677516672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560874605.279090 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874605.279981 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874605.280760 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:45.342228 47892832088960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560874605.265960 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874605.266887 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874605.267738 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:45.342269 47608056644480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 10:16:45.343321 46935403168640 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpphbut1fg
W0618 10:16:45.343535 47955677516672 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpgk04qqi0
I0618 10:16:45.344429 46935403168640 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpphbut1fg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab0489ece48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:45.344634 47955677516672 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpgk04qqi0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9dd5b5de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:45.344872 46935403168640 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:16:45.343280 47892832088960 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpapfrrap7
I0618 10:16:45.345084 47955677516672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:16:45.343309 47608056644480 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp_xpb61m3
I0618 10:16:45.344327 47892832088960 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpapfrrap7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8f33d4ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:45.344360 47608056644480 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp_xpb61m3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4ce5e45e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:45.344778 47892832088960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:16:45.344808 47608056644480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:16:45.350144 46935403168640 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:45.350273 47955677516672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:45.350125 47608056644480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:45.350361 47892832088960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:45.357912 47686299915136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:16:45.358393 47393396298624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874605.293999 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874605.294749 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874605.295383 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:45.366782 47259025519488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560874605.291486 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874605.292182 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874605.292902 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:45.366942 47018323039104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560874605.308985 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874605.309471 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874605.309918 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:45.367417 47193385063296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560874605.316767 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874605.317173 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874605.317525 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:45.367453 47231263884160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 10:16:45.367808 47259025519488 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpp1mqd8nz
W0618 10:16:45.367910 47018323039104 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpim45avgh
I0618 10:16:45.368796 47259025519488 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpp1mqd8nz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afba2040e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:45.368896 47018323039104 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpim45avgh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac39707ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:45.369191 47259025519488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:16:45.369288 47018323039104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:16:45.368482 47193385063296 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpehilexeo
W0618 10:16:45.368455 47231263884160 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpwieb5omh
I0618 10:16:45.369435 47231263884160 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpwieb5omh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af52b4b0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:45.369452 47193385063296 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpehilexeo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aec598a2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:45.369822 47231263884160 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:16:45.369842 47193385063296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:16:45.372212 46935403168640 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874605.329399 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874605.329847 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874605.330184 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:45.371903 47401050182528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 10:16:45.372470 47955677516672 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874605.330742 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874605.331128 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874605.331449 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:45.371970 47135809770368 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 10:16:45.372854 47608056644480 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:16:45.372961 47401050182528 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmplo2g9zkk
W0618 10:16:45.372988 47135809770368 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmptma612jy
W0618 10:16:45.374181 47018323039104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:16:45.374015 47401050182528 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmplo2g9zkk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1cb3584e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:16:45.374186 47259025519488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:16:45.374020 47135809770368 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmptma612jy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adef1c8ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:16:45.374544 47193385063296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:45.374548 47231263884160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:16:45.374408 47401050182528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:16:45.374408 47135809770368 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:16:45.373829 47892832088960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:16:45.379243 47401050182528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:45.379244 47135809770368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874605.308131 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874605.308996 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874605.309775 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:45.382105 47057207022464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560874605.308565 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874605.309424 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874605.310192 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:45.382234 47937474241408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 10:16:45.383103 47057207022464 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpihgjh45w
W0618 10:16:45.383216 47937474241408 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp7zjqzch5
I0618 10:16:45.384079 47057207022464 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpihgjh45w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acca4b22dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:45.384185 47937474241408 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp7zjqzch5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9998b5fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:45.384474 47057207022464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:16:45.384569 47937474241408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874605.343834 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874605.344240 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874605.344601 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:45.384551 47650307081088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560874605.343631 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874605.344029 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874605.344437 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:45.384542 47454441329536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 10:16:45.385570 47454441329536 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpxtix8pl5
W0618 10:16:45.385601 47650307081088 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpw__v37g9
I0618 10:16:45.386518 47454441329536 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpxtix8pl5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2921b4ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:45.386566 47650307081088 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpw__v37g9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b56bc36de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:45.386907 47454441329536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:16:45.386957 47650307081088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:16:45.389503 47057207022464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:45.389544 47937474241408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:45.391591 47454441329536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:45.391596 47650307081088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:45.394088 47231263884160 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:16:45.394187 47193385063296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:16:45.394201 47018323039104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:16:45.394297 47259025519488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874605.348828 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874605.349334 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874605.349818 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:45.395415 47891808211840 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560874605.350065 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874605.350542 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874605.350960 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:45.395463 47678045467520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 10:16:45.396393 47891808211840 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp4kp85c9n
W0618 10:16:45.396428 47678045467520 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpj25upgec
I0618 10:16:45.397395 47891808211840 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp4kp85c9n', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8ef6cdae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:45.397394 47678045467520 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpj25upgec', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5d318d0da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:45.397800 47891808211840 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:16:45.397798 47678045467520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:16:45.398710 47401050182528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:16:45.398694 47135809770368 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:16:45.402630 47891808211840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:45.402634 47678045467520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:45.408721 47686299915136 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:16:45.409379 47937474241408 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:16:45.409368 47057207022464 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:16:45.409943 47393396298624 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:16:45.411301 47650307081088 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:16:45.411338 47454441329536 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:16:45.413244 47686299915136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560874605.372428 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874605.372910 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874605.373359 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:45.413170 47595554734976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 10:16:45.414534 47393396298624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560874605.375024 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874605.375469 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874605.375862 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:45.414605 47223611544448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 10:16:45.414237 47595554734976 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpd_esh2jx
I0618 10:16:45.415248 47595554734976 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpd_esh2jx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b49fcb85e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:45.415665 47595554734976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:16:45.415590 47223611544448 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpn6zymeh2
I0618 10:16:45.416613 47223611544448 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpn6zymeh2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af3632d9dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:45.417055 47223611544448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:16:45.418522 47686299915136 estimator.py:1111] Calling model_fn.
W0618 10:16:45.418653 47686299915136 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:16:45.419781 46935403168640 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:16:45.419900 47955677516672 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:16:45.419854 47393396298624 estimator.py:1111] Calling model_fn.
W0618 10:16:45.419963 47393396298624 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:16:45.420030 47686299915136 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:16:45.420653 47595554734976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:45.421427 47393396298624 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:16:45.422044 47223611544448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:45.422296 47891808211840 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:16:45.422415 47678045467520 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:16:45.422119 47608056644480 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:16:45.422850 47892832088960 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:16:45.424084 46935403168640 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:16:45.424183 47955677516672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:16:45.426424 47608056644480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:16:45.427175 47892832088960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:16:45.429130 46935403168640 estimator.py:1111] Calling model_fn.
W0618 10:16:45.429239 46935403168640 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:16:45.429255 47955677516672 estimator.py:1111] Calling model_fn.
W0618 10:16:45.429360 47955677516672 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560874605.362282 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874605.363032 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874605.363715 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:45.428925 47203979883392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560874605.357969 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874605.358922 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874605.359715 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:16:45.429095 47189182534528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 10:16:45.430601 46935403168640 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:16:45.430727 47955677516672 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:16:45.430052 47203979883392 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpaupgpn0b
I0618 10:16:45.430163 47189182534528 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb074/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeb5f0cacf8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:45.431191 47203979883392 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpaupgpn0b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeed10a3e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:16:45.431410 47189182534528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:16:45.431637 47203979883392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:16:45.431487 47608056644480 estimator.py:1111] Calling model_fn.
W0618 10:16:45.431595 47608056644480 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:16:45.432251 47892832088960 estimator.py:1111] Calling model_fn.
W0618 10:16:45.432359 47892832088960 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:16:45.432975 47608056644480 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:16:45.433720 47892832088960 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:16:45.436822 47189182534528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:16:45.437022 47203979883392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatic[2019-06-18 10:17:24] divide_golden_chunk finished: 3.331 seconds
[2019-06-18 10:17:24] generate golden chunk: 3.346 seconds
[2019-06-18 10:17:24] moving /lfs/lfs12/gma_akey/results/epb074/models/000006-000002.meta --> /lfs/lfs12/gma_akey/results/epb074/models/000006-000003.meta
[2019-06-18 10:17:24] moving /lfs/lfs12/gma_akey/results/epb074/models/000006-000002.pb --> /lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb
[2019-06-18 10:17:24] moving /lfs/lfs12/gma_akey/results/epb074/models/000006-000002.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb074/models/000006-000003.data-00000-of-00001
[2019-06-18 10:17:24] moving /lfs/lfs12/gma_akey/results/epb074/models/000006-000002.index --> /lfs/lfs12/gma_akey/results/epb074/models/000006-000003.index
[2019-06-18 10:17:24] iteration time 5: 48.805 seconds
2019-06-18 10:17:25.530244: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874644.963944 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 6}}
[2019-06-18 10:17:28] minmax time: 3.236 seconds
2019-06-18 10:17:28.776397: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:17:28.781866: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:17:28.786359: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874648.795840 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 5}}
[2019-06-18 10:17:28] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000007-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000007-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000007-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000007-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000007-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000007-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000007-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000007-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000007-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000007-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000007-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir 
[2019-06-18 10:17:28] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-7-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000006-000003 --seed=7 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000006-000003 --seed=1023779838 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000006-000003 --seed=2047559669 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000006-000003 --seed=3071339500 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000006-000003 --seed=4095119331 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000006-000003 --seed=5118899162 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000006-000003 --seed=6142678993 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000006-000003 --seed=7166458824 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000006-000003 --seed=8190238655 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000006-000003 --seed=9214018486 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000006-000003 --seed=10237798317 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000006-000003 --seed=11261578148 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000006-000003 --seed=12285357979 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000006-000003 --seed=13309137810 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000006-000003 --seed=14332917641 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000006-000003 --seed=15356697472 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000006-000003 --seed=16380477303 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000006-000003 --seed=17404257134 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000006-000003 --seed=18428036965 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000006-000003 --seed=19451816796 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000006-000003 --seed=20475596627 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 10:17:41] eval finished: 12.565 seconds
[2019-06-18 10:17:41] Win rate 000006-000003 vs 000005-000002: 0.550
:::MLL 1560874661.435593 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 5}}
[2019-06-18 10:17:41] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-8-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000007-000002 --seed=8 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000007-000002 --seed=1023779839 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000007-000002 --seed=2047559670 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000007-000002 --seed=3071339501 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000007-000002 --seed=4095119332 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000007-000002 --seed=5118899163 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000007-000002 --seed=6142678994 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000007-000002 --seed=7166458825 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000007-000002 --seed=8190238656 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000007-000002 --seed=9214018487 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000007-000002 --seed=10237798318 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000007-000002 --seed=11261578149 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000007-000002 --seed=12285357980 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000007-000002 --seed=13309137811 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000007-000002 --seed=14332917642 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000007-000002 --seed=15356697473 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000007-000002 --seed=16380477304 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000007-000002 --seed=17404257135 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000007-000002 --seed=18428036966 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/
[2019-06-18 10:18:10] selfplay finished: 28.603 seconds
[2019-06-18 10:18:10] selfplay mn: 28.619 seconds
[2019-06-18 10:18:10] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-8-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779839 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559670 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339501 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119332 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899163 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142678994 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458825 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238656 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018487 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798318 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578149 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285357980 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137811 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917642 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697473 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477304 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257135 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036966 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816797 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596628 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376459 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156290 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000007-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_
[2019-06-18 10:18:12] train finished: 43.716 seconds
:::MLL 1560874654.061395 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874654.062087 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874654.062761 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:34.129002 47276004656000 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560874654.055832 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874654.056652 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874654.057508 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:34.129219 47519585575808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 10:17:34.130075 47276004656000 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmph8tt0dt5
W0618 10:17:34.130270 47519585575808 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpcbppzjku
I0618 10:17:34.131030 47276004656000 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmph8tt0dt5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aff960d1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:34.131254 47519585575808 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpcbppzjku', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b384c9afda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:34.131434 47276004656000 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:17:34.131670 47519585575808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:17:34.136125 47276004656000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:34.136450 47519585575808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874654.073514 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874654.074261 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874654.074938 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:34.142198 47026114872192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560874654.068367 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874654.069249 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874654.070088 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:34.142302 47965767308160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 10:17:34.143258 47026114872192 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpu8x87eg8
W0618 10:17:34.143343 47965767308160 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmplxrscray
I0618 10:17:34.144345 47026114872192 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpu8x87eg8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac567759e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:34.144405 47965767308160 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmplxrscray', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba02f1bee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:34.144828 47026114872192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:17:34.144853 47965767308160 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:17:34.150091 47965767308160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:34.150384 47026114872192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:34.156376 47276004656000 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:17:34.157362 47519585575808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874654.117663 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874654.118150 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874654.118607 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:34.161370 47126767350656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 10:17:34.162417 47126767350656 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpwr1nd0jy
I0618 10:17:34.163445 47126767350656 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpwr1nd0jy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adcd6d08e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:34.163837 47126767350656 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874654.122168 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874654.122620 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874654.123003 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:34.164246 47586894504832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560874654.095851 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874654.096594 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874654.097250 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:34.165027 47694882534272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560874654.086980 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874654.087867 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874654.088705 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:34.165192 47361196876672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 10:17:34.165273 47586894504832 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpjrszysg2
I0618 10:17:34.166281 47586894504832 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpjrszysg2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b47f887ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:34.166683 47586894504832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:17:34.166148 47694882534272 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmprs0t1wrv
W0618 10:17:34.166376 47361196876672 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpbn4kwrmx
I0618 10:17:34.167252 47694882534272 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmprs0t1wrv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b611d1e4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:34.167440 47361196876672 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpbn4kwrmx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b136be73dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:34.167686 47694882534272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:17:34.167884 47361196876672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:17:34.168701 47126767350656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:34.171454 47586894504832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874654.103395 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874654.104175 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874654.104885 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:34.171198 47097212916608 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560874654.096152 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874654.097071 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874654.097957 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:34.171340 47100413444992 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 10:17:34.173017 47694882534272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:34.172827 47965767308160 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:17:34.173086 47361196876672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:34.172313 47097212916608 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp5pwkpr8n
W0618 10:17:34.172418 47100413444992 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpsxi6i171
I0618 10:17:34.173418 47097212916608 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp5pwkpr8n', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad5f53bae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:34.173548 47100413444992 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpsxi6i171', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad6b3ffde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:17:34.174374 47026114872192 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:17:34.173855 47097212916608 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:17:34.173988 47100413444992 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:17:34.178858 47097212916608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:34.178854 47100413444992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874654.141729 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874654.142169 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874654.142491 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:34.184778 47893306377088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 10:17:34.185827 47893306377088 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp2p_0hesz
I0618 10:17:34.186797 47893306377088 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp2p_0hesz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8f5019dda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560874654.144871 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874654.145313 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874654.145688 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:34.186832 47179573023616 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000006.tfrecord.zz_0
I0618 10:17:34.187184 47893306377088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:17:34.188633 47126767350656 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:17:34.187874 47179573023616 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpf4s9ir2z
I0618 10:17:34.188909 47179573023616 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpf4s9ir2z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae922472da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:34.189298 47179573023616 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:17:34.191305 47586894504832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:17:34.191925 47893306377088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:34.193848 47179573023616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:34.195611 47361196876672 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:17:34.195636 47694882534272 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874654.155865 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874654.156314 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874654.156706 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:34.198996 47883160806272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 10:17:34.200074 47883160806272 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpfsg9riy8
I0618 10:17:34.201158 47883160806272 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpfsg9riy8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8cf360be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:34.201602 47883160806272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:17:34.201466 47100413444992 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874654.161749 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874654.162209 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874654.162602 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:34.202578 47496590156672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 10:17:34.201784 47097212916608 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:17:34.203608 47496590156672 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp5fyn_49x
W0618 10:17:34.204353 47276004656000 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:17:34.204638 47496590156672 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp5fyn_49x', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b32f1f8be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:34.205095 47496590156672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:17:34.205116 47519585575808 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:17:34.206668 47883160806272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874654.132007 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874654.132764 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874654.133535 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:34.206681 47151468630912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560874654.133883 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874654.134640 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874654.135364 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:34.206699 47333426017152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 10:17:34.208638 47276004656000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:17:34.207784 47151468630912 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp2kor4gl9
I0618 10:17:34.207813 47333426017152 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb074/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0cf4a18d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:34.208859 47151468630912 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp2kor4gl9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae297202e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:34.209126 47333426017152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:17:34.209433 47519585575808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:17:34.209304 47151468630912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:17:34.209780 47496590156672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:34.211659 47893306377088 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:17:34.213704 47276004656000 estimator.py:1111] Calling model_fn.
W0618 10:17:34.213404 47179573023616 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:17:34.213810 47276004656000 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:17:34.214518 47519585575808 estimator.py:1111] Calling model_fn.
W0618 10:17:34.214630 47519585575808 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:17:34.214596 47151468630912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:34.214613 47333426017152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:34.215169 47276004656000 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:17:34.215979 47519585575808 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560874654.176453 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874654.176849 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874654.177238 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:34.219638 47204285141888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560874654.178393 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874654.178767 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874654.179133 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:34.220039 46970992976768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 10:17:34.220619 47204285141888 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmptr0tsdcv
I0618 10:17:34.221589 47204285141888 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmptr0tsdcv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeee33c2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:17:34.220968 46970992976768 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpof9o6llk
I0618 10:17:34.221960 46970992976768 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpof9o6llk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab891f03e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:34.222020 47204285141888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:17:34.222370 46970992976768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:17:34.224106 47965767308160 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:17:34.225583 47026114872192 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:17:34.226325 47883160806272 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:17:34.226858 47204285141888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:34.227147 46970992976768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:34.228701 47965767308160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:17:34.229423 47496590156672 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:17:34.230196 47026114872192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:17:34.233963 47965767308160 estimator.py:1111] Calling model_fn.
W0618 10:17:34.234095 47965767308160 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:17:34.235507 47026114872192 estimator.py:1111] Calling model_fn.
W0618 10:17:34.235548 47965767308160 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:17:34.235644 47026114872192 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:17:34.236314 47126767350656 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560874654.162948 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874654.163833 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874654.164612 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:34.236016 47804734374784 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560874654.164157 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874654.165003 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874654.165667 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:34.236027 47450030285696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 10:17:34.237038 47151468630912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:17:34.237104 47026114872192 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:17:34.237287 47333426017152 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874654.185354 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874654.185816 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874654.186222 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:34.237231 47672187892608 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560874654.190568 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874654.190965 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874654.191297 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:17:34.237281 47291553616768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 10:17:34.237068 47804734374784 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmph84vawv7
W0618 10:17:34.237100 47450030285696 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpsd1ovcaq
I0618 10:17:34.238122 47804734374784 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmph84vawv7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7ab0cc5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:34.238140 47450030285696 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpsd1ovcaq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b281ac97dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:34.238524 47804734374784 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:17:34.238546 47450030285696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:17:34.238804 47586894504832 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:17:34.238211 47672187892608 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpkj3tmi4a
W0618 10:17:34.238253 47291553616768 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp33v2mt_k
I0618 10:17:34.239174 47672187892608 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpkj3tmi4a', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5bd4698e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:34.239227 47291553616768 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp33v2mt_k', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0334d76e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:17:34.239565 47672187892608 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:17:34.239620 47291553616768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:17:34.240636 47126767350656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:17:34.243141 47586894504832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:17:34.243288 47450030285696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:34.243296 47804734374784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:34.244004 47361196876672 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:17:34.244340 47291553616768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:17:34.244629 47694882534272 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:17:34.244344 47672187892608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:17:34.245729 47126767350656 estimator.py:1111] Calling model_fn.
W0618 10:17:34.245838 47126767350656 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:17:34.247199 47126767350656 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of [2019-06-18 10:18:13] divide_golden_chunk finished: 3.316 seconds
[2019-06-18 10:18:13] generate golden chunk: 3.331 seconds
[2019-06-18 10:18:13] moving /lfs/lfs12/gma_akey/results/epb074/models/000007-000003.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb074/models/000007-000004.data-00000-of-00001
[2019-06-18 10:18:13] moving /lfs/lfs12/gma_akey/results/epb074/models/000007-000003.meta --> /lfs/lfs12/gma_akey/results/epb074/models/000007-000004.meta
[2019-06-18 10:18:13] moving /lfs/lfs12/gma_akey/results/epb074/models/000007-000003.pb --> /lfs/lfs12/gma_akey/results/epb074/models/000007-000004.pb
[2019-06-18 10:18:13] moving /lfs/lfs12/gma_akey/results/epb074/models/000007-000003.index --> /lfs/lfs12/gma_akey/results/epb074/models/000007-000004.index
[2019-06-18 10:18:13] iteration time 6: 48.465 seconds
2019-06-18 10:18:14.036157: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874693.428795 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 7}}
[2019-06-18 10:18:17] minmax time: 3.245 seconds
2019-06-18 10:18:17.291190: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:18:17.296492: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:18:17.300975: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874697.310525 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 6}}
[2019-06-18 10:18:17] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000008-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000008-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000008-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000008-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000008-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000008-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000008-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000008-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000008-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000008-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000008-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir 
[2019-06-18 10:18:17] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-8-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000007-000004 --seed=8 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000007-000004 --seed=1023779839 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000007-000004 --seed=2047559670 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000007-000004 --seed=3071339501 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000007-000004 --seed=4095119332 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000007-000004 --seed=5118899163 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000007-000004 --seed=6142678994 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000007-000004 --seed=7166458825 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000007-000004 --seed=8190238656 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000007-000004 --seed=9214018487 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000007-000004 --seed=10237798318 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000007-000004 --seed=11261578149 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000007-000004 --seed=12285357980 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000007-000004 --seed=13309137811 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000007-000004 --seed=14332917642 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000007-000004 --seed=15356697473 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000007-000004 --seed=16380477304 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000007-000004 --seed=17404257135 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000007-000004 --seed=18428036966 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000007-000004 --seed=19451816797 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000007-000004 --seed=20475596628 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 10:18:28] eval finished: 11.563 seconds
[2019-06-18 10:18:28] Win rate 000007-000004 vs 000006-000003: 0.360
:::MLL 1560874708.948267 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 6}}
[2019-06-18 10:18:28] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-9-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000008-000003 --seed=9 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000008-000003 --seed=1023779840 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000008-000003 --seed=2047559671 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000008-000003 --seed=3071339502 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000008-000003 --seed=4095119333 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000008-000003 --seed=5118899164 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000008-000003 --seed=6142678995 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000008-000003 --seed=7166458826 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000008-000003 --seed=8190238657 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000008-000003 --seed=9214018488 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000008-000003 --seed=10237798319 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000008-000003 --seed=11261578150 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000008-000003 --seed=12285357981 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000008-000003 --seed=13309137812 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000008-000003 --seed=14332917643 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000008-000003 --seed=15356697474 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000008-000003 --seed=16380477305 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000008-000003 --seed=17404257136 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000008-000003 --seed=18428036967 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/
[2019-06-18 10:18:57] selfplay finished: 29.012 seconds
[2019-06-18 10:18:57] selfplay mn: 29.028 seconds
[2019-06-18 10:18:57] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-9-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779840 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559671 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339502 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119333 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899164 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142678995 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458826 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238657 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018488 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798319 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578150 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285357981 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137812 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917643 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697474 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477305 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257136 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036967 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816798 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596629 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376460 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156291 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_
[2019-06-18 10:19:01] divide_golden_chunk finished: 3.261 seconds
[2019-06-18 10:19:01] generate golden chunk: 3.276 seconds
[2019-06-18 10:19:01] train finished: 44.044 seconds
:::MLL 1560874702.600016 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874702.600853 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874702.601592 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:22.674858 47437477634944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560874702.599676 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874702.600459 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874702.601231 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:22.674893 47935413158784 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 10:18:22.675917 47935413158784 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpe_ewrj4y
W0618 10:18:22.675949 47437477634944 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpszy6d7n5
I0618 10:18:22.676949 47935413158784 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpe_ewrj4y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b991ddc5e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:22.676988 47437477634944 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpszy6d7n5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b252e973e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:22.677342 47935413158784 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:18:22.677383 47437477634944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:18:22.682201 47935413158784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:22.682204 47437477634944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874702.610222 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874702.611130 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874702.611995 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:22.685637 47189517595520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560874702.617335 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874702.618064 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874702.618758 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:22.685822 47310859629440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 10:18:22.686700 47189517595520 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpcjf350xl
W0618 10:18:22.686802 47310859629440 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp2yqbnrhf
I0618 10:18:22.687700 47189517595520 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpcjf350xl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeb73054e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:22.687777 47310859629440 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp2yqbnrhf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b07b391ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:22.688096 47189517595520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:18:22.688176 47310859629440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:18:22.693265 47189517595520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:22.693322 47310859629440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874702.617287 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874702.618167 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874702.619029 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:22.696322 47723106464640 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560874702.626282 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874702.627000 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874702.627678 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:22.696436 47333506376576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 10:18:22.697417 47723106464640 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpi7yo5g59
W0618 10:18:22.697533 47333506376576 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmptnq0m18w
I0618 10:18:22.698513 47723106464640 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpi7yo5g59', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b67af654dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:22.698651 47333506376576 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmptnq0m18w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0cf96b9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:22.698959 47723106464640 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:18:22.699109 47333506376576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:18:22.702036 47935413158784 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:22.702214 47437477634944 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:22.704183 47723106464640 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:22.704374 47333506376576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:22.715693 47189517595520 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:22.715705 47310859629440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874702.676042 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874702.676477 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874702.676858 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:22.721094 47842246931328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 10:18:22.722168 47842246931328 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpfd4fqai8
I0618 10:18:22.723233 47842246931328 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpfd4fqai8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b836cb88e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:22.723722 47842246931328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874702.676151 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874702.676596 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874702.676980 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:22.725679 47651642049408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 10:18:22.726289 47723106464640 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:22.726844 47333506376576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:22.726639 47651642049408 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpwknq10pw
I0618 10:18:22.727633 47651642049408 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpwknq10pw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b570bc8ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:22.728049 47651642049408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:18:22.728570 47842246931328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874702.679162 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874702.679660 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874702.680104 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:22.729591 47648590189440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560874702.678918 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874702.679334 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874702.679737 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:22.729712 47453498110848 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 10:18:22.730581 47648590189440 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpuoxgg9i2
W0618 10:18:22.730661 47453498110848 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp2ywj02n7
I0618 10:18:22.731547 47648590189440 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpuoxgg9i2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5655e12e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:22.731623 47453498110848 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp2ywj02n7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b28e97c3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:22.731946 47648590189440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:18:22.732036 47453498110848 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:18:22.732659 47651642049408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874702.688355 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874702.688779 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874702.689101 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:22.734040 47558024553344 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560874702.687430 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874702.687843 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874702.688221 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:22.734051 47567659127680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 10:18:22.735067 47558024553344 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpu73zhtnt
W0618 10:18:22.735094 47567659127680 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp58ds7k9z
I0618 10:18:22.736043 47558024553344 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpu73zhtnt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b413fbf2e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:22.736073 47567659127680 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp58ds7k9z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b437e032e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:22.736435 47558024553344 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:18:22.736459 47567659127680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:18:22.736723 47453498110848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:22.736753 47648590189440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:22.741091 47567659127680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:22.741144 47558024553344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:22.748138 47842246931328 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:22.749751 47935413158784 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:18:22.750001 47437477634944 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:18:22.752283 47651642049408 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:22.754035 47935413158784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:18:22.754291 47437477634944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:18:22.756244 47453498110848 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874702.674017 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874702.674907 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874702.675719 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:22.755077 47330900960128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560874702.673753 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874702.674630 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874702.675498 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:22.755070 47829286691712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 10:18:22.756487 47648590189440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:22.756213 47330900960128 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpk1dg5x17
W0618 10:18:22.756247 47829286691712 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp8nmsyyfz
I0618 10:18:22.757325 47330900960128 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpk1dg5x17', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0c5e203e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:22.757344 47829286691712 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp8nmsyyfz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b80683afe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:22.757757 47330900960128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:18:22.757778 47829286691712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:18:22.759091 47935413158784 estimator.py:1111] Calling model_fn.
W0618 10:18:22.759200 47935413158784 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:18:22.759329 47437477634944 estimator.py:1111] Calling model_fn.
W0618 10:18:22.759441 47437477634944 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:18:22.760557 47935413158784 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:18:22.760792 47437477634944 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:18:22.760958 47558024553344 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:22.760992 47567659127680 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:22.763116 47330900960128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:22.763114 47829286691712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:22.765510 47310859629440 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:18:22.765565 47189517595520 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560874702.696173 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874702.696918 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874702.697591 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:22.767574 47193323320192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560874702.692144 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874702.693070 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874702.693820 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:22.767585 47879905215360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 10:18:22.768677 47879905215360 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp8x7wrxmm
I0618 10:18:22.768704 47193323320192 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb074/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aec55dc0d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:22.769761 47879905215360 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp8x7wrxmm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8c31545e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:18:22.769814 47310859629440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:18:22.769964 47193323320192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:18:22.769856 47189517595520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:18:22.770209 47879905215360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:18:22.774519 47723106464640 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:18:22.774972 47333506376576 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:18:22.774896 47310859629440 estimator.py:1111] Calling model_fn.
I0618 10:18:22.774895 47189517595520 estimator.py:1111] Calling model_fn.
W0618 10:18:22.775004 47310859629440 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:18:22.775005 47189517595520 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:18:22.775229 47193323320192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:22.775377 47879905215360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:22.776375 47310859629440 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:18:22.776358 47189517595520 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:18:22.778805 47723106464640 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:18:22.779262 47333506376576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:18:22.783862 47723106464640 estimator.py:1111] Calling model_fn.
W0618 10:18:22.783970 47723106464640 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:18:22.784327 47333506376576 estimator.py:1111] Calling model_fn.
W0618 10:18:22.784433 47333506376576 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560874702.731071 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874702.731471 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874702.731824 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:22.783390 47943879037824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560874702.720836 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874702.721342 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874702.721779 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:22.783590 47572157752192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 10:18:22.785329 47723106464640 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:18:22.785785 47333506376576 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:18:22.784845 47330900960128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:22.784953 47829286691712 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:22.784381 47943879037824 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpahp14niz
W0618 10:18:22.784539 47572157752192 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpkybneiys
I0618 10:18:22.785357 47943879037824 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpahp14niz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9b16775e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:22.785483 47572157752192 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpkybneiys', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b448a26be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:22.785745 47943879037824 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:18:22.785867 47572157752192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874702.715189 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874702.715960 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874702.716748 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:22.790734 47794550195072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560874702.717203 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874702.717959 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874702.718644 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:22.790961 46961587499904 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 10:18:22.790398 47943879037824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:22.790450 47572157752192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:22.791878 47794550195072 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp1sg2krho
W0618 10:18:22.792040 46961587499904 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp1lyp2_op
I0618 10:18:22.792902 47794550195072 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp1sg2krho', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7851c61dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:22.793034 46961587499904 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp1lyp2_op', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab66153fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:22.793297 47794550195072 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:18:22.793421 46961587499904 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:18:22.795732 47842246931328 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:18:22.797482 47193323320192 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:22.797946 47879905215360 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:18:22.798040 47794550195072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:22.798162 46961587499904 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:18:22.799601 47651642049408 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:18:22.800048 47842246931328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560874702.753397 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874702.753972 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874702.754433 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:22.799560 47321858237312 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 10:18:22.800545 47321858237312 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpsagnuhja
:::MLL 1560874702.757386 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874702.757825 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874702.758205 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:18:22.801276 47831900226432 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000007.tfrecord.zz_0
I0618 10:18:22.801530 47321858237312 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpsagnuhja', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0a43232e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:18:22.801953 47321858237312 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:18:22.802294 47831900226432 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp0er65a_h
I0618 10:18:22.803276 47831900226432 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp0er65a_h', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_[2019-06-18 10:19:01] iteration time 7: 47.947 seconds
2019-06-18 10:19:02.025826: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874741.375881 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 8}}
[2019-06-18 10:19:05] minmax time: 3.241 seconds
2019-06-18 10:19:05.277011: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:19:05.282305: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:19:05.286917: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874745.298324 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 7}}
[2019-06-18 10:19:05] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000009-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000009-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000009-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000009-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000009-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000009-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000009-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000009-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000009-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000009-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000009-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:19:05] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-9-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000008-000004 --seed=9 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000008-000004 --seed=1023779840 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000008-000004 --seed=2047559671 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000008-000004 --seed=3071339502 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000008-000004 --seed=4095119333 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000008-000004 --seed=5118899164 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000008-000004 --seed=6142678995 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000008-000004 --seed=7166458826 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000008-000004 --seed=8190238657 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000008-000004 --seed=9214018488 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000008-000004 --seed=10237798319 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000008-000004 --seed=11261578150 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000008-000004 --seed=12285357981 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000008-000004 --seed=13309137812 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000008-000004 --seed=14332917643 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000008-000004 --seed=15356697474 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000008-000004 --seed=16380477305 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000008-000004 --seed=17404257136 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000008-000004 --seed=18428036967 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000008-000004 --seed=19451816798 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000008-000004 --seed=20475596629 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 10:19:16] eval finished: 11.556 seconds
[2019-06-18 10:19:16] Win rate 000008-000004 vs 000006-000003: 0.640
:::MLL 1560874756.930926 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 7}}
[2019-06-18 10:19:16] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-10-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000009-000003 --seed=10 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000009-000003 --seed=1023779841 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000009-000003 --seed=2047559672 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000009-000003 --seed=3071339503 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000009-000003 --seed=4095119334 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000009-000003 --seed=5118899165 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000009-000003 --seed=6142678996 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000009-000003 --seed=7166458827 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000009-000003 --seed=8190238658 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000009-000003 --seed=9214018489 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000009-000003 --seed=10237798320 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000009-000003 --seed=11261578151 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000009-000003 --seed=12285357982 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000009-000003 --seed=13309137813 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000009-000003 --seed=14332917644 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000009-000003 --seed=15356697475 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000009-000003 --seed=16380477306 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000009-000003 --seed=17404257137 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000009-000003 --seed=18428036968 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:19:48] train finished: 43.401 seconds
:::MLL 1560874750.588970 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874750.589723 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874750.590369 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:10.660192 47197315670912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560874750.581667 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874750.582529 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874750.583311 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:10.660241 47993508868992 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 10:19:10.661212 47197315670912 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp6bpwjvn8
W0618 10:19:10.661300 47993508868992 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpody49y77
I0618 10:19:10.662201 47197315670912 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp6bpwjvn8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aed43d26da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:10.662298 47993508868992 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpody49y77', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba6a4a27e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:10.662599 47197315670912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:19:10.662709 47993508868992 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:19:10.667310 47197315670912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:10.667345 47993508868992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874750.599039 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874750.599789 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874750.600468 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:10.667894 46970111320960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560874750.585920 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874750.586818 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874750.587649 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:10.667932 47660711637888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560874750.588166 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874750.588901 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874750.589616 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:10.669406 46946456777600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560874750.582338 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874750.583202 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874750.584054 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:10.669440 46992357475200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 10:19:10.668895 46970111320960 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpas5cebnr
W0618 10:19:10.668920 47660711637888 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpbs5mwj1i
I0618 10:19:10.669871 46970111320960 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpas5cebnr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab85d633e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:10.669881 47660711637888 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpbs5mwj1i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b59285fce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:10.670319 46970111320960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:19:10.670319 47660711637888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:19:10.670471 46992357475200 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmplzkqt06n
W0618 10:19:10.670500 46946456777600 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpydf13e9g
I0618 10:19:10.671465 46992357475200 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmplzkqt06n', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abd8b5c9e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:10.671490 46946456777600 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpydf13e9g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab2db778e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:10.671866 46992357475200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:19:10.671896 46946456777600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:19:10.675643 47660711637888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:10.675650 46970111320960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:10.677156 46946456777600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:10.677221 46992357475200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874750.584602 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874750.585450 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874750.586114 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:10.684064 47854979830656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560874750.583799 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874750.584633 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874750.585413 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:10.684308 47189956174720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 10:19:10.685160 47854979830656 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp1vjpomq2
W0618 10:19:10.685406 47189956174720 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpc60hmerp
I0618 10:19:10.686264 47854979830656 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp1vjpomq2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8663a91e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:10.686517 47189956174720 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpc60hmerp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeb8d297dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:10.686717 47854979830656 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:19:10.686969 47189956174720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:19:10.687421 47197315670912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:19:10.687499 47993508868992 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:19:10.691993 47854979830656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:10.692370 47189956174720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:10.697878 47660711637888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:19:10.698126 46970111320960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:19:10.699426 46946456777600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:19:10.699650 46992357475200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874750.652996 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874750.653440 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874750.653857 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:10.701715 47149040587648 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560874750.654046 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874750.654488 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874750.654861 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:10.701850 47128814179200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 10:19:10.702720 47149040587648 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp34d8lj0z
W0618 10:19:10.702798 47128814179200 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpdjsh152o
I0618 10:19:10.703698 47149040587648 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp34d8lj0z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae206672e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:10.703763 47128814179200 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpdjsh152o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2add50d0ada0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:10.704086 47149040587648 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:19:10.704150 47128814179200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:19:10.708712 47128814179200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:10.708721 47149040587648 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874750.643803 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874750.644226 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874750.644591 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:10.711434 47388724249472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560874750.638536 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874750.639032 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874750.639439 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:10.711402 47259895255936 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 10:19:10.712403 47259895255936 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp_j1d52st
W0618 10:19:10.712434 47388724249472 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp62xns_r5
I0618 10:19:10.713393 47259895255936 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp_j1d52st', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afbd5db2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:10.713438 47388724249472 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp62xns_r5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b19d4a99e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:10.713789 47259895255936 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:19:10.713833 47388724249472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:19:10.714084 47854979830656 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:19:10.714475 47189956174720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874750.662950 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874750.663401 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874750.663779 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:10.716939 48007559701376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560874750.667127 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874750.667503 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874750.667828 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:10.716944 47978552341376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 10:19:10.718426 47259895255936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:10.718447 47388724249472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874750.669347 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874750.669793 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874750.670233 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:10.718359 47975848702848 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560874750.669339 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874750.669793 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874750.670232 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:10.718400 47679815598976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 10:19:10.717952 48007559701376 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpv306wb50
W0618 10:19:10.717985 47978552341376 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmptm21_szw
I0618 10:19:10.719004 48007559701376 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpv306wb50', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba9ea213e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:10.719038 47978552341376 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmptm21_szw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba329280e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:19:10.719401 47975848702848 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpsfwh6t31
W0618 10:19:10.719374 47679815598976 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmps9am64iz
I0618 10:19:10.719404 48007559701376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:19:10.719424 47978552341376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:19:10.720353 47679815598976 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmps9am64iz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5d9b0f1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:10.720375 47975848702848 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpsfwh6t31', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba28801cda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:10.720755 47679815598976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:19:10.720769 47975848702848 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:19:10.724169 48007559701376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:10.724189 47978552341376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:10.725489 47975848702848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:10.725498 47679815598976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:10.728251 47149040587648 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:19:10.728300 47128814179200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:19:10.735115 47197315670912 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:19:10.735411 47993508868992 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560874750.662116 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874750.662859 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874750.663573 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:10.736916 47877385053056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560874750.660172 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874750.660942 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874750.661749 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:10.736873 47186313483136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 10:19:10.738060 47259895255936 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:19:10.738177 47388724249472 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:19:10.737933 47877385053056 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmped49ymqy
W0618 10:19:10.737900 47186313483136 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpz0kwi7e4
I0618 10:19:10.738892 47186313483136 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpz0kwi7e4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeab40a5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:10.738942 47877385053056 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmped49ymqy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8b9b1dbdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:19:10.739419 47197315670912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:19:10.739319 47186313483136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:19:10.739363 47877385053056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:19:10.739729 47993508868992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:19:10.744174 47186313483136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:19:10.744451 47197315670912 estimator.py:1111] Calling model_fn.
W0618 10:19:10.744181 47877385053056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:10.744561 47197315670912 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:19:10.743600 47978552341376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:19:10.743649 48007559701376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:19:10.744779 47993508868992 estimator.py:1111] Calling model_fn.
W0618 10:19:10.744889 47993508868992 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:19:10.745092 47975848702848 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:19:10.745079 47679815598976 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:19:10.745908 47197315670912 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:19:10.746247 47993508868992 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:19:10.749823 47660711637888 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:19:10.749912 46970111320960 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:19:10.750875 46946456777600 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:19:10.751462 46992357475200 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:19:10.754451 47660711637888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:19:10.754529 46970111320960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:19:10.755470 46946456777600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:19:10.756112 46992357475200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:19:10.759943 46970111320960 estimator.py:1111] Calling model_fn.
I0618 10:19:10.759906 47660711637888 estimator.py:1111] Calling model_fn.
W0618 10:19:10.760019 47660711637888 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:19:10.760054 46970111320960 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:19:10.760889 46946456777600 estimator.py:1111] Calling model_fn.
W0618 10:19:10.761006 46946456777600 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:19:10.761585 46992357475200 estimator.py:1111] Calling model_fn.
W0618 10:19:10.761698 46992357475200 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:19:10.762137 47854979830656 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:19:10.762350 47189956174720 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:19:10.761505 46970111320960 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:19:10.761479 47660711637888 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:19:10.762459 46946456777600 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:19:10.763151 46992357475200 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560874750.687181 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874750.688142 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874750.689031 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:10.763548 47363707790208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 10:19:10.763723 47877385053056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874750.694032 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874750.694844 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874750.695566 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:10.763669 47887716778880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 10:19:10.763875 47186313483136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:19:10.764620 47363707790208 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpuntfxmi4
I0618 10:19:10.764780 47887716778880 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb074/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8e02ef5d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:10.765719 47363707790208 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpuntfxmi4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b140190be80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:19:10.766035 47887716778880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:19:10.766160 47363707790208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:19:10.766440 47854979830656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:19:10.766634 47189956174720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:19:10.771461 47854979830656 estimator.py:1111] Calling model_fn.
W0618 10:19:10.771571 47854979830656 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:19:10.771709 47189956174720 estimator.py:1111] Calling model_fn.
W0618 10:19:10.771437 47363707790208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:10.771482 47887716778880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:19:10.771818 47189956174720 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:19:10.772922 47854979830656 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:19:10.773194 47189956174720 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:19:10.775856 47149040587648 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:19:10.776108 47128814179200 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:19:10.780188 47149040587648 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:19:10.780422 47128814179200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:19:10.785268 47149040587648 estimator.py:1111] Calling model_fn.
W0618 10:19:10.785379 47149040587648 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:19:10.785359 47259895255936 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:19:10.785495 47128814179200 estimator.py:1111] Calling model_fn.
W0618 10:19:10.785602 47128814179200 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:19:10.785756 47388724249472 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560874750.736586 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874750.736974 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874750.737293 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:10.785740 47574385890176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560874750.738807 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874750.739286 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874750.739701 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:19:10.786136 47437413790592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 10:19:10.786754 47149040587648 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:19:10.786965 47128814179200 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:19:10.786747 47574385890176 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpmpy9odx9
I0618 10:19:10.787714 47574385890176 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpmpy9odx9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
[2019-06-18 10:19:50] selfplay finished: 33.382 seconds
[2019-06-18 10:19:50] selfplay mn: 33.398 seconds
[2019-06-18 10:19:50] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-10-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779841 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559672 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339503 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119334 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899165 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142678996 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458827 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238658 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018489 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798320 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578151 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285357982 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137813 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917644 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697475 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477306 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257137 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036968 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816799 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596630 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376461 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156292 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000009-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golde
[2019-06-18 10:19:53] divide_golden_chunk finished: 3.359 seconds
[2019-06-18 10:19:53] generate golden chunk: 3.374 seconds
[2019-06-18 10:19:53] moving /lfs/lfs12/gma_akey/results/epb074/models/000009-000004.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb074/models/000009-000005.data-00000-of-00001
[2019-06-18 10:19:53] moving /lfs/lfs12/gma_akey/results/epb074/models/000009-000004.meta --> /lfs/lfs12/gma_akey/results/epb074/models/000009-000005.meta
[2019-06-18 10:19:53] moving /lfs/lfs12/gma_akey/results/epb074/models/000009-000004.pb --> /lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb
[2019-06-18 10:19:53] moving /lfs/lfs12/gma_akey/results/epb074/models/000009-000004.index --> /lfs/lfs12/gma_akey/results/epb074/models/000009-000005.index
[2019-06-18 10:19:53] iteration time 8: 52.372 seconds
2019-06-18 10:19:54.435856: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874793.748152 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 9}}
[2019-06-18 10:19:57] minmax time: 3.251 seconds
2019-06-18 10:19:57.696655: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:19:57.701787: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:19:57.706226: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874797.715803 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 8}}
[2019-06-18 10:19:57] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000010-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000010-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000010-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000010-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000010-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000010-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000010-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000010-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000010-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000010-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000010-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:19:57] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-10-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000009-000005 --seed=10 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000009-000005 --seed=1023779841 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000009-000005 --seed=2047559672 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000009-000005 --seed=3071339503 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000009-000005 --seed=4095119334 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000009-000005 --seed=5118899165 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000009-000005 --seed=6142678996 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000009-000005 --seed=7166458827 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000009-000005 --seed=8190238658 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000009-000005 --seed=9214018489 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000009-000005 --seed=10237798320 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000009-000005 --seed=11261578151 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000009-000005 --seed=12285357982 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000009-000005 --seed=13309137813 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000009-000005 --seed=14332917644 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000009-000005 --seed=15356697475 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000009-000005 --seed=16380477306 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000009-000005 --seed=17404257137 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000009-000005 --seed=18428036968 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000009-000005 --seed=19451816799 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000009-000005 --seed=20475596630 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:20:10] eval finished: 12.521 seconds
[2019-06-18 10:20:10] Win rate 000009-000005 vs 000008-000004: 0.500
:::MLL 1560874810.314219 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 8}}
[2019-06-18 10:20:10] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-11-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000010-000004 --seed=11 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000010-000004 --seed=1023779842 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000010-000004 --seed=2047559673 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000010-000004 --seed=3071339504 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000010-000004 --seed=4095119335 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000010-000004 --seed=5118899166 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000010-000004 --seed=6142678997 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000010-000004 --seed=7166458828 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000010-000004 --seed=8190238659 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000010-000004 --seed=9214018490 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000010-000004 --seed=10237798321 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000010-000004 --seed=11261578152 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000010-000004 --seed=12285357983 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000010-000004 --seed=13309137814 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000010-000004 --seed=14332917645 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000010-000004 --seed=15356697476 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000010-000004 --seed=16380477307 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000010-000004 --seed=17404257138 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000010-000004 --seed=18428036969 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:20:40] selfplay finished: 30.575 seconds
[2019-06-18 10:20:40] selfplay mn: 30.592 seconds
[2019-06-18 10:20:40] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-11-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779842 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559673 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339504 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119335 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899166 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142678997 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458828 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238659 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018490 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798321 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578152 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285357983 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137814 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917645 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697476 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477307 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257138 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036969 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816800 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596631 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376462 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156293 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000010-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golde
[2019-06-18 10:20:41] train finished: 43.958 seconds
:::MLL 1560874802.966889 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874802.967595 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874802.968215 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:03.042930 47088239899520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560874802.965035 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874802.965702 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874802.966450 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:03.043148 47535880160128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 10:20:03.044025 47088239899520 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp_dne3nht
W0618 10:20:03.044159 47535880160128 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmptebpwhk7
I0618 10:20:03.045018 47088239899520 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp_dne3nht', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad3de664e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:03.045147 47535880160128 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmptebpwhk7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3c17d69e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:03.045429 47088239899520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:20:03.045542 47535880160128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:03.050200 47088239899520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:03.050201 47535880160128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874802.972201 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874802.973106 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874802.973973 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:03.050778 47584563348352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560874802.993588 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874802.994434 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874802.995228 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:03.050927 47902532526976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 10:20:03.051808 47584563348352 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpqag1mj9v
W0618 10:20:03.051906 47902532526976 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpbmsg38ug
I0618 10:20:03.052777 47584563348352 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpqag1mj9v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b476d951da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:03.052894 47902532526976 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpbmsg38ug', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b917605ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:03.053168 47584563348352 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:20:03.053300 47902532526976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:03.058318 47584563348352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:03.058676 47902532526976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:03.070007 47535880160128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:03.070091 47088239899520 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874802.992028 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874802.992758 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874802.993464 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:03.069864 47073186620288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560874802.988096 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874802.988969 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874802.989663 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:03.069934 47358840300416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 10:20:03.070935 47073186620288 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpb5p8_4re
W0618 10:20:03.070971 47358840300416 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpz7hyt_oj
I0618 10:20:03.072108 47073186620288 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpb5p8_4re', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad05d276e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:03.072154 47358840300416 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpz7hyt_oj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b12df709e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:03.072567 47073186620288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:20:03.072605 47358840300416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:03.077784 47073186620288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:03.077829 47358840300416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:03.080775 47584563348352 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:03.081537 47902532526976 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874803.039358 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874803.039780 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874803.040147 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:03.090916 47763143123840 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560874803.040611 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874803.041016 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874803.041363 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:03.091011 47610981507968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 10:20:03.091972 47763143123840 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpg2l7sxya
W0618 10:20:03.092030 47610981507968 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmprq06uoqb
I0618 10:20:03.092957 47763143123840 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpg2l7sxya', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7101c43e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:03.093007 47610981507968 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmprq06uoqb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4d943a2da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:03.093342 47763143123840 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:20:03.093393 47610981507968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874803.016459 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874803.017362 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874803.018190 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:03.094305 47168820880256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560874803.025326 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874803.026020 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874803.026686 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:03.094395 47519769944960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 10:20:03.095403 47168820880256 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpb05q9dv2
W0618 10:20:03.095488 47519769944960 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp2ke9i088
I0618 10:20:03.096469 47168820880256 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpb05q9dv2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae6a1667dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:03.096591 47519769944960 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp2ke9i088', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3857983e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:20:03.097954 47610981507968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:20:03.096915 47168820880256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:03.097963 47763143123840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:20:03.097043 47519769944960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:03.100081 47358840300416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:03.100454 47073186620288 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874803.048912 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874803.049291 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874803.049615 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:03.101827 47884043932544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560874803.051414 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874803.051790 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874803.052105 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:03.101809 47438704251776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 10:20:03.102168 47168820880256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:03.102278 47519769944960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:03.102901 47884043932544 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmps8lv7hzl
W0618 10:20:03.102870 47438704251776 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp00t2rndk
I0618 10:20:03.103958 47438704251776 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp00t2rndk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2577b3ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:03.103991 47884043932544 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmps8lv7hzl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8d28042da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:03.104373 47438704251776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:20:03.104407 47884043932544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:03.109064 47438704251776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:03.109136 47884043932544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:03.117414 47610981507968 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:03.117459 47763143123840 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:03.117604 47535880160128 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:03.118179 47088239899520 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560874803.067841 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874803.068251 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874803.068602 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:03.118347 47515833213824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560874803.067970 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874803.068383 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874803.068727 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:03.118418 47626914009984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560874803.040684 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874803.041581 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874803.042446 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:03.118361 47407590069120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560874803.053849 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874803.054709 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874803.055502 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:03.118378 47710254805888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 10:20:03.119301 47515833213824 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpe4az37jm
W0618 10:20:03.119396 47626914009984 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpby012yk1
I0618 10:20:03.120325 47515833213824 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpe4az37jm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b376cf27dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:03.120517 47626914009984 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpby012yk1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5149e0edd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:20:03.119516 47407590069120 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp79ajwgrv
I0618 10:20:03.119533 47710254805888 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb074/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b64b1607d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:03.120751 47515833213824 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:20:03.120627 47407590069120 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp79ajwgrv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1e39272e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:03.120940 47626914009984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:20:03.120847 47710254805888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:20:03.121081 47407590069120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:03.121881 47535880160128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:20:03.122512 47088239899520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:20:03.125499 47515833213824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:03.124560 47168820880256 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:03.125656 47626914009984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:03.124804 47519769944960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:03.126290 47407590069120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:03.126415 47710254805888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:20:03.126912 47535880160128 estimator.py:1111] Calling model_fn.
W0618 10:20:03.127018 47535880160128 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:20:03.127540 47088239899520 estimator.py:1111] Calling model_fn.
W0618 10:20:03.127651 47088239899520 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:20:03.128368 47535880160128 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:20:03.128424 47438704251776 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:03.128994 47088239899520 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:20:03.128606 47884043932544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:03.130787 47584563348352 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:03.131364 47902532526976 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:03.135071 47584563348352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:20:03.135693 47902532526976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560874803.087090 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874803.087528 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874803.087919 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:03.137618 47085560120192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 10:20:03.138588 47085560120192 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp9otikgse
I0618 10:20:03.140112 47584563348352 estimator.py:1111] Calling model_fn.
W0618 10:20:03.140219 47584563348352 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:20:03.139564 47085560120192 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp9otikgse', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad33eac0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560874803.091504 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874803.091959 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874803.092321 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:03.139567 46925937341312 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_0
I0618 10:20:03.139959 47085560120192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:20:03.140735 47902532526976 estimator.py:1111] Calling model_fn.
W0618 10:20:03.140847 47902532526976 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:20:03.141571 47584563348352 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:20:03.140554 46925937341312 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpt1z20a26
W0618 10:20:03.142195 47902532526976 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:20:03.141558 46925937341312 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpt1z20a26', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aae1469ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:03.141950 46925937341312 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:03.145077 47515833213824 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:03.145379 47626914009984 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:03.144559 47085560120192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:03.146401 46925937341312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:03.148579 47407590069120 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:03.149953 47710254805888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:03.150194 47358840300416 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:03.150404 47073186620288 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:03.154657 47358840300416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:20:03.154848 47073186620288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:20:03.159849 47358840300416 estimator.py:1111] Calling model_fn.
W0618 10:20:03.159983 47358840300416 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:20:03.160017 47073186620288 estimator.py:1111] Calling model_fn.
W0618 10:20:03.160134 47073186620288 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:20:03.161435 47358840300416 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:20:03.161618 47073186620288 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:20:03.164066 47085560120192 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:03.165305 47610981507968 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:03.165382 47763143123840 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:03.165701 46925937341312 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874803.115159 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874803.115532 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874803.115847 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:03.166823 46923990844288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560874803.116955 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874803.117328 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874803.117657 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:03.166934 47588026409856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 10:20:03.167832 46923990844288 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmps9pkly1a
W0618 10:20:03.167911 47588026409856 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpaj1l5fry
I0618 10:20:03.168842 46923990844288 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmps9pkly1a', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aada0649e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:03.168878 47588026409856 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpaj1l5fry', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b483bff2e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:03.169243 46923990844288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:20:03.169265 47588026409856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:03.169627 47610981507968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:20:03.169717 47763143123840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:20:03.173884 47588026409856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:03.173884 46923990844288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874803.096992 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874803.097965 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874803.098833 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:03.174032 47598632268672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560874803.096924 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874803.097878 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874803.098794 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:03.174067 47734200800128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz_0
I0618 10:20:03.174686 47610981507968 estimator.py:1111] Calling model_fn.
W0618 10:20:03.174793 47610981507968 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmar[2019-06-18 10:20:44] divide_golden_chunk finished: 3.307 seconds
[2019-06-18 10:20:44] generate golden chunk: 3.322 seconds
[2019-06-18 10:20:44] moving /lfs/lfs12/gma_akey/results/epb074/models/000010-000005.meta --> /lfs/lfs12/gma_akey/results/epb074/models/000010-000006.meta
[2019-06-18 10:20:44] moving /lfs/lfs12/gma_akey/results/epb074/models/000010-000005.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb074/models/000010-000006.data-00000-of-00001
[2019-06-18 10:20:44] moving /lfs/lfs12/gma_akey/results/epb074/models/000010-000005.index --> /lfs/lfs12/gma_akey/results/epb074/models/000010-000006.index
[2019-06-18 10:20:44] moving /lfs/lfs12/gma_akey/results/epb074/models/000010-000005.pb --> /lfs/lfs12/gma_akey/results/epb074/models/000010-000006.pb
[2019-06-18 10:20:44] iteration time 9: 50.522 seconds
2019-06-18 10:20:44.993432: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874844.270453 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 10}}
[2019-06-18 10:20:48] minmax time: 3.249 seconds
2019-06-18 10:20:48.251908: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:20:48.257322: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:20:48.261862: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874848.271837 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 9}}
[2019-06-18 10:20:48] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:20:48] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-11-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000010-000006 --seed=11 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000010-000006 --seed=1023779842 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000010-000006 --seed=2047559673 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000010-000006 --seed=3071339504 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000010-000006 --seed=4095119335 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000010-000006 --seed=5118899166 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000010-000006 --seed=6142678997 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000010-000006 --seed=7166458828 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000010-000006 --seed=8190238659 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000010-000006 --seed=9214018490 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000010-000006 --seed=10237798321 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000010-000006 --seed=11261578152 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000010-000006 --seed=12285357983 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000010-000006 --seed=13309137814 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000010-000006 --seed=14332917645 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000010-000006 --seed=15356697476 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000010-000006 --seed=16380477307 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000010-000006 --seed=17404257138 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000010-000006 --seed=18428036969 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000010-000006 --seed=19451816800 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000010-000006 --seed=20475596631 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:20:58] eval finished: 10.636 seconds
[2019-06-18 10:20:58] Win rate 000010-000006 vs 000009-000005: 0.280
:::MLL 1560874858.983878 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 9}}
[2019-06-18 10:20:58] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-12-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000011-000005 --seed=12 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000011-000005 --seed=1023779843 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000011-000005 --seed=2047559674 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000011-000005 --seed=3071339505 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000011-000005 --seed=4095119336 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000011-000005 --seed=5118899167 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000011-000005 --seed=6142678998 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000011-000005 --seed=7166458829 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000011-000005 --seed=8190238660 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000011-000005 --seed=9214018491 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000011-000005 --seed=10237798322 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000011-000005 --seed=11261578153 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000011-000005 --seed=12285357984 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000011-000005 --seed=13309137815 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000011-000005 --seed=14332917646 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000011-000005 --seed=15356697477 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000011-000005 --seed=16380477308 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000011-000005 --seed=17404257139 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000011-000005 --seed=18428036970 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:21:30] selfplay finished: 31.418 seconds
[2019-06-18 10:21:30] selfplay mn: 31.435 seconds
[2019-06-18 10:21:30] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-12-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779843 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559674 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339505 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119336 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899167 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142678998 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458829 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238660 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018491 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798322 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578153 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285357984 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137815 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917646 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697477 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477308 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257139 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036970 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816801 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596632 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376463 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156294 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golde
[2019-06-18 10:21:32] train finished: 43.737 seconds
:::MLL 1560874853.507061 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874853.507772 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874853.508463 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:53.579680 47173291201408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560874853.499331 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874853.500174 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874853.500980 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:53.579834 47761705743232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 10:20:53.580730 47173291201408 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpyifuxd80
W0618 10:20:53.580797 47761705743232 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpnxcrf36q
I0618 10:20:53.581714 47173291201408 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpyifuxd80', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae7abda2e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:53.581775 47761705743232 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpnxcrf36q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b70ac178e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:53.582110 47173291201408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:20:53.582166 47761705743232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:53.587085 47761705743232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:53.587105 47173291201408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874853.508467 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874853.509202 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874853.509963 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:53.588447 47896186487680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560874853.510234 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874853.510953 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874853.511633 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:53.588461 46974720058240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 10:20:53.589502 46974720058240 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpu_ry85tx
W0618 10:20:53.589527 47896186487680 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpfyg8kufq
I0618 10:20:53.590496 46974720058240 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpu_ry85tx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab97016ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:53.590524 47896186487680 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpfyg8kufq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8ffbc4dda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:53.590891 46974720058240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:20:53.590914 47896186487680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:53.595731 47896186487680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:53.595741 46974720058240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:53.608755 47761705743232 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:53.609558 47173291201408 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:53.615492 46974720058240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:53.615546 47896186487680 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874853.585156 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874853.585582 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874853.585930 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:53.638138 47602326123392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560874853.584288 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874853.584723 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874853.585117 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:53.638189 47447185466240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560874853.561448 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874853.562164 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874853.562783 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:53.638519 47914124665728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560874853.557729 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874853.558639 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874853.559330 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:53.638544 47373665203072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 10:20:53.639193 47602326123392 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpihjpd0fh
W0618 10:20:53.639223 47447185466240 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpas8p94qa
I0618 10:20:53.640203 47602326123392 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpihjpd0fh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4b90538e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:53.640216 47447185466240 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpas8p94qa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b277138fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:53.640605 47602326123392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:20:53.640605 47447185466240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874853.573721 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874853.574558 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874853.575381 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:53.641028 47576669328256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560874853.556262 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874853.557173 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874853.558032 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:53.641025 47768125526912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 10:20:53.639631 47914124665728 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp96vfepsd
W0618 10:20:53.639661 47373665203072 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpw25cmk37
I0618 10:20:53.640744 47914124665728 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp96vfepsd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9428f7bdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:53.640754 47373665203072 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpw25cmk37', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b165312ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:53.641189 47914124665728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:20:53.641194 47373665203072 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:53.642122 47576669328256 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpuir7vi2c
W0618 10:20:53.642153 47768125526912 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpwpx9gctz
I0618 10:20:53.643218 47576669328256 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpuir7vi2c', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b45970fde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:53.643235 47768125526912 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpwpx9gctz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b722abdae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560874853.589242 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874853.589630 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874853.589954 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:53.643049 47148310000512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560874853.591188 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874853.591565 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874853.591884 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:53.643121 47492527956864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_0_0
I0618 10:20:53.643663 47576669328256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:20:53.643687 47768125526912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:53.644080 47148310000512 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpce096fmh
W0618 10:20:53.644137 47492527956864 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmplr315fjw
I0618 10:20:53.645037 47148310000512 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpce096fmh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae1dadb4e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:20:53.645342 47602326123392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:53.645374 47447185466240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:20:53.645110 47492527956864 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmplr315fjw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b31ffd87e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:53.645427 47148310000512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:20:53.645495 47492527956864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:53.646486 47914124665728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:53.646521 47373665203072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:53.648967 47576669328256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:53.649117 47768125526912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:53.650027 47148310000512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:53.650073 47492527956864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874853.577249 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874853.578125 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874853.578965 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:53.650685 47707525837696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560874853.583896 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874853.584675 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874853.585460 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:53.650729 47502731039616 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 10:20:53.651812 47502731039616 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp7c36dhud
I0618 10:20:53.651835 47707525837696 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb074/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b640eb7cd68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:53.652909 47502731039616 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp7c36dhud', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b345fff2e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:53.653147 47707525837696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:20:53.653352 47502731039616 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:53.658558 47502731039616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:53.658575 47707525837696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:53.661399 47761705743232 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:53.662328 47173291201408 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:53.663427 46974720058240 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:53.663693 47896186487680 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:53.664758 47602326123392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:53.664968 47447185466240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:53.666033 47761705743232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:20:53.666957 47173291201408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:20:53.667721 46974720058240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:20:53.667987 47896186487680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:20:53.669439 47492527956864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:53.669474 47148310000512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:53.668946 47914124665728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:53.668989 47373665203072 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:53.671312 47768125526912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:53.671421 47576669328256 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:20:53.671468 47761705743232 estimator.py:1111] Calling model_fn.
W0618 10:20:53.671588 47761705743232 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:20:53.672428 47173291201408 estimator.py:1111] Calling model_fn.
I0618 10:20:53.672773 46974720058240 estimator.py:1111] Calling model_fn.
W0618 10:20:53.672543 47173291201408 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:20:53.672881 46974720058240 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:20:53.673056 47896186487680 estimator.py:1111] Calling model_fn.
W0618 10:20:53.673165 47896186487680 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:20:53.673036 47761705743232 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:20:53.674236 46974720058240 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:20:53.674006 47173291201408 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:20:53.674518 47896186487680 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560874853.620284 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874853.620791 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874853.621247 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:53.676248 47921230345088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 10:20:53.677294 47921230345088 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp_r_9o9im
I0618 10:20:53.678312 47921230345088 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp_r_9o9im', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b95d07fce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:53.678712 47921230345088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874853.625559 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874853.625953 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874853.626295 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:53.680890 47780663649152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 10:20:53.681154 47502731039616 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:53.681797 47707525837696 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:53.681826 47780663649152 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpgr63cb3j
I0618 10:20:53.682801 47780663649152 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpgr63cb3j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7516123e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:53.683196 47780663649152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:53.683332 47921230345088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874853.626157 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874853.626573 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874853.627059 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:53.685826 47282342011776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560874853.626328 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874853.626737 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874853.627239 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:53.685821 47665884439424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 10:20:53.687775 47780663649152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:53.686838 47282342011776 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpdm63_psi
W0618 10:20:53.686807 47665884439424 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp39ccvwxb
I0618 10:20:53.687777 47665884439424 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp39ccvwxb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5a5cb27e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:53.687814 47282342011776 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpdm63_psi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b010fc97e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:53.688173 47665884439424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:20:53.688223 47282342011776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:53.692755 47665884439424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:53.692810 47282342011776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874853.622900 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874853.623764 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874853.624643 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:53.699541 47614892856192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560874853.628206 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874853.628971 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874853.629642 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:53.699557 47330832593792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 10:20:53.700664 47614892856192 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpd3wx30qq
W0618 10:20:53.700694 47330832593792 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpcs71e4um
I0618 10:20:53.701650 47614892856192 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpd3wx30qq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4e7d5cae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:53.701671 47330832593792 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpcs71e4um', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0c5a0d0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560874853.648417 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874853.648795 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874853.649112 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:53.701434 47459336831872 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560874853.650221 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874853.650599 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874853.650925 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:20:53.701671 47428519936896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000001-000000.tfrecord.zz_0_0
I0618 10:20:53.702069 47614892856192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:20:53.702104 47330832593792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:53.702750 47921230345088 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:53.702454 47459336831872 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp583ei20b
W0618 10:20:53.702654 47428519936896 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpmibivki4
I0618 10:20:53.703506 47459336831872 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp583ei20b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2a45801e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:53.703687 47428519936896 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpmibivki4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2318ab8e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:20:53.703931 47459336831872 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:20:53.704087 47428519936896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:20:53.707224 47780663649152 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:53.706993 47330832593792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:53.706997 47614892856192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:53.708474 47459336831872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:53.708632 47428519936896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:20:53.712239 47602326123392 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:53.712933 47447185466240 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:53.711998 47665884439424 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:53.712234 47282342011776 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:20:53.716549 47602326123392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:20:53.717278 47447185466240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:20:53.716942 47148310000512 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:20:53.717055 47492527956864 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the seman[2019-06-18 10:21:33] divide_golden_chunk finished: 3.336 seconds
[2019-06-18 10:21:33] generate golden chunk: 3.351 seconds
[2019-06-18 10:21:33] iteration time 10: 49.501 seconds
2019-06-18 10:21:34.516835: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874893.771274 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 11}}
[2019-06-18 10:21:37] minmax time: 3.269 seconds
2019-06-18 10:21:37.796007: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:21:37.801449: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:21:37.806086: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874897.818249 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 10}}
[2019-06-18 10:21:37] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000012-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000012-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000012-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000012-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000012-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000012-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000012-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000012-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000012-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000012-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000012-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:21:37] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-12-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000011-000006 --seed=12 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000011-000006 --seed=1023779843 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000011-000006 --seed=2047559674 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000011-000006 --seed=3071339505 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000011-000006 --seed=4095119336 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000011-000006 --seed=5118899167 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000011-000006 --seed=6142678998 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000011-000006 --seed=7166458829 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000011-000006 --seed=8190238660 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000011-000006 --seed=9214018491 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000011-000006 --seed=10237798322 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000011-000006 --seed=11261578153 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000011-000006 --seed=12285357984 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000011-000006 --seed=13309137815 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000011-000006 --seed=14332917646 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000011-000006 --seed=15356697477 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000011-000006 --seed=16380477308 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000011-000006 --seed=17404257139 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000011-000006 --seed=18428036970 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000011-000006 --seed=19451816801 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000011-000006 --seed=20475596632 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:21:48] eval finished: 10.661 seconds
[2019-06-18 10:21:48] Win rate 000011-000006 vs 000009-000005: 0.710
:::MLL 1560874908.557541 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 10}}
[2019-06-18 10:21:48] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-13-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000012-000005 --seed=13 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000012-000005 --seed=1023779844 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000012-000005 --seed=2047559675 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000012-000005 --seed=3071339506 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000012-000005 --seed=4095119337 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000012-000005 --seed=5118899168 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000012-000005 --seed=6142678999 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000012-000005 --seed=7166458830 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000012-000005 --seed=8190238661 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000012-000005 --seed=9214018492 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000012-000005 --seed=10237798323 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000012-000005 --seed=11261578154 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000012-000005 --seed=12285357985 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000012-000005 --seed=13309137816 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000012-000005 --seed=14332917647 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000012-000005 --seed=15356697478 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000012-000005 --seed=16380477309 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000012-000005 --seed=17404257140 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000012-000005 --seed=18428036971 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:22:17] selfplay finished: 29.375 seconds
[2019-06-18 10:22:17] selfplay mn: 29.392 seconds
[2019-06-18 10:22:17] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-13-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779844 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559675 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339506 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119337 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899168 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142678999 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458830 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238661 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018492 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798323 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578154 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285357985 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137816 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917647 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697478 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477309 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257140 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036971 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816802 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596633 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376464 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156295 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000012-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golde
[2019-06-18 10:22:21] divide_golden_chunk finished: 3.329 seconds
[2019-06-18 10:22:21] generate golden chunk: 3.344 seconds
[2019-06-18 10:22:21] train finished: 43.973 seconds
:::MLL 1560874903.112210 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.112952 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.113666 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.184555 47365067256704 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560874903.100228 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.101128 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.101973 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.184582 47108429095808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560874903.094589 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.095493 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.096345 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.185727 47457095025536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 10:21:43.185583 47365067256704 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp4defnm8d
W0618 10:21:43.185611 47108429095808 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp6ug8qhyr
:::MLL 1560874903.113325 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.114032 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.114729 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.186004 47507617698688 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_0_0
I0618 10:21:43.186584 47365067256704 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp4defnm8d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1452988e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.186602 47108429095808 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp6ug8qhyr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad891c4fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.186978 47365067256704 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:21:43.186999 47108429095808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:21:43.186732 47457095025536 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp115lfhaw
W0618 10:21:43.186988 47507617698688 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpf_ss3e3w
I0618 10:21:43.187719 47457095025536 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp115lfhaw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b29bfe0de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.187979 47507617698688 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpf_ss3e3w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3583439e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.188115 47457095025536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:21:43.188371 47507617698688 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874903.102953 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.103663 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.104360 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.190043 47522053309312 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560874903.097331 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.098237 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.099058 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.190004 47651045548928 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 10:21:43.191997 47365067256704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.191162 47522053309312 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmphif3zq_3
W0618 10:21:43.192044 47108429095808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.191192 47651045548928 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpfx89fv62
I0618 10:21:43.192271 47522053309312 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmphif3zq_3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b38dfb18dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.192280 47651045548928 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpfx89fv62', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b56e83aee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.192730 47522053309312 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:21:43.192731 47651045548928 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:21:43.193396 47457095025536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.193742 47507617698688 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.198011 47651045548928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.198052 47522053309312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.211701 47108429095808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.212028 47365067256704 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.215744 47457095025536 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.216373 47507617698688 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874903.141603 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.142353 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.143005 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.216490 47352627532672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560874903.133873 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.134786 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.135650 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.216564 47137492816768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 10:21:43.217634 47352627532672 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpq1c5k1x2
W0618 10:21:43.217667 47137492816768 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp9esb38mk
W0618 10:21:43.219682 47651045548928 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:21:43.218735 47352627532672 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpq1c5k1x2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b116d215e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.218779 47137492816768 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp9esb38mk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adf561a2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:21:43.219994 47522053309312 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:21:43.219179 47352627532672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:21:43.219226 47137492816768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:21:43.224497 47137492816768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.224500 47352627532672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874903.162590 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.163078 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.163509 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.227353 47623681663872 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560874903.167874 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.168270 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.168623 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.227354 47992880309120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560874903.172334 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.172894 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.173329 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.228223 47526958019456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 10:21:43.228334 47992880309120 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp7r9uk9te
W0618 10:21:43.228360 47623681663872 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp4csnldia
I0618 10:21:43.229380 47992880309120 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp7r9uk9te', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba67f2b6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.229412 47623681663872 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp4csnldia', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5089373e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.229804 47992880309120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:21:43.229830 47623681663872 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:21:43.229206 47526958019456 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpfmgzxq2o
:::MLL 1560874903.176341 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.176789 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.177180 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.229942 47802274698112 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_0_0
I0618 10:21:43.230192 47526958019456 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpfmgzxq2o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3a04098e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.230599 47526958019456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:21:43.230894 47802274698112 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpo_339ijv
I0618 10:21:43.231858 47802274698112 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpo_339ijv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7a1e30ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.232249 47802274698112 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:21:43.234524 47623681663872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.234525 47992880309120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.235234 47526958019456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.236799 47802274698112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874903.157544 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.158289 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.158980 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.237292 47609995518848 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560874903.155275 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.156029 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.156765 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.237302 47616946566016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 10:21:43.238304 47616946566016 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp2hm5a3k1
I0618 10:21:43.238326 47609995518848 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb074/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4d59753d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.239291 47616946566016 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp2hm5a3k1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4ef7c5ce80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.239454 47609995518848 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:21:43.239698 47616946566016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874903.186698 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.187071 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.187387 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.241760 47608495776640 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560874903.189240 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.189699 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.190103 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.243100 47056898413440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 10:21:43.242752 47608495776640 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpsltm2b14
I0618 10:21:43.243740 47608495776640 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpsltm2b14', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4d0010fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.244143 47608495776640 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:21:43.244051 47056898413440 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmptc7hv7vi
W0618 10:21:43.244820 47616946566016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.244842 47609995518848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:21:43.245040 47056898413440 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmptc7hv7vi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acc924d1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.245433 47056898413440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:21:43.246739 47352627532672 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.246793 47137492816768 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.248824 47608495776640 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.250078 47056898413440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.253919 47623681663872 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.254039 47992880309120 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.254740 47526958019456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.256200 47802274698112 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.260343 47108429095808 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:21:43.260482 47365067256704 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560874903.207643 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.208041 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.208364 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.263159 47770228364160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560874903.207073 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.207498 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.207845 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.263185 47644473750400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 10:21:43.264659 47108429095808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:21:43.264828 47365067256704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:21:43.264206 47770228364160 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpvywi_la0
W0618 10:21:43.264235 47644473750400 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp_jv1rpno
I0618 10:21:43.265253 47770228364160 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpvywi_la0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b72a8145e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.265261 47644473750400 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp_jv1rpno', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5560853e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.265707 47770228364160 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:21:43.265709 47644473750400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:21:43.267083 47616946566016 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.267584 47609995518848 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.267949 47651045548928 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:21:43.268214 47522053309312 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:21:43.268337 47608495776640 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:21:43.269814 47108429095808 estimator.py:1111] Calling model_fn.
W0618 10:21:43.269927 47108429095808 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:21:43.269586 47457095025536 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:21:43.269988 47365067256704 estimator.py:1111] Calling model_fn.
W0618 10:21:43.270102 47365067256704 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:21:43.269910 47507617698688 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:21:43.269948 47056898413440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.271300 47108429095808 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:21:43.271472 47365067256704 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:21:43.270457 47770228364160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.270459 47644473750400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.272242 47651045548928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:21:43.272504 47522053309312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:21:43.274496 47457095025536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:21:43.274777 47507617698688 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:21:43.277276 47651045548928 estimator.py:1111] Calling model_fn.
W0618 10:21:43.277381 47651045548928 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:21:43.277552 47522053309312 estimator.py:1111] Calling model_fn.
W0618 10:21:43.277662 47522053309312 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:21:43.278729 47651045548928 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:21:43.279013 47522053309312 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:21:43.280320 47457095025536 estimator.py:1111] Calling model_fn.
W0618 10:21:43.280440 47457095025536 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:21:43.280533 47507617698688 estimator.py:1111] Calling model_fn.
W0618 10:21:43.280658 47507617698688 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:21:43.281970 47457095025536 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:21:43.282188 47507617698688 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:21:43.289595 47770228364160 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:21:43.289620 47644473750400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874903.231440 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.231816 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.232137 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.295089 47403212907392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560874903.229922 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874903.230328 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874903.230680 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:21:43.295500 47681394967424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 10:21:43.296097 47403212907392 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpwkhvek9o
W0618 10:21:43.296115 47352627532672 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:21:43.297063 47403212907392 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpwkhvek9o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1d3440ee80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:21:43.296465 47681394967424 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmprhat5kh3
W0618 10:21:43.296483 47137492816768 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:21:43.297439 47681394967424 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmprhat5kh3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5df9323e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:21:43.297460 47403212907392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:21:43.297836 47681394967424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:21:43.301269 47623681663872 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:21:43.300452 47352627532672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:21:43.300860 47137492816768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:21:43.301962 47992880309120 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:21:43.302249 47403212907392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:21:43.302753 47526958019456 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.pytho[2019-06-18 10:22:21] moving /lfs/lfs12/gma_akey/results/epb074/models/000012-000006.index --> /lfs/lfs12/gma_akey/results/epb074/models/000012-000007.index
[2019-06-18 10:22:21] moving /lfs/lfs12/gma_akey/results/epb074/models/000012-000006.pb --> /lfs/lfs12/gma_akey/results/epb074/models/000012-000007.pb
[2019-06-18 10:22:21] moving /lfs/lfs12/gma_akey/results/epb074/models/000012-000006.meta --> /lfs/lfs12/gma_akey/results/epb074/models/000012-000007.meta
[2019-06-18 10:22:21] moving /lfs/lfs12/gma_akey/results/epb074/models/000012-000006.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb074/models/000012-000007.data-00000-of-00001
[2019-06-18 10:22:21] iteration time 11: 48.089 seconds
2019-06-18 10:22:22.655717: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874941.860047 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 12}}
[2019-06-18 10:22:25] minmax time: 3.235 seconds
2019-06-18 10:22:25.900146: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:22:25.905495: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:22:25.910074: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874945.920261 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 11}}
[2019-06-18 10:22:25] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000013-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000013-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000013-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000013-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000013-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000013-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000013-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000013-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000013-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000013-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000013-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:22:25] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-13-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000012-000007 --seed=13 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000012-000007 --seed=1023779844 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000012-000007 --seed=2047559675 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000012-000007 --seed=3071339506 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000012-000007 --seed=4095119337 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000012-000007 --seed=5118899168 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000012-000007 --seed=6142678999 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000012-000007 --seed=7166458830 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000012-000007 --seed=8190238661 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000012-000007 --seed=9214018492 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000012-000007 --seed=10237798323 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000012-000007 --seed=11261578154 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000012-000007 --seed=12285357985 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000012-000007 --seed=13309137816 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000012-000007 --seed=14332917647 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000012-000007 --seed=15356697478 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000012-000007 --seed=16380477309 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000012-000007 --seed=17404257140 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000012-000007 --seed=18428036971 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000012-000007 --seed=19451816802 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000012-000007 --seed=20475596633 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:22:36] eval finished: 10.943 seconds
[2019-06-18 10:22:36] Win rate 000012-000007 vs 000011-000006: 0.420
:::MLL 1560874956.937647 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 11}}
[2019-06-18 10:22:36] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-14-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000013-000006 --seed=14 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000013-000006 --seed=1023779845 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000013-000006 --seed=2047559676 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000013-000006 --seed=3071339507 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000013-000006 --seed=4095119338 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000013-000006 --seed=5118899169 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000013-000006 --seed=6142679000 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000013-000006 --seed=7166458831 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000013-000006 --seed=8190238662 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000013-000006 --seed=9214018493 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000013-000006 --seed=10237798324 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000013-000006 --seed=11261578155 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000013-000006 --seed=12285357986 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000013-000006 --seed=13309137817 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000013-000006 --seed=14332917648 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000013-000006 --seed=15356697479 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000013-000006 --seed=16380477310 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000013-000006 --seed=17404257141 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000013-000006 --seed=18428036972 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:23:07] selfplay finished: 30.581 seconds
[2019-06-18 10:23:07] selfplay mn: 30.598 seconds
[2019-06-18 10:23:07] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-14-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779845 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559676 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339507 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119338 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899169 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142679000 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458831 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238662 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018493 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798324 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578155 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285357986 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137817 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917648 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697479 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477310 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257141 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036972 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816803 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596634 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376465 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156296 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golde
[2019-06-18 10:23:09] train finished: 43.786 seconds
:::MLL 1560874951.127329 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.128213 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.129051 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.213057 47198567789440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_0_0
:::MLL 1560874951.133961 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.134683 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.135372 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.213176 47556192232320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_0_0
W0618 10:22:31.214171 47198567789440 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpdgc6nlpk
W0618 10:22:31.214259 47556192232320 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpjqz1g_3f
I0618 10:22:31.215255 47198567789440 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpdgc6nlpk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aed8e743e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.215345 47556192232320 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpjqz1g_3f', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b40d2883e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.215703 47198567789440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:22:31.215791 47556192232320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:22:31.221010 47556192232320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.221015 47198567789440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874951.137317 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.138175 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.138956 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.223627 46990421689216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_0_0
:::MLL 1560874951.145324 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.146016 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.146677 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.223772 47758225724288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_0_0
W0618 10:22:31.224651 46990421689216 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpq4fu79dx
W0618 10:22:31.224757 47758225724288 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp2mftnuc0
I0618 10:22:31.225627 46990421689216 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpq4fu79dx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abd17fade10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.225757 47758225724288 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp2mftnuc0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6fdcaaae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.226018 46990421689216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:22:31.226165 47758225724288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:22:31.230908 46990421689216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.231092 47758225724288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874951.149339 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.150243 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.151119 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.237608 47456729150336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_0_0
:::MLL 1560874951.162863 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.163567 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.164317 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.237789 47157171975040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_0_0
W0618 10:22:31.238734 47456729150336 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp6m33zew5
W0618 10:22:31.238854 47157171975040 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpri3dl_mh
I0618 10:22:31.239841 47456729150336 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp6m33zew5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b29aa120e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.239980 47157171975040 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpri3dl_mh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae3eb123dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.240312 47456729150336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:22:31.240481 47157171975040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:22:31.243289 47556192232320 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.243295 47198567789440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.245684 47456729150336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.245720 47157171975040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560874951.174021 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.174739 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.175414 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.248729 47879921894272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_0_0
:::MLL 1560874951.162994 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.163917 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.164784 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.249165 47976474960768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_0_0
W0618 10:22:31.250684 46990421689216 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.251498 47758225724288 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.249851 47879921894272 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmphljculjg
I0618 10:22:31.250940 47879921894272 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmphljculjg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8c3252cdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:22:31.250246 47976474960768 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpf998bxvr
I0618 10:22:31.251376 47879921894272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:22:31.251380 47976474960768 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpf998bxvr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba2ad55be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.251843 47976474960768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874951.205254 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.205695 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.206083 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.254070 47066536207232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_0_0
W0618 10:22:31.255149 47066536207232 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpgk5nwh_r
I0618 10:22:31.256253 47066536207232 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpgk5nwh_r', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aced0c23e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.256702 47066536207232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:22:31.256607 47879921894272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.257339 47976474960768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.261808 47066536207232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.267901 47456729150336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.268112 47157171975040 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874951.209559 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.210005 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.210387 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.271907 47616177656704 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_0_0
:::MLL 1560874951.213120 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.213631 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.214069 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.273188 47876822057856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_0_0
W0618 10:22:31.272855 47616177656704 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp5c3mbezu
I0618 10:22:31.273829 47616177656704 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp5c3mbezu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4ec9f12e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.274217 47616177656704 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:22:31.274242 47876822057856 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmppa5__zt4
I0618 10:22:31.275319 47876822057856 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmppa5__zt4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8b798f1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.275765 47876822057856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:22:31.278832 47616177656704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.278913 47879921894272 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560874951.216668 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.217097 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.217472 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.280332 47336993346432 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_0_0
W0618 10:22:31.280892 47876822057856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.279863 47976474960768 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.281578 47066536207232 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.281349 47336993346432 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpv3sfcl70
I0618 10:22:31.282382 47336993346432 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpv3sfcl70', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0dc942ada0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.282804 47336993346432 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874951.228523 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.228901 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.229222 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.285649 47067364561792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_0_0
:::MLL 1560874951.230313 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.230683 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.231012 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.286592 47444999291776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_0_0
W0618 10:22:31.286652 47067364561792 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp49f1zuzn
I0618 10:22:31.287630 47067364561792 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp49f1zuzn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acf0221ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:22:31.287677 47336993346432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:22:31.288027 47067364561792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:22:31.287554 47444999291776 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpvzl8p82m
I0618 10:22:31.288548 47444999291776 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpvzl8p82m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b26eeea8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.288945 47444999291776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560874951.230460 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.230951 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.231384 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.289453 47359575315328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_0_0
W0618 10:22:31.290452 47359575315328 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpbh32noab
I0618 10:22:31.291440 47359575315328 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpbh32noab', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b130b402e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560874951.234658 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.235316 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.235762 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.291512 47580962263936 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_0_0
W0618 10:22:31.292729 47067364561792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:22:31.291840 47359575315328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:22:31.293536 47444999291776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.292444 47580962263936 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpw8ddcjvb
I0618 10:22:31.293411 47580962263936 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpw8ddcjvb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4696f0de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.293809 47580962263936 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:22:31.295016 47556192232320 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:22:31.295093 47198567789440 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:22:31.296483 47359575315328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.298332 47616177656704 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.298730 46990421689216 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:22:31.299222 47758225724288 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:22:31.298346 47580962263936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.299632 47556192232320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:22:31.299718 47198567789440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560874951.225150 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.225890 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.226568 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.300279 47793622410112 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_0_0
:::MLL 1560874951.207299 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.208215 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.209107 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.300339 47601385800576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_0_0
W0618 10:22:31.301910 47876822057856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.301338 47793622410112 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpdmyrhhbi
W0618 10:22:31.301363 47601385800576 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpujnj5ew_
I0618 10:22:31.302340 47793622410112 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpdmyrhhbi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b781a792e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.302342 47601385800576 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpujnj5ew_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4b58475e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.302732 47793622410112 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:22:31.302734 47601385800576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:22:31.303024 46990421689216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:22:31.303515 47758225724288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:22:31.305175 47556192232320 estimator.py:1111] Calling model_fn.
W0618 10:22:31.305314 47556192232320 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:22:31.305310 47198567789440 estimator.py:1111] Calling model_fn.
W0618 10:22:31.305418 47198567789440 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:22:31.306697 47556192232320 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:22:31.306774 47198567789440 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560874951.215173 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.216013 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.216673 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.307352 47597939594112 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_0_0
W0618 10:22:31.307670 47793622410112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.307671 47601385800576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:22:31.308100 46990421689216 estimator.py:1111] Calling model_fn.
W0618 10:22:31.308209 46990421689216 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560874951.214217 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560874951.215066 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560874951.215816 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:22:31.307764 47865834107776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000003-000000.tfrecord.zz_0_0
W0618 10:22:31.308489 47336993346432 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:22:31.308592 47758225724288 estimator.py:1111] Calling model_fn.
W0618 10:22:31.308706 47758225724288 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:22:31.309573 46990421689216 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:22:31.308487 47597939594112 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp1qkc2tjd
I0618 10:22:31.309583 47597939594112 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp1qkc2tjd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4a8ade6e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:22:31.308884 47865834107776 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb074/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b88eaa04d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:22:31.310056 47758225724288 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:22:31.310029 47597939594112 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:22:31.310129 47865834107776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:22:31.312103 47067364561792 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.312888 47444999291776 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.315426 47597939594112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.315643 47865834107776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:22:31.315787 47359575315328 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.317861 47157171975040 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:22:31.318150 47456729150336 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:22:31.317733 47580962263936 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.322211 47157171975040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:22:31.322551 47456729150336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:22:31.327376 47157171975040 estimator.py:1111] Calling model_fn.
W0618 10:22:31.327485 47157171975040 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:22:31.327348 47793622410112 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:22:31.327355 47601385800576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:22:31.327786 47456729150336 estimator.py:1111] Calling model_fn.
W0618 10:22:31.327899 47456729150336 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:22:31.326998 47879921894272 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:22:31.328836 47157171975040 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:22:31.327881 47976474960768 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:22:31.328739 47066536207232 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:22:31.329283 47456729150336 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:22:31.331299 47879921894272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:22:31.332187 47976474960768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:22:31.333004 47066536207232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.dat[2019-06-18 10:23:10] divide_golden_chunk finished: 3.338 seconds
[2019-06-18 10:23:10] generate golden chunk: 3.353 seconds
[2019-06-18 10:23:10] iteration time 12: 49.031 seconds
2019-06-18 10:23:11.733493: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560874990.890834 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 13}}
[2019-06-18 10:23:14] minmax time: 3.240 seconds
2019-06-18 10:23:14.983560: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:23:14.988874: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:23:14.993249: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560874995.004954 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 12}}
[2019-06-18 10:23:15] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000014-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000014-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000014-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000014-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000014-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000014-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000014-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000014-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000014-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000014-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000014-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:23:15] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-14-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000013-000007 --seed=14 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000013-000007 --seed=1023779845 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000013-000007 --seed=2047559676 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000013-000007 --seed=3071339507 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000013-000007 --seed=4095119338 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000013-000007 --seed=5118899169 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000013-000007 --seed=6142679000 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000013-000007 --seed=7166458831 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000013-000007 --seed=8190238662 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000013-000007 --seed=9214018493 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000013-000007 --seed=10237798324 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000013-000007 --seed=11261578155 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000013-000007 --seed=12285357986 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000013-000007 --seed=13309137817 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000013-000007 --seed=14332917648 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000013-000007 --seed=15356697479 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000013-000007 --seed=16380477310 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000013-000007 --seed=17404257141 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000013-000007 --seed=18428036972 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000013-000007 --seed=19451816803 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000013-000007 --seed=20475596634 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:23:26] eval finished: 11.912 seconds
[2019-06-18 10:23:26] Win rate 000013-000007 vs 000011-000006: 0.540
:::MLL 1560875006.996175 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 12}}
[2019-06-18 10:23:26] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-15-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000014-000006 --seed=15 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000014-000006 --seed=1023779846 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000014-000006 --seed=2047559677 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000014-000006 --seed=3071339508 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000014-000006 --seed=4095119339 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000014-000006 --seed=5118899170 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000014-000006 --seed=6142679001 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000014-000006 --seed=7166458832 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000014-000006 --seed=8190238663 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000014-000006 --seed=9214018494 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000014-000006 --seed=10237798325 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000014-000006 --seed=11261578156 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000014-000006 --seed=12285357987 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000014-000006 --seed=13309137818 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000014-000006 --seed=14332917649 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000014-000006 --seed=15356697480 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000014-000006 --seed=16380477311 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000014-000006 --seed=17404257142 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000014-000006 --seed=18428036973 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:23:58] train finished: 43.613 seconds
:::MLL 1560875000.265831 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875000.266763 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875000.267560 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:20.364901 47498421179264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560875000.280931 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875000.281645 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875000.282311 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:20.365102 46984246670208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560875000.283376 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875000.284092 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875000.284804 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:20.365525 47006276023168 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560875000.276611 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875000.277496 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875000.278352 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:20.365883 47478930047872 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 10:23:20.365975 47498421179264 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmphr_b5u0g
W0618 10:23:20.366121 46984246670208 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpb97jis4b
I0618 10:23:20.366968 47498421179264 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmphr_b5u0g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b335f1bee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:23:20.366631 47006276023168 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp7fam0zkn
I0618 10:23:20.367088 46984246670208 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpb97jis4b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abba7eb7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:20.367672 47006276023168 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp7fam0zkn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac0c8f8ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:23:20.366947 47478930047872 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpsqilp0tn
I0618 10:23:20.367363 47498421179264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:23:20.367473 46984246670208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:23:20.367955 47478930047872 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpsqilp0tn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2ed558ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:20.368090 47006276023168 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:23:20.368367 47478930047872 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:23:20.372148 47498421179264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:20.372234 46984246670208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:20.373090 47006276023168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:20.373307 47478930047872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875000.286653 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875000.287406 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875000.288092 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:20.388283 47699485660032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560875000.283812 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875000.284594 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875000.285294 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:20.388397 47080828388224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 10:23:20.389384 47699485660032 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp4nwfp7qk
W0618 10:23:20.389503 47080828388224 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpwq8bv5pm
I0618 10:23:20.390489 47699485660032 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp4nwfp7qk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b622f7c5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:20.390589 47080828388224 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpwq8bv5pm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad224a38e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560875000.300553 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875000.301425 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875000.302273 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:20.389358 47760311866240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560875000.308223 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875000.308995 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875000.309698 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:20.389450 47115314942848 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_0_0
I0618 10:23:20.390941 47699485660032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:23:20.391040 47080828388224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:23:20.390456 47760311866240 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmphqn02c3x
W0618 10:23:20.390510 47115314942848 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmph9n3_771
I0618 10:23:20.391551 47760311866240 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmphqn02c3x', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b705902ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:20.391603 47115314942848 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmph9n3_771', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ada2c32ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:20.391997 47760311866240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:23:20.393171 47006276023168 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:23:20.392079 47115314942848 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:23:20.393491 47478930047872 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:23:20.394121 47498421179264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:23:20.394811 46984246670208 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:23:20.396211 47699485660032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:20.396322 47080828388224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875000.341910 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875000.342487 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875000.343004 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:20.397165 47480926745472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 10:23:20.397277 47760311866240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:20.397301 47115314942848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:20.398272 47480926745472 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp3420lwq4
I0618 10:23:20.399369 47480926745472 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp3420lwq4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2f4c5c0e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:20.399823 47480926745472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:23:20.405060 47480926745472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875000.327018 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875000.327806 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875000.328453 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:20.412842 47628800201600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560875000.325506 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875000.326288 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875000.327083 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:20.413022 47628819424128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 10:23:20.413923 47628800201600 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpsiaohti3
I0618 10:23:20.414150 47628819424128 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb074/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b51bb733d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:20.414996 47628800201600 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpsiaohti3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b51ba4dee80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:20.415413 47628819424128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:23:20.415442 47628800201600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875000.365298 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875000.365932 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875000.366327 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:20.417572 47668183909248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 10:23:20.418005 47699485660032 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:23:20.418256 47080828388224 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:23:20.418610 47668183909248 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp7pmbw_kt
I0618 10:23:20.419643 47668183909248 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp7pmbw_kt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5ae5c19e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:20.420070 47668183909248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:23:20.419293 47760311866240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:23:20.419564 47115314942848 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:23:20.420798 47628819424128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:20.420809 47628800201600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875000.342602 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875000.343015 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875000.343370 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:20.423690 47699603166080 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560875000.341422 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875000.341826 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875000.342204 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:20.423619 47654137987968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 10:23:20.424932 47668183909248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:20.424643 47699603166080 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpokoty96g
W0618 10:23:20.424599 47654137987968 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp61rna6in
I0618 10:23:20.425591 47654137987968 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp61rna6in', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b57a08dce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:20.425613 47699603166080 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpokoty96g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b62367d5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:20.425999 47654137987968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:23:20.426006 47699603166080 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:23:20.426454 47480926745472 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:23:20.430648 47699603166080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:20.430652 47654137987968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875000.363674 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875000.364084 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875000.364424 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:20.430682 47129425826688 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560875000.363436 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875000.363848 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875000.364209 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:20.430752 47268529505152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 10:23:20.431722 47129425826688 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp5igwr853
W0618 10:23:20.431748 47268529505152 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpski8kqde
I0618 10:23:20.432707 47129425826688 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp5igwr853', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2add7545ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:20.432706 47268529505152 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpski8kqde', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afdd87f4e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:20.433103 47268529505152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:23:20.433108 47129425826688 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:23:20.437906 47268529505152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:20.437924 47129425826688 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:20.440964 47006276023168 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:23:20.441104 47478930047872 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560875000.383512 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875000.383883 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875000.384200 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:20.441590 46937169814400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560875000.381984 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875000.382413 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875000.382761 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:20.441603 47564017865600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 10:23:20.443006 47628800201600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:23:20.443184 47628819424128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:23:20.442576 46937169814400 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpf67q0ow2
W0618 10:23:20.442604 47564017865600 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpv2zbpsth
I0618 10:23:20.443564 46937169814400 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpf67q0ow2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab0b1ebadd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:20.443583 47564017865600 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpv2zbpsth', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b42a4f9ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:23:20.444931 47668183909248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:23:20.444002 46937169814400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:23:20.444009 47564017865600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:23:20.445271 47006276023168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:23:20.445392 47478930047872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:23:20.445074 47498421179264 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:23:20.445939 46984246670208 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560875000.365055 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875000.365782 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875000.366476 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:20.447642 47464245502848 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560875000.359175 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875000.360061 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875000.360930 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:20.447635 47559151674240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 10:23:20.448687 47559151674240 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpse2z9u0w
W0618 10:23:20.448718 47464245502848 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp7x3s2fsa
W0618 10:23:20.449380 47498421179264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:23:20.449683 47559151674240 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpse2z9u0w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4182edbe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:23:20.448781 46937169814400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:20.448769 47564017865600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:20.449856 47654137987968 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:23:20.449724 47464245502848 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp7x3s2fsa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2b6a147e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:23:20.449944 47699603166080 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:23:20.450309 47006276023168 estimator.py:1111] Calling model_fn.
W0618 10:23:20.450418 47006276023168 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:23:20.450096 47559151674240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:23:20.450448 47478930047872 estimator.py:1111] Calling model_fn.
I0618 10:23:20.450128 47464245502848 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:23:20.450554 47478930047872 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:23:20.450248 46984246670208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:23:20.451774 47006276023168 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:23:20.451908 47478930047872 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560875000.391341 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875000.391754 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875000.392107 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:20.453664 47092414559104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560875000.383619 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875000.384117 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875000.384578 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:23:20.453816 47205958357888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000004-000001.tfrecord.zz_0_0
I0618 10:23:20.454412 47498421179264 estimator.py:1111] Calling model_fn.
W0618 10:23:20.454519 47498421179264 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:23:20.454927 47464245502848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:20.455014 47559151674240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:23:20.455299 46984246670208 estimator.py:1111] Calling model_fn.
W0618 10:23:20.455409 46984246670208 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:23:20.454681 47092414559104 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpggq1key3
W0618 10:23:20.454799 47205958357888 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpgwek8ia9
I0618 10:23:20.455664 47092414559104 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpggq1key3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad4d73a7e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:23:20.455764 47205958357888 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpgwek8ia9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aef46f76e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:23:20.455864 47498421179264 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:23:20.456061 47092414559104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:23:20.456156 47205958357888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:23:20.456777 46984246670208 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:23:20.457357 47129425826688 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:23:20.457370 47268529505152 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:23:20.460705 47092414559104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:20.460812 47205958357888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:23:20.465369 47699485660032 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:23:20.465619 47080828388224 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:23:20.468117 46937169814400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:23:20.468096 47564017865600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:23:20.469656 47699485660032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:23:20.469954 47080828388224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:23:20.468831 47760311866240 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:23:20.469080 47115314942848 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:23:20.474106 47480926745472 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:23:20.473289 47760311866240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:23:20.473518 47115314942848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:23:20.474678 47699485660032 estimator.py:1111] Calling model_fn.
W0618 10:23:20.474783 47699485660032 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:23:20.474670 47464245502848 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:23:20.475017 47080828388224 estimator.py:1111] Calling model_fn.
W0618 10:23:20.475126 47080828388224 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:23:20.475185 47559151674240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:23:20.476150 47699485660032 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:23:20.476500 47080828388224 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:23:20.478413 47480926745472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:23:20.478341 47760311866240 estimator.py:1111] Calling model_fn.
W0618 10:23:20.478447 47760311866240 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:23:20.478587 47115314942848 estimator.py:1111] Calling model_fn.
W0618 10:23:20.478695 47115314942848 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:23:20.480192 47092414559104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:23:20.480479 47205958357888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:23:20.479825 47760311866240 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:23:20.480093 47115314942848 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:23:20.483431 47480926745472 estimator.py:1111] Calling model_fn.
W0618 10:23:20.483537 47480926745472 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional)[2019-06-18 10:23:58] selfplay finished: 31.969 seconds
[2019-06-18 10:23:58] selfplay mn: 31.986 seconds
[2019-06-18 10:23:58] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-15-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779846 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559677 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339508 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119339 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899170 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142679001 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458832 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238663 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018494 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798325 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578156 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285357987 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137818 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917649 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697480 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477311 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257142 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036973 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816804 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596635 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376466 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156297 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000014-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golde
[2019-06-18 10:24:02] divide_golden_chunk finished: 3.317 seconds
[2019-06-18 10:24:02] generate golden chunk: 3.333 seconds
[2019-06-18 10:24:02] moving /lfs/lfs12/gma_akey/results/epb074/models/000014-000007.pb --> /lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb
[2019-06-18 10:24:02] moving /lfs/lfs12/gma_akey/results/epb074/models/000014-000007.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb074/models/000014-000008.data-00000-of-00001
[2019-06-18 10:24:02] moving /lfs/lfs12/gma_akey/results/epb074/models/000014-000007.index --> /lfs/lfs12/gma_akey/results/epb074/models/000014-000008.index
[2019-06-18 10:24:02] moving /lfs/lfs12/gma_akey/results/epb074/models/000014-000007.meta --> /lfs/lfs12/gma_akey/results/epb074/models/000014-000008.meta
[2019-06-18 10:24:02] iteration time 13: 51.467 seconds
2019-06-18 10:24:03.251253: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560875042.357747 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 14}}
[2019-06-18 10:24:06] minmax time: 3.258 seconds
2019-06-18 10:24:06.519158: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:24:06.524447: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:24:06.528945: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560875046.539253 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 13}}
[2019-06-18 10:24:06] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000015-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000015-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000015-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000015-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000015-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000015-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000015-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000015-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000015-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000015-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000015-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:24:06] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-15-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000014-000008 --seed=15 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000014-000008 --seed=1023779846 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000014-000008 --seed=2047559677 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000014-000008 --seed=3071339508 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000014-000008 --seed=4095119339 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000014-000008 --seed=5118899170 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000014-000008 --seed=6142679001 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000014-000008 --seed=7166458832 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000014-000008 --seed=8190238663 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000014-000008 --seed=9214018494 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000014-000008 --seed=10237798325 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000014-000008 --seed=11261578156 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000014-000008 --seed=12285357987 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000014-000008 --seed=13309137818 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000014-000008 --seed=14332917649 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000014-000008 --seed=15356697480 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000014-000008 --seed=16380477311 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000014-000008 --seed=17404257142 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000014-000008 --seed=18428036973 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000014-000008 --seed=19451816804 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000014-000008 --seed=20475596635 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:24:17] eval finished: 10.659 seconds
[2019-06-18 10:24:17] Win rate 000014-000008 vs 000013-000007: 0.630
:::MLL 1560875057.276716 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 13}}
[2019-06-18 10:24:17] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-16-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000015-000007 --seed=16 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000015-000007 --seed=1023779847 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000015-000007 --seed=2047559678 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000015-000007 --seed=3071339509 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000015-000007 --seed=4095119340 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000015-000007 --seed=5118899171 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000015-000007 --seed=6142679002 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000015-000007 --seed=7166458833 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000015-000007 --seed=8190238664 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000015-000007 --seed=9214018495 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000015-000007 --seed=10237798326 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000015-000007 --seed=11261578157 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000015-000007 --seed=12285357988 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000015-000007 --seed=13309137819 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000015-000007 --seed=14332917650 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000015-000007 --seed=15356697481 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000015-000007 --seed=16380477312 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000015-000007 --seed=17404257143 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000015-000007 --seed=18428036974 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:24:47] selfplay finished: 30.518 seconds
[2019-06-18 10:24:47] selfplay mn: 30.535 seconds
[2019-06-18 10:24:47] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-16-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779847 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559678 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339509 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119340 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899171 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142679002 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458833 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238664 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018495 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798326 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578157 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285357988 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137819 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917650 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697481 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477312 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257143 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036974 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816805 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596636 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376467 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156298 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golde
[2019-06-18 10:24:50] train finished: 43.666 seconds
:::MLL 1560875051.794414 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.795311 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.796154 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.885056 47840247554944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_0_0
:::MLL 1560875051.799207 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.799930 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.800631 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.885152 47409606079360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_0_0
W0618 10:24:11.886152 47840247554944 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpb6arrlmp
W0618 10:24:11.886209 47409606079360 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpeys4nrab
I0618 10:24:11.887258 47840247554944 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpb6arrlmp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b82f58c7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.887331 47409606079360 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpeys4nrab', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1eb1510e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.887704 47840247554944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:24:11.887790 47409606079360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:24:11.893016 47840247554944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.893082 47409606079360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875051.817226 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.817960 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.818692 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.895150 47616377668480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_0_0
:::MLL 1560875051.806370 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.807239 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.808093 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.895237 47085269042048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_0_0
W0618 10:24:11.896311 47616377668480 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpovhiohfa
W0618 10:24:11.896345 47085269042048 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp4y1mogwt
I0618 10:24:11.897450 47085269042048 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp4y1mogwt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad32d529e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.897450 47616377668480 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpovhiohfa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4ed5dd1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.897896 47085269042048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:24:11.897917 47616377668480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:24:11.903155 47085269042048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.903368 47616377668480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875051.829331 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.830100 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.830818 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.906439 47104933081984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_0_0
:::MLL 1560875051.817038 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.817961 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.818826 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.906438 47411539661696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_0_0
W0618 10:24:11.907524 47411539661696 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp82ubq2ru
I0618 10:24:11.907574 47104933081984 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb074/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad7c1640d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.908614 47411539661696 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp82ubq2ru', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1f24912e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.908821 47104933081984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:24:11.909052 47411539661696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:24:11.914202 47104933081984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.914297 47411539661696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.915139 47840247554944 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:24:11.915420 47409606079360 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:24:11.925347 47085269042048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:24:11.926106 47616377668480 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875051.864353 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.864759 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.865101 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.929216 47544004555648 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_0_0
:::MLL 1560875051.862509 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.862931 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.863292 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.929268 47395766317952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_0_0
W0618 10:24:11.930246 47544004555648 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpqw9qxhgm
W0618 10:24:11.930273 47395766317952 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpjvxyn6u0
I0618 10:24:11.931294 47544004555648 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpqw9qxhgm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3dfc170e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.931301 47395766317952 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpjvxyn6u0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1b78670e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.931716 47544004555648 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:24:11.931716 47395766317952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875051.836543 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.837427 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.838269 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.936177 47526551344000 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_0_0
:::MLL 1560875051.851237 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.851974 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.852662 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.936123 47770848080768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_0_0
W0618 10:24:11.936448 47395766317952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.936466 47544004555648 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.936531 47104933081984 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:24:11.936532 47411539661696 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:24:11.937231 47526551344000 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpld53zps2
W0618 10:24:11.937201 47770848080768 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpwwuwthcy
I0618 10:24:11.938214 47526551344000 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpld53zps2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b39ebcc0dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.938214 47770848080768 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpwwuwthcy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b72cd047e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.938611 47526551344000 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:24:11.938612 47770848080768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:24:11.943559 47770848080768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.943686 47526551344000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875051.838727 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.839488 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.840330 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.944487 47091219108736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_0_0
:::MLL 1560875051.840572 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.841332 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.842046 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.944909 47185363796864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_0_0
:::MLL 1560875051.885734 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.886196 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.886593 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.943929 46990614168448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_0_0
W0618 10:24:11.945499 47091219108736 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp1ry4s7i0
I0618 10:24:11.946519 47091219108736 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp1ry4s7i0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad48ff96e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:24:11.945883 47185363796864 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp9cz3inge
W0618 10:24:11.945033 46990614168448 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpjr44ov0l
I0618 10:24:11.946930 47185363796864 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp9cz3inge', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aea7b6f5e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.946968 47091219108736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:24:11.946067 46990614168448 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpjr44ov0l', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abd2373de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.947368 47185363796864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:24:11.946464 46990614168448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875051.811227 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.812001 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.812645 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.947985 47465295692672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_0_0
:::MLL 1560875051.809907 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.810647 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.811442 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.948072 47552297116544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_0_0
W0618 10:24:11.949075 47465295692672 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpk4y43857
W0618 10:24:11.949150 47552297116544 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpqjl09cgj
I0618 10:24:11.950289 47465295692672 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpk4y43857', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2ba8ad1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.950290 47552297116544 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpqjl09cgj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3fea5d7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.950739 47552297116544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:24:11.950739 47465295692672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:24:11.951790 47091219108736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.952123 47185363796864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.951280 46990614168448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875051.896822 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.897260 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.897650 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.952190 46972489839488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_0_0
W0618 10:24:11.953164 46972489839488 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpuhni7blx
I0618 10:24:11.954131 46972489839488 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpuhni7blx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab8eb287dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.954529 46972489839488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:24:11.955976 47465295692672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.956060 47552297116544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.955678 47395766317952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:24:11.955807 47544004555648 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:24:11.959049 46972489839488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875051.897541 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.897920 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.898242 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.959952 47647984767872 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_0_0
:::MLL 1560875051.899736 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.900111 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.900440 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.961043 47998524121984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_0_0
W0618 10:24:11.960957 47647984767872 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp5zwo3v9r
I0618 10:24:11.961930 47647984767872 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp5zwo3v9r', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5631cb2e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.962321 47647984767872 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:24:11.961983 47998524121984 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp305vkut9
I0618 10:24:11.962965 47998524121984 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp305vkut9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba7cf913e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:24:11.963074 47770848080768 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:24:11.963246 47526551344000 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:24:11.963351 47998524121984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:24:11.964211 47409606079360 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:24:11.964361 47840247554944 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:24:11.966984 47647984767872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.967916 47998524121984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.968478 47409606079360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:24:11.968651 47840247554944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:24:11.971497 47091219108736 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:24:11.970725 46990614168448 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:24:11.972282 47185363796864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:24:11.973515 47409606079360 estimator.py:1111] Calling model_fn.
W0618 10:24:11.973629 47409606079360 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:24:11.973692 47840247554944 estimator.py:1111] Calling model_fn.
W0618 10:24:11.973799 47840247554944 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560875051.865924 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.866311 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.866666 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.974114 47161706460032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_0_0
:::MLL 1560875051.862217 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.862744 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.863210 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.974300 47417666200448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_0_0
W0618 10:24:11.974978 47409606079360 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:24:11.975140 47840247554944 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:24:11.975114 47161706460032 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmphc5xzcrc
W0618 10:24:11.975258 47417666200448 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpbvc9jm85
I0618 10:24:11.976089 47161706460032 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmphc5xzcrc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae4f958fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.976243 47417666200448 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpbvc9jm85', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2091bcae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.976480 47161706460032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:24:11.976631 47417666200448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:24:11.977579 47465295692672 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:24:11.977923 47552297116544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:24:11.977158 47085269042048 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:24:11.977836 47616377668480 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:24:11.978358 46972489839488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875051.914904 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.915424 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.915832 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.980537 47625092879232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_0_0
:::MLL 1560875051.914389 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.914917 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.915371 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.980597 47424372253568 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_0_0
W0618 10:24:11.981124 47161706460032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.981253 47417666200448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.981553 47625092879232 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmptlx0w075
W0618 10:24:11.981590 47424372253568 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpw8mp7i81
W0618 10:24:11.981531 47085269042048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:24:11.982541 47625092879232 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmptlx0w075', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b50dd54add8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.982574 47424372253568 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpw8mp7i81', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b222172fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.982969 47625092879232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:24:11.982991 47424372253568 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:24:11.982203 47616377668480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560875051.903925 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.904417 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.904871 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.985970 47236324537216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_0_0
:::MLL 1560875051.906392 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875051.906898 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875051.907340 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:24:11.986245 47131844285312 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000005-000001.tfrecord.zz_0_0
W0618 10:24:11.986142 47647984767872 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:24:11.987071 47998524121984 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:24:11.986950 47236324537216 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp77v_cbox
I0618 10:24:11.986613 47085269042048 estimator.py:1111] Calling model_fn.
W0618 10:24:11.986722 47085269042048 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:24:11.987234 47131844285312 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp4xdpky9s
I0618 10:24:11.987950 47236324537216 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp77v_cbox', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af658ee8e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:24:11.987678 47424372253568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:24:11.987694 47625092879232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:24:11.988200 47131844285312 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp4xdpky9s', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ade056c4da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:24:11.988343 47236324537216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:24:11.987284 47616377668480 estimator.py:1111] Calling model_fn.
W0618 10:24:11.987393 47616377668480 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:24:11.988598 47131844285312 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:24:11.988072 47085269042048 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:24:11.988759 47616377668480 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:24:11.989596 47104933081984 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:24:11.989639 47411539661696 deprecation.py:323] From ./preprocessing.py:177: py_func ([2019-06-18 10:24:51] divide_golden_chunk finished: 3.359 seconds
[2019-06-18 10:24:51] generate golden chunk: 3.373 seconds
[2019-06-18 10:24:51] moving /lfs/lfs12/gma_akey/results/epb074/models/000015-000008.index --> /lfs/lfs12/gma_akey/results/epb074/models/000015-000009.index
[2019-06-18 10:24:51] moving /lfs/lfs12/gma_akey/results/epb074/models/000015-000008.pb --> /lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb
[2019-06-18 10:24:51] moving /lfs/lfs12/gma_akey/results/epb074/models/000015-000008.meta --> /lfs/lfs12/gma_akey/results/epb074/models/000015-000009.meta
[2019-06-18 10:24:51] moving /lfs/lfs12/gma_akey/results/epb074/models/000015-000008.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb074/models/000015-000009.data-00000-of-00001
[2019-06-18 10:24:51] iteration time 14: 48.869 seconds
2019-06-18 10:24:52.124221: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560875091.227198 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 15}}
[2019-06-18 10:24:55] minmax time: 3.262 seconds
2019-06-18 10:24:55.395781: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:24:55.401218: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:24:55.405812: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560875095.416121 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 14}}
[2019-06-18 10:24:55] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:24:55] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-16-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000015-000009 --seed=16 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000015-000009 --seed=1023779847 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000015-000009 --seed=2047559678 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000015-000009 --seed=3071339509 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000015-000009 --seed=4095119340 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000015-000009 --seed=5118899171 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000015-000009 --seed=6142679002 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000015-000009 --seed=7166458833 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000015-000009 --seed=8190238664 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000015-000009 --seed=9214018495 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000015-000009 --seed=10237798326 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000015-000009 --seed=11261578157 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000015-000009 --seed=12285357988 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000015-000009 --seed=13309137819 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000015-000009 --seed=14332917650 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000015-000009 --seed=15356697481 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000015-000009 --seed=16380477312 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000015-000009 --seed=17404257143 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000015-000009 --seed=18428036974 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000015-000009 --seed=19451816805 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000015-000009 --seed=20475596636 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:25:05] eval finished: 10.426 seconds
[2019-06-18 10:25:05] Win rate 000015-000009 vs 000014-000008: 0.650
:::MLL 1560875105.918142 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 14}}
[2019-06-18 10:25:05] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-17-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000016-000008 --seed=17 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000016-000008 --seed=1023779848 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000016-000008 --seed=2047559679 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000016-000008 --seed=3071339510 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000016-000008 --seed=4095119341 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000016-000008 --seed=5118899172 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000016-000008 --seed=6142679003 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000016-000008 --seed=7166458834 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000016-000008 --seed=8190238665 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000016-000008 --seed=9214018496 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000016-000008 --seed=10237798327 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000016-000008 --seed=11261578158 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000016-000008 --seed=12285357989 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000016-000008 --seed=13309137820 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000016-000008 --seed=14332917651 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000016-000008 --seed=15356697482 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000016-000008 --seed=16380477313 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000016-000008 --seed=17404257144 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000016-000008 --seed=18428036975 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:25:36] selfplay finished: 30.766 seconds
[2019-06-18 10:25:36] selfplay mn: 30.784 seconds
[2019-06-18 10:25:36] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-17-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779848 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559679 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339510 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119341 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899172 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142679003 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458834 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238665 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018496 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798327 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578158 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285357989 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137820 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917651 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697482 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477313 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257144 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036975 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816806 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596637 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376468 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156299 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golde
[2019-06-18 10:25:38] train finished: 43.452 seconds
:::MLL 1560875100.623240 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.624146 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.624949 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.715922 47165690352512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_0_0
:::MLL 1560875100.632222 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.632915 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.633568 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.716323 47351940801408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_0_0
W0618 10:25:00.717033 47165690352512 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpzq_wez5q
I0618 10:25:00.718146 47165690352512 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpzq_wez5q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae5e6ce6e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:25:00.717395 47351940801408 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpu08b7g7p
I0618 10:25:00.718524 47351940801408 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpu08b7g7p', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b114432be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.718596 47165690352512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:00.719008 47351940801408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:00.723827 47165690352512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:00.724383 47351940801408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:00.745862 47165690352512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:00.746727 47351940801408 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875100.702561 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.702934 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.703251 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.767173 47799112627072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_0_0
:::MLL 1560875100.701173 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.701554 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.701873 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.767293 47179719271296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_0_0
W0618 10:25:00.768233 47799112627072 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpr7jy5cke
W0618 10:25:00.768307 47179719271296 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp4p31qakt
I0618 10:25:00.769229 47799112627072 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpr7jy5cke', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7961b74e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.769292 47179719271296 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp4p31qakt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae92afebe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.769631 47799112627072 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:00.769694 47179719271296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875100.679576 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.680326 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.681063 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.773046 46928908628864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_0_0
:::MLL 1560875100.681765 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.682514 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.683210 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.773192 47464230515584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_0_0
W0618 10:25:00.774202 47799112627072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:00.774271 47179719271296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:00.774183 46928908628864 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpecf74dry
W0618 10:25:00.774246 47464230515584 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpyn09wtvu
I0618 10:25:00.775270 46928908628864 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpecf74dry', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aaec5840e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.775345 47464230515584 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpyn09wtvu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2b692fbe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.775723 46928908628864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:00.775785 47464230515584 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:00.781079 47464230515584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:00.781095 46928908628864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875100.707160 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.707993 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.708729 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.783002 47316634489728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_0_0
:::MLL 1560875100.686390 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.687278 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.688126 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.783245 47759327839104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_0_0
W0618 10:25:00.784037 47316634489728 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp9cbd6v44
W0618 10:25:00.784225 47759327839104 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp0t0hrfy6
I0618 10:25:00.785037 47316634489728 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp9cbd6v44', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b090bc6fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.785225 47759327839104 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp0t0hrfy6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b701e5b9e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.785448 47316634489728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:00.785629 47759327839104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:00.790364 47316634489728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:00.790490 47759327839104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:00.793273 47799112627072 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:00.793458 47179719271296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:00.795507 47165690352512 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:00.795983 47351940801408 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:00.799801 47165690352512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:25:00.800281 47351940801408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560875100.709439 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.710382 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.711236 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.800283 47277535323008 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_0_0
W0618 10:25:00.802822 47464230515584 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:00.803048 46928908628864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:00.801350 47277535323008 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp4ecagimq
I0618 10:25:00.802414 47277535323008 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp4ecagimq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afff1493e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.802843 47277535323008 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:00.804853 47165690352512 estimator.py:1111] Calling model_fn.
W0618 10:25:00.804961 47165690352512 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:25:00.805321 47351940801408 estimator.py:1111] Calling model_fn.
W0618 10:25:00.805428 47351940801408 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:25:00.806325 47165690352512 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:25:00.806778 47351940801408 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560875100.735800 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.736637 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.737418 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.806344 47738801513344 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_0_0
W0618 10:25:00.807736 47277535323008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:00.807354 47738801513344 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpetrbmzyt
I0618 10:25:00.808345 47738801513344 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpetrbmzyt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6b56e4add8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.808753 47738801513344 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:00.809873 47316634489728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:00.810024 47759327839104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:00.813864 47738801513344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875100.745579 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.745992 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.746338 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.818603 47742527341440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_0_0
:::MLL 1560875100.747710 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.748149 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.748517 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.818655 47608820462464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_0_0
W0618 10:25:00.819685 47742527341440 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpuyab_kfz
W0618 10:25:00.819714 47608820462464 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpv_d4bdam
I0618 10:25:00.820745 47742527341440 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpuyab_kfz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6c34f84e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.820778 47608820462464 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpv_d4bdam', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4d136b3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.821197 47742527341440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:00.821217 47608820462464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875100.735527 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.736274 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.736982 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.821617 47749508965248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_0_0
:::MLL 1560875100.732161 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.733048 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.733764 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.821744 47957329728384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_0_0
W0618 10:25:00.822745 47749508965248 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp8d9a9vr6
I0618 10:25:00.822834 47957329728384 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb074/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9e38308d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.823846 47749508965248 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp8d9a9vr6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6dd51b6e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.824069 47957329728384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:00.824293 47749508965248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:00.825828 47742527341440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:00.825855 47608820462464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:00.829603 47749508965248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:00.829662 47957329728384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875100.762272 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.762761 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.763190 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.829982 47060472697728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_0_0
:::MLL 1560875100.756692 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.757270 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.757755 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.830005 47440550642560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_0_0
W0618 10:25:00.829423 47277535323008 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:00.831005 47060472697728 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmphqimniia
W0618 10:25:00.831035 47440550642560 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpttb3dj1e
I0618 10:25:00.832000 47060472697728 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmphqimniia', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acd67585e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.831999 47440550642560 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpttb3dj1e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b25e5c19e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.832384 47440550642560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:00.832391 47060472697728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875100.733711 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.734624 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.735504 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.833986 47620201456512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_0_0
:::MLL 1560875100.745684 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.746445 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.747118 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.834059 47471655924608 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_0_0
W0618 10:25:00.835013 47620201456512 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpzmpu5ymy
W0618 10:25:00.835078 47471655924608 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmps58ui3ge
I0618 10:25:00.836056 47620201456512 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpzmpu5ymy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4fb9c77e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.836102 47471655924608 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmps58ui3ge', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2d23c68dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.836477 47620201456512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:00.836522 47471655924608 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:00.837156 47060472697728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:00.837140 47440550642560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:00.836394 47738801513344 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:00.840439 47799112627072 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:00.840916 47179719271296 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:00.841272 47620201456512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:00.841318 47471655924608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:00.844706 47799112627072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:25:00.845141 47608820462464 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:00.845231 47742527341440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:00.845198 47179719271296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:25:00.849713 47799112627072 estimator.py:1111] Calling model_fn.
W0618 10:25:00.849821 47799112627072 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:25:00.850272 47179719271296 estimator.py:1111] Calling model_fn.
W0618 10:25:00.850386 47179719271296 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:25:00.851073 47464230515584 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:00.851287 46928908628864 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:00.851172 47799112627072 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:25:00.851750 47179719271296 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:25:00.851933 47957329728384 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:00.852070 47749508965248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:00.855353 47464230515584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:25:00.855587 46928908628864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:25:00.856354 47060472697728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:00.856411 47440550642560 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:00.858128 47759327839104 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:00.858211 47316634489728 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:25:00.860419 47464230515584 estimator.py:1111] Calling model_fn.
W0618 10:25:00.860529 47464230515584 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:25:00.860659 46928908628864 estimator.py:1111] Calling model_fn.
W0618 10:25:00.860767 46928908628864 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:25:00.860796 47471655924608 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:00.860810 47620201456512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:00.861903 47464230515584 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:25:00.862129 46928908628864 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:25:00.862454 47759327839104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:25:00.862545 47316634489728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:25:00.867511 47759327839104 estimator.py:1111] Calling model_fn.
W0618 10:25:00.867624 47759327839104 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:25:00.867621 47316634489728 estimator.py:1111] Calling model_fn.
W0618 10:25:00.867731 47316634489728 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:25:00.868986 47759327839104 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:25:00.869080 47316634489728 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560875100.806513 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.806979 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.807321 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.870814 47854868177792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_0_0
:::MLL 1560875100.806007 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.806489 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.806884 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.870882 47608356684672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_0_0
W0618 10:25:00.871842 47854868177792 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpfl1glwc7
W0618 10:25:00.871873 47608356684672 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp5llmc7f9
I0618 10:25:00.872815 47854868177792 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpfl1glwc7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b865d017e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.872864 47608356684672 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp5llmc7f9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4cf7c68e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:00.873216 47854868177792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:00.873270 47608356684672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875100.811428 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875100.811810 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875100.812125 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:00.875259 47590959485824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000006-000001.tfrecord.zz_0_0
:[2019-06-18 10:25:39] divide_golden_chunk finished: 3.272 seconds
[2019-06-18 10:25:39] generate golden chunk: 3.287 seconds
[2019-06-18 10:25:39] moving /lfs/lfs12/gma_akey/results/epb074/models/000016-000009.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb074/models/000016-000010.data-00000-of-00001
[2019-06-18 10:25:40] moving /lfs/lfs12/gma_akey/results/epb074/models/000016-000009.meta --> /lfs/lfs12/gma_akey/results/epb074/models/000016-000010.meta
[2019-06-18 10:25:40] moving /lfs/lfs12/gma_akey/results/epb074/models/000016-000009.index --> /lfs/lfs12/gma_akey/results/epb074/models/000016-000010.index
[2019-06-18 10:25:40] moving /lfs/lfs12/gma_akey/results/epb074/models/000016-000009.pb --> /lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb
[2019-06-18 10:25:40] iteration time 15: 48.805 seconds
2019-06-18 10:25:41.006697: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560875140.032107 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 16}}
[2019-06-18 10:25:44] minmax time: 3.263 seconds
2019-06-18 10:25:44.279381: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:25:44.284868: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:25:44.289522: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560875144.300059 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 15}}
[2019-06-18 10:25:44] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:25:44] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-17-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000016-000010 --seed=17 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000016-000010 --seed=1023779848 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000016-000010 --seed=2047559679 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000016-000010 --seed=3071339510 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000016-000010 --seed=4095119341 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000016-000010 --seed=5118899172 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000016-000010 --seed=6142679003 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000016-000010 --seed=7166458834 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000016-000010 --seed=8190238665 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000016-000010 --seed=9214018496 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000016-000010 --seed=10237798327 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000016-000010 --seed=11261578158 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000016-000010 --seed=12285357989 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000016-000010 --seed=13309137820 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000016-000010 --seed=14332917651 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000016-000010 --seed=15356697482 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000016-000010 --seed=16380477313 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000016-000010 --seed=17404257144 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000016-000010 --seed=18428036975 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000016-000010 --seed=19451816806 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000016-000010 --seed=20475596637 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:25:56] eval finished: 12.337 seconds
[2019-06-18 10:25:56] Win rate 000016-000010 vs 000015-000009: 0.520
:::MLL 1560875156.712309 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 15}}
[2019-06-18 10:25:56] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-18-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000017-000009 --seed=18 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000017-000009 --seed=1023779849 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000017-000009 --seed=2047559680 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000017-000009 --seed=3071339511 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000017-000009 --seed=4095119342 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000017-000009 --seed=5118899173 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000017-000009 --seed=6142679004 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000017-000009 --seed=7166458835 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000017-000009 --seed=8190238666 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000017-000009 --seed=9214018497 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000017-000009 --seed=10237798328 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000017-000009 --seed=11261578159 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000017-000009 --seed=12285357990 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000017-000009 --seed=13309137821 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000017-000009 --seed=14332917652 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000017-000009 --seed=15356697483 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000017-000009 --seed=16380477314 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000017-000009 --seed=17404257145 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000017-000009 --seed=18428036976 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:26:27] selfplay finished: 30.345 seconds
[2019-06-18 10:26:27] selfplay mn: 30.363 seconds
[2019-06-18 10:26:27] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-18-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779849 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559680 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339511 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119342 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899173 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142679004 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458835 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238666 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018497 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798328 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578159 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285357990 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137821 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917652 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697483 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477314 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257145 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036976 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816807 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596638 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376469 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156300 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golde
[2019-06-18 10:26:28] train finished: 43.731 seconds
:::MLL 1560875149.516769 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875149.517664 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875149.518478 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:49.608658 46947570271104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_0_0
W0618 10:25:49.609680 46947570271104 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpw5e5rxnt
I0618 10:25:49.610655 46947570271104 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpw5e5rxnt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab31dd61e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:49.611100 46947570271104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:49.616317 46947570271104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875149.533983 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875149.534850 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875149.535653 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:49.618336 47422712337280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_0_0
W0618 10:25:49.619665 47422712337280 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpwwtu6cxe
I0618 10:25:49.620966 47422712337280 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpwwtu6cxe', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b21be82ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:49.621581 47422712337280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:49.628126 47422712337280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875149.539579 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875149.540286 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875149.540997 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:49.630337 47482098140032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_0_0
:::MLL 1560875149.542308 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875149.543032 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875149.543737 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:49.630686 46971745895296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_0_0
W0618 10:25:49.631449 47482098140032 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpcay8xg51
W0618 10:25:49.631764 46971745895296 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpci9ywrsl
I0618 10:25:49.632468 47482098140032 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpcay8xg51', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2f922e1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:49.632742 46971745895296 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpci9ywrsl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab8bed0dda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:49.632865 47482098140032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:49.633158 46971745895296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:49.637580 47482098140032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:49.637964 46971745895296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:49.638421 46947570271104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:49.656743 47482098140032 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:49.657797 46971745895296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875149.570838 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875149.571593 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875149.572260 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:49.657831 47904517583744 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_0_0
:::MLL 1560875149.563392 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875149.564298 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875149.565159 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:49.658220 47364068123520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_0_0
W0618 10:25:49.658944 47904517583744 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpq72417bq
I0618 10:25:49.660036 47904517583744 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpq72417bq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b91ec573dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:25:49.659277 47364068123520 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp95d2rite
I0618 10:25:49.660400 47364068123520 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp95d2rite', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b14170afe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:49.660482 47904517583744 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:49.660848 47364068123520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:49.661071 47422712337280 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:49.665709 47904517583744 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:49.666122 47364068123520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875149.608908 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875149.609353 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875149.609747 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:49.676452 47844111061888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_0_0
W0618 10:25:49.677450 47844111061888 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmplgtzhsao
:::MLL 1560875149.612772 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875149.613218 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875149.613583 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:49.678081 47600269288320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_0_0
I0618 10:25:49.678434 47844111061888 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmplgtzhsao', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b83dbd4ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560875149.605713 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875149.606222 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875149.606689 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:49.678674 47988167041920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_0_0
I0618 10:25:49.678843 47844111061888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875149.608640 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875149.609095 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875149.609489 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:49.679111 46922175406976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_0_0
W0618 10:25:49.679064 47600269288320 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmppglcy1fj
I0618 10:25:49.680078 47600269288320 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmppglcy1fj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4b15babe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:25:49.679722 47988167041920 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp_izo7cry
I0618 10:25:49.680782 47988167041920 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp_izo7cry', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba5663cbe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:49.680473 47600269288320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:49.680108 46922175406976 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpk2jxdvwv
I0618 10:25:49.681120 46922175406976 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpk2jxdvwv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aad342f3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:49.681184 47988167041920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:49.681507 46922175406976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:49.683489 47844111061888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:49.685016 47600269288320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:49.685748 47988167041920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:49.686034 46922175406976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:49.687688 47904517583744 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875149.595947 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875149.596856 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875149.597762 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:49.687326 46925505065856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_0_0
:::MLL 1560875149.603608 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875149.604346 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875149.605059 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:49.687507 46962535502720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_0_0
W0618 10:25:49.688518 47364068123520 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:49.688484 46925505065856 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpwq7eess7
I0618 10:25:49.688641 46962535502720 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb074/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab699d55cf8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:49.689582 46925505065856 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpwq7eess7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aadfaa5ce80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:25:49.689845 46947570271104 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:25:49.689901 46962535502720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:49.690030 46925505065856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:49.694144 46947570271104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:25:49.695298 46925505065856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:49.695396 46962535502720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:25:49.699206 46947570271104 estimator.py:1111] Calling model_fn.
W0618 10:25:49.699316 46947570271104 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:25:49.700671 46947570271104 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:25:49.702632 47844111061888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875149.626000 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875149.626426 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875149.626784 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:49.703334 47804582441856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_0_0
:::MLL 1560875149.627469 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875149.627874 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875149.628229 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:49.703470 47685372724096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_0_0
W0618 10:25:49.704434 47482098140032 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:49.704229 47600269288320 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:49.704850 47988167041920 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875149.623802 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875149.624512 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875149.625189 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:49.703682 47416958849920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_0_0
:::MLL 1560875149.612602 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875149.613513 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875149.614378 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:49.703764 47169973810048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_0_0
W0618 10:25:49.705156 46971745895296 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:49.704362 47804582441856 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp8deqons3
W0618 10:25:49.705254 46922175406976 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:49.704458 47685372724096 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpdh1pm7tn
I0618 10:25:49.705354 47804582441856 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp8deqons3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7aa7be0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:49.705444 47685372724096 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpdh1pm7tn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5ee64a1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:49.705748 47804582441856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:49.705839 47685372724096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:49.704822 47416958849920 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpjq8tlosx
W0618 10:25:49.704856 47169973810048 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpzhgqifxv
I0618 10:25:49.705908 47416958849920 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpjq8tlosx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2067935e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:49.705943 47169973810048 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpzhgqifxv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae6e61ece48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:49.706359 47416958849920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:49.706380 47169973810048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:49.708804 47482098140032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:25:49.709490 46971745895296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:25:49.710487 47804582441856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:49.710578 47685372724096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:49.711632 47416958849920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:49.711634 47169973810048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:25:49.713920 47482098140032 estimator.py:1111] Calling model_fn.
W0618 10:25:49.714028 47482098140032 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:25:49.713850 47422712337280 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:25:49.714578 46971745895296 estimator.py:1111] Calling model_fn.
W0618 10:25:49.714687 46971745895296 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:25:49.715374 47482098140032 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:25:49.716035 46971745895296 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:25:49.717418 46925505065856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:49.718148 47422712337280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:25:49.718553 46962535502720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:25:49.723199 47422712337280 estimator.py:1111] Calling model_fn.
W0618 10:25:49.723306 47422712337280 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:25:49.724677 47422712337280 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:25:49.729806 47804582441856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:49.729908 47685372724096 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875149.653698 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875149.654457 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875149.655194 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:49.732067 47855644722048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_0_0
:::MLL 1560875149.639026 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875149.639959 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875149.640815 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:49.732085 47085644772224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_0_0
W0618 10:25:49.733140 47855644722048 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpqgz9aigz
W0618 10:25:49.733173 47085644772224 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmph97ie15r
I0618 10:25:49.734128 47855644722048 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpqgz9aigz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b868b4a9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:49.734158 47085644772224 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmph97ie15r', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad343b7cdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:49.734521 47855644722048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:49.734561 47085644772224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:49.733796 47169973810048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:49.733966 47416958849920 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:25:49.736948 47904517583744 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:49.737598 47364068123520 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:49.739530 47855644722048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:49.739552 47085644772224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875149.672508 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875149.672883 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875149.673201 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:49.740448 46939078787968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_0_0
W0618 10:25:49.741255 47904517583744 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:25:49.741915 47364068123520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560875149.674774 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875149.675183 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875149.675574 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:49.741527 47276275807104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_0_0
W0618 10:25:49.741475 46939078787968 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpsgdpk596
I0618 10:25:49.742449 46939078787968 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpsgdpk596', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab123b45e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:49.742854 46939078787968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:25:49.742496 47276275807104 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp7gsceeq4
I0618 10:25:49.743475 47276275807104 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp7gsceeq4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2affa6367e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:25:49.743873 47276275807104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:25:49.746306 47904517583744 estimator.py:1111] Calling model_fn.
W0618 10:25:49.746414 47904517583744 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:25:49.746976 47364068123520 estimator.py:1111] Calling model_fn.
W0618 10:25:49.747085 47364068123520 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:25:49.747760 47904517583744 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:25:49.747440 46939078787968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:49.748444 47364068123520 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:25:49.748376 47276275807104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:25:49.749927 47844111061888 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:49.751763 47600269288320 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:49.752453 47988167041920 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:25:49.752729 46922175406976 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560875149.685444 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875149.685878 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875149.686265 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:25:49.751605 46937879683968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000007-000002.tfrecord.zz_0_0
W0618 10:25:49.752658 46937879683968 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmplyoqlz68
W0618 10:25:49.754207 47844111061888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:25:49.753668 46937879683968 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmplyoqlz68', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_[2019-06-18 10:26:30] divide_golden_chunk finished: 3.347 seconds
[2019-06-18 10:26:30] generate golden chunk: 3.361 seconds
[2019-06-18 10:26:30] moving /lfs/lfs12/gma_akey/results/epb074/models/000017-000010.pb --> /lfs/lfs12/gma_akey/results/epb074/models/000017-000011.pb
[2019-06-18 10:26:30] moving /lfs/lfs12/gma_akey/results/epb074/models/000017-000010.meta --> /lfs/lfs12/gma_akey/results/epb074/models/000017-000011.meta
[2019-06-18 10:26:30] moving /lfs/lfs12/gma_akey/results/epb074/models/000017-000010.index --> /lfs/lfs12/gma_akey/results/epb074/models/000017-000011.index
[2019-06-18 10:26:30] moving /lfs/lfs12/gma_akey/results/epb074/models/000017-000010.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb074/models/000017-000011.data-00000-of-00001
[2019-06-18 10:26:30] iteration time 16: 50.445 seconds
2019-06-18 10:26:31.559316: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
Got 343572 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000009.tfrecord.zz: 9.871 seconds
Got 377495 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000004.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000004.tfrecord.zz: 14.886 seconds
Got 380569 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000005.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000005.tfrecord.zz: 11.544 seconds
Got 347658 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000006.tfrecord.zz: 0.309 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000006.tfrecord.zz: 14.129 seconds
Got 391461 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000000.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000000.tfrecord.zz: 16.011 seconds
Got 383263 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000002.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000002.tfrecord.zz: 15.270 seconds
Got 348718 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000007.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000007.tfrecord.zz: 11.941 seconds
Got 346341 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000008.tfrecord.zz: 0.312 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000008.tfrecord.zz: 13.416 seconds
Got 389066 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000003.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000003.tfrecord.zz: 15.433 seconds
Got 386476 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000001.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000000-000001.tfrecord.zz: 15.034 seconds
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/checkpoint_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/checkpointlog.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000001-000001_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000001-000001log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000002-000001_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000002-000001log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000003-000002_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000003-000002log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000004-000002_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000004-000002log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000005-000002_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000005-000002log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000006-000003_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000006-000003log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000007-000004_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000007-000004log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000008-000004_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000008-000004log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000009-000005_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000009-000005log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000010-000006_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000010-000006log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000011-000006_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000011-000006log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000012-000007_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000012-000007log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000013-000007_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000013-000007log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000014-000008_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000014-000008log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000015-000009_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000015-000009log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000016-000010_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000016-000010log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000017-000011_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000017-000011log.txt['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560875190.477548 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 17}}
[2019-06-18 10:26:34] minmax time: 3.269 seconds
2019-06-18 10:26:34.838466: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:26:34.843662: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:26:34.848156: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560875194.858569 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 16}}
[2019-06-18 10:26:34] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000018-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000018-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000018-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000018-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000018-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000018-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000018-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000018-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000018-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000018-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000018-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:26:34] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-18-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000017-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000017-000011 --seed=18 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000017-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000017-000011 --seed=1023779849 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000017-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000017-000011 --seed=2047559680 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000017-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000017-000011 --seed=3071339511 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000017-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000017-000011 --seed=4095119342 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000017-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000017-000011 --seed=5118899173 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000017-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000017-000011 --seed=6142679004 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000017-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000017-000011 --seed=7166458835 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000017-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000017-000011 --seed=8190238666 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000017-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000017-000011 --seed=9214018497 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000017-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000017-000011 --seed=10237798328 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000017-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000017-000011 --seed=11261578159 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000017-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000017-000011 --seed=12285357990 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000017-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000017-000011 --seed=13309137821 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000017-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000017-000011 --seed=14332917652 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000017-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000017-000011 --seed=15356697483 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000017-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000017-000011 --seed=16380477314 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000017-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000017-000011 --seed=17404257145 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000017-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000017-000011 --seed=18428036976 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000017-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000017-000011 --seed=19451816807 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000017-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000017-000011 --seed=20475596638 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:26:45] eval finished: 10.881 seconds
[2019-06-18 10:26:45] Win rate 000017-000011 vs 000016-000010: 0.450
:::MLL 1560875205.816805 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 16}}
[2019-06-18 10:26:45] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-19-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000018-000010 --seed=19 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000018-000010 --seed=1023779850 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000018-000010 --seed=2047559681 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000018-000010 --seed=3071339512 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000018-000010 --seed=4095119343 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000018-000010 --seed=5118899174 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000018-000010 --seed=6142679005 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000018-000010 --seed=7166458836 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000018-000010 --seed=8190238667 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000018-000010 --seed=9214018498 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000018-000010 --seed=10237798329 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000018-000010 --seed=11261578160 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000018-000010 --seed=12285357991 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000018-000010 --seed=13309137822 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000018-000010 --seed=14332917653 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000018-000010 --seed=15356697484 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000018-000010 --seed=16380477315 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000018-000010 --seed=17404257146 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000018-000010 --seed=18428036977 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:27:16] selfplay finished: 30.371 seconds
[2019-06-18 10:27:16] selfplay mn: 30.389 seconds
[2019-06-18 10:27:16] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-19-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779850 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559681 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339512 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119343 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899174 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142679005 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458836 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238667 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018498 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798329 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578160 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285357991 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137822 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917653 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697484 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477315 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257146 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036977 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816808 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596639 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376470 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156301 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000018-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golde
[2019-06-18 10:27:18] train finished: 44.009 seconds
:::MLL 1560875200.132941 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875200.133667 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875200.134339 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:40.225564 47653492732800 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_0_0
:::MLL 1560875200.130381 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875200.131039 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875200.131715 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:40.226251 47385236185984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_0_0
W0618 10:26:40.226652 47653492732800 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpjl8lfa6_
I0618 10:26:40.227705 47653492732800 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpjl8lfa6_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b577a180e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:26:40.227294 47385236185984 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpi5acz91a
I0618 10:26:40.228103 47653492732800 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:26:40.228280 47385236185984 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpi5acz91a', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1904c1fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:40.228682 47385236185984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:26:40.232967 47653492732800 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:40.233365 47385236185984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875200.139243 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875200.140179 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875200.141011 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:40.238426 47485768405888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_0_0
:::MLL 1560875200.146910 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875200.147563 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875200.148232 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:40.238467 47690725335936 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_0_0
W0618 10:26:40.239526 47485768405888 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp0vjfhi2e
W0618 10:26:40.239560 47690725335936 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpbpqhh_dd
I0618 10:26:40.240644 47485768405888 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp0vjfhi2e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b306cf1ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:40.240683 47690725335936 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpbpqhh_dd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6025546e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:40.241079 47485768405888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:26:40.241117 47690725335936 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:26:40.246300 47485768405888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:40.246297 47690725335936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:40.253269 47653492732800 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:26:40.253621 47385236185984 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875200.164509 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875200.165401 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875200.166223 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:40.258342 47606620545920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_0_0
:::MLL 1560875200.169045 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875200.169790 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875200.170441 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:40.258443 47598214538112 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_0_0
W0618 10:26:40.259406 47606620545920 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpgfwgc13g
W0618 10:26:40.259492 47598214538112 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpp8zqrulm
I0618 10:26:40.260482 47606620545920 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpgfwgc13g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4c904b3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:40.260584 47598214538112 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpp8zqrulm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4a9b41be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:40.260940 47606620545920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:26:40.261039 47598214538112 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:26:40.266009 47606620545920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:40.266005 47598214538112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:40.267151 47485768405888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:26:40.267184 47690725335936 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875200.191277 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875200.192022 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875200.192711 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:40.272374 47176990778240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_0_0
:::MLL 1560875200.182084 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875200.182995 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875200.183847 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:40.272523 47865634235264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_0_0
:::MLL 1560875200.202412 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875200.202942 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875200.203379 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:40.274687 47295079723904 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_0_0
:::MLL 1560875200.202315 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875200.202829 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875200.203260 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:40.274775 47625630897024 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_0_0
W0618 10:26:40.273558 47176990778240 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmplrtb0h9b
W0618 10:26:40.273646 47865634235264 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp4zhttfcv
I0618 10:26:40.274675 47176990778240 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmplrtb0h9b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae8885d3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:40.274751 47865634235264 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp4zhttfcv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b88deb67e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:40.275137 47176990778240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:26:40.275198 47865634235264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:26:40.275761 47625630897024 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpmo6kzd8f
W0618 10:26:40.275697 47295079723904 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpsawchybe
I0618 10:26:40.276701 47295079723904 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpsawchybe', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0407038e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:40.276731 47625630897024 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpmo6kzd8f', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b50fd662e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:40.277098 47295079723904 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:26:40.277121 47625630897024 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:26:40.280340 47176990778240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:40.280325 47865634235264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:40.281787 47625630897024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:40.281802 47295079723904 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875200.208465 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875200.208946 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875200.209379 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:40.284075 47778519573376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_0_0
:::MLL 1560875200.208500 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875200.208973 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875200.209403 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:40.284411 47482958287744 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_0_0
W0618 10:26:40.285110 47778519573376 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpc71nbk5z
W0618 10:26:40.285388 47482958287744 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpy4f829qv
I0618 10:26:40.286108 47778519573376 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpc71nbk5z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7496463e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:40.286363 47482958287744 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpy4f829qv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2fc572ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:40.286501 47778519573376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:26:40.286755 47482958287744 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:26:40.287483 47598214538112 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:26:40.287544 47606620545920 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:26:40.291158 47778519573376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:40.291350 47482958287744 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:40.301142 47625630897024 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:26:40.301144 47295079723904 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:26:40.301570 47653492732800 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:26:40.301527 47385236185984 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:26:40.302291 47865634235264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:26:40.302532 47176990778240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:26:40.305899 47653492732800 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:26:40.305860 47385236185984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:26:40.310262 47778519573376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:26:40.310506 47482958287744 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:26:40.310981 47385236185984 estimator.py:1111] Calling model_fn.
I0618 10:26:40.311047 47653492732800 estimator.py:1111] Calling model_fn.
W0618 10:26:40.311090 47385236185984 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:26:40.311155 47653492732800 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:26:40.312450 47385236185984 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:26:40.312540 47653492732800 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:26:40.315270 47485768405888 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:26:40.315546 47690725335936 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560875200.242352 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875200.242799 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875200.243270 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:40.317077 47360740426624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_0_0
:::MLL 1560875200.242257 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875200.242668 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875200.243221 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:40.317383 47909117703040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_0_0
W0618 10:26:40.318072 47360740426624 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpogwrv1in
I0618 10:26:40.319065 47360740426624 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpogwrv1in', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1350b25e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:26:40.318367 47909117703040 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpto4x7p_b
I0618 10:26:40.319346 47909117703040 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpto4x7p_b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b92fe875e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:26:40.319604 47485768405888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:26:40.319465 47360740426624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:26:40.319904 47690725335936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:26:40.319745 47909117703040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875200.259899 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875200.260326 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875200.260705 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:40.319349 47706022839168 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_0_0
W0618 10:26:40.320360 47706022839168 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpphbihvqg
I0618 10:26:40.321347 47706022839168 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpphbihvqg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b63b521de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:40.321756 47706022839168 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:26:40.324143 47360740426624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:40.324358 47909117703040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:26:40.324705 47485768405888 estimator.py:1111] Calling model_fn.
W0618 10:26:40.324815 47485768405888 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:26:40.325001 47690725335936 estimator.py:1111] Calling model_fn.
W0618 10:26:40.325112 47690725335936 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:26:40.326192 47485768405888 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:26:40.326485 47690725335936 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:26:40.326415 47706022839168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875200.247623 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875200.248348 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875200.249011 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:40.329065 47545671119744 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_0_0
:::MLL 1560875200.234446 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875200.235374 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875200.236265 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:40.329159 47390960288640 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_0_0
W0618 10:26:40.330142 47545671119744 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpb_1zu2bl
W0618 10:26:40.330171 47390960288640 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp610qs21w
I0618 10:26:40.331211 47545671119744 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpb_1zu2bl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3e5f6cce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:40.331218 47390960288640 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp610qs21w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1a59f0de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:40.331611 47545671119744 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:26:40.331615 47390960288640 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875200.259887 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875200.260316 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875200.260696 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:26:40.330930 47652527227776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000008-000003.tfrecord.zz_0_0
W0618 10:26:40.331897 47652527227776 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpe056rwt7
I0618 10:26:40.332878 47652527227776 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpe056rwt7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b57408b7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:26:40.333278 47652527227776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:26:40.336771 47545671119744 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:40.336799 47390960288640 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:40.337476 47598214538112 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:26:40.337871 47606620545920 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:26:40.337786 47652527227776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:26:40.341768 47598214538112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:26:40.342170 47606620545920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:26:40.343300 47909117703040 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:26:40.343415 47360740426624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:26:40.345439 47706022839168 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:26:40.346859 47598214538112 estimator.py:1111] Calling model_fn.
W0618 10:26:40.346969 47598214538112 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:26:40.347283 47606620545920 estimator.py:1111] Calling model_fn.
W0618 10:26:40.347392 47606620545920 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:26:40.348332 47598214538112 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:26:40.348770 47606620545920 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:26:40.349122 47625630897024 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:26:40.349207 47295079723904 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:26:40.351639 47865634235264 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:26:40.352110 47176990778240 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:26:40.353442 47625630897024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:26:40.353545 47295079723904 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:26:40.355949 47545671119744 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:26:40.356147 47390960288640 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:26:40.355947 47865634235264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:26:40.356442 47176990778240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:26:40.357762 47482958287744 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:26:40.356805 47652527227776 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:26:40.358016 47778519573376 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:26:40.358571 47625630897024 estimator.py:1111] Calling model_fn.
W0618 10:26:40.358681 47625630897024 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:26:40.358685 47295079723904 estimator.py:1111] Calling model_fn.
W0618 10:26:40.358793 47295079723904 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:26:40.360054 47625630897024 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python[2019-06-18 10:27:19] divide_golden_chunk finished: 3.308 seconds
[2019-06-18 10:27:19] generate golden chunk: 3.323 seconds
[2019-06-18 10:27:19] iteration time 17: 49.052 seconds
2019-06-18 10:27:20.580182: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560875239.529955 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 18}}
[2019-06-18 10:27:23] minmax time: 3.208 seconds
2019-06-18 10:27:23.798355: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:27:23.803836: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:27:23.808356: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560875243.820294 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 17}}
[2019-06-18 10:27:23] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000019-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000019-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000019-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000019-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000019-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000019-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000019-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000019-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000019-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000019-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000019-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:27:23] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-19-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000018-000011 --seed=19 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000018-000011 --seed=1023779850 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000018-000011 --seed=2047559681 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000018-000011 --seed=3071339512 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000018-000011 --seed=4095119343 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000018-000011 --seed=5118899174 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000018-000011 --seed=6142679005 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000018-000011 --seed=7166458836 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000018-000011 --seed=8190238667 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000018-000011 --seed=9214018498 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000018-000011 --seed=10237798329 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000018-000011 --seed=11261578160 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000018-000011 --seed=12285357991 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000018-000011 --seed=13309137822 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000018-000011 --seed=14332917653 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000018-000011 --seed=15356697484 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000018-000011 --seed=16380477315 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000018-000011 --seed=17404257146 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000018-000011 --seed=18428036977 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000018-000011 --seed=19451816808 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000018-000011 --seed=20475596639 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:27:35] eval finished: 11.627 seconds
[2019-06-18 10:27:35] Win rate 000018-000011 vs 000016-000010: 0.450
:::MLL 1560875255.523194 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 17}}
[2019-06-18 10:27:35] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-20-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000019-000010 --seed=20 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000019-000010 --seed=1023779851 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000019-000010 --seed=2047559682 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000019-000010 --seed=3071339513 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000019-000010 --seed=4095119344 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000019-000010 --seed=5118899175 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000019-000010 --seed=6142679006 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000019-000010 --seed=7166458837 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000019-000010 --seed=8190238668 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000019-000010 --seed=9214018499 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000019-000010 --seed=10237798330 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000019-000010 --seed=11261578161 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000019-000010 --seed=12285357992 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000019-000010 --seed=13309137823 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000019-000010 --seed=14332917654 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000019-000010 --seed=15356697485 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000019-000010 --seed=16380477316 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000019-000010 --seed=17404257147 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000019-000010 --seed=18428036978 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:28:05] selfplay finished: 30.350 seconds
[2019-06-18 10:28:05] selfplay mn: 30.371 seconds
[2019-06-18 10:28:05] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-20-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779851 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559682 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339513 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119344 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899175 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142679006 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458837 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238668 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018499 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798330 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578161 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285357992 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137823 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917654 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697485 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477316 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257147 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036978 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816809 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596640 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376471 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156302 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golde
[2019-06-18 10:28:07] train finished: 44.112 seconds
:::MLL 1560875249.040986 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875249.041720 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875249.042334 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:27:29.127851 47386125841280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_0_0
:::MLL 1560875249.030119 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875249.030976 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875249.031834 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:27:29.127944 47173195912064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_0_0
W0618 10:27:29.129007 47386125841280 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpz4kjc1w0
W0618 10:27:29.129078 47173195912064 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpmrq76ssm
I0618 10:27:29.130128 47386125841280 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpz4kjc1w0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1939c8fdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:27:29.130181 47173195912064 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpmrq76ssm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae7a62c2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:27:29.130585 47386125841280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:27:29.130627 47173195912064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:27:29.135882 47386125841280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:27:29.135959 47173195912064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:27:29.157990 47386125841280 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:27:29.158422 47173195912064 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875249.067300 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875249.067982 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875249.068665 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:27:29.164117 47055074395008 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_0_0
:::MLL 1560875249.069542 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875249.070269 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875249.070984 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:27:29.164137 47955855954816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_0_0
W0618 10:27:29.165247 47955855954816 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp84zz037o
W0618 10:27:29.165277 47055074395008 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmppkrdzoxf
I0618 10:27:29.166340 47955855954816 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp84zz037o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9de058ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:27:29.166388 47055074395008 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmppkrdzoxf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acc2594de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:27:29.166790 47955855954816 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:27:29.166843 47055074395008 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:27:29.172163 47055074395008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:27:29.172167 47955855954816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875249.109880 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875249.110310 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875249.110691 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:27:29.183452 47974807753600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_0_0
W0618 10:27:29.184542 47974807753600 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpf5nol92t
I0618 10:27:29.185568 47974807753600 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpf5nol92t', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba249f62e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:27:29.185993 47974807753600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:27:29.191044 47974807753600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:27:29.194035 47955855954816 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:27:29.194407 47055074395008 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875249.120000 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875249.120408 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875249.120764 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:27:29.194850 47285494342528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_0_0
W0618 10:27:29.195801 47285494342528 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpbrw2scyx
I0618 10:27:29.196767 47285494342528 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpbrw2scyx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b01cbae1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:27:29.197170 47285494342528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875249.093326 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875249.094264 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875249.095151 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:27:29.196730 47903895729024 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_0_0
:::MLL 1560875249.112411 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875249.113175 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875249.113867 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:27:29.197176 47544719537024 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_0_0
W0618 10:27:29.197845 47903895729024 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpvtyv6mkb
I0618 10:27:29.198928 47903895729024 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpvtyv6mkb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b91c7468dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:27:29.198282 47544719537024 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpc_zu_bws
I0618 10:27:29.199362 47903895729024 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:27:29.199411 47544719537024 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpc_zu_bws', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3e26b4ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:27:29.199863 47544719537024 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:27:29.201660 47285494342528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:27:29.204568 47903895729024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:27:29.205104 47544719537024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:27:29.209404 47386125841280 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:27:29.209501 47173195912064 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:27:29.210196 47974807753600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:27:29.213701 47386125841280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:27:29.213803 47173195912064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560875249.135859 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875249.136263 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875249.136606 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:27:29.215246 47387958604672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_0_0
:::MLL 1560875249.138247 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875249.138669 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875249.139011 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:27:29.215226 47976250901376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_0_0
:::MLL 1560875249.119930 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875249.120793 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875249.121524 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:27:29.216359 46973577053056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_0_0
:::MLL 1560875249.123959 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875249.124692 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875249.125301 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:27:29.216778 47278774596480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_0_0
W0618 10:27:29.216285 47976250901376 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp1sasg9pn
W0618 10:27:29.216313 47387958604672 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp4o9zxl5_
I0618 10:27:29.217275 47976250901376 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp1sasg9pn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba29ffade10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:27:29.217306 47387958604672 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp4o9zxl5_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b19a706ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:27:29.217673 47976250901376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:27:29.217705 47387958604672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:27:29.217402 46973577053056 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpy7bl6v__
I0618 10:27:29.218402 46973577053056 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpy7bl6v__', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab92bf61e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:27:29.217773 47278774596480 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpvnyfgi0o
I0618 10:27:29.218804 47386125841280 estimator.py:1111] Calling model_fn.
W0618 10:27:29.218920 47386125841280 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:27:29.218916 47173195912064 estimator.py:1111] Calling model_fn.
I0618 10:27:29.218771 47278774596480 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpvnyfgi0o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b003b270e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:27:29.219026 47173195912064 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:27:29.218798 46973577053056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:27:29.219166 47278774596480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:27:29.220286 47386125841280 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:27:29.220389 47173195912064 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:27:29.220602 47285494342528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:27:29.222263 47976250901376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:27:29.222370 47387958604672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:27:29.223482 46973577053056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:27:29.223748 47278774596480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875249.127812 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875249.128757 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875249.129632 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:27:29.224884 46945687315328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_0_0
:::MLL 1560875249.133428 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875249.134221 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875249.134945 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:27:29.225184 47024432554880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_0_0
W0618 10:27:29.226001 46945687315328 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp4_uufdtu
I0618 10:27:29.226275 47024432554880 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb074/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac5032f6d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:27:29.227127 46945687315328 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp4_uufdtu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab2ad9a7e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:27:29.226411 47903895729024 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:27:29.227544 47024432554880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:27:29.227586 46945687315328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:27:29.227778 47544719537024 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:27:29.232946 46945687315328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:27:29.233136 47024432554880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:27:29.241323 47976250901376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:27:29.241600 47387958604672 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:27:29.243141 47955855954816 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:27:29.243281 46973577053056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:27:29.243340 47055074395008 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:27:29.243410 47278774596480 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875249.180799 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875249.181252 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875249.181631 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:27:29.244096 46949848290176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_0_0
W0618 10:27:29.245108 46949848290176 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp__ddw9hb
I0618 10:27:29.246100 46949848290176 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp__ddw9hb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab3a59dedd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:27:29.246502 46949848290176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:27:29.247453 47955855954816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:27:29.247657 47055074395008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:27:29.251282 46949848290176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:27:29.252539 47955855954816 estimator.py:1111] Calling model_fn.
W0618 10:27:29.252650 47955855954816 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:27:29.252788 47055074395008 estimator.py:1111] Calling model_fn.
W0618 10:27:29.252900 47055074395008 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560875249.099082 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875249.099980 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875249.100842 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:27:29.254046 47835304141696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_0_0
W0618 10:27:29.254000 47955855954816 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560875249.099079 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875249.099971 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875249.100829 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:27:29.254331 47088900309888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_0_0
W0618 10:27:29.254269 47055074395008 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:27:29.254924 46945687315328 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:27:29.255223 47024432554880 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:27:29.255085 47835304141696 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpxvara4t9
W0618 10:27:29.255311 47088900309888 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpgm56pntf
I0618 10:27:29.256101 47835304141696 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpxvara4t9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b81cee5ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:27:29.256298 47088900309888 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpgm56pntf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad405c34e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:27:29.256504 47835304141696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:27:29.256697 47088900309888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:27:29.257707 47974807753600 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560875249.196273 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875249.196694 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875249.197061 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:27:29.257402 47325396468608 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_0_0
W0618 10:27:29.258367 47325396468608 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmph2we6qr0
I0618 10:27:29.259334 47325396468608 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmph2we6qr0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0b16084e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:27:29.259724 47325396468608 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:27:29.261707 47835304141696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:27:29.261828 47088900309888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:27:29.262026 47974807753600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:27:29.264261 47325396468608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:27:29.267127 47974807753600 estimator.py:1111] Calling model_fn.
W0618 10:27:29.267235 47974807753600 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:27:29.267466 47285494342528 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:27:29.268626 47974807753600 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560875249.196020 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875249.196454 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875249.196830 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:27:29.269719 47593629954944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_0_0
:::MLL 1560875249.198352 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875249.198783 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875249.199250 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:27:29.269967 47440829825920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_0_0
W0618 10:27:29.270719 47593629954944 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpy4bft38v
W0618 10:27:29.270606 46949848290176 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:27:29.271744 47285494342528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:27:29.270950 47440829825920 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp97fdai89
I0618 10:27:29.271699 47593629954944 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpy4bft38v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4989fe8dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:27:29.271941 47440829825920 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp97fdai89', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b25f6659e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:27:29.272102 47593629954944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:27:29.272339 47440829825920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875249.199697 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875249.200169 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875249.200550 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:27:29.275596 47082790785920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_0_0
:::MLL 1560875249.199373 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875249.199858 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875249.200276 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:27:29.275609 47738618684288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000009-000003.tfrecord.zz_0_0
I0618 10:27:29.276810 47285494342528 estimator.py:1111] Calling model_fn.
W0618 10:27:29.276662 47593629954944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:27:29.276926 47285494342528 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:27:29.276932 47440829825920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:27:29.276620 47082790785920 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpvr0vcbr1
W0618 10:27:29.276649 47738618684288 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpryi1jg_n
I0618 10:27:29.277615 47082790785920 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpvr0vcbr1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad2999b6e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:27:29.277631 47738618684288 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpryi1jg_n', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6b4bfefe80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:27:29.278015 47082790785920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:27:29.278024 47738618684288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:27:29.278284 47285494342528 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:27:29.278059 47903895729024 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:27:29.279582 47544719537024 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:27:29.281172 47835304141696 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determ[2019-06-18 10:28:09] divide_golden_chunk finished: 3.368 seconds
[2019-06-18 10:28:09] generate golden chunk: 3.382 seconds
[2019-06-18 10:28:09] iteration time 18: 49.749 seconds
2019-06-18 10:28:10.383340: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560875289.278721 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 19}}
[2019-06-18 10:28:13] minmax time: 3.237 seconds
2019-06-18 10:28:13.630989: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:28:13.636345: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:28:13.640861: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560875293.653026 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 18}}
[2019-06-18 10:28:13] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000020-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000020-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000020-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000020-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000020-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000020-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000020-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000020-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000020-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000020-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000020-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:28:13] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-20-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000019-000011 --seed=20 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000019-000011 --seed=1023779851 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000019-000011 --seed=2047559682 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000019-000011 --seed=3071339513 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000019-000011 --seed=4095119344 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000019-000011 --seed=5118899175 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000019-000011 --seed=6142679006 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000019-000011 --seed=7166458837 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000019-000011 --seed=8190238668 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000019-000011 --seed=9214018499 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000019-000011 --seed=10237798330 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000019-000011 --seed=11261578161 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000019-000011 --seed=12285357992 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000019-000011 --seed=13309137823 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000019-000011 --seed=14332917654 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000019-000011 --seed=15356697485 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000019-000011 --seed=16380477316 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000019-000011 --seed=17404257147 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000019-000011 --seed=18428036978 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000019-000011 --seed=19451816809 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000016-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000019-000011 --seed=20475596640 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:28:23] eval finished: 10.183 seconds
[2019-06-18 10:28:23] Win rate 000019-000011 vs 000016-000010: 0.710
:::MLL 1560875303.913049 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 18}}
[2019-06-18 10:28:23] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-21-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000020-000010 --seed=21 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000020-000010 --seed=1023779852 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000020-000010 --seed=2047559683 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000020-000010 --seed=3071339514 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000020-000010 --seed=4095119345 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000020-000010 --seed=5118899176 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000020-000010 --seed=6142679007 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000020-000010 --seed=7166458838 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000020-000010 --seed=8190238669 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000020-000010 --seed=9214018500 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000020-000010 --seed=10237798331 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000020-000010 --seed=11261578162 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000020-000010 --seed=12285357993 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000020-000010 --seed=13309137824 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000020-000010 --seed=14332917655 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000020-000010 --seed=15356697486 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000020-000010 --seed=16380477317 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000020-000010 --seed=17404257148 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000020-000010 --seed=18428036979 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:28:53] selfplay finished: 29.721 seconds
[2019-06-18 10:28:53] selfplay mn: 29.740 seconds
[2019-06-18 10:28:53] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-21-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779852 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559683 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339514 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119345 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899176 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142679007 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458838 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238669 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018500 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798331 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578162 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285357993 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137824 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917655 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697486 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477317 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257148 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036979 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816810 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596641 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376472 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156303 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golde
[2019-06-18 10:28:56] divide_golden_chunk finished: 3.337 seconds
[2019-06-18 10:28:57] generate golden chunk: 3.352 seconds
[2019-06-18 10:28:57] train finished: 43.450 seconds
:::MLL 1560875298.904786 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875298.905513 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875298.906203 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:28:18.992826 47101525320576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_0_0
:::MLL 1560875298.891520 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875298.892441 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875298.893346 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:28:18.993071 47579673592704 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_0_0
W0618 10:28:18.993858 47101525320576 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpdsy0jjdl
W0618 10:28:18.994081 47579673592704 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmprvxa1i1d
I0618 10:28:18.994893 47101525320576 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpdsy0jjdl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad6f645be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:28:18.995126 47579673592704 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmprvxa1i1d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b464a215da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:28:18.995301 47101525320576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:28:18.995530 47579673592704 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:28:19.000354 47101525320576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:28:19.000524 47579673592704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:28:19.020204 47579673592704 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:28:19.020287 47101525320576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875298.937203 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875298.937959 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875298.938655 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:28:19.042036 48008008995712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_0_0
:::MLL 1560875298.932408 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875298.933264 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875298.934160 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:28:19.042138 46914728350592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_0_0
W0618 10:28:19.043179 48008008995712 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpl55rjhgd
W0618 10:28:19.043213 46914728350592 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpuba6iwf5
I0618 10:28:19.044230 48008008995712 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpl55rjhgd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2baa04e8ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:28:19.044260 46914728350592 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpuba6iwf5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aab784e2dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:28:19.044715 48008008995712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:28:19.044721 46914728350592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:28:19.049948 46914728350592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:28:19.049978 48008008995712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875298.969603 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875298.970113 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875298.970520 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:28:19.052396 47254195233664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_0_0
:::MLL 1560875298.969037 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875298.969550 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875298.969996 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:28:19.052441 47118625633152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_0_0
W0618 10:28:19.053428 47254195233664 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp7lpp1k_4
W0618 10:28:19.053459 47118625633152 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpsvdyi1fo
I0618 10:28:19.054419 47254195233664 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp7lpp1k_4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afa821bae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:28:19.054423 47118625633152 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpsvdyi1fo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adaf187be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560875298.899632 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875298.900411 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875298.901108 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:28:19.054132 47337682432896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_0_0
I0618 10:28:19.054818 47118625633152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:28:19.054822 47254195233664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875298.902838 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875298.903573 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875298.904229 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:28:19.054348 47792516985728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_0_0
W0618 10:28:19.055285 47337682432896 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpllrpjago
W0618 10:28:19.055444 47792516985728 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpbb5b1z4m
I0618 10:28:19.056388 47337682432896 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpllrpjago', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0df2554e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:28:19.056564 47792516985728 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpbb5b1z4m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b77d895be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:28:19.056842 47337682432896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:28:19.057026 47792516985728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:28:19.059567 47254195233664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:28:19.059569 47118625633152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:28:19.062200 47337682432896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:28:19.062469 47792516985728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:28:19.068162 47101525320576 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:28:19.068346 47579673592704 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:28:19.070763 46914728350592 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:28:19.071321 48008008995712 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:28:19.072489 47101525320576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:28:19.072733 47579673592704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:28:19.077558 47101525320576 estimator.py:1111] Calling model_fn.
W0618 10:28:19.077683 47101525320576 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:28:19.077883 47579673592704 estimator.py:1111] Calling model_fn.
W0618 10:28:19.077993 47579673592704 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:28:19.078772 47118625633152 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:28:19.078994 47254195233664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:28:19.079044 47101525320576 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:28:19.079346 47579673592704 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560875298.963248 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875298.963978 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875298.964685 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:28:19.078908 47516463977344 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_0_0
:::MLL 1560875298.961053 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875298.961840 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875298.962582 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:28:19.079259 47152476992384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_0_0
W0618 10:28:19.080011 47516463977344 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpx0s_8mlw
I0618 10:28:19.081089 47516463977344 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpx0s_8mlw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b37928b1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:28:19.080360 47152476992384 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp0iun616p
I0618 10:28:19.081450 47152476992384 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp0iun616p', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae2d33a8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:28:19.081537 47516463977344 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:28:19.081895 47152476992384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:28:19.082765 47337682432896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:28:19.083099 47792516985728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875298.954911 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875298.955403 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875298.955827 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:28:19.084019 47836447978368 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_0_0
W0618 10:28:19.085049 47836447978368 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpy2zht41_
I0618 10:28:19.086050 47836447978368 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpy2zht41_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8213138e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560875298.960980 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875298.961380 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875298.961734 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:28:19.085999 47944752432000 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_0_0
I0618 10:28:19.086450 47836447978368 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:28:19.086762 47516463977344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:28:19.086976 47944752432000 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpluctlvwo
W0618 10:28:19.087012 47152476992384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:28:19.087947 47944752432000 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpluctlvwo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9b4a865da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:28:19.088341 47944752432000 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875299.008550 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875299.008970 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875299.009339 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:28:19.088995 47833449792384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_0_0
:::MLL 1560875298.999746 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875299.000298 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875299.000769 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:28:19.089060 47376544064384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_0_0
W0618 10:28:19.090029 47833449792384 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpwj25geqi
W0618 10:28:19.090057 47376544064384 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpojwb_r9z
I0618 10:28:19.091025 47833449792384 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpwj25geqi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b81605ede48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:28:19.091026 47376544064384 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpojwb_r9z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b16feaabe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:28:19.091423 47833449792384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:28:19.091425 47376544064384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:28:19.091215 47836447978368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:28:19.092937 47944752432000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875298.983854 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875298.984605 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875298.985327 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:28:19.095599 47222522844032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_0_0
:::MLL 1560875298.981905 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875298.982643 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875298.983451 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:28:19.095798 47415438353280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_0_0
W0618 10:28:19.096125 47833449792384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:28:19.096154 47376544064384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:28:19.096742 47222522844032 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp_8p125bj
W0618 10:28:19.096881 47415438353280 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp_336fq6d
I0618 10:28:19.097807 47222522844032 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp_8p125bj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af322496e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:28:19.097905 47415438353280 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp_336fq6d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b200cf24e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:28:19.098211 47222522844032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:28:19.098295 47415438353280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:28:19.102972 47415438353280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:28:19.102986 47222522844032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:28:19.108618 47516463977344 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:28:19.108783 47152476992384 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875298.986639 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875298.987330 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875298.988001 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:28:19.110193 47442879980416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_0_0
W0618 10:28:19.110579 47836447978368 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875298.981959 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875298.982900 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875298.983752 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:28:19.110783 47384532927360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_0_0
W0618 10:28:19.112044 47944752432000 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:28:19.111378 47442879980416 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb074/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2670986d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:28:19.112622 47442879980416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:28:19.111889 47384532927360 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp7370k9x7
I0618 10:28:19.112983 47384532927360 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp7370k9x7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b18dad71e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:28:19.113435 47384532927360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:28:19.115347 47833449792384 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:28:19.115535 47376544064384 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:28:19.118082 47442879980416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:28:19.118481 46914728350592 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:28:19.118821 47384532927360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:28:19.119184 48008008995712 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:28:19.122483 47415438353280 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:28:19.122784 46914728350592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:28:19.122750 47222522844032 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:28:19.123526 48008008995712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560875299.022931 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875299.023374 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875299.023751 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:28:19.122896 47844673975168 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_0_0
:::MLL 1560875299.022696 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875299.023135 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875299.023532 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:28:19.123069 47809767654272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000010-000004.tfrecord.zz_0_0
W0618 10:28:19.123913 47844673975168 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp2ljioizy
W0618 10:28:19.124040 47809767654272 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpg29x33rx
I0618 10:28:19.124895 47844673975168 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp2ljioizy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b83fd624e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:28:19.125017 47809767654272 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpg29x33rx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7bdcce0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:28:19.125291 47844673975168 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:28:19.125414 47809767654272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:28:19.126510 47118625633152 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:28:19.126838 47254195233664 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:28:19.127819 46914728350592 estimator.py:1111] Calling model_fn.
W0618 10:28:19.127931 46914728350592 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:28:19.128641 48008008995712 estimator.py:1111] Calling model_fn.
W0618 10:28:19.128751 48008008995712 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:28:19.129294 46914728350592 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:28:19.130138 48008008995712 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:28:19.130210 47337682432896 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:28:19.130290 47792516985728 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:28:19.130860 47118625633152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:28:19.129936 47844673975168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:28:19.130015 47809767654272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:28:19.131192 47254195233664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:28:19.134506 47337682432896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:28:19.134595 47792516985728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:28:19.135910 47118625633152 estimator.py:1111] Calling model_fn.
W0618 10:28:19.136017 47118625633152 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:28:19.136278 47254195233664 estimator.py:1111] Calling model_fn.
W0618 10:28:19.136390 47254195233664 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:28:19.137362 47118625633152 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:28:19.137766 47254195233664 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:28:19.139479 47442879980416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:28:19.139560 47337682432896 estimator.py:1111] Calling model_fn.
I0618 10:28:19.139631 47792516985728 estimator.py:1111] Calling model_fn.
W0618 10:28:19.139670 47337682432896 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:28:19.139737 47792516985728 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:28:19.140116 47384532927360 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:28:19.141024 47337682432896 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:28:19.141094 47792516985728 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops[2019-06-18 10:28:57] moving /lfs/lfs12/gma_akey/results/epb074/models/000020-000011.meta --> /lfs/lfs12/gma_akey/results/epb074/models/000020-000012.meta
[2019-06-18 10:28:57] moving /lfs/lfs12/gma_akey/results/epb074/models/000020-000011.index --> /lfs/lfs12/gma_akey/results/epb074/models/000020-000012.index
[2019-06-18 10:28:57] moving /lfs/lfs12/gma_akey/results/epb074/models/000020-000011.pb --> /lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb
[2019-06-18 10:28:57] moving /lfs/lfs12/gma_akey/results/epb074/models/000020-000011.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb074/models/000020-000012.data-00000-of-00001
[2019-06-18 10:28:57] iteration time 19: 47.887 seconds
2019-06-18 10:28:58.269298: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560875337.166131 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 20}}
[2019-06-18 10:29:01] minmax time: 3.240 seconds
2019-06-18 10:29:01.519819: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:29:01.525169: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:29:01.529744: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560875341.540372 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 19}}
[2019-06-18 10:29:01] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000021-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000021-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000021-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000021-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000021-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000021-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000021-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000021-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000021-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000021-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000021-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:29:01] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-21-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000020-000012 --seed=21 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000020-000012 --seed=1023779852 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000020-000012 --seed=2047559683 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000020-000012 --seed=3071339514 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000020-000012 --seed=4095119345 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000020-000012 --seed=5118899176 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000020-000012 --seed=6142679007 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000020-000012 --seed=7166458838 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000020-000012 --seed=8190238669 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000020-000012 --seed=9214018500 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000020-000012 --seed=10237798331 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000020-000012 --seed=11261578162 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000020-000012 --seed=12285357993 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000020-000012 --seed=13309137824 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000020-000012 --seed=14332917655 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000020-000012 --seed=15356697486 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000020-000012 --seed=16380477317 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000020-000012 --seed=17404257148 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000020-000012 --seed=18428036979 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000020-000012 --seed=19451816810 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000019-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000020-000012 --seed=20475596641 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:29:14] eval finished: 12.422 seconds
[2019-06-18 10:29:14] Win rate 000020-000012 vs 000019-000011: 0.500
:::MLL 1560875354.040144 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 19}}
[2019-06-18 10:29:14] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-22-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000021-000011 --seed=22 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000021-000011 --seed=1023779853 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000021-000011 --seed=2047559684 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000021-000011 --seed=3071339515 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000021-000011 --seed=4095119346 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000021-000011 --seed=5118899177 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000021-000011 --seed=6142679008 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000021-000011 --seed=7166458839 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000021-000011 --seed=8190238670 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000021-000011 --seed=9214018501 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000021-000011 --seed=10237798332 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000021-000011 --seed=11261578163 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000021-000011 --seed=12285357994 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000021-000011 --seed=13309137825 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000021-000011 --seed=14332917656 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000021-000011 --seed=15356697487 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000021-000011 --seed=16380477318 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000021-000011 --seed=17404257149 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000021-000011 --seed=18428036980 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:29:43] selfplay finished: 29.503 seconds
[2019-06-18 10:29:43] selfplay mn: 29.521 seconds
[2019-06-18 10:29:43] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-22-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779853 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559684 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339515 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119346 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899177 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142679008 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458839 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238670 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018501 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798332 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578163 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285357994 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137825 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917656 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697487 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477318 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257149 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036980 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816811 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596642 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376473 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156304 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000021-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golde
[2019-06-18 10:29:45] train finished: 43.616 seconds
:::MLL 1560875346.773698 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875346.774420 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875346.775108 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:06.873150 47520676107136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 10:29:06.874279 47520676107136 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp74wlyori
I0618 10:29:06.875394 47520676107136 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp74wlyori', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b388d9b1da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:06.875863 47520676107136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875346.771097 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875346.771799 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875346.772507 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:06.876381 47268580705152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 10:29:06.877591 47268580705152 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpg1xlv079
I0618 10:29:06.878804 47268580705152 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpg1xlv079', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afddb8c8e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:06.879243 47268580705152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:29:06.881245 47520676107136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:06.884869 47268580705152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875346.783173 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875346.784092 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875346.784943 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:06.890216 47735348740992 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560875346.796451 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875346.797202 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875346.797845 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:06.890322 47728739300224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 10:29:06.891335 47735348740992 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpjhifx1ti
W0618 10:29:06.891432 47728739300224 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmplxyi7ps5
I0618 10:29:06.892438 47735348740992 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpjhifx1ti', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6a89179e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:06.892538 47728739300224 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmplxyi7ps5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b68ff237e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:06.892890 47735348740992 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:29:06.892992 47728739300224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:29:06.898164 47735348740992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:06.898283 47728739300224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:06.903580 47520676107136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875346.785267 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875346.786021 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875346.786817 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:06.909115 47408766976896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560875346.786561 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875346.787384 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875346.788086 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:06.909122 47377100047232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 10:29:06.910166 47408766976896 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpb8gztz38
W0618 10:29:06.910473 47268580705152 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:06.910199 47377100047232 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpw2gx7ih3
I0618 10:29:06.911137 47408766976896 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpb8gztz38', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1e7f4d4e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:06.911185 47377100047232 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpw2gx7ih3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b171fce5e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:06.911543 47408766976896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:29:06.911590 47377100047232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:29:06.916448 47408766976896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:06.916466 47377100047232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:06.920047 47735348740992 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:06.920476 47728739300224 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875346.807360 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875346.808255 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875346.809078 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:06.928109 47376995693440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560875346.817631 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875346.818393 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875346.819027 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:06.928138 46924160983936 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560875346.843198 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875346.843629 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875346.844035 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:06.930443 47513480881024 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560875346.844141 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875346.844554 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875346.844930 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:06.930604 46979738596224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 10:29:06.929231 46924160983936 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpoosyy0a9
W0618 10:29:06.929264 47376995693440 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpeq99sfh2
I0618 10:29:06.930349 46924160983936 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpoosyy0a9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aadaa88be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:06.930349 47376995693440 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpeq99sfh2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1719960e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:06.930797 46924160983936 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:29:06.930802 47376995693440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:29:06.931587 47513480881024 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmptnnjtner
W0618 10:29:06.931723 46979738596224 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpgpmsnifa
I0618 10:29:06.932613 47513480881024 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmptnnjtner', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b36e0bcada0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:06.932737 46979738596224 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpgpmsnifa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aba9b37ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:06.933007 47513480881024 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:29:06.933134 46979738596224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:29:06.936038 47408766976896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:06.936242 47377100047232 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:06.936126 47376995693440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:06.936165 46924160983936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:06.937656 47513480881024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:06.937766 46979738596224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875346.839215 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875346.840173 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875346.841024 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:06.938338 47916566041472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560875346.850568 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875346.851303 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875346.852002 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:06.938516 47282576061312 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 10:29:06.939363 47916566041472 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp2s5zsuc4
:::MLL 1560875346.827535 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875346.828290 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875346.828957 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:06.939974 47895354893184 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 10:29:06.939502 47282576061312 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpon5m48o2
:::MLL 1560875346.816132 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875346.817046 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875346.817892 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:06.940110 47822729237376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_0_0
I0618 10:29:06.940444 47916566041472 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp2s5zsuc4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b94ba7c2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:06.940627 47282576061312 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpon5m48o2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b011dbcce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:06.940900 47916566041472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:29:06.941097 47282576061312 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:29:06.941148 47895354893184 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb074/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8fca33bd68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:29:06.941244 47822729237376 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmppfelt1o1
:::MLL 1560875346.861896 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875346.862363 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875346.862766 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:06.942277 47618321863552 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560875346.861800 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875346.862270 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875346.862671 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:06.942378 47827869012864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_0_0
I0618 10:29:06.942349 47822729237376 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmppfelt1o1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7ee1602e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:06.942416 47895354893184 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:29:06.942796 47822729237376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:29:06.943302 47618321863552 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpw6gvde5e
W0618 10:29:06.943372 47827869012864 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp_ula1wqr
I0618 10:29:06.944302 47618321863552 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpw6gvde5e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4f49bf1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:06.944360 47827869012864 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp_ula1wqr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8013bade48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:06.944705 47618321863552 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:29:06.944760 47827869012864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:29:06.945673 47916566041472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:06.945717 47282576061312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:06.947774 47895354893184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:06.948099 47822729237376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:06.949372 47618321863552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:06.949384 47827869012864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875346.834281 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875346.834827 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875346.835292 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:06.952824 47808591827840 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560875346.840388 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875346.840878 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875346.841277 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:06.952790 47458909741952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 10:29:06.953011 47520676107136 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:29:06.953839 47808591827840 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpfrud3lkp
W0618 10:29:06.953807 47458909741952 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp1nnhw7e9
I0618 10:29:06.954796 47458909741952 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp1nnhw7e9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2a2c0b3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:06.954812 47808591827840 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpfrud3lkp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7b96b86e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:06.955193 47458909741952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:29:06.955200 47808591827840 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:29:06.956932 47513480881024 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:06.957026 46979738596224 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:06.957336 47520676107136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:29:06.957862 46924160983936 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:06.957934 47376995693440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:06.959862 47808591827840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:06.959859 47458909741952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:29:06.962428 47520676107136 estimator.py:1111] Calling model_fn.
W0618 10:29:06.962538 47520676107136 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:29:06.963756 47268580705152 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:29:06.963922 47520676107136 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:29:06.964971 47916566041472 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:06.965318 47282576061312 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:06.968455 47618321863552 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:06.968627 47827869012864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:06.968558 47268580705152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:29:06.969058 47735348740992 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:29:06.969756 47728739300224 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:29:06.969834 47895354893184 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:06.970346 47822729237376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:06.973372 47735348740992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:29:06.974101 47728739300224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:29:06.974378 47268580705152 estimator.py:1111] Calling model_fn.
W0618 10:29:06.974501 47268580705152 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560875346.877759 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875346.878160 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875346.878516 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:06.973910 47427461825408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560875346.874064 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875346.874543 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875346.874968 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:06.973969 47980771492736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 10:29:06.975916 47268580705152 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:29:06.974927 47427461825408 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp7g9z4l1g
W0618 10:29:06.974954 47980771492736 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpy12djo9r
I0618 10:29:06.975920 47427461825408 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp7g9z4l1g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b22d99a1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:06.975924 47980771492736 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpy12djo9r', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba3ad6d9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:06.976313 47980771492736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:29:06.976316 47427461825408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:29:06.978418 47735348740992 estimator.py:1111] Calling model_fn.
W0618 10:29:06.978527 47735348740992 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:29:06.978957 47808591827840 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:06.978971 47458909741952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:29:06.979208 47728739300224 estimator.py:1111] Calling model_fn.
W0618 10:29:06.979322 47728739300224 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:29:06.979882 47735348740992 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:29:06.980702 47728739300224 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:29:06.980967 47427461825408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:06.980971 47980771492736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:06.983808 47408766976896 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:29:06.984330 47377100047232 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560875346.892292 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875346.892747 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875346.893111 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:06.986454 47176750842752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560875346.890902 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875346.891330 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875346.891837 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:06.986603 47391227847552 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 10:29:06.988092 47408766976896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:29:06.988660 47377100047232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:29:06.987450 47176750842752 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp78e3q6hw
W0618 10:29:06.987590 47391227847552 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp8ljwmcj9
I0618 10:29:06.988432 47176750842752 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp78e3q6hw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae87a100e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:06.988583 47391227847552 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp8ljwmcj9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1a69e37e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:06.988829 47176750842752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:29:06.988981 47391227847552 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:29:06.993150 47408766976896 estimator.py:1111] Calling model_fn.
W0618 10:29:06.993260 47408766976896 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:29:06.993731 47377100047232 estimator.py:1111] Calling model_fn.
W0618 10:29:06.993840 47377100047232 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:29:06.993411 47176750842752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:06.993607 47391227847552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:06.994625 47408766976896 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:29:06.995206 47377100047232 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for [2019-06-18 10:29:46] divide_golden_chunk finished: 3.253 seconds
[2019-06-18 10:29:46] generate golden chunk: 3.267 seconds
[2019-06-18 10:29:46] moving /lfs/lfs12/gma_akey/results/epb074/models/000021-000012.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb074/models/000021-000013.data-00000-of-00001
[2019-06-18 10:29:46] moving /lfs/lfs12/gma_akey/results/epb074/models/000021-000012.index --> /lfs/lfs12/gma_akey/results/epb074/models/000021-000013.index
[2019-06-18 10:29:46] moving /lfs/lfs12/gma_akey/results/epb074/models/000021-000012.pb --> /lfs/lfs12/gma_akey/results/epb074/models/000021-000013.pb
[2019-06-18 10:29:46] moving /lfs/lfs12/gma_akey/results/epb074/models/000021-000012.meta --> /lfs/lfs12/gma_akey/results/epb074/models/000021-000013.meta
[2019-06-18 10:29:46] iteration time 20: 49.704 seconds
2019-06-18 10:29:48.029457: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560875386.870739 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 21}}
[2019-06-18 10:29:51] minmax time: 3.269 seconds
2019-06-18 10:29:51.308548: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:29:51.314063: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:29:51.318671: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560875391.329521 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 20}}
[2019-06-18 10:29:51] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000022-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000022-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000022-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000022-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000022-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000022-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000022-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000022-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000022-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000022-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000022-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:29:51] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-22-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000021-000013 --seed=22 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000021-000013 --seed=1023779853 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000021-000013 --seed=2047559684 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000021-000013 --seed=3071339515 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000021-000013 --seed=4095119346 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000021-000013 --seed=5118899177 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000021-000013 --seed=6142679008 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000021-000013 --seed=7166458839 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000021-000013 --seed=8190238670 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000021-000013 --seed=9214018501 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000021-000013 --seed=10237798332 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000021-000013 --seed=11261578163 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000021-000013 --seed=12285357994 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000021-000013 --seed=13309137825 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000021-000013 --seed=14332917656 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000021-000013 --seed=15356697487 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000021-000013 --seed=16380477318 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000021-000013 --seed=17404257149 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000021-000013 --seed=18428036980 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000021-000013 --seed=19451816811 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000021-000013 --seed=20475596642 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:30:02] eval finished: 11.260 seconds
[2019-06-18 10:30:02] Win rate 000021-000013 vs 000020-000012: 0.460
:::MLL 1560875402.668347 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 20}}
[2019-06-18 10:30:02] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-23-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000022-000012 --seed=23 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000022-000012 --seed=1023779854 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000022-000012 --seed=2047559685 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000022-000012 --seed=3071339516 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000022-000012 --seed=4095119347 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000022-000012 --seed=5118899178 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000022-000012 --seed=6142679009 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000022-000012 --seed=7166458840 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000022-000012 --seed=8190238671 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000022-000012 --seed=9214018502 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000022-000012 --seed=10237798333 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000022-000012 --seed=11261578164 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000022-000012 --seed=12285357995 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000022-000012 --seed=13309137826 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000022-000012 --seed=14332917657 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000022-000012 --seed=15356697488 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000022-000012 --seed=16380477319 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000022-000012 --seed=17404257150 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000022-000012 --seed=18428036981 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:30:32] selfplay finished: 29.509 seconds
[2019-06-18 10:30:32] selfplay mn: 29.527 seconds
[2019-06-18 10:30:32] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-23-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=23 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779854 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559685 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339516 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119347 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899178 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142679009 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458840 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238671 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018502 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798333 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578164 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285357995 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137826 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917657 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697488 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477319 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257150 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036981 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816812 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596643 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376474 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156305 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golde
[2019-06-18 10:30:35] train finished: 44.129 seconds
:::MLL 1560875396.602129 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875396.602875 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875396.603703 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:56.707892 47526604145536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_0_0
:::MLL 1560875396.603801 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875396.604551 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875396.605227 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:56.707963 47507527324544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_0_0
W0618 10:29:56.708996 47526604145536 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmps20hei2t
W0618 10:29:56.709066 47507527324544 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp30ao41tw
I0618 10:29:56.710115 47526604145536 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmps20hei2t', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b39eef1de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:56.710186 47507527324544 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp30ao41tw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b357de0ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:56.710566 47526604145536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:29:56.710633 47507527324544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:29:56.715872 47507527324544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:56.715879 47526604145536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:56.737802 47526604145536 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:56.737893 47507527324544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875396.631479 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875396.632383 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875396.633255 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:56.744860 47570663236480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_0_0
:::MLL 1560875396.647203 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875396.647961 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875396.648621 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:56.745064 47957767721856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_0_0
W0618 10:29:56.745949 47570663236480 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpyog9u02u
W0618 10:29:56.746147 47957767721856 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpwmb38p38
I0618 10:29:56.747040 47570663236480 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpyog9u02u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4431122e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:56.747267 47957767721856 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpwmb38p38', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9e524bde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:56.747489 47570663236480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:29:56.747709 47957767721856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:29:56.752721 47570663236480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:56.753116 47957767721856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875396.603445 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875396.604335 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875396.605166 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:56.758626 47994446582656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_0_0
:::MLL 1560875396.615071 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875396.615760 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875396.616404 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:56.760076 47383909737344 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_0_0
W0618 10:29:56.759790 47994446582656 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpz02xr6e8
I0618 10:29:56.760926 47994446582656 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpz02xr6e8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba6dc86ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:56.761395 47994446582656 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:29:56.761146 47383909737344 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp1qvf55pw
I0618 10:29:56.762237 47383909737344 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp1qvf55pw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b18b5b1edd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560875396.662973 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875396.663707 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875396.664412 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:56.761900 46944750793600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_0_0
:::MLL 1560875396.657506 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875396.658438 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875396.659270 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:56.761996 47985418650496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_0_0
I0618 10:29:56.762675 47383909737344 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:29:56.762968 46944750793600 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp9u3o_g2e
W0618 10:29:56.763001 47985418650496 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpt8ji7fbv
I0618 10:29:56.763971 46944750793600 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp9u3o_g2e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab275c84e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:56.763997 47985418650496 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpt8ji7fbv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba4c26b8dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:56.764370 46944750793600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:29:56.764390 47985418650496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:29:56.766744 47994446582656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:56.767769 47383909737344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:56.769262 47985418650496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:56.769269 46944750793600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875396.685426 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875396.685933 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875396.686307 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:56.773064 47195387577216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_0_0
:::MLL 1560875396.692755 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875396.693415 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875396.693756 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:56.773197 47795047740288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_0_0
W0618 10:29:56.774095 47195387577216 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp5c8thn7i
W0618 10:29:56.774174 47795047740288 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpzhk7rty_
I0618 10:29:56.775083 47195387577216 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp5c8thn7i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aecd0e60e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:56.775160 47795047740288 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpzhk7rty_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b786f6e0da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:29:56.774497 47570663236480 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:29:56.775487 47195387577216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:29:56.775563 47795047740288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:29:56.775676 47957767721856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:56.780137 47195387577216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:56.780200 47795047740288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875396.682927 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875396.683642 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875396.684273 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:56.782003 46987767559040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_0_0
:::MLL 1560875396.677524 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875396.678445 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875396.679294 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:56.782167 47500770874240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_0_0
I0618 10:29:56.783104 46987767559040 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb074/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abc79c80cf8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:29:56.783240 47500770874240 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmprx2seh_u
I0618 10:29:56.784283 47500770874240 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmprx2seh_u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b33eb295e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:56.784348 46987767559040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:29:56.784727 47500770874240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:29:56.788697 47994446582656 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:56.788587 46944750793600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:56.788643 47985418650496 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:56.789318 47383909737344 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:56.789805 46987767559040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:56.790046 47526604145536 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:29:56.790112 47507527324544 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:29:56.790111 47500770874240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:56.794719 47526604145536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:29:56.794770 47507527324544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560875396.670219 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875396.670700 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875396.671135 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:56.798455 47645548540800 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_0_0
W0618 10:29:56.799187 47195387577216 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:56.799368 47795047740288 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875396.670206 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875396.670685 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875396.671112 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:56.799874 47605897896832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_0_0
W0618 10:29:56.799494 47645548540800 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpf0bag_a1
I0618 10:29:56.800493 47645548540800 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpf0bag_a1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b55a0953e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:56.800186 47526604145536 estimator.py:1111] Calling model_fn.
:::MLL 1560875396.715423 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875396.715932 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875396.716370 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:56.799199 47512979800960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_0_0
I0618 10:29:56.800220 47507527324544 estimator.py:1111] Calling model_fn.
:::MLL 1560875396.720737 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875396.721161 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875396.721522 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:56.799373 47221193413504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_0_0
W0618 10:29:56.800305 47526604145536 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:29:56.800332 47507527324544 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:29:56.800899 47645548540800 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:29:56.800833 47605897896832 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpqp4qr75c
I0618 10:29:56.801805 47605897896832 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpqp4qr75c', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4c65387e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:29:56.800203 47512979800960 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp057wic6k
W0618 10:29:56.801795 47507527324544 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:29:56.800361 47221193413504 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpojzo2jy_
I0618 10:29:56.802206 47605897896832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:29:56.801753 47526604145536 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:29:56.801196 47512979800960 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp057wic6k', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b36c2dede48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:56.801338 47221193413504 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpojzo2jy_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af2d30bee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:56.801592 47512979800960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:29:56.801729 47221193413504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:29:56.805566 47645548540800 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:56.806723 47605897896832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:56.806186 47512979800960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:56.806340 47221193413504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875396.621113 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875396.621978 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875396.622799 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:56.808333 47551991186304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_0_0
W0618 10:29:56.809361 47551991186304 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpw80d52gq
I0618 10:29:56.810351 47551991186304 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpw80d52gq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3fd8215e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:56.810762 47551991186304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:29:56.811132 46987767559040 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:56.811200 47500770874240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:56.815689 47551991186304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875396.621570 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875396.622430 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875396.623162 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:56.817402 47823507526528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_0_0
:::MLL 1560875396.729553 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875396.730065 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875396.730537 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:56.817234 47812882776960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_0_0
:::MLL 1560875396.729994 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875396.730519 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875396.730932 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:56.817274 47616613921664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_0_0
W0618 10:29:56.818388 47823507526528 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp0074zuzj
I0618 10:29:56.819362 47823507526528 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp0074zuzj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7f0fc3dda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:29:56.818298 47616613921664 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpfcq8aroq
W0618 10:29:56.818328 47812882776960 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpdstqi4oe
I0618 10:29:56.819285 47616613921664 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpfcq8aroq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4ee3f20e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:56.819311 47812882776960 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpdstqi4oe', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7c967b0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:56.819764 47823507526528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:29:56.819682 47616613921664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:29:56.819705 47812882776960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:29:56.824248 47823507526528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:56.824615 47645548540800 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:56.824292 47812882776960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:56.824300 47616613921664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:29:56.823847 47570663236480 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:29:56.825907 47605897896832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:56.825093 47512979800960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:56.825383 47957767721856 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:29:56.825519 47221193413504 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:56.828119 47570663236480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:29:56.829803 47957767721856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:29:56.833233 47570663236480 estimator.py:1111] Calling model_fn.
W0618 10:29:56.833339 47570663236480 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:29:56.835153 47551991186304 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:29:56.834681 47570663236480 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:29:56.834868 47957767721856 estimator.py:1111] Calling model_fn.
W0618 10:29:56.834974 47957767721856 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:29:56.836623 47994446582656 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:29:56.836783 47383909737344 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:29:56.836753 46944750793600 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560875396.749680 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875396.750114 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875396.750485 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:56.836899 47741144716160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_0_0
W0618 10:29:56.837219 47985418650496 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:29:56.836345 47957767721856 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560875396.748764 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875396.749207 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875396.749728 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:56.837007 47377575125888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_0_0
W0618 10:29:56.837907 47741144716160 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpxsh8dfut
W0618 10:29:56.837991 47377575125888 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpz6zf4z5q
I0618 10:29:56.838912 47741144716160 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpxsh8dfut', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6be28f2e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:56.838958 47377575125888 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpz6zf4z5q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b173c1f7e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:29:56.839313 47741144716160 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:29:56.839346 47377575125888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875396.663446 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875396.664041 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875396.664543 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:56.840615 47436400010112 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_0_0
:::MLL 1560875396.671293 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875396.671769 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875396.672198 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:29:56.840639 47759636128640 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000012-000005.tfrecord.zz_0_0
W0618 10:29:56.840919 47994446582656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:29:56.841092 47383909737344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, yo[2019-06-18 10:30:35] divide_golden_chunk finished: 3.327 seconds
[2019-06-18 10:30:35] generate golden chunk: 3.341 seconds
[2019-06-18 10:30:35] iteration time 21: 48.667 seconds
2019-06-18 10:30:36.788028: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560875435.538308 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 22}}
[2019-06-18 10:30:40] minmax time: 3.255 seconds
2019-06-18 10:30:40.053285: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:30:40.058824: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:30:40.063481: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560875440.076425 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 21}}
[2019-06-18 10:30:40] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000023-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000023-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000023-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000023-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000023-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000023-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000023-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000023-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000023-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000023-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000023-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:30:40] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-23-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000022-000013 --seed=23 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000022-000013 --seed=1023779854 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000022-000013 --seed=2047559685 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000022-000013 --seed=3071339516 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000022-000013 --seed=4095119347 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000022-000013 --seed=5118899178 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000022-000013 --seed=6142679009 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000022-000013 --seed=7166458840 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000022-000013 --seed=8190238671 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000022-000013 --seed=9214018502 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000022-000013 --seed=10237798333 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000022-000013 --seed=11261578164 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000022-000013 --seed=12285357995 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000022-000013 --seed=13309137826 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000022-000013 --seed=14332917657 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000022-000013 --seed=15356697488 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000022-000013 --seed=16380477319 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000022-000013 --seed=17404257150 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000022-000013 --seed=18428036981 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000022-000013 --seed=19451816812 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000020-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000022-000013 --seed=20475596643 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:30:50] eval finished: 10.636 seconds
[2019-06-18 10:30:50] Win rate 000022-000013 vs 000020-000012: 0.620
:::MLL 1560875450.792658 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 21}}
[2019-06-18 10:30:50] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-24-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000023-000012 --seed=24 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000023-000012 --seed=1023779855 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000023-000012 --seed=2047559686 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000023-000012 --seed=3071339517 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000023-000012 --seed=4095119348 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000023-000012 --seed=5118899179 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000023-000012 --seed=6142679010 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000023-000012 --seed=7166458841 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000023-000012 --seed=8190238672 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000023-000012 --seed=9214018503 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000023-000012 --seed=10237798334 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000023-000012 --seed=11261578165 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000023-000012 --seed=12285357996 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000023-000012 --seed=13309137827 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000023-000012 --seed=14332917658 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000023-000012 --seed=15356697489 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000023-000012 --seed=16380477320 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000023-000012 --seed=17404257151 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000023-000012 --seed=18428036982 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:31:20] selfplay finished: 29.647 seconds
[2019-06-18 10:31:20] selfplay mn: 29.668 seconds
[2019-06-18 10:31:20] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-24-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=24 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779855 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559686 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339517 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119348 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899179 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142679010 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458841 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238672 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018503 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798334 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578165 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285357996 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137827 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917658 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697489 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477320 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257151 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036982 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816813 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596644 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376475 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156306 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000023-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golde
[2019-06-18 10:31:23] divide_golden_chunk finished: 3.330 seconds
[2019-06-18 10:31:23] generate golden chunk: 3.343 seconds
[2019-06-18 10:31:24] train finished: 44.203 seconds
:::MLL 1560875445.322911 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875445.323790 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875445.324634 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:30:45.428686 48009323574144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_0_0
:::MLL 1560875445.336483 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875445.337229 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875445.337819 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:30:45.428850 47546984498048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_0_0
W0618 10:30:45.429689 48009323574144 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpfj3yfi6_
W0618 10:30:45.429837 47546984498048 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmphxgpg_bl
I0618 10:30:45.430653 48009323574144 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpfj3yfi6_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2baa5343be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:30:45.430794 47546984498048 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmphxgpg_bl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3eadb54e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:30:45.431053 48009323574144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:30:45.431187 47546984498048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:30:45.435773 48009323574144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:30:45.435787 47546984498048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:30:45.454954 48009323574144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:30:45.455140 47546984498048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875445.377593 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875445.378431 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875445.379088 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:30:45.485689 47466563998592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_0_0
:::MLL 1560875445.376578 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875445.377457 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875445.378250 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:30:45.485750 47330075218816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_0_0
W0618 10:30:45.486838 47466563998592 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpavxv1g8b
W0618 10:30:45.486871 47330075218816 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpdkbukup2
I0618 10:30:45.487949 47466563998592 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpavxv1g8b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2bf445ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:30:45.487962 47330075218816 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpdkbukup2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0c2ce86e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:30:45.488398 47466563998592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:30:45.488405 47330075218816 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:30:45.493882 47466563998592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:30:45.493930 47330075218816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875445.393591 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875445.394353 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875445.395146 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:30:45.493515 47852630008704 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_0_0
W0618 10:30:45.494665 47852630008704 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp2t05cvaf
I0618 10:30:45.495810 47852630008704 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp2t05cvaf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b85d799bdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:30:45.496282 47852630008704 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:30:45.501658 47852630008704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:30:45.502987 47546984498048 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:30:45.503206 48009323574144 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:30:45.507289 47546984498048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:30:45.507555 48009323574144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560875445.395007 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875445.395756 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875445.396463 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:30:45.508101 47714328757120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_0_0
W0618 10:30:45.509180 47714328757120 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp371a88lc
I0618 10:30:45.510292 47714328757120 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp371a88lc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b65a4341dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:30:45.510727 47714328757120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:30:45.512463 47546984498048 estimator.py:1111] Calling model_fn.
W0618 10:30:45.512573 47546984498048 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:30:45.512722 48009323574144 estimator.py:1111] Calling model_fn.
W0618 10:30:45.512828 48009323574144 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560875445.405675 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875445.406213 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875445.406684 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:30:45.513434 47858251338624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_0_0
W0618 10:30:45.513931 47546984498048 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:30:45.514189 48009323574144 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:30:45.514507 47858251338624 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpghc88fj1
I0618 10:30:45.515487 47858251338624 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpghc88fj1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8726a86e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:30:45.515885 47858251338624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:30:45.515713 47466563998592 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:30:45.516232 47330075218816 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:30:45.515787 47714328757120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875445.411520 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875445.411948 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875445.412315 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:30:45.517451 47574576718720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_0_0
W0618 10:30:45.518452 47574576718720 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp2rdytd4_
I0618 10:30:45.519438 47574576718720 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp2rdytd4_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b451a552e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:30:45.519846 47574576718720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875445.403148 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875445.404067 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875445.404889 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:30:45.519724 47471155577728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_0_0
W0618 10:30:45.520514 47858251338624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875445.410496 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875445.411238 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875445.411948 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:30:45.519936 47270577353600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_0_0
W0618 10:30:45.520856 47471155577728 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpu9__grgz
I0618 10:30:45.521066 47270577353600 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb074/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afe528f0d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:30:45.521928 47471155577728 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpu9__grgz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2d05f3de80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:30:45.522317 47270577353600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:30:45.522372 47471155577728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:30:45.524407 47574576718720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:30:45.523744 47852630008704 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:30:45.527672 47270577353600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:30:45.527679 47471155577728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875445.421163 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875445.421893 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875445.422573 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:30:45.536107 47038806885248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_0_0
:::MLL 1560875445.417946 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875445.418742 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875445.419453 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:30:45.536145 46912895484800 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_0_0
W0618 10:30:45.537247 47038806885248 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp6x2osesh
W0618 10:30:45.537360 46912895484800 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpkv5tlx6a
I0618 10:30:45.538286 47038806885248 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp6x2osesh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac85bf65e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:30:45.538380 46912895484800 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpkv5tlx6a', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aab0b0ede48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:30:45.537777 47714328757120 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:30:45.538681 47038806885248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:30:45.538783 46912895484800 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:30:45.539679 47858251338624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875445.449445 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875445.449936 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875445.450366 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:30:45.539948 47466078565248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_0_0
:::MLL 1560875445.453990 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875445.454404 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875445.454771 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:30:45.540054 46945462342528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_0_0
W0618 10:30:45.540988 47466078565248 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpnbs_1cv1
W0618 10:30:45.541032 46945462342528 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpa7u7pi5c
I0618 10:30:45.541978 47466078565248 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpnbs_1cv1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2bd756ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:30:45.542029 46945462342528 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpa7u7pi5c', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab2a0319e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:30:45.542383 47466078565248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:30:45.542425 46945462342528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:30:45.543494 47574576718720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:30:45.543390 47038806885248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:30:45.543423 46912895484800 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:30:45.547068 47466078565248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:30:45.547091 46945462342528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:30:45.549549 47471155577728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:30:45.549866 47270577353600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875445.471737 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875445.472238 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875445.472683 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:30:45.560780 47656527868800 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_0_0
:::MLL 1560875445.476377 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875445.476826 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875445.477341 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:30:45.560760 47248491291520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_0_0
W0618 10:30:45.562873 47038806885248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:30:45.562884 46912895484800 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:30:45.561814 47248491291520 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpwgpcxu4_
W0618 10:30:45.561843 47656527868800 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmptck4i21t
I0618 10:30:45.562816 47248491291520 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpwgpcxu4_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af92e205e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:30:45.562909 47656527868800 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmptck4i21t', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b582f008e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:30:45.563224 47248491291520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:30:45.563311 47656527868800 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:30:45.565069 47330075218816 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:30:45.565072 47466563998592 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:30:45.566198 47466078565248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:30:45.566375 46945462342528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:30:45.567919 47248491291520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:30:45.567986 47656527868800 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:30:45.569362 47330075218816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:30:45.569363 47466563998592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560875445.469971 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875445.470376 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875445.470736 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:30:45.571139 47503064011648 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_0_0
:::MLL 1560875445.472120 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875445.472552 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875445.472916 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:30:45.571128 47754670363520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_0_0
W0618 10:30:45.572252 47503064011648 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp_7_5i86b
W0618 10:30:45.572223 47754670363520 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp3m33kf1n
I0618 10:30:45.573217 47754670363520 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp3m33kf1n', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6f08c02e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:30:45.573240 47503064011648 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp_7_5i86b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3473d7ee80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:30:45.573622 47754670363520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:30:45.573641 47503064011648 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:30:45.574477 47330075218816 estimator.py:1111] Calling model_fn.
I0618 10:30:45.574509 47466563998592 estimator.py:1111] Calling model_fn.
W0618 10:30:45.574592 47330075218816 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:30:45.574622 47466563998592 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:30:45.574700 47852630008704 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:30:45.575955 47330075218816 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:30:45.575975 47466563998592 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:30:45.578262 47503064011648 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:30:45.578261 47754670363520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:30:45.579061 47852630008704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:30:45.584169 47852630008704 estimator.py:1111] Calling model_fn.
W0618 10:30:45.584281 47852630008704 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:30:45.585671 47852630008704 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:30:45.586092 47714328757120 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:30:45.587317 47858251338624 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:30:45.587136 47248491291520 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:30:45.587419 47656527868800 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:30:45.590672 47574576718720 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560875445.499188 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875445.499655 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875445.500061 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:30:45.590906 47958073095040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_0_0
:::MLL 1560875445.498187 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875445.498682 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875445.499147 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:30:45.590960 47203996324736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000013-000006.tfrecord.zz_0_0
W0618 10:30:45.590392 47714328757120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:30:45.591653 47858251338624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:30:45.591938 47958073095040 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpsvtk_x7c
W0618 10:30:45.591968 47203996324736 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpeluox1kx
I0618 10:30:45.592912 47958073095040 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpsvtk_x7c', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9e647f7dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:30:45.592933 47203996324736 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpeluox1kx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeed2051e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:30:45.593309 47958073095040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:30:45.593328 47203996324736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:30:45.595045 47574576718720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:30:45.595503 47714328757120 estimator.py:1111] Calling model_fn.
W0618 10:30:45.595617 47714328757120 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:30:45.596816 47858251338624 estimator.py:1111] Calling model_fn.
W0618 10:30:45.596926 47858251338624 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:30:45.597312 47503064011648 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:30:45.597273 47754670363520 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:30:45.597049 47714328757120 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:30:45.598287 47858251338624 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:30:45.597956 47958073095040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:30:45.597970 47203996324736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:30:45.600085 47574576718720 estimator.py:1111] Calling model_fn.
W0618 10:30:45.600193 47574576718720 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:30:45.600131 47471155577728 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will[2019-06-18 10:31:24] moving /lfs/lfs12/gma_akey/results/epb074/models/000023-000013.meta --> /lfs/lfs12/gma_akey/results/epb074/models/000023-000014.meta
[2019-06-18 10:31:24] moving /lfs/lfs12/gma_akey/results/epb074/models/000023-000013.pb --> /lfs/lfs12/gma_akey/results/epb074/models/000023-000014.pb
[2019-06-18 10:31:24] moving /lfs/lfs12/gma_akey/results/epb074/models/000023-000013.index --> /lfs/lfs12/gma_akey/results/epb074/models/000023-000014.index
[2019-06-18 10:31:24] moving /lfs/lfs12/gma_akey/results/epb074/models/000023-000013.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb074/models/000023-000014.data-00000-of-00001
[2019-06-18 10:31:24] iteration time 22: 48.811 seconds
2019-06-18 10:31:25.624506: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560875484.349337 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 23}}
[2019-06-18 10:31:28] minmax time: 3.351 seconds
2019-06-18 10:31:28.985299: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:31:28.990764: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:31:28.995422: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560875489.006293 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 22}}
[2019-06-18 10:31:29] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000024-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000024-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000024-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000024-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000024-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000024-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000024-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000024-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000024-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000024-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000024-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:31:29] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-24-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000023-000014 --seed=24 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000023-000014 --seed=1023779855 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000023-000014 --seed=2047559686 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000023-000014 --seed=3071339517 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000023-000014 --seed=4095119348 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000023-000014 --seed=5118899179 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000023-000014 --seed=6142679010 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000023-000014 --seed=7166458841 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000023-000014 --seed=8190238672 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000023-000014 --seed=9214018503 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000023-000014 --seed=10237798334 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000023-000014 --seed=11261578165 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000023-000014 --seed=12285357996 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000023-000014 --seed=13309137827 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000023-000014 --seed=14332917658 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000023-000014 --seed=15356697489 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000023-000014 --seed=16380477320 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000023-000014 --seed=17404257151 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000023-000014 --seed=18428036982 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000023-000014 --seed=19451816813 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000023-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000023-000014 --seed=20475596644 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:31:41] eval finished: 11.948 seconds
[2019-06-18 10:31:41] Win rate 000023-000014 vs 000022-000013: 0.360
:::MLL 1560875501.034478 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 22}}
[2019-06-18 10:31:41] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-25-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000024-000013 --seed=25 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000024-000013 --seed=1023779856 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000024-000013 --seed=2047559687 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000024-000013 --seed=3071339518 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000024-000013 --seed=4095119349 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000024-000013 --seed=5118899180 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000024-000013 --seed=6142679011 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000024-000013 --seed=7166458842 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000024-000013 --seed=8190238673 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000024-000013 --seed=9214018504 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000024-000013 --seed=10237798335 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000024-000013 --seed=11261578166 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000024-000013 --seed=12285357997 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000024-000013 --seed=13309137828 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000024-000013 --seed=14332917659 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000024-000013 --seed=15356697490 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000024-000013 --seed=16380477321 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000024-000013 --seed=17404257152 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000024-000013 --seed=18428036983 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:32:10] selfplay finished: 29.521 seconds
[2019-06-18 10:32:10] selfplay mn: 29.541 seconds
[2019-06-18 10:32:10] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-25-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=25 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779856 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559687 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339518 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119349 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899180 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142679011 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458842 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238673 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018504 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798335 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578166 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285357997 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137828 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917659 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697490 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477321 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257152 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036983 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816814 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596645 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376476 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156307 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000024-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golde
[2019-06-18 10:32:13] train finished: 44.031 seconds
:::MLL 1560875494.239871 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875494.240732 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875494.241618 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:31:34.349145 47044069995392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_0_0
:::MLL 1560875494.252807 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875494.253481 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875494.254152 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:31:34.349216 47531179426688 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_0_0
W0618 10:31:34.350257 47044069995392 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpsrqt98uv
W0618 10:31:34.350322 47531179426688 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpb7mkg_hr
I0618 10:31:34.351339 47044069995392 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpsrqt98uv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac995aafe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:31:34.351402 47531179426688 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpb7mkg_hr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3affa71da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:31:34.351787 47044069995392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:31:34.351843 47531179426688 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:31:34.357123 47044069995392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:31:34.357142 47531179426688 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875494.274148 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875494.274911 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875494.275585 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:31:34.371014 47471507641216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_0_0
:::MLL 1560875494.261851 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875494.262771 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875494.263624 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:31:34.371438 47683678937984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_0_0
W0618 10:31:34.372045 47471507641216 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp2j9b_rt_
I0618 10:31:34.373051 47471507641216 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp2j9b_rt_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2d1aefde10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:31:34.372430 47683678937984 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpzdo2gk_w
I0618 10:31:34.373414 47683678937984 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpzdo2gk_w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5e8154fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:31:34.373468 47471507641216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:31:34.373808 47683678937984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:31:34.378319 47471507641216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:31:34.378535 47683678937984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:31:34.379015 47044069995392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:31:34.379387 47531179426688 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:31:34.397771 47471507641216 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:31:34.397929 47683678937984 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875494.327434 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875494.327813 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875494.328132 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:31:34.411293 47121975657344 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_0_0
:::MLL 1560875494.325895 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875494.326272 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875494.326610 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:31:34.411650 47922173281152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_0_0
W0618 10:31:34.412324 47121975657344 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmps4cb1wco
I0618 10:31:34.413322 47121975657344 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmps4cb1wco', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adbb9351e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:31:34.412634 47922173281152 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpwrfnsi9g
I0618 10:31:34.413597 47922173281152 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpwrfnsi9g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9608b3dda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:31:34.413736 47121975657344 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:31:34.413999 47922173281152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:31:34.418351 47121975657344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:31:34.418524 47922173281152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875494.291722 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875494.292571 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875494.293409 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:31:34.425071 47748780405632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_0_0
:::MLL 1560875494.292991 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875494.293797 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875494.294492 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:31:34.425283 47546328494976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_0_0
W0618 10:31:34.426170 47748780405632 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpf8esvtiw
W0618 10:31:34.426370 47546328494976 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpbfz3ujt6
I0618 10:31:34.427262 47748780405632 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpf8esvtiw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6da9ae7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:31:34.427446 47546328494976 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpbfz3ujt6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3e869b8dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:31:34.427703 47748780405632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:31:34.427938 47546328494976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875494.326411 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875494.326952 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875494.327447 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:31:34.429505 47470661071744 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_0_0
W0618 10:31:34.429368 47044069995392 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:31:34.429632 47531179426688 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560875494.337985 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875494.338488 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875494.338947 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:31:34.430501 47412257059712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_0_0
W0618 10:31:34.430523 47470661071744 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpfpwbkanp
I0618 10:31:34.431490 47470661071744 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpfpwbkanp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2ce87a4e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:31:34.431893 47470661071744 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:31:34.431478 47412257059712 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp0i_21n3b
I0618 10:31:34.432461 47412257059712 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp0i_21n3b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1f4f53ada0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:31:34.432869 47412257059712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875494.281245 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875494.281917 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875494.282739 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:31:34.432860 46945394627456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_0_0
:::MLL 1560875494.282866 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875494.283579 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875494.284216 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:31:34.433023 47126545036160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_0_0
W0618 10:31:34.432917 47748780405632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:31:34.433666 47044069995392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:31:34.433131 47546328494976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:31:34.433970 47531179426688 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:31:34.434021 46945394627456 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpyvkhr25b
W0618 10:31:34.434084 47126545036160 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpyafy5705
I0618 10:31:34.435124 46945394627456 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpyvkhr25b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab29c286e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:31:34.435163 47126545036160 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpyafy5705', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adcc9904e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:31:34.435579 46945394627456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:31:34.435599 47126545036160 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:31:34.436501 47470661071744 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:31:34.437417 47412257059712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:31:34.437379 47121975657344 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:31:34.437545 47922173281152 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875494.331090 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875494.331880 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875494.332587 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:31:34.437420 47409864184704 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_0_0
:::MLL 1560875494.329175 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875494.329920 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875494.330723 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:31:34.437673 47508372693888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_0_0
I0618 10:31:34.438762 47044069995392 estimator.py:1111] Calling model_fn.
W0618 10:31:34.438874 47044069995392 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:31:34.439102 47531179426688 estimator.py:1111] Calling model_fn.
W0618 10:31:34.439216 47531179426688 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:31:34.438457 47409864184704 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpl6l2wj12
W0618 10:31:34.438662 47508372693888 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpbra2rckm
I0618 10:31:34.439557 47409864184704 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpl6l2wj12', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1ec0b36e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:31:34.439790 47508372693888 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpbra2rckm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b35b043ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:31:34.440004 47409864184704 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:31:34.440245 47508372693888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:31:34.440229 47044069995392 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:31:34.440840 47126545036160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:31:34.440587 47531179426688 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:31:34.440883 46945394627456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875494.313268 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875494.314048 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875494.314756 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:31:34.440901 47636767523712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_0_0
:::MLL 1560875494.312029 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875494.312876 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875494.313662 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:31:34.441118 47208703161216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_0_0
W0618 10:31:34.441996 47636767523712 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpqnrddg4f
I0618 10:31:34.442224 47208703161216 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb074/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aefea91cd68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:31:34.443089 47636767523712 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpqnrddg4f', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5395319e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:31:34.443475 47208703161216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:31:34.443554 47636767523712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:31:34.444772 47409864184704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:31:34.444891 47508372693888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:31:34.446213 47471507641216 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:31:34.446619 47683678937984 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:31:34.448742 47636767523712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:31:34.448778 47208703161216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:31:34.450539 47471507641216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:31:34.450930 47683678937984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:31:34.455324 47470661071744 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:31:34.455672 47471507641216 estimator.py:1111] Calling model_fn.
W0618 10:31:34.455786 47471507641216 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:31:34.454607 47748780405632 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:31:34.456024 47683678937984 estimator.py:1111] Calling model_fn.
W0618 10:31:34.456133 47683678937984 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:31:34.455391 47546328494976 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:31:34.456642 47412257059712 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:31:34.457170 47471507641216 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:31:34.457493 47683678937984 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:31:34.462060 47126545036160 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:31:34.462352 46945394627456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:31:34.464504 47508372693888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:31:34.464570 47409864184704 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:31:34.470565 47208703161216 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:31:34.470607 47636767523712 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875494.358125 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875494.358622 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875494.359054 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:31:34.472347 47516984251264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_0_0
:::MLL 1560875494.361738 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875494.362154 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875494.362505 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:31:34.472417 47027974386560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_0_0
:::MLL 1560875494.343665 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875494.344219 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875494.344635 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:31:34.473546 47993090413440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_0_0
:::MLL 1560875494.343784 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875494.344463 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875494.344840 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:31:34.473901 47831301391232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_0_0
W0618 10:31:34.473335 47516984251264 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpoxc5hfk1
W0618 10:31:34.473396 47027974386560 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpsn4r8xbn
W0618 10:31:34.474553 47993090413440 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpazom05n4
I0618 10:31:34.474327 47516984251264 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpoxc5hfk1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b37b18dee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:31:34.474380 47027974386560 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpsn4r8xbn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac5d64b7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:31:34.475551 47993090413440 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpazom05n4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba68bb16e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:31:34.474875 47831301391232 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpiwwpa3ot
I0618 10:31:34.474723 47516984251264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:31:34.475850 47831301391232 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpiwwpa3ot', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b80e050de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:31:34.474783 47027974386560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:31:34.475956 47993090413440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:31:34.476244 47831301391232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:31:34.479342 47516984251264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:31:34.479361 47027974386560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:31:34.480578 47993090413440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:31:34.480845 47831301391232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:31:34.484738 47922173281152 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:31:34.484829 47121975657344 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560875494.378669 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875494.379089 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875494.379457 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:31:34.488108 47160175313792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_0_0
:::MLL 1560875494.376099 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875494.376538 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875494.376904 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:31:34.488426 47728380806016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_0_0
W0618 10:31:34.489003 47922173281152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:31:34.489116 47121975657344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:31:34.489250 47160175313792 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp6tjslb8r
W0618 10:31:34.489552 47728380806016 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpak6rp91r
I0618 10:31:34.490314 47160175313792 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp6tjslb8r', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae49e158e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:31:34.490576 47728380806016 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpak6rp91r', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b68e9c54e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:31:34.490711 47160175313792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:31:34.490968 47728380806016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:31:34.494075 47922173281152 estimator.py:1111] Calling model_fn.
W0618 10:31:34.494188 47922173281152 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:31:34.494205 47121975657344 estimator.py:1111] Calling model_fn.
W0618 10:31:34.494315 47121975657344 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:31:34.495324 47160175313792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:31:34.495556 47922173281152 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:31:34.495528 47728380806016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:31:34.495683 47121975657344 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560875494.409564 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875494.410124 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875494.410600 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:31:34.496987 47034669007744 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000023-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000014-000006.tfrecord.zz_0_0
W0618 10:31:34.498007 47034669007744 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpn96bkvb_
I0618 10:31:34.498977 47034669007744 estimator.py:201] Using con[2019-06-18 10:32:13] divide_golden_chunk finished: 3.321 seconds
[2019-06-18 10:32:13] generate golden chunk: 3.335 seconds
[2019-06-18 10:32:13] iteration time 23: 49.563 seconds
2019-06-18 10:32:15.236498: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560875533.912688 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 24}}
[2019-06-18 10:32:18] minmax time: 3.355 seconds
2019-06-18 10:32:18.602204: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:32:18.607683: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:32:18.612251: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560875538.624789 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 23}}
[2019-06-18 10:32:18] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:32:18] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-25-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000024-000014 --seed=25 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000024-000014 --seed=1023779856 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000024-000014 --seed=2047559687 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000024-000014 --seed=3071339518 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000024-000014 --seed=4095119349 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000024-000014 --seed=5118899180 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000024-000014 --seed=6142679011 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000024-000014 --seed=7166458842 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000024-000014 --seed=8190238673 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000024-000014 --seed=9214018504 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000024-000014 --seed=10237798335 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000024-000014 --seed=11261578166 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000024-000014 --seed=12285357997 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000024-000014 --seed=13309137828 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000024-000014 --seed=14332917659 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000024-000014 --seed=15356697490 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000024-000014 --seed=16380477321 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000024-000014 --seed=17404257152 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000024-000014 --seed=18428036983 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000024-000014 --seed=19451816814 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000024-000014 --seed=20475596645 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:32:29] eval finished: 10.337 seconds
[2019-06-18 10:32:29] Win rate 000024-000014 vs 000022-000013: 0.420
:::MLL 1560875549.038443 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 23}}
[2019-06-18 10:32:29] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-26-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000025-000013 --seed=26 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000025-000013 --seed=1023779857 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000025-000013 --seed=2047559688 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000025-000013 --seed=3071339519 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000025-000013 --seed=4095119350 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000025-000013 --seed=5118899181 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000025-000013 --seed=6142679012 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000025-000013 --seed=7166458843 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000025-000013 --seed=8190238674 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000025-000013 --seed=9214018505 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000025-000013 --seed=10237798336 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000025-000013 --seed=11261578167 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000025-000013 --seed=12285357998 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000025-000013 --seed=13309137829 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000025-000013 --seed=14332917660 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000025-000013 --seed=15356697491 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000025-000013 --seed=16380477322 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000025-000013 --seed=17404257153 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000025-000013 --seed=18428036984 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:32:58] selfplay finished: 29.450 seconds
[2019-06-18 10:32:58] selfplay mn: 29.471 seconds
[2019-06-18 10:32:58] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-26-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=26 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779857 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559688 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339519 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119350 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899181 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142679012 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458843 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238674 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018505 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798336 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578167 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285357998 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137829 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917660 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697491 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477322 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257153 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036984 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816815 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596646 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376477 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156308 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golde
[2019-06-18 10:33:01] divide_golden_chunk finished: 3.328 seconds
[2019-06-18 10:33:01] generate golden chunk: 3.343 seconds
[2019-06-18 10:33:02] train finished: 43.811 seconds
:::MLL 1560875543.848976 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875543.849718 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875543.850385 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:32:23.956135 47660359447424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_0_0
:::MLL 1560875543.835311 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875543.836189 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875543.837049 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:32:23.956465 47027175756672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_0_0
W0618 10:32:23.957234 47660359447424 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp8uzlxbaf
W0618 10:32:23.957463 47027175756672 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpbyr83zo5
I0618 10:32:23.958225 47660359447424 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp8uzlxbaf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b591361ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:32:23.958441 47027175756672 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpbyr83zo5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac5a6b16e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:32:23.958630 47660359447424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:32:23.958839 47027175756672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:32:23.963410 47660359447424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:32:23.963480 47027175756672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875543.859771 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875543.860539 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875543.861287 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:32:23.964619 47947746083712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_0_0
:::MLL 1560875543.860935 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875543.861726 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875543.862411 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:32:23.964662 47842034176896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_0_0
W0618 10:32:23.965728 47947746083712 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpgs7_dd5j
W0618 10:32:23.965759 47842034176896 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpbo3ck3m3
I0618 10:32:23.966836 47947746083712 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpgs7_dd5j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9bfcf5ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:32:23.966892 47842034176896 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpbo3ck3m3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b83600a2e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:32:23.967324 47947746083712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:32:23.967364 47842034176896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:32:23.972531 47947746083712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:32:23.972553 47842034176896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:32:23.982693 47660359447424 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:32:23.983168 47027175756672 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:32:23.994167 47947746083712 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:32:23.994743 47842034176896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875543.829994 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875543.830922 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875543.831786 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:32:24.006221 46999125394304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_0_0
:::MLL 1560875543.855977 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875543.856665 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875543.857325 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:32:24.007079 47486266430336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_0_0
W0618 10:32:24.007366 46999125394304 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpr9jvkm49
I0618 10:32:24.008478 46999125394304 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpr9jvkm49', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abf1ec2de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:32:24.008929 46999125394304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:32:24.008179 47486266430336 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpin9fd0nt
I0618 10:32:24.009382 47486266430336 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpin9fd0nt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b308aa12e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:32:24.009830 47486266430336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:32:24.014212 46999125394304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:32:24.014976 47486266430336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875543.927274 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875543.927831 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875543.928311 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:32:24.022796 47550089102208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_0_0
W0618 10:32:24.023822 47550089102208 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpt6wmi8qt
I0618 10:32:24.024818 47550089102208 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpt6wmi8qt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3f66c1de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:32:24.025216 47550089102208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875543.927320 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875543.927896 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875543.928381 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:32:24.029131 47302958384000 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_0_0
W0618 10:32:24.029870 47550089102208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:32:24.030737 47660359447424 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:32:24.030124 47302958384000 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpc1lekxg9
I0618 10:32:24.031089 47302958384000 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpc1lekxg9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b05dc9e5e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:32:24.031343 47027175756672 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:32:24.031496 47302958384000 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:32:24.035046 47660359447424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:32:24.035473 46999125394304 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:32:24.035676 47027175756672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:32:24.036039 47302958384000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:32:24.036161 47486266430336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875543.950014 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875543.950420 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875543.950775 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:32:24.039072 47667426661248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_0_0
:::MLL 1560875543.947786 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875543.948162 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875543.948480 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:32:24.039213 47584947188608 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_0_0
I0618 10:32:24.040079 47660359447424 estimator.py:1111] Calling model_fn.
W0618 10:32:24.040185 47660359447424 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:32:24.040713 47027175756672 estimator.py:1111] Calling model_fn.
W0618 10:32:24.040819 47027175756672 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:32:24.040112 47667426661248 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpal5s25qg
W0618 10:32:24.040204 47584947188608 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp5kk4i9wb
I0618 10:32:24.041103 47667426661248 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpal5s25qg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5ab89eee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:32:24.041546 47660359447424 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:32:24.041188 47584947188608 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp5kk4i9wb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4784760e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:32:24.041500 47667426661248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:32:24.041593 47584947188608 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:32:24.042154 47027175756672 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560875543.901666 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875543.902077 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875543.902431 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:32:24.044950 46992278848384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_0_0
:::MLL 1560875543.899958 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875543.900509 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875543.900866 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:32:24.045098 47706374136704 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_0_0
W0618 10:32:24.045334 47947746083712 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:32:24.046163 47667426661248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:32:24.046147 47584947188608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:32:24.045965 46992278848384 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp962ykxqy
W0618 10:32:24.046064 47706374136704 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmppjg5h20m
I0618 10:32:24.046968 46992278848384 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp962ykxqy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abd86acddd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:32:24.047066 47706374136704 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmppjg5h20m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b63ca123e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:32:24.046898 47842034176896 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:32:24.047365 46992278848384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:32:24.047463 47706374136704 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875543.921741 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875543.922649 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875543.923352 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:32:24.046691 47029420114816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_0_0
W0618 10:32:24.048985 47550089102208 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:32:24.047823 47029420114816 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpulkuxk7m
W0618 10:32:24.049632 47947746083712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:32:24.048946 47029420114816 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpulkuxk7m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac62c779e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:32:24.049418 47029420114816 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875543.925531 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875543.926282 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875543.926956 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:32:24.049881 47819281437568 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_0_0
W0618 10:32:24.051251 47842034176896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:32:24.052022 46992278848384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:32:24.052062 47706374136704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:32:24.050968 47819281437568 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpxbmseztj
I0618 10:32:24.052087 47819281437568 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpxbmseztj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7e13deedd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:32:24.052534 47819281437568 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:32:24.055014 47302958384000 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:32:24.054707 47947746083712 estimator.py:1111] Calling model_fn.
W0618 10:32:24.054816 47947746083712 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:32:24.054726 47029420114816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:32:24.056182 47947746083712 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:32:24.056365 47842034176896 estimator.py:1111] Calling model_fn.
W0618 10:32:24.056478 47842034176896 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:32:24.057856 47842034176896 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:32:24.057778 47819281437568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:32:24.065042 47584947188608 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:32:24.065230 47667426661248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:32:24.070946 47706374136704 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:32:24.071158 46992278848384 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:32:24.076516 47029420114816 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:32:24.079567 47819281437568 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:32:24.083491 46999125394304 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:32:24.083670 47486266430336 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:32:24.087824 46999125394304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:32:24.088004 47486266430336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:32:24.092934 46999125394304 estimator.py:1111] Calling model_fn.
W0618 10:32:24.093045 46999125394304 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:32:24.093090 47486266430336 estimator.py:1111] Calling model_fn.
W0618 10:32:24.093197 47486266430336 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:32:24.094418 46999125394304 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:32:24.094558 47486266430336 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:32:24.096743 47550089102208 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:32:24.101076 47550089102208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560875543.995444 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875543.995952 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875543.996393 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:32:24.100449 47575145681792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_0_0
W0618 10:32:24.102055 47302958384000 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560875544.000690 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875544.001110 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875544.001469 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:32:24.100900 46971162706816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_0_0
W0618 10:32:24.101469 47575145681792 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpzat8i_7x
I0618 10:32:24.102478 47575145681792 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpzat8i_7x', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b453c3eee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:32:24.101867 46971162706816 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp197mpaae
I0618 10:32:24.102838 46971162706816 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp197mpaae', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab89c0e1dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:32:24.102880 47575145681792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:32:24.103238 46971162706816 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:32:24.106152 47550089102208 estimator.py:1111] Calling model_fn.
W0618 10:32:24.106261 47550089102208 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:32:24.106366 47302958384000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:32:24.107629 47550089102208 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560875543.938067 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875543.938809 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875543.939480 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:32:24.107103 47149113672576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_0_0
:::MLL 1560875543.926934 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875543.927883 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875543.928765 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:32:24.107706 47296597635968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_0_0
W0618 10:32:24.107512 47575145681792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:32:24.107757 46971162706816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:32:24.108252 47149113672576 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb074/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae20ac25d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:32:24.109529 47149113672576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:32:24.108817 47296597635968 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmphbq9ohkg
I0618 10:32:24.109902 47296597635968 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmphbq9ohkg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b04617cfe80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:32:24.110354 47296597635968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:32:24.111447 47302958384000 estimator.py:1111] Calling model_fn.
W0618 10:32:24.111565 47302958384000 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:32:24.112011 47584947188608 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:32:24.112506 47667426661248 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:32:24.112927 47302958384000 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:32:24.114872 47149113672576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:32:24.115538 47296597635968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:32:24.116272 47584947188608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:32:24.116808 47667426661248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:32:24.118417 47706374136704 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:32:24.119027 46992278848384 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560875543.974873 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875543.975601 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875543.976257 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:32:24.120430 47369511089024 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_0_0
:::MLL 1560875543.971250 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875543.972123 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875543.972819 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:32:24.120935 47453553259392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000024-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000015-000007.tfrecord.zz_0_0
I0618 10:32:24.121293 47584947188608 estimator.py:1111] Calling model_fn.
W0618 10:32:24.1214[2019-06-18 10:33:02] iteration time 24: 48.544 seconds
2019-06-18 10:33:03.812045: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560875582.457225 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 25}}
[2019-06-18 10:33:07] minmax time: 3.227 seconds
2019-06-18 10:33:07.048941: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:33:07.054502: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:33:07.059154: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560875587.071904 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 24}}
[2019-06-18 10:33:07] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000026-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000026-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000026-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000026-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000026-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000026-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000026-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000026-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000026-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000026-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000026-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:33:07] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-26-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000025-000014 --seed=26 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000025-000014 --seed=1023779857 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000025-000014 --seed=2047559688 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000025-000014 --seed=3071339519 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000025-000014 --seed=4095119350 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000025-000014 --seed=5118899181 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000025-000014 --seed=6142679012 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000025-000014 --seed=7166458843 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000025-000014 --seed=8190238674 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000025-000014 --seed=9214018505 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000025-000014 --seed=10237798336 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000025-000014 --seed=11261578167 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000025-000014 --seed=12285357998 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000025-000014 --seed=13309137829 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000025-000014 --seed=14332917660 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000025-000014 --seed=15356697491 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000025-000014 --seed=16380477322 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000025-000014 --seed=17404257153 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000025-000014 --seed=18428036984 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000025-000014 --seed=19451816815 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000025-000014 --seed=20475596646 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:33:17] eval finished: 10.613 seconds
[2019-06-18 10:33:17] Win rate 000025-000014 vs 000022-000013: 0.240
:::MLL 1560875597.763242 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 24}}
[2019-06-18 10:33:17] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-27-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000026-000013 --seed=27 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000026-000013 --seed=1023779858 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000026-000013 --seed=2047559689 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000026-000013 --seed=3071339520 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000026-000013 --seed=4095119351 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000026-000013 --seed=5118899182 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000026-000013 --seed=6142679013 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000026-000013 --seed=7166458844 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000026-000013 --seed=8190238675 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000026-000013 --seed=9214018506 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000026-000013 --seed=10237798337 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000026-000013 --seed=11261578168 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000026-000013 --seed=12285357999 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000026-000013 --seed=13309137830 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000026-000013 --seed=14332917661 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000026-000013 --seed=15356697492 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000026-000013 --seed=16380477323 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000026-000013 --seed=17404257154 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000026-000013 --seed=18428036985 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:33:46] selfplay finished: 29.179 seconds
[2019-06-18 10:33:46] selfplay mn: 29.198 seconds
[2019-06-18 10:33:46] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-27-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=27 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779858 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559689 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339520 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119351 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899182 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142679013 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458844 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238675 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018506 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798337 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578168 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285357999 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137830 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917661 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697492 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477323 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257154 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036985 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816816 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596647 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376478 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156309 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golde
[2019-06-18 10:33:50] divide_golden_chunk finished: 3.319 seconds
[2019-06-18 10:33:50] generate golden chunk: 3.334 seconds
[2019-06-18 10:33:50] train finished: 43.805 seconds
:::MLL 1560875592.293238 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875592.293975 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875592.294692 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:33:12.401773 47247882220416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_0_0
:::MLL 1560875592.287352 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875592.288209 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875592.289003 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:33:12.402125 47757423481728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 10:33:12.402928 47247882220416 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp4z6ysayz
I0618 10:33:12.404030 47247882220416 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp4z6ysayz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af909d2ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:33:12.403261 47757423481728 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpj7n18j06
I0618 10:33:12.404392 47757423481728 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpj7n18j06', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6facd96da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:33:12.404494 47247882220416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:33:12.404856 47757423481728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:33:12.409855 47247882220416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:33:12.410196 47757423481728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:33:12.431906 47247882220416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:33:12.432579 47757423481728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875592.323273 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875592.324200 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875592.325045 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:33:12.441989 47398044517248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 10:33:12.443108 47398044517248 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpg8oqtgwc
I0618 10:33:12.444215 47398044517248 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpg8oqtgwc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1c00319e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:33:12.444621 47398044517248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875592.336233 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875592.336971 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875592.337634 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:33:12.444628 47835424531328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 10:33:12.445632 47835424531328 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpx37nulvm
I0618 10:33:12.446624 47835424531328 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpx37nulvm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b81d612eda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:33:12.447026 47835424531328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:33:12.449418 47398044517248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:33:12.451807 47835424531328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:33:12.468867 47398044517248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:33:12.471093 47835424531328 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875592.382488 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875592.382915 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875592.383241 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:33:12.474946 47313329795968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 10:33:12.476027 47313329795968 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp3dr29igx
I0618 10:33:12.477009 47313329795968 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp3dr29igx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0846cd7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:33:12.477408 47313329795968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:33:12.482239 47313329795968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875592.382102 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875592.382512 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875592.382879 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:33:12.483928 47870139855744 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 10:33:12.484931 47247882220416 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:33:12.484954 47870139855744 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpwxtydmbl
I0618 10:33:12.485937 47870139855744 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpwxtydmbl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b89eb44be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:33:12.486338 47870139855744 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:33:12.486692 47757423481728 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:33:12.489262 47247882220416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:33:12.490920 47870139855744 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:33:12.491103 47757423481728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:33:12.494368 47247882220416 estimator.py:1111] Calling model_fn.
W0618 10:33:12.494476 47247882220416 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:33:12.495848 47247882220416 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:33:12.496257 47757423481728 estimator.py:1111] Calling model_fn.
W0618 10:33:12.496371 47757423481728 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:33:12.497756 47757423481728 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560875592.373144 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875592.374041 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875592.374875 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:33:12.500686 47576349766528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 10:33:12.501446 47313329795968 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875592.380938 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875592.381687 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875592.382377 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:33:12.501290 46947593233280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 10:33:12.501849 47576349766528 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmplkceiz52
I0618 10:33:12.502961 47576349766528 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmplkceiz52', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b458403ce80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:33:12.502443 46947593233280 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb074/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab31f346d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:33:12.503421 47576349766528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:33:12.503677 46947593233280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875592.401231 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875592.401709 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875592.402183 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:33:12.506225 47586050798464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_0_0
:::MLL 1560875592.402619 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875592.403090 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875592.403503 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:33:12.507012 47411094004608 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 10:33:12.507256 47586050798464 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpshnux70i
I0618 10:33:12.508252 47586050798464 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpshnux70i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b47c63dce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:33:12.508658 47586050798464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:33:12.508009 47411094004608 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpabtw5rr7
I0618 10:33:12.508981 47411094004608 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpabtw5rr7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1f0a00ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:33:12.508775 47576349766528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:33:12.509373 47411094004608 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:33:12.508858 46947593233280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:33:12.510057 47870139855744 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:33:12.513350 47586050798464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:33:12.513942 47411094004608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:33:12.517166 47398044517248 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:33:12.518569 47835424531328 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:33:12.521477 47398044517248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:33:12.522859 47835424531328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:33:12.526525 47398044517248 estimator.py:1111] Calling model_fn.
W0618 10:33:12.526636 47398044517248 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:33:12.527919 47835424531328 estimator.py:1111] Calling model_fn.
W0618 10:33:12.528010 47398044517248 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:33:12.528025 47835424531328 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560875592.413922 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875592.414620 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875592.415346 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:33:12.527717 47621197435776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_0_0
:::MLL 1560875592.398843 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875592.399775 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875592.400648 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:33:12.527728 47200237458304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 10:33:12.529363 47835424531328 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:33:12.528809 47621197435776 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp39k14n6u
W0618 10:33:12.528779 47200237458304 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpcnhm8xf7
I0618 10:33:12.529825 47621197435776 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp39k14n6u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4ff524ddd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:33:12.529824 47200237458304 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpcnhm8xf7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aedf1f95e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:33:12.530257 47621197435776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:33:12.530255 47200237458304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:33:12.530648 46947593233280 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:33:12.530794 47576349766528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:33:12.532421 47586050798464 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:33:12.532975 47411094004608 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875592.341097 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875592.342001 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875592.342715 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:33:12.535490 47405933589376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 10:33:12.535506 47621197435776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:33:12.535506 47200237458304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875592.345115 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875592.345851 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875592.346547 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:33:12.535983 47388393407360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 10:33:12.536627 47405933589376 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmprbh2dblu
I0618 10:33:12.537744 47405933589376 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmprbh2dblu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1dd66b4dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:33:12.537054 47388393407360 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpczwqfa5n
I0618 10:33:12.538141 47388393407360 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpczwqfa5n', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b19c0f14e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:33:12.538196 47405933589376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:33:12.538593 47388393407360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:33:12.543438 47405933589376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:33:12.543765 47388393407360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:33:12.549417 47313329795968 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:33:12.553787 47313329795968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:33:12.555107 47621197435776 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:33:12.555086 47200237458304 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875592.449495 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875592.450109 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875592.450522 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:33:12.556129 47872929493888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_0_0
:::MLL 1560875592.449404 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875592.450054 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875592.450474 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:33:12.556215 47129217008512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 10:33:12.557357 47870139855744 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:33:12.557145 47872929493888 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp6_x_wh_2
W0618 10:33:12.557216 47129217008512 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp3tidkrrb
I0618 10:33:12.558132 47872929493888 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp6_x_wh_2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8a918b4e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:33:12.558201 47129217008512 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp3tidkrrb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2add68d35e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:33:12.558531 47872929493888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:33:12.558597 47129217008512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:33:12.558919 47313329795968 estimator.py:1111] Calling model_fn.
W0618 10:33:12.559033 47313329795968 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:33:12.560399 47313329795968 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560875592.373850 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875592.374724 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875592.375416 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:33:12.559613 47812297065344 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 10:33:12.561673 47870139855744 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:33:12.560743 47812297065344 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpoz7ea6r1
I0618 10:33:12.561907 47812297065344 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpoz7ea6r1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7c7391be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:33:12.562376 47812297065344 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:33:12.563202 47872929493888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:33:12.563253 47129217008512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875592.388192 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875592.388707 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875592.389141 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:33:12.564017 47649652929408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 10:33:12.564175 47405933589376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:33:12.564518 47388393407360 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875592.396646 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875592.397088 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875592.397470 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:33:12.564977 47527003730816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 10:33:12.565052 47649652929408 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpevhppgk5
I0618 10:33:12.566046 47649652929408 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpevhppgk5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5695394e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:33:12.566440 47649652929408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:33:12.565980 47527003730816 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpaxi2rr1t
I0618 10:33:12.567036 47527003730816 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpaxi2rr1t', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3a06c30e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:33:12.566745 47870139855744 estimator.py:1111] Calling model_fn.
W0618 10:33:12.566854 47870139855744 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:33:12.567465 47527003730816 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:33:12.568226 47870139855744 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:33:12.567831 47812297065344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:33:12.571184 47649652929408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875592.377589 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875592.378299 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875592.378999 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:33:12.570107 47074352231296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 10:33:12.572101 47527003730816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:33:12.571179 47074352231296 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpowxwhtvp
I0618 10:33:12.572211 47074352231296 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpowxwhtvp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad0a2a14e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:33:12.572652 47074352231296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:33:12.577838 47074352231296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:33:12.579849 47586050798464 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:33:12.580359 47411094004608 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:33:12.580136 46947593233280 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:33:12.580279 47576349766528 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:33:12.582219 47129217008512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:33:12.582209 47872929493888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875592.473556 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875592.474052 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875592.474448 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:33:12.582853 47745751733120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_0_0
:::MLL 1560875592.472838 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875592.473350 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875592.473785 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:33:12.582922 47792493884288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 10:33:12.584162 47586050798464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input funct[2019-06-18 10:33:50] iteration time 25: 48.441 seconds
2019-06-18 10:33:52.239222: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560875630.898684 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 26}}
[2019-06-18 10:33:55] minmax time: 3.250 seconds
2019-06-18 10:33:55.498943: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:33:55.504459: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:33:55.509167: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560875635.521962 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 25}}
[2019-06-18 10:33:55] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000027-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000027-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000027-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000027-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000027-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000027-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000027-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000027-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000027-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000027-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000027-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:33:55] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-27-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000026-000014 --seed=27 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000026-000014 --seed=1023779858 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000026-000014 --seed=2047559689 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000026-000014 --seed=3071339520 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000026-000014 --seed=4095119351 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000026-000014 --seed=5118899182 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000026-000014 --seed=6142679013 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000026-000014 --seed=7166458844 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000026-000014 --seed=8190238675 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000026-000014 --seed=9214018506 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000026-000014 --seed=10237798337 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000026-000014 --seed=11261578168 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000026-000014 --seed=12285357999 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000026-000014 --seed=13309137830 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000026-000014 --seed=14332917661 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000026-000014 --seed=15356697492 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000026-000014 --seed=16380477323 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000026-000014 --seed=17404257154 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000026-000014 --seed=18428036985 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000026-000014 --seed=19451816816 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000026-000014 --seed=20475596647 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:34:06] eval finished: 10.937 seconds
[2019-06-18 10:34:06] Win rate 000026-000014 vs 000022-000013: 0.420
:::MLL 1560875646.535616 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 25}}
[2019-06-18 10:34:06] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-28-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000027-000013 --seed=28 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000027-000013 --seed=1023779859 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000027-000013 --seed=2047559690 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000027-000013 --seed=3071339521 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000027-000013 --seed=4095119352 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000027-000013 --seed=5118899183 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000027-000013 --seed=6142679014 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000027-000013 --seed=7166458845 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000027-000013 --seed=8190238676 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000027-000013 --seed=9214018507 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000027-000013 --seed=10237798338 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000027-000013 --seed=11261578169 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000027-000013 --seed=12285358000 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000027-000013 --seed=13309137831 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000027-000013 --seed=14332917662 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000027-000013 --seed=15356697493 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000027-000013 --seed=16380477324 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000027-000013 --seed=17404257155 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000027-000013 --seed=18428036986 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:34:35] selfplay finished: 29.115 seconds
[2019-06-18 10:34:35] selfplay mn: 29.134 seconds
[2019-06-18 10:34:35] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-28-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=28 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779859 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559690 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339521 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119352 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899183 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142679014 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458845 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238676 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018507 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798338 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578169 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285358000 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137831 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917662 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697493 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477324 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257155 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036986 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816817 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596648 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376479 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156310 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golde
[2019-06-18 10:34:38] divide_golden_chunk finished: 3.263 seconds
[2019-06-18 10:34:38] generate golden chunk: 3.278 seconds
[2019-06-18 10:34:39] train finished: 43.592 seconds
:::MLL 1560875640.722526 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875640.723267 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875640.723912 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:00.824912 47016922547072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_0_0
:::MLL 1560875640.706561 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875640.707461 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875640.708305 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:00.824992 47560272769920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 10:34:00.826058 47016922547072 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp4jodp1ya
W0618 10:34:00.826096 47560272769920 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp5xy8ta2y
I0618 10:34:00.827185 47016922547072 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp4jodp1ya', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac3438dde10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:00.827186 47560272769920 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp5xy8ta2y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b41c5c03e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:00.827638 47560272769920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:34:00.827646 47016922547072 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:34:00.832895 47560272769920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:00.833062 47016922547072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:00.854728 47560272769920 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:34:00.855437 47016922547072 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875640.795291 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875640.795750 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875640.796168 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:00.892597 47782049936256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 10:34:00.893662 47782049936256 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmprn22wg4_
I0618 10:34:00.894657 47782049936256 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmprn22wg4_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7568b34e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:00.895063 47782049936256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875640.752470 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875640.753391 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875640.754248 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:00.898549 47514657207168 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_0_0
:::MLL 1560875640.764140 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875640.764825 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875640.765531 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:00.898886 47631839048576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 10:34:00.899765 47782049936256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:00.899698 47514657207168 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp9qqm77c7
W0618 10:34:00.899964 47631839048576 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpgsqg2ywp
I0618 10:34:00.900828 47514657207168 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp9qqm77c7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3726da0dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:00.901099 47631839048576 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpgsqg2ywp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b526f6efe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:00.901285 47514657207168 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:34:00.901534 47631839048576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875640.796192 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875640.796617 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875640.796980 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:00.900983 47048172893056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 10:34:00.901976 47048172893056 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp1zik6vm7
I0618 10:34:00.902946 47048172893056 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp1zik6vm7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aca8a383e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:00.903341 47048172893056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:34:00.906512 47514657207168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:00.906797 47631839048576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:00.907409 47560272769920 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:34:00.907903 47048172893056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:00.908762 47016922547072 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:34:00.912065 47560272769920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:34:00.913494 47016922547072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:34:00.917498 47560272769920 estimator.py:1111] Calling model_fn.
W0618 10:34:00.917619 47560272769920 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:34:00.918950 47782049936256 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:34:00.919047 47016922547072 estimator.py:1111] Calling model_fn.
W0618 10:34:00.919089 47560272769920 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:34:00.919169 47016922547072 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:34:00.920656 47016922547072 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:34:00.927004 47048172893056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:34:00.927870 47514657207168 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:34:00.928463 47631839048576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875640.829865 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875640.830276 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875640.830628 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:00.947985 47768315462528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_0_0
:::MLL 1560875640.823427 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875640.823926 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875640.824353 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:00.948077 47073508070272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 10:34:00.948983 47768315462528 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpspfv7p1z
W0618 10:34:00.949035 47073508070272 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpgjw8o7fc
I0618 10:34:00.949977 47768315462528 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpspfv7p1z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b72360fce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:00.950011 47073508070272 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpgjw8o7fc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad070506e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:00.950381 47768315462528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:34:00.950407 47073508070272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:34:00.955081 47768315462528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:00.955087 47073508070272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875640.841307 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875640.842078 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875640.842757 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:00.959389 47386857796480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_0_0
:::MLL 1560875640.788979 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875640.789798 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875640.790619 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:00.959699 47398411244416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_0_0
:::MLL 1560875640.833977 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875640.834874 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875640.835710 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:00.959530 47513495921536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 10:34:00.960731 47398411244416 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp20ufv636
W0618 10:34:00.960425 47386857796480 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpbzxim90s
W0618 10:34:00.960542 47513495921536 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpowzf5b4c
I0618 10:34:00.961730 47398411244416 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp20ufv636', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1c160d6e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:00.961441 47386857796480 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpbzxim90s', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b196569ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:00.961529 47513495921536 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpowzf5b4c', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b36e1a23e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:00.962127 47398411244416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:34:00.961848 47386857796480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:34:00.961930 47513495921536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:34:00.966333 47782049936256 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:34:00.966812 47513495921536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:00.967198 47398411244416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:00.966826 47386857796480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:00.970633 47782049936256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560875640.789645 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875640.790482 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875640.791193 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:00.972207 47407757783936 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 10:34:00.973218 47407757783936 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpwl28rqim
W0618 10:34:00.974058 47768315462528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:34:00.974205 47407757783936 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpwl28rqim', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1e43264e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:34:00.974058 47073508070272 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:34:00.974615 47407757783936 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:34:00.974489 47048172893056 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:34:00.975694 47782049936256 estimator.py:1111] Calling model_fn.
W0618 10:34:00.976018 47514657207168 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:34:00.975810 47782049936256 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:34:00.976165 47631839048576 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:34:00.977161 47782049936256 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:34:00.979305 47407757783936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:00.978816 47048172893056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:34:00.980408 47514657207168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:34:00.980564 47631839048576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:34:00.983897 47048172893056 estimator.py:1111] Calling model_fn.
W0618 10:34:00.984009 47048172893056 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:34:00.985618 47514657207168 estimator.py:1111] Calling model_fn.
W0618 10:34:00.985731 47514657207168 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:34:00.985356 47048172893056 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:34:00.985799 47631839048576 estimator.py:1111] Calling model_fn.
W0618 10:34:00.985920 47631839048576 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:34:00.986110 47386857796480 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:34:00.986155 47513495921536 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:34:00.986781 47398411244416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:34:00.987117 47514657207168 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:34:00.987295 47631839048576 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:34:00.999080 47407757783936 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875640.796109 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875640.796993 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875640.797681 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:00.998909 47905063150464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_0_0
:::MLL 1560875640.795174 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875640.796028 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875640.796826 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:00.999620 47963870565248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 10:34:01.000033 47905063150464 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp857jkdc1
I0618 10:34:01.001134 47905063150464 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp857jkdc1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b920cdbfe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:34:01.000702 47963870565248 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpr1x1odht
I0618 10:34:01.001585 47905063150464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:34:01.001808 47963870565248 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpr1x1odht', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9fbe0dee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:01.002255 47963870565248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:34:01.006873 47905063150464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:01.007386 47963870565248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875640.847644 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875640.848108 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875640.848514 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:01.011528 47185858474880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_0_0
:::MLL 1560875640.842554 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875640.843091 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875640.843575 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:01.012483 47384857359232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 10:34:01.012535 47185858474880 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp3eng05ep
I0618 10:34:01.013508 47185858474880 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp3eng05ep', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aea98eb8e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:01.013911 47185858474880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:34:01.013441 47384857359232 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpctrmgmsr
I0618 10:34:01.014412 47384857359232 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpctrmgmsr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b18ee2d8da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:01.014804 47384857359232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875640.909183 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875640.909669 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875640.910122 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:01.017458 47027435000704 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_0_0
:::MLL 1560875640.909407 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875640.909947 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875640.910377 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:01.017573 47612024595328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 10:34:01.018635 47185858474880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:01.019349 47384857359232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:01.018500 47027435000704 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmprv13rpk_
W0618 10:34:01.018580 47612024595328 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmphsc1g3bp
I0618 10:34:01.019466 47027435000704 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmprv13rpk_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac5b6252e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:01.019562 47612024595328 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmphsc1g3bp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4dd2667dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:01.019863 47027435000704 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:34:01.019963 47612024595328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:34:01.021135 47073508070272 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:34:01.021652 47768315462528 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:34:01.024504 47027435000704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:01.024602 47612024595328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:01.025415 47073508070272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:34:01.025954 47768315462528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:34:01.027244 47905063150464 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:34:01.027804 47963870565248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875640.844301 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875640.844799 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875640.845259 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:01.027849 47614644511616 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_0_0
:::MLL 1560875640.848688 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875640.849149 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875640.849505 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:01.028493 47951035208576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000017-000009.tfrecord.zz_0_0
I0618 10:34:01.030458 47073508070272 estimator.py:1111] Calling model_fn.
W0618 10:34:01.030566 47073508070272 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:34:01.028851 47614644511616 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpl2kzk94u
I0618 10:34:01.029843 47614644511616 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpl2kzk94u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4e6e8f2dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:01.030988 47768315462528 estimator.py:1111] Calling model_fn.
W0618 10:34:01.031095 47768315462528 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:34:01.029475 47951035208576 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpblbnqm2v
I0618 10:34:01.030244 47614644511616 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:34:01.030467 47951035208576 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpblbnqm2v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9cc101ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:34:01.031933 47073508070272 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:34:01.030870 47951035208576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:34:01.032456 47768315462528 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:34:01.034149 47513495921536 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:34:01.034853 47398411244416 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:34:01.034893 47386857796480 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differenti[2019-06-18 10:34:39] iteration time 26: 48.236 seconds
2019-06-18 10:34:40.516048: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560875679.135041 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 27}}
[2019-06-18 10:34:43] minmax time: 3.227 seconds
2019-06-18 10:34:43.753336: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:34:43.758827: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:34:43.763312: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560875683.775856 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 26}}
[2019-06-18 10:34:43] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000028-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000028-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000028-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000028-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000028-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000028-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000028-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000028-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000028-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000028-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000028-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:34:43] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-28-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000027-000014 --seed=28 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000027-000014 --seed=1023779859 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000027-000014 --seed=2047559690 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000027-000014 --seed=3071339521 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000027-000014 --seed=4095119352 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000027-000014 --seed=5118899183 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000027-000014 --seed=6142679014 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000027-000014 --seed=7166458845 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000027-000014 --seed=8190238676 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000027-000014 --seed=9214018507 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000027-000014 --seed=10237798338 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000027-000014 --seed=11261578169 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000027-000014 --seed=12285358000 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000027-000014 --seed=13309137831 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000027-000014 --seed=14332917662 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000027-000014 --seed=15356697493 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000027-000014 --seed=16380477324 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000027-000014 --seed=17404257155 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000027-000014 --seed=18428036986 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000027-000014 --seed=19451816817 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000022-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000027-000014 --seed=20475596648 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:34:54] eval finished: 10.891 seconds
[2019-06-18 10:34:54] Win rate 000027-000014 vs 000022-000013: 0.490
:::MLL 1560875694.756248 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 26}}
[2019-06-18 10:34:54] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-29-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000028-000013 --seed=29 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000028-000013 --seed=1023779860 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000028-000013 --seed=2047559691 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000028-000013 --seed=3071339522 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000028-000013 --seed=4095119353 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000028-000013 --seed=5118899184 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000028-000013 --seed=6142679015 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000028-000013 --seed=7166458846 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000028-000013 --seed=8190238677 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000028-000013 --seed=9214018508 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000028-000013 --seed=10237798339 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000028-000013 --seed=11261578170 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000028-000013 --seed=12285358001 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000028-000013 --seed=13309137832 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000028-000013 --seed=14332917663 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000028-000013 --seed=15356697494 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000028-000013 --seed=16380477325 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000028-000013 --seed=17404257156 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000028-000013 --seed=18428036987 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:35:24] selfplay finished: 29.846 seconds
[2019-06-18 10:35:24] selfplay mn: 29.867 seconds
[2019-06-18 10:35:24] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-29-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=29 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779860 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559691 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339522 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119353 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899184 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142679015 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458846 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238677 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018508 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798339 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578170 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285358001 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137832 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917663 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697494 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477325 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257156 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036987 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816818 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596649 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376480 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156311 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000028-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golde
[2019-06-18 10:35:27] train finished: 43.467 seconds
:::MLL 1560875689.035206 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875689.036095 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875689.036988 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:49.160801 47236283978624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_0_0
W0618 10:34:49.161847 47236283978624 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpu324vfu8
I0618 10:34:49.162852 47236283978624 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpu324vfu8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af656838e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:49.163258 47236283978624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:34:49.168424 47236283978624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875689.046120 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875689.046849 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875689.047544 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:49.168419 47219148637056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_0_0
W0618 10:34:49.169460 47219148637056 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp0ng5tp3l
I0618 10:34:49.170466 47219148637056 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp0ng5tp3l', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af2592b1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:49.170877 47219148637056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:34:49.175668 47219148637056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:49.187665 47236283978624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:34:49.195225 47219148637056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875689.044287 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875689.045023 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875689.045726 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:49.228425 47930906428288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_0_0
:::MLL 1560875689.115510 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875689.115975 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875689.116402 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:49.228985 47502997767040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_0_0
:::MLL 1560875689.040652 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875689.041554 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875689.042238 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:49.228431 47599526855552 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_0_0
:::MLL 1560875689.116724 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875689.117197 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875689.117606 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:49.229058 47409183327104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_0_0
W0618 10:34:49.230008 47502997767040 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpx6qww6pk
W0618 10:34:49.230071 47409183327104 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpnjq1808j
W0618 10:34:49.229603 47930906428288 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp8njbux4w
W0618 10:34:49.229635 47599526855552 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpqrg4wna3
I0618 10:34:49.231001 47502997767040 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpx6qww6pk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b346fe51da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:49.231040 47409183327104 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpnjq1808j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1e981e5e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:49.230682 47930906428288 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp8njbux4w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b98113d1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:49.230713 47599526855552 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpqrg4wna3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4ae97a0e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:49.231406 47502997767040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:34:49.231436 47409183327104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:34:49.231112 47930906428288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:34:49.231137 47599526855552 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:34:49.235450 47236283978624 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:34:49.236093 47409183327104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:49.236114 47502997767040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:49.236296 47599526855552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:49.236344 47930906428288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:49.239745 47236283978624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560875689.079254 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875689.080159 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875689.081017 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:49.239524 47652003169152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_0_0
W0618 10:34:49.240660 47652003169152 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp2761ggjz
I0618 10:34:49.241786 47652003169152 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp2761ggjz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b57214efe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:49.242253 47652003169152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:34:49.243307 47219148637056 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:34:49.244774 47236283978624 estimator.py:1111] Calling model_fn.
W0618 10:34:49.244885 47236283978624 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:34:49.246229 47236283978624 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560875689.084679 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875689.085395 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875689.086072 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:49.246486 46916321530752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_0_0
W0618 10:34:49.247659 47219148637056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:34:49.247716 47652003169152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:49.247595 46916321530752 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp0a3reo09
I0618 10:34:49.248701 46916321530752 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp0a3reo09', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aabd7441e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560875689.086879 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875689.087826 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875689.088722 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:49.247653 47969101755264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_0_0
:::MLL 1560875689.094712 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875689.095445 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875689.096104 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:49.247705 47894329623424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_0_0
I0618 10:34:49.249150 46916321530752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:34:49.248800 47969101755264 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpwviweqko
W0618 10:34:49.248831 47894329623424 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpsyjalztd
I0618 10:34:49.249900 47969101755264 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpwviweqko', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba0f5db7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:49.249919 47894329623424 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpsyjalztd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8f8d175e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:49.250339 47969101755264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:34:49.250362 47894329623424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:34:49.252760 47219148637056 estimator.py:1111] Calling model_fn.
W0618 10:34:49.252872 47219148637056 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:34:49.254253 47219148637056 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:34:49.254324 46916321530752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:49.255047 47409183327104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:34:49.255135 47502997767040 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:34:49.255682 47969101755264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:49.255722 47894329623424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:49.256786 47599526855552 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:34:49.256820 47930906428288 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875689.109699 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875689.110116 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875689.110475 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:49.268612 47267753399168 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_0_0
:::MLL 1560875689.107438 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875689.107867 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875689.108235 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:49.268647 47114175767424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_0_0
W0618 10:34:49.270025 47652003169152 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:34:49.269682 47114175767424 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpqfahy6sn
W0618 10:34:49.269709 47267753399168 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmprn3lkc1w
I0618 10:34:49.270694 47114175767424 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpqfahy6sn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad9e84c3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:49.270704 47267753399168 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmprn3lkc1w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afdaa3cee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:49.271098 47267753399168 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:34:49.271094 47114175767424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:34:49.276031 46916321530752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:34:49.275794 47267753399168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:49.275806 47114175767424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:49.277259 47894329623424 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:34:49.277287 47969101755264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875689.149189 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875689.149604 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875689.149975 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:49.292946 48007224378240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_0_0
:::MLL 1560875689.150799 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875689.151329 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875689.151740 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:49.293636 46991884616576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_0_0
W0618 10:34:49.293999 48007224378240 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpsie9hb4e
I0618 10:34:49.294996 48007224378240 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpsie9hb4e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba9d6248e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:34:49.294808 47267753399168 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:34:49.294897 47114175767424 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:34:49.294604 46991884616576 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpr0hu4ohx
I0618 10:34:49.295392 48007224378240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:34:49.295589 46991884616576 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpr0hu4ohx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abd6f2d5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:49.295992 46991884616576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875689.163115 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875689.163611 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875689.164050 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:49.297158 47944083923840 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_0_0
:::MLL 1560875689.166844 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875689.167250 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875689.167600 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:49.297263 47990033494912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_0_0
:::MLL 1560875689.146398 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875689.147144 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875689.147847 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:49.299359 47561032094592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_0_0
W0618 10:34:49.298171 47944083923840 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp0icbnj4f
W0618 10:34:49.300039 48007224378240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:49.298264 47990033494912 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpmpz501nr
:::MLL 1560875689.144163 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875689.144908 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875689.145627 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:49.299655 47848134738816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_0_0
I0618 10:34:49.299170 47944083923840 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp0icbnj4f', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9b22adae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:49.299245 47990033494912 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpmpz501nr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba5d57c5dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:34:49.300573 46991884616576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:34:49.299563 47944083923840 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:34:49.299648 47990033494912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:34:49.300413 47561032094592 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpllqwtfpk
W0618 10:34:49.300645 47848134738816 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpkqezoijs
I0618 10:34:49.301398 47561032094592 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpllqwtfpk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b41f302ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:49.301625 47848134738816 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpkqezoijs', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b84cba95e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:49.301801 47561032094592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:34:49.302029 47848134738816 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:34:49.302559 47409183327104 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:34:49.302936 47502997767040 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:34:49.304636 47599526855552 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:34:49.304181 47944083923840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:49.304234 47990033494912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:49.305287 47930906428288 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:34:49.306874 47409183327104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:34:49.306542 47561032094592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:49.306653 47848134738816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:34:49.307271 47502997767040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:34:49.309036 47599526855552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:34:49.309620 47930906428288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:34:49.311918 47409183327104 estimator.py:1111] Calling model_fn.
W0618 10:34:49.312025 47409183327104 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:34:49.312375 47502997767040 estimator.py:1111] Calling model_fn.
W0618 10:34:49.312488 47502997767040 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:34:49.313371 47409183327104 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:34:49.313856 47502997767040 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:34:49.314107 47599526855552 estimator.py:1111] Calling model_fn.
W0618 10:34:49.314214 47599526855552 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:34:49.314727 47930906428288 estimator.py:1111] Calling model_fn.
W0618 10:34:49.314836 47930906428288 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:34:49.315591 47599526855552 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:34:49.316208 47930906428288 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:34:49.318818 47652003169152 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:34:49.319020 48007224378240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:34:49.319519 46991884616576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:34:49.323196 47652003169152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:34:49.324044 46916321530752 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:34:49.323098 47944083923840 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:34:49.323327 47990033494912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:34:49.325870 47561032094592 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:34:49.326050 47848134738816 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:34:49.325974 47894329623424 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:34:49.325975 47969101755264 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:34:49.328338 47652003169152 estimator.py:1111] Calling model_fn.
W0618 10:34:49.328452 47652003169152 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:34:49.328432 46916321530752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:34:49.329837 47652003169152 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560875689.132087 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875689.132910 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875689.133686 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:34:49.330650 47213207266176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000018-000010.tfrecord.zz_0_0
W0618 10:34:49.330439 47894329623424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:34:49.330425 47969101755264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:34:49.331806 47213207266176 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb074/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af0f708ed68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:34:49.333040 47213207266176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:34:49.333555 46916321530752 estimator.py:1111] Calling model_fn.
W0618 10:34:49.333669 46916321530752 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in[2019-06-18 10:35:27] divide_golden_chunk finished: 3.283 seconds
[2019-06-18 10:35:27] generate golden chunk: 3.297 seconds
[2019-06-18 10:35:27] moving /lfs/lfs12/gma_akey/results/epb074/models/000028-000014.index --> /lfs/lfs12/gma_akey/results/epb074/models/000028-000015.index
[2019-06-18 10:35:27] moving /lfs/lfs12/gma_akey/results/epb074/models/000028-000014.meta --> /lfs/lfs12/gma_akey/results/epb074/models/000028-000015.meta
[2019-06-18 10:35:27] moving /lfs/lfs12/gma_akey/results/epb074/models/000028-000014.pb --> /lfs/lfs12/gma_akey/results/epb074/models/000028-000015.pb
[2019-06-18 10:35:27] moving /lfs/lfs12/gma_akey/results/epb074/models/000028-000014.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb074/models/000028-000015.data-00000-of-00001
[2019-06-18 10:35:27] iteration time 27: 48.829 seconds
2019-06-18 10:35:29.465481: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560875727.963922 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 28}}
[2019-06-18 10:35:32] minmax time: 3.249 seconds
2019-06-18 10:35:32.724677: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:35:32.730176: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:35:32.734837: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560875732.745849 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 27}}
[2019-06-18 10:35:32] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000029-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000029-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000029-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000029-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000029-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000029-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000029-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000029-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000029-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000029-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000029-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:35:32] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-29-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000028-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000028-000015 --seed=29 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000028-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000028-000015 --seed=1023779860 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000028-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000028-000015 --seed=2047559691 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000028-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000028-000015 --seed=3071339522 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000028-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000028-000015 --seed=4095119353 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000028-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000028-000015 --seed=5118899184 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000028-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000028-000015 --seed=6142679015 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000028-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000028-000015 --seed=7166458846 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000028-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000028-000015 --seed=8190238677 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000028-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000028-000015 --seed=9214018508 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000028-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000028-000015 --seed=10237798339 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000028-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000028-000015 --seed=11261578170 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000028-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000028-000015 --seed=12285358001 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000028-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000028-000015 --seed=13309137832 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000028-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000028-000015 --seed=14332917663 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000028-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000028-000015 --seed=15356697494 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000028-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000028-000015 --seed=16380477325 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000028-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000028-000015 --seed=17404257156 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000028-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000028-000015 --seed=18428036987 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000028-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000028-000015 --seed=19451816818 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000028-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000028-000015 --seed=20475596649 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:35:43] eval finished: 10.742 seconds
[2019-06-18 10:35:43] Win rate 000028-000015 vs 000027-000014: 0.420
:::MLL 1560875743.565333 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 27}}
[2019-06-18 10:35:43] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-30-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000029-000014 --seed=30 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000029-000014 --seed=1023779861 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000029-000014 --seed=2047559692 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000029-000014 --seed=3071339523 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000029-000014 --seed=4095119354 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000029-000014 --seed=5118899185 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000029-000014 --seed=6142679016 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000029-000014 --seed=7166458847 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000029-000014 --seed=8190238678 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000029-000014 --seed=9214018509 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000029-000014 --seed=10237798340 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000029-000014 --seed=11261578171 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000029-000014 --seed=12285358002 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000029-000014 --seed=13309137833 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000029-000014 --seed=14332917664 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000029-000014 --seed=15356697495 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000029-000014 --seed=16380477326 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000029-000014 --seed=17404257157 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000029-000014 --seed=18428036988 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:36:13] selfplay finished: 30.405 seconds
[2019-06-18 10:36:13] selfplay mn: 30.423 seconds
[2019-06-18 10:36:13] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-30-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=30 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779861 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559692 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339523 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119354 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899185 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142679016 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458847 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238678 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018509 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798340 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578171 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285358002 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137833 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917664 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697495 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477326 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257157 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036988 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816819 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596650 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376481 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156312 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000029-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golde
[2019-06-18 10:36:16] train finished: 43.380 seconds
:::MLL 1560875738.003247 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875738.004085 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875738.004849 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:35:38.124846 47053949076352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_0_0
W0618 10:35:38.125936 47053949076352 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpq5k21org
I0618 10:35:38.126952 47053949076352 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpq5k21org', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acbe281be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:35:38.127359 47053949076352 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875738.004474 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875738.005287 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875738.006003 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:35:38.129298 47606333084544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_0_0
W0618 10:35:38.130372 47606333084544 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp3zd8gkxl
I0618 10:35:38.131377 47606333084544 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp3zd8gkxl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4c7f28eda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:35:38.131790 47606333084544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:35:38.132339 47053949076352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:35:38.136363 47606333084544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:35:38.151310 47053949076352 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:35:38.155409 47606333084544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875738.008626 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875738.009506 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875738.010370 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:35:38.173630 47306585486208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_0_0
W0618 10:35:38.174731 47306585486208 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp5nbml_58
I0618 10:35:38.175839 47306585486208 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp5nbml_58', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b06b4cf7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:35:38.176294 47306585486208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:35:38.181545 47306585486208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875738.018695 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875738.019444 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875738.020105 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:35:38.191459 47593757815680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_0_0
W0618 10:35:38.192605 47593757815680 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp1vsatnkd
I0618 10:35:38.193728 47593757815680 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp1vsatnkd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b49919d7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:35:38.194189 47593757815680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875738.090487 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875738.091139 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875738.091594 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:35:38.196183 47890588660608 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_0_0
W0618 10:35:38.197211 47890588660608 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpd7mk55dq
I0618 10:35:38.198212 47890588660608 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpd7mk55dq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8eae1ccda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560875738.091328 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875738.091839 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875738.092253 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:35:38.198387 47784111661952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_0_0
I0618 10:35:38.198621 47890588660608 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:35:38.199292 47053949076352 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:35:38.199543 47593757815680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:35:38.199376 47784111661952 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpvec45ku2
I0618 10:35:38.200350 47784111661952 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpvec45ku2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b75e396ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:35:38.200753 47784111661952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:35:38.203141 47606333084544 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:35:38.203279 47890588660608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875738.012508 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875738.013332 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875738.014213 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:35:38.203305 47931570176896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_0_0
W0618 10:35:38.203590 47053949076352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:35:38.203396 47306585486208 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:35:38.204389 47931570176896 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpdcja1rc0
W0618 10:35:38.205278 47784111661952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:35:38.205498 47931570176896 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpdcja1rc0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9838cd1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:35:38.205945 47931570176896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:35:38.207472 47606333084544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:35:38.208630 47053949076352 estimator.py:1111] Calling model_fn.
W0618 10:35:38.208738 47053949076352 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:35:38.210104 47053949076352 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:35:38.211147 47931570176896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:35:38.212530 47606333084544 estimator.py:1111] Calling model_fn.
W0618 10:35:38.212641 47606333084544 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:35:38.213995 47606333084544 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560875738.072772 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875738.073564 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875738.074259 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:35:38.220968 47027474539392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_0_0
W0618 10:35:38.221811 47593757815680 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875738.061411 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875738.062326 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875738.063185 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:35:38.221563 47640786256768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_0_0
:::MLL 1560875738.057232 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875738.058020 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875738.058819 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:35:38.221017 47434758583168 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_0_0
W0618 10:35:38.222414 47890588660608 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:35:38.222123 47027474539392 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb074/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac5b8807d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:35:38.223372 47027474539392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:35:38.222683 47640786256768 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp9ishgzfd
W0618 10:35:38.222170 47434758583168 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpx4wjmwxf
W0618 10:35:38.224267 47784111661952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:35:38.223817 47640786256768 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp9ishgzfd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5484ba9e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:35:38.223262 47434758583168 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpx4wjmwxf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b248c85be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:35:38.224266 47640786256768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:35:38.223711 47434758583168 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:35:38.228687 47027474539392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:35:38.229427 47640786256768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:35:38.228922 47434758583168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:35:38.232894 47931570176896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875738.087339 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875738.087828 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875738.088284 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:35:38.244647 47353526223744 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_0_0
:::MLL 1560875738.092092 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875738.092500 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875738.092865 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:35:38.245802 47638227239808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_0_0
W0618 10:35:38.245645 47353526223744 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp9mudncim
I0618 10:35:38.246631 47353526223744 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp9mudncim', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b11a2b25e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:35:38.247036 47353526223744 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:35:38.246786 47638227239808 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp19po1xw6
I0618 10:35:38.247777 47638227239808 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp19po1xw6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b53ec330e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:35:38.248178 47638227239808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:35:38.250427 47027474539392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:35:38.249761 47434758583168 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:35:38.251686 47353526223744 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:35:38.251400 47640786256768 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:35:38.252782 47638227239808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875738.100648 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875738.101399 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875738.102067 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:35:38.252693 47436422751104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_0_0
:::MLL 1560875738.090285 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875738.091193 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875738.092055 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:35:38.252751 47533042508672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_0_0
W0618 10:35:38.253767 47436422751104 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp3pqqivqo
W0618 10:35:38.253795 47533042508672 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpffjwbpm4
I0618 10:35:38.254903 47436422751104 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp3pqqivqo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b24efb6ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:35:38.254920 47533042508672 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpffjwbpm4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3b6eb36e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:35:38.255349 47436422751104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:35:38.255378 47533042508672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:35:38.255316 47306585486208 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560875738.111598 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875738.112016 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875738.112379 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:35:38.257951 47416662467456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_0_0
:::MLL 1560875738.109506 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875738.109935 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875738.110303 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:35:38.258175 47603931321216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_0_0
W0618 10:35:38.260300 47436422751104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:35:38.260305 47533042508672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:35:38.259616 47306585486208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:35:38.258984 47416662467456 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp18s_27si
W0618 10:35:38.259170 47603931321216 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp5qv8cqll
I0618 10:35:38.259992 47416662467456 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp18s_27si', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2055e8fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:35:38.260175 47603931321216 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp5qv8cqll', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4bf000de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:35:38.260385 47416662467456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:35:38.260579 47603931321216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875738.027389 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875738.028277 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875738.029070 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:35:38.264307 47649190040448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_0_0
:::MLL 1560875738.027451 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875738.028308 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875738.029099 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:35:38.264336 47314169414528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_0_0
I0618 10:35:38.264700 47306585486208 estimator.py:1111] Calling model_fn.
W0618 10:35:38.264818 47306585486208 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:35:38.265040 47416662467456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:35:38.265152 47603931321216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:35:38.265492 47649190040448 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmptmpe3ju7
W0618 10:35:38.265524 47314169414528 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmph7o99ik_
I0618 10:35:38.266594 47649190040448 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmptmpe3ju7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5679a21e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:35:38.266622 47314169414528 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmph7o99ik_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0878d91e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:35:38.266164 47306585486208 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:35:38.267041 47649190040448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:35:38.267070 47314169414528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:35:38.270274 47890588660608 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:35:38.270518 47593757815680 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:35:38.270868 47353526223744 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:35:38.271233 47784111661952 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:35:38.271942 47638227239808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:35:38.272191 47314169414528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:35:38.272188 47649190040448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875738.130752 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875738.131256 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875738.131857 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:35:38.271952 47024628790144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_0_0
:::MLL 1560875738.140520 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875738.140960 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875738.141325 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:35:38.271979 47620442424192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_0_0
W0618 10:35:38.273097 47024628790144 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpij72bj6g
W0618 10:35:38.273066 47620442424192 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpdf8wctt9
I0618 10:35:38.274055 47620442424192 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpdf8wctt9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4fc8244e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:35:38.274088 47024628790144 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpij72bj6g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac50ee1ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:35:38.274626 47890588660608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:35:38.274461 47620442424192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:35:38.274823 47593757815680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:35:38.274492 47024628790144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:35:38.275548 47784111661952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:35:38.279145 47024628790144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:35:38.279120 47620442424192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:35:38.279721 47890588660608 estimator.py:1111] Calling model_fn.
W0618 10:35:38.279830 47890588660608 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:35:38.279898 47593757815680 estimator.py:1111] Calling model_fn.
W0618 10:35:38.280006 47593757815680 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:35:38.279652 47436422751104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:35:38.279629 47533042508672 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:35:38.280596 47784111661952 estimator.py:1111] Calling model_fn.
W0618 10:35:38.280709 47784111661952 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:35:38.280665 47931570176896 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:35:38.281190 47890588660608 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:35:38.281375 47593757815680 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:35:38.282059 47784111661952 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:35:38.284994 47931570176896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:35:38.284105 47416662467456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:35:38.284133 47603931321216 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875738.078497 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875738.078960 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875738.079378 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:35:38.286880 47647585948544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_0_0
:::MLL 1560875738.079000 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875738.079454 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875738.079819 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:35:38.287220 47875930186624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000028-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000019-000010.tfrecord.zz_0_0
W0618 10:35:38.287914 47647585948544 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpd3abifr1
W0618 10:35:38.288216 47875930186624 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmponvpnxua
I0618 10:35:38.288926 47647585948544 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpd3abifr1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b561a05ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:35:38.289198 47875930186624 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmponvpnxua', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8b44663e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:35:38.289324 47647585948544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:35:38.289608 47875930186624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:35:38.290031 47931570176896 estimator.py:1111] Calling model_fn.
W0618 10:35:38.290139 47931570176896 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolut[2019-06-18 10:36:17] divide_golden_chunk finished: 3.247 seconds
[2019-06-18 10:36:17] generate golden chunk: 3.262 seconds
[2019-06-18 10:36:17] iteration time 28: 49.288 seconds
2019-06-18 10:36:18.787263: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560875777.252226 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 29}}
[2019-06-18 10:36:22] minmax time: 3.244 seconds
2019-06-18 10:36:22.041398: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:36:22.046847: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:36:22.051365: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560875782.064437 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 28}}
[2019-06-18 10:36:22] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000030-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000030-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000030-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000030-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000030-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000030-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000030-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000030-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000030-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000030-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000030-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:36:22] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-30-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000029-000015 --seed=30 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000029-000015 --seed=1023779861 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000029-000015 --seed=2047559692 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000029-000015 --seed=3071339523 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000029-000015 --seed=4095119354 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000029-000015 --seed=5118899185 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000029-000015 --seed=6142679016 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000029-000015 --seed=7166458847 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000029-000015 --seed=8190238678 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000029-000015 --seed=9214018509 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000029-000015 --seed=10237798340 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000029-000015 --seed=11261578171 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000029-000015 --seed=12285358002 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000029-000015 --seed=13309137833 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000029-000015 --seed=14332917664 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000029-000015 --seed=15356697495 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000029-000015 --seed=16380477326 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000029-000015 --seed=17404257157 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000029-000015 --seed=18428036988 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000029-000015 --seed=19451816819 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000027-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000029-000015 --seed=20475596650 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:36:34] eval finished: 12.606 seconds
[2019-06-18 10:36:34] Win rate 000029-000015 vs 000027-000014: 0.620
:::MLL 1560875794.747987 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 28}}
[2019-06-18 10:36:34] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-31-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000030-000014 --seed=31 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000030-000014 --seed=1023779862 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000030-000014 --seed=2047559693 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000030-000014 --seed=3071339524 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000030-000014 --seed=4095119355 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000030-000014 --seed=5118899186 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000030-000014 --seed=6142679017 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000030-000014 --seed=7166458848 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000030-000014 --seed=8190238679 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000030-000014 --seed=9214018510 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000030-000014 --seed=10237798341 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000030-000014 --seed=11261578172 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000030-000014 --seed=12285358003 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000030-000014 --seed=13309137834 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000030-000014 --seed=14332917665 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000030-000014 --seed=15356697496 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000030-000014 --seed=16380477327 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000030-000014 --seed=17404257158 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000030-000014 --seed=18428036989 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:37:05] selfplay finished: 30.389 seconds
[2019-06-18 10:37:05] selfplay mn: 30.407 seconds
[2019-06-18 10:37:05] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-31-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=31 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779862 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559693 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339524 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119355 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899186 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142679017 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458848 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238679 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018510 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798341 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578172 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285358003 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137834 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917665 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697496 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477327 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257158 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036989 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816820 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596651 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376482 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156313 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000030-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golde
[2019-06-18 10:37:05] train finished: 43.400 seconds
:::MLL 1560875787.348953 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875787.349846 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875787.350688 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:36:27.506023 47521665471360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_0_0
:::MLL 1560875787.341680 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875787.342563 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875787.343373 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:36:27.505607 47439359329152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_0_0
:::MLL 1560875787.355380 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875787.356144 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875787.356845 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:36:27.506731 47789547209600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_0_0
W0618 10:36:27.507070 47521665471360 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp5ssms0aq
I0618 10:36:27.508059 47521665471360 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp5ssms0aq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b38c893ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:36:27.506769 47439359329152 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpueamvoqk
W0618 10:36:27.507675 47789547209600 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpp_o7to4t
I0618 10:36:27.507898 47439359329152 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpueamvoqk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b259ebf9e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:36:27.508466 47521665471360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:36:27.508632 47789547209600 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpp_o7to4t', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7727929da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:36:27.508353 47439359329152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:36:27.509028 47789547209600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:36:27.513333 47521665471360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:36:27.513726 47789547209600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:36:27.513612 47439359329152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560875787.356655 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875787.357341 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875787.358016 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:36:27.526571 47347556983680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_0_0
W0618 10:36:27.527658 47347556983680 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpyqmwb9tw
I0618 10:36:27.528783 47347556983680 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpyqmwb9tw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b103ee6fda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:36:27.529226 47347556983680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:36:27.532695 47521665471360 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:36:27.533170 47789547209600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:36:27.534476 47347556983680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:36:27.535583 47439359329152 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:36:27.555411 47347556983680 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875787.431247 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875787.431754 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875787.432183 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:36:27.566934 47095825384320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_0_0
:::MLL 1560875787.428621 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875787.429089 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875787.429524 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:36:27.566963 47228474196864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_0_0
:::MLL 1560875787.426621 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875787.427351 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875787.428038 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:36:27.566202 47598977008512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_0_0
:::MLL 1560875787.419305 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875787.420220 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875787.421073 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:36:27.566534 46971013362560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_0_0
W0618 10:36:27.568007 47095825384320 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp35zx7hfi
W0618 10:36:27.568036 47228474196864 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmptypr1qj1
I0618 10:36:27.568977 47095825384320 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp35zx7hfi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad5a2879e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:36:27.569011 47228474196864 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmptypr1qj1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af48503ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:36:27.569371 47095825384320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:36:27.569414 47228474196864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:36:27.567379 47598977008512 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpcwt6pc_n
W0618 10:36:27.567653 46971013362560 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpfcd58avf
I0618 10:36:27.568491 47598977008512 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpcwt6pc_n', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4ac8b41e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:36:27.568774 46971013362560 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpfcd58avf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab893274e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560875787.399490 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875787.400408 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875787.401106 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:36:27.569660 47127317930880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_0_0
I0618 10:36:27.568939 47598977008512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875787.398586 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875787.399439 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875787.400245 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:36:27.570041 47394182714240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_0_0
I0618 10:36:27.569222 46971013362560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875787.408730 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875787.409164 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875787.409514 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:36:27.570093 47018358875008 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_0_0
:::MLL 1560875787.408143 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875787.408602 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875787.408985 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:36:27.570209 47832659612544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_0_0
W0618 10:36:27.570795 47127317930880 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpfsyyil8c
I0618 10:36:27.571914 47127317930880 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpfsyyil8c', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adcf7a1bdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:36:27.571133 47394182714240 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmph7eb45w7
I0618 10:36:27.572235 47394182714240 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmph7eb45w7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1b1a032e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:36:27.571121 47018358875008 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpjmceyfpr
W0618 10:36:27.571204 47832659612544 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpt20mzs_h
I0618 10:36:27.572362 47127317930880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:36:27.572181 47018358875008 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpjmceyfpr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac3992a6da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:36:27.572688 47394182714240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:36:27.572253 47832659612544 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpt20mzs_h', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b813145ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:36:27.572654 47018358875008 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:36:27.572721 47832659612544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:36:27.574039 47095825384320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:36:27.574029 47228474196864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:36:27.574236 47598977008512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:36:27.574475 46971013362560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:36:27.577601 47127317930880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:36:27.577409 47018358875008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:36:27.577398 47832659612544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:36:27.577954 47394182714240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:36:27.580509 47521665471360 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:36:27.580862 47789547209600 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:36:27.584804 47521665471360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:36:27.584503 47439359329152 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:36:27.585151 47789547209600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:36:27.588818 47439359329152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:36:27.589926 47521665471360 estimator.py:1111] Calling model_fn.
W0618 10:36:27.590033 47521665471360 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:36:27.590258 47789547209600 estimator.py:1111] Calling model_fn.
W0618 10:36:27.590367 47789547209600 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:36:27.591397 47521665471360 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:36:27.591737 47789547209600 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:36:27.593069 47095825384320 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:36:27.593112 47228474196864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 10:36:27.593942 47439359329152 estimator.py:1111] Calling model_fn.
W0618 10:36:27.594053 47439359329152 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:36:27.595437 47439359329152 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:36:27.596436 47018358875008 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:36:27.596512 47832659612544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:36:27.595979 47598977008512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:36:27.596396 46971013362560 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:36:27.597975 47127317930880 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:36:27.598660 47394182714240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:36:27.603050 47347556983680 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560875787.468422 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875787.468835 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875787.469197 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:36:27.605469 47850101699456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_0_0
:::MLL 1560875787.470797 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875787.471241 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875787.471625 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:36:27.605546 47697284707200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_0_0
W0618 10:36:27.606552 47697284707200 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpturih3a8
W0618 10:36:27.606524 47850101699456 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpr_wab3xs
I0618 10:36:27.607509 47850101699456 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpr_wab3xs', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8540e6cdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:36:27.607530 47697284707200 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpturih3a8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b61ac4c8dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:36:27.607349 47347556983680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:36:27.607916 47850101699456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:36:27.607931 47697284707200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:36:27.612552 47697284707200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:36:27.612558 47850101699456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:36:27.612470 47347556983680 estimator.py:1111] Calling model_fn.
W0618 10:36:27.612580 47347556983680 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:36:27.613937 47347556983680 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560875787.504022 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875787.504433 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875787.504805 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:36:27.624265 46947106296704 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_0_0
W0618 10:36:27.625285 46947106296704 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpiiuu64iv
I0618 10:36:27.626280 46947106296704 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpiiuu64iv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab3022e5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:36:27.626691 46947106296704 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875787.500828 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875787.501310 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875787.501698 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:36:27.627471 47661493089152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_0_0
W0618 10:36:27.628562 47661493089152 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp773n7gdw
I0618 10:36:27.629528 47661493089152 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp773n7gdw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5956f3bdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:36:27.629929 47661493089152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:36:27.631650 47850101699456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:36:27.631703 47697284707200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:36:27.631335 46947106296704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:36:27.634852 47661493089152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:36:27.640646 47095825384320 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:36:27.640960 47228474196864 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:36:27.643699 47832659612544 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:36:27.644226 47018358875008 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:36:27.644936 47095825384320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:36:27.645268 47228474196864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:36:27.645184 47127317930880 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:36:27.644050 46971013362560 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:36:27.644142 47598977008512 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560875787.484589 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875787.485539 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875787.486272 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:36:27.645404 47921693508480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_0_0
W0618 10:36:27.646078 47394182714240 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560875787.488745 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875787.489492 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875787.490211 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:36:27.645649 47097628414848 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000029-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000020-000010.tfrecord.zz_0_0
W0618 10:36:27.646433 47921693508480 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp35zyvivw
W0618 10:36:27.646640 47097628414848 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmppnr93yf0
I0618 10:36:27.647422 47921693508480 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp35zyvivw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b95ec1b1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:36:27.647627 47097628414848 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmppnr93yf0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad60dff9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:36:27.647830 47921693508480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:36:27.648035 47097628414848 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:36:27.647994 47832659612544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:36:27.648536 47018358875008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:36:27.649459 47127317930880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:36:27.648342 46971013362560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:36:27.648434 47598977008512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:36:27.649994 47095825384320 estimator.py:1111] Calling model_fn.
W0618 10:36:27.650103 47095825384320 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:36:27.650357 47228474196864 estimator.py:1111] Calling model_fn.
W0618 10:36:27.650473 47228474196864 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:36:27.650401 47394182714240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:36:27.651452 47095825384320 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:36:27.650362 46947106296704 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:36:27.651838 47228474196864 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:36:27.652504 47921693508480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:36:27.652627 47097628414848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:36:27.653041 47832659612544 estimator.py:1111] Calling model_fn.
W0618 10:36:27.653149 47832659612544 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:36:27.653664 47018358875008 estimator.py:1111] Calling model_fn.
W0618 10:36:27.653775 47018358875008 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:36:27.654535 47127317930880 estimator.py:1111] Calling model_fn.
I0618 10:36:27.653408 46971013362560 estimator.py:1111] Calling model_fn.
W0618 10:36:27.654642 47127317930880 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.lay[2019-06-18 10:37:08] divide_golden_chunk finished: 3.257 seconds
[2019-06-18 10:37:08] generate golden chunk: 3.271 seconds
[2019-06-18 10:37:08] moving /lfs/lfs12/gma_akey/results/epb074/models/000030-000015.index --> /lfs/lfs12/gma_akey/results/epb074/models/000030-000016.index
[2019-06-18 10:37:08] moving /lfs/lfs12/gma_akey/results/epb074/models/000030-000015.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb074/models/000030-000016.data-00000-of-00001
[2019-06-18 10:37:08] moving /lfs/lfs12/gma_akey/results/epb074/models/000030-000015.pb --> /lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb
[2019-06-18 10:37:08] moving /lfs/lfs12/gma_akey/results/epb074/models/000030-000015.meta --> /lfs/lfs12/gma_akey/results/epb074/models/000030-000016.meta
[2019-06-18 10:37:08] iteration time 29: 51.217 seconds
2019-06-18 10:37:10.061435: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560875828.469003 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 30}}
[2019-06-18 10:37:13] minmax time: 3.281 seconds
2019-06-18 10:37:13.352989: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 10:37:13.358506: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 10:37:13.363107: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560875833.374269 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 29}}
[2019-06-18 10:37:13] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000031-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000031-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000031-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb311 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000031-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000031-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000031-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000031-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb130 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000031-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000031-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000031-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb074/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb074/models/000031-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb073 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:37:13] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-eval-31-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000030-000016 --seed=31 : \
-host epb087 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000030-000016 --seed=1023779862 : \
-host epb155 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000030-000016 --seed=2047559693 : \
-host epb230 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000030-000016 --seed=3071339524 : \
-host epb079 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000030-000016 --seed=4095119355 : \
-host epb287 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000030-000016 --seed=5118899186 : \
-host epb076 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000030-000016 --seed=6142679017 : \
-host epb233 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000030-000016 --seed=7166458848 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000030-000016 --seed=8190238679 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000030-000016 --seed=9214018510 : \
-host epb263 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000030-000016 --seed=10237798341 : \
-host epb239 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000030-000016 --seed=11261578172 : \
-host epb156 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000030-000016 --seed=12285358003 : \
-host epb077 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000030-000016 --seed=13309137834 : \
-host epb078 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000030-000016 --seed=14332917665 : \
-host epb101 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000030-000016 --seed=15356697496 : \
-host epb252 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000030-000016 --seed=16380477327 : \
-host epb231 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000030-000016 --seed=17404257158 : \
-host epb050 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000030-000016 --seed=18428036989 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000030-000016 --seed=19451816820 : \
-host epb100 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/000029-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/000030-000016 --seed=20475596651 : \
-host epb237 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 10:37:25] eval finished: 11.606 seconds
[2019-06-18 10:37:25] Win rate 000030-000016 vs 000029-000015: 0.600
:::MLL 1560875845.060627 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 29}}
[2019-06-18 10:37:25] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-selfplay-32-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb074 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000031-000015 --seed=32 : \
-host epb087 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000031-000015 --seed=1023779863 : \
-host epb155 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000031-000015 --seed=2047559694 : \
-host epb230 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000031-000015 --seed=3071339525 : \
-host epb079 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000031-000015 --seed=4095119356 : \
-host epb287 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000031-000015 --seed=5118899187 : \
-host epb076 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000031-000015 --seed=6142679018 : \
-host epb233 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000031-000015 --seed=7166458849 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000031-000015 --seed=8190238680 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000031-000015 --seed=9214018511 : \
-host epb263 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000031-000015 --seed=10237798342 : \
-host epb239 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000031-000015 --seed=11261578173 : \
-host epb156 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000031-000015 --seed=12285358004 : \
-host epb077 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000031-000015 --seed=13309137835 : \
-host epb078 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000031-000015 --seed=14332917666 : \
-host epb101 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000031-000015 --seed=15356697497 : \
-host epb252 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000031-000015 --seed=16380477328 : \
-host epb231 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000031-000015 --seed=17404257159 : \
-host epb050 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb074/data/holdout/000031-000015 --seed=18428036990 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb074/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000030-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb07
[2019-06-18 10:37:54] selfplay finished: 29.301 seconds
[2019-06-18 10:37:54] selfplay mn: 29.321 seconds
[2019-06-18 10:37:54] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb074/mpi/out-divide_golden_chunk-32-%r.txt \
-host epb074 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000031-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=32 : \
-host epb087 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000031-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=1023779863 : \
-host epb155 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000031-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=2047559694 : \
-host epb230 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000031-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=3071339525 : \
-host epb079 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000031-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=4095119356 : \
-host epb287 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000031-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=5118899187 : \
-host epb076 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000031-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=6142679018 : \
-host epb233 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000031-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=7166458849 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000031-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=8190238680 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000031-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=9214018511 : \
-host epb263 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000031-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=10237798342 : \
-host epb239 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000031-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=11261578173 : \
-host epb156 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000031-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=12285358004 : \
-host epb077 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000031-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=13309137835 : \
-host epb078 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000031-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=14332917666 : \
-host epb101 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000031-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=15356697497 : \
-host epb252 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000031-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=16380477328 : \
-host epb231 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000031-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=17404257159 : \
-host epb050 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000031-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=18428036990 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000031-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=19451816821 : \
-host epb100 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000031-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=20475596652 : \
-host epb237 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000031-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=21499376483 : \
-host epb235 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000031-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb074 --seed=22523156314 : \
-host epb159 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb074/data/selfplay/000031-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb074/data/golde
[2019-06-18 10:37:56] train finished: 43.572 seconds
:::MLL 1560875838.626554 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875838.627435 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875838.628243 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:37:18.748258 47820205364096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_0_0
:::MLL 1560875838.637354 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875838.638051 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875838.638654 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:37:18.748731 47764943586176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_0_0
W0618 10:37:18.749257 47820205364096 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpe6n3u9xh
I0618 10:37:18.750254 47820205364096 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpe6n3u9xh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7e4af0ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:37:18.749726 47764943586176 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpdybqci9j
I0618 10:37:18.750719 47820205364096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:37:18.750773 47764943586176 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpdybqci9j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b716d151da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:37:18.751234 47764943586176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875838.620223 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875838.620894 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875838.621543 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:37:18.753033 47718469776256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_0_0
:::MLL 1560875838.605039 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875838.605901 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875838.606729 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:37:18.753042 47257476752256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_0_0
W0618 10:37:18.754208 47718469776256 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmppddxem_n
W0618 10:37:18.754241 47257476752256 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp98vocn9i
W0618 10:37:18.755583 47820205364096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:37:18.755332 47718469776256 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmppddxem_n', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b669b06fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:37:18.755333 47257476752256 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp98vocn9i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afb45b3be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:37:18.755970 47764943586176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:37:18.755783 47718469776256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:37:18.755782 47257476752256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:37:18.761149 47718469776256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:37:18.761168 47257476752256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:37:18.774924 47820205364096 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:37:18.775453 47764943586176 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:37:18.782269 47257476752256 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:37:18.782572 47718469776256 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875838.684762 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875838.685179 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875838.685534 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:37:18.815583 47925852730240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_0_0
:::MLL 1560875838.687395 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875838.687816 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875838.688160 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:37:18.816397 47643533370240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_0_0
W0618 10:37:18.816635 47925852730240 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpynavev1u
:::MLL 1560875838.657992 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875838.658836 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875838.659646 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:37:18.817696 47175621546880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_0_0
:::MLL 1560875838.657800 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875838.658624 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875838.659468 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:37:18.817660 47678316057472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_0_0
I0618 10:37:18.817639 47925852730240 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpynavev1u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b96e403ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:37:18.818044 47925852730240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:37:18.817379 47643533370240 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpmehtmy96
I0618 10:37:18.818357 47643533370240 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpmehtmy96', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5528781e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560875838.711802 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875838.712280 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875838.712720 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:37:18.818752 47904102122368 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_0_0
:::MLL 1560875838.713179 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875838.713667 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875838.714089 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:37:18.818968 47659245863808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_0_0
I0618 10:37:18.818755 47643533370240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:37:18.819020 47678316057472 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmprz2wmx1z
W0618 10:37:18.819047 47175621546880 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpv0rm_d6w
W0618 10:37:18.819774 47904102122368 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpk_q7d8gi
W0618 10:37:18.819967 47659245863808 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp4u8oljex
I0618 10:37:18.820559 47175621546880 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpv0rm_d6w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae836c06dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:37:18.820558 47678316057472 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmprz2wmx1z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5d41adee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:37:18.820778 47904102122368 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpk_q7d8gi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b91d393de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:37:18.820950 47659245863808 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp4u8oljex', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b58d101de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:37:18.821178 47904102122368 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:37:18.821350 47659245863808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:37:18.821224 47175621546880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:37:18.821224 47678316057472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:37:18.823146 47820205364096 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:37:18.822709 47925852730240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:37:18.823334 47643533370240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:37:18.823995 47764943586176 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:37:18.825886 47904102122368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:37:18.825952 47659245863808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:37:18.827478 47820205364096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:37:18.828405 47764943586176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:37:18.828549 47175621546880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:37:18.828549 47678316057472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:37:18.831213 47257476752256 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:37:18.831684 47718469776256 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 10:37:18.832611 47820205364096 estimator.py:1111] Calling model_fn.
W0618 10:37:18.832721 47820205364096 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:37:18.833571 47764943586176 estimator.py:1111] Calling model_fn.
W0618 10:37:18.833683 47764943586176 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:37:18.834080 47820205364096 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:37:18.835059 47764943586176 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:37:18.835497 47257476752256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:37:18.836018 47718469776256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:37:18.840543 47257476752256 estimator.py:1111] Calling model_fn.
W0618 10:37:18.840657 47257476752256 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:37:18.841140 47718469776256 estimator.py:1111] Calling model_fn.
W0618 10:37:18.841255 47718469776256 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:37:18.841586 47925852730240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:37:18.842000 47257476752256 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:37:18.842280 47643533370240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:37:18.842631 47718469776256 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:37:18.844878 47659245863808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:37:18.845181 47904102122368 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875838.690105 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875838.691005 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875838.691859 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:37:18.849818 47705098539904 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_0_0
:::MLL 1560875838.699922 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875838.700683 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875838.701350 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:37:18.850205 47407722111872 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_0_0
W0618 10:37:18.850981 47705098539904 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpiwdbjdjy
I0618 10:37:18.852090 47705098539904 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpiwdbjdjy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b637e0a1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:37:18.851297 47407722111872 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmp_v5a8asg
I0618 10:37:18.852463 47407722111872 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmp_v5a8asg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1e4105edd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:37:18.852545 47705098539904 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:37:18.852895 47407722111872 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:37:18.856937 47175621546880 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:37:18.857266 47678316057472 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560875838.735738 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875838.736460 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875838.737137 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:37:18.857662 47988383036288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_0_0
:::MLL 1560875838.725956 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875838.726885 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875838.727757 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:37:18.857697 47506479281024 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_0_0
W0618 10:37:18.857765 47705098539904 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:37:18.857982 47407722111872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:37:18.858843 47506479281024 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpcg7muzzw
I0618 10:37:18.858864 47988383036288 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb074/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba5731c7d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560875838.728936 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875838.729379 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875838.729798 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:37:18.860036 47472220672896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_0_0
I0618 10:37:18.859944 47506479281024 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpcg7muzzw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b353f68ce80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:37:18.860108 47988383036288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560875838.729161 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875838.729618 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875838.730009 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:37:18.860515 47809660552064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_0_0
I0618 10:37:18.860378 47506479281024 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:37:18.861040 47472220672896 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpzi7bjfmm
I0618 10:37:18.862045 47472220672896 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpzi7bjfmm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2d456fee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 10:37:18.861497 47809660552064 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpsew8q99m
I0618 10:37:18.862461 47472220672896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:37:18.862503 47809660552064 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpsew8q99m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7bd66bde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:37:18.862910 47809660552064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:37:18.865344 47988383036288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:37:18.865461 47506479281024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:37:18.867149 47472220672896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:37:18.867484 47809660552064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:37:18.879383 47705098539904 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:37:18.879449 47407722111872 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:37:18.886044 47472220672896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:37:18.886521 47809660552064 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:37:18.886796 47988383036288 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:37:18.886903 47506479281024 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 10:37:18.888820 47925852730240 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:37:18.889085 47643533370240 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:37:18.892268 47659245863808 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:37:18.892842 47904102122368 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:37:18.893092 47925852730240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:37:18.893395 47643533370240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:37:18.896579 47659245863808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:37:18.897213 47904102122368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 10:37:18.898143 47925852730240 estimator.py:1111] Calling model_fn.
W0618 10:37:18.898252 47925852730240 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:37:18.898452 47643533370240 estimator.py:1111] Calling model_fn.
W0618 10:37:18.898568 47643533370240 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:37:18.899612 47925852730240 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:37:18.899919 47643533370240 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 10:37:18.901678 47659245863808 estimator.py:1111] Calling model_fn.
W0618 10:37:18.901787 47659245863808 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:37:18.902416 47904102122368 estimator.py:1111] Calling model_fn.
W0618 10:37:18.902526 47904102122368 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:37:18.903133 47659245863808 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:37:18.903910 47904102122368 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:37:18.904311 47175621546880 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 10:37:18.904752 47678316057472 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560875838.765481 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875838.765960 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875838.766364 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:37:18.904572 47884291429248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_0_0
:::MLL 1560875838.765607 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875838.766085 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875838.766494 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:37:18.904670 47703419671424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000030-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/000021-000011.tfrecord.zz_0_0
W0618 10:37:18.905618 47884291429248 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmppakuosyc
W0618 10:37:18.905663 47703419671424 estimator.py:1760] Using temporary folder as model directory: /tmp/96728.tmpdir/tmpq1fb5lrq
I0618 10:37:18.906607 47884291429248 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmppakuosyc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8d36c4ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:37:18.906649 47703419671424 estimator.py:201] Using config: {'_model_dir': '/tmp/96728.tmpdir/tmpq1fb5lrq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6319f89e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 10:37:18.907013 47884291429248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 10:37:18.907047 47703419671424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 10:37:18.908611 47175621546880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:37:18.909073 47678316057472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 10:37:18.911684 47884291429248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 10:37:18.911694 47703419671424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 10:37:18.913716 47175621546880 estimator.py:1111] Calling model_fn.
W0618 10:37:18.913823 47175621546880 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 10:37:18.914173 47678316057472 estimator.py:1111] Calling model_fn.
W0618 10:37:18.914284 47678316057472 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 10:37:18.915188 47175621546880 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 10:37:18.915652 47678316057472 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560875838.810296 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560875838.810837 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560875838.811245 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 10:37:18.924802 47868512830336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb074/d[2019-06-18 10:37:57] divide_golden_chunk finished: 3.426 seconds
[2019-06-18 10:37:57] generate golden chunk: 3.441 seconds
[2019-06-18 10:37:57] moving /lfs/lfs12/gma_akey/results/epb074/models/000031-000016.pb --> /lfs/lfs12/gma_akey/results/epb074/models/000031-000017.pb
[2019-06-18 10:37:57] moving /lfs/lfs12/gma_akey/results/epb074/models/000031-000016.index --> /lfs/lfs12/gma_akey/results/epb074/models/000031-000017.index
[2019-06-18 10:37:57] moving /lfs/lfs12/gma_akey/results/epb074/models/000031-000016.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb074/models/000031-000017.data-00000-of-00001
[2019-06-18 10:37:57] moving /lfs/lfs12/gma_akey/results/epb074/models/000031-000016.meta --> /lfs/lfs12/gma_akey/results/epb074/models/000031-000017.meta
[2019-06-18 10:37:57] iteration time 30: 49.396 seconds
:::MLL 1560875877.865452 epoch_stop: {"value": null, "metadata": {'lineno': 737, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 30}}
[2019-06-18 10:37:57] Total time: 1704.903 seconds

numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000018-000011_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000018-000011log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000019-000011_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000019-000011log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000020-000012_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000020-000012log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000021-000013_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000021-000013log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000022-000013_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000022-000013log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000023-000014_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000023-000014log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000024-000014_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000024-000014log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000025-000014_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000025-000014log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000026-000014_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000026-000014log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000027-000014_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000027-000014log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000028-000015_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000028-000015log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000029-000015_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000029-000015log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb074/models/000030-000016_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb074/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb074/models/000030-000016log.txt
:::MLL 1560875880.585779 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 0}}
I0618 10:38:00.586556 47083541758848 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/target --seed=1
I0618 10:38:27.164166 47083541758848 utils.py:86] eval finished: 26.577 seconds
I0618 10:38:27.177071 47083541758848 reference_implementation.py:563] Win rate 000001-000001 vs target: 0.050
:::MLL 1560875907.177777 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 0}}
:::MLL 1560875907.178120 eval_accuracy: {"value": 0.05, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 0}}
:::MLL 1560875907.178457 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 1}}
I0618 10:38:27.178769 47083541758848 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/target --seed=2
I0618 10:38:54.484765 47083541758848 utils.py:86] eval finished: 27.306 seconds
I0618 10:38:54.487607 47083541758848 reference_implementation.py:563] Win rate 000002-000001 vs target: 0.090
:::MLL 1560875934.488815 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 1}}
:::MLL 1560875934.489146 eval_accuracy: {"value": 0.09, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 1}}
:::MLL 1560875934.489472 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 2}}
I0618 10:38:54.489794 47083541758848 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/target --seed=3
I0618 10:39:21.869532 47083541758848 utils.py:86] eval finished: 27.380 seconds
I0618 10:39:21.872420 47083541758848 reference_implementation.py:563] Win rate 000003-000002 vs target: 0.060
:::MLL 1560875961.873108 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 2}}
:::MLL 1560875961.873443 eval_accuracy: {"value": 0.06, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 2}}
:::MLL 1560875961.873777 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 3}}
I0618 10:39:21.874112 47083541758848 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/target --seed=4
I0618 10:39:48.205450 47083541758848 utils.py:86] eval finished: 26.331 seconds
I0618 10:39:48.208348 47083541758848 reference_implementation.py:563] Win rate 000004-000002 vs target: 0.090
:::MLL 1560875988.209029 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 3}}
:::MLL 1560875988.209370 eval_accuracy: {"value": 0.09, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 3}}
:::MLL 1560875988.209699 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 4}}
I0618 10:39:48.210012 47083541758848 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000005-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/target --seed=5
I0618 10:40:14.302592 47083541758848 utils.py:86] eval finished: 26.092 seconds
I0618 10:40:14.305467 47083541758848 reference_implementation.py:563] Win rate 000005-000002 vs target: 0.130
:::MLL 1560876014.306279 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 4}}
:::MLL 1560876014.306605 eval_accuracy: {"value": 0.13, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 4}}
:::MLL 1560876014.306922 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 5}}
I0618 10:40:14.307247 47083541758848 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000006-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/target --seed=6
I0618 10:40:40.532267 47083541758848 utils.py:86] eval finished: 26.225 seconds
I0618 10:40:40.535129 47083541758848 reference_implementation.py:563] Win rate 000006-000003 vs target: 0.060
:::MLL 1560876040.535817 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 5}}
:::MLL 1560876040.536146 eval_accuracy: {"value": 0.06, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 5}}
:::MLL 1560876040.536470 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 6}}
I0618 10:40:40.536764 47083541758848 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/target --seed=7
I0618 10:41:03.433163 47083541758848 utils.py:86] eval finished: 22.896 seconds
I0618 10:41:03.436021 47083541758848 reference_implementation.py:563] Win rate 000007-000004 vs target: 0.110
:::MLL 1560876063.436914 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 6}}
:::MLL 1560876063.437258 eval_accuracy: {"value": 0.11, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 6}}
:::MLL 1560876063.437584 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 7}}
I0618 10:41:03.437907 47083541758848 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000008-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/target --seed=8
I0618 10:41:31.135742 47083541758848 utils.py:86] eval finished: 27.698 seconds
I0618 10:41:31.148548 47083541758848 reference_implementation.py:563] Win rate 000008-000004 vs target: 0.170
:::MLL 1560876091.149391 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 7}}
:::MLL 1560876091.149726 eval_accuracy: {"value": 0.17, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 7}}
:::MLL 1560876091.150062 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 8}}
I0618 10:41:31.150368 47083541758848 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000009-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/target --seed=9
I0618 10:41:56.572359 47083541758848 utils.py:86] eval finished: 25.422 seconds
I0618 10:41:56.575310 47083541758848 reference_implementation.py:563] Win rate 000009-000005 vs target: 0.140
:::MLL 1560876116.575984 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 8}}
:::MLL 1560876116.576316 eval_accuracy: {"value": 0.14, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 8}}
:::MLL 1560876116.576634 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 9}}
I0618 10:41:56.576945 47083541758848 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/target --seed=10
I0618 10:42:24.306053 47083541758848 utils.py:86] eval finished: 27.729 seconds
I0618 10:42:24.314126 47083541758848 reference_implementation.py:563] Win rate 000010-000006 vs target: 0.110
:::MLL 1560876144.314785 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 9}}
:::MLL 1560876144.315101 eval_accuracy: {"value": 0.11, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 9}}
:::MLL 1560876144.315403 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 10}}
I0618 10:42:24.315703 47083541758848 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000011-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/target --seed=11
I0618 10:42:48.401255 47083541758848 utils.py:86] eval finished: 24.085 seconds
I0618 10:42:48.404139 47083541758848 reference_implementation.py:563] Win rate 000011-000006 vs target: 0.210
:::MLL 1560876168.404948 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 10}}
:::MLL 1560876168.405282 eval_accuracy: {"value": 0.21, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 10}}
:::MLL 1560876168.405602 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 11}}
I0618 10:42:48.405900 47083541758848 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/target --seed=12
I0618 10:43:12.458960 47083541758848 utils.py:86] eval finished: 24.053 seconds
I0618 10:43:12.461756 47083541758848 reference_implementation.py:563] Win rate 000012-000007 vs target: 0.200
:::MLL 1560876192.462630 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 11}}
:::MLL 1560876192.462956 eval_accuracy: {"value": 0.2, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 11}}
:::MLL 1560876192.463302 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 12}}
I0618 10:43:12.463611 47083541758848 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000013-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/target --seed=13
I0618 10:43:37.332466 47083541758848 utils.py:86] eval finished: 24.869 seconds
I0618 10:43:37.335349 47083541758848 reference_implementation.py:563] Win rate 000013-000007 vs target: 0.190
:::MLL 1560876217.336049 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 12}}
:::MLL 1560876217.336378 eval_accuracy: {"value": 0.19, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 12}}
:::MLL 1560876217.336680 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 13}}
I0618 10:43:37.336977 47083541758848 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/target --seed=14
I0618 10:44:01.003524 47083541758848 utils.py:86] eval finished: 23.666 seconds
I0618 10:44:01.006520 47083541758848 reference_implementation.py:563] Win rate 000014-000008 vs target: 0.300
:::MLL 1560876241.007417 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 13}}
:::MLL 1560876241.007751 eval_accuracy: {"value": 0.3, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 13}}
:::MLL 1560876241.008086 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 14}}
I0618 10:44:01.008397 47083541758848 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb074/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb074/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb074/sgf/eval/target --seed=15
I0618 10:44:23.742141 47083541758848 utils.py:86] eval finished: 22.734 seconds
I0618 10:44:23.744923 47083541758848 reference_implementation.py:563] Win rate 000015-000009 vs target: 0.520
:::MLL 1560876263.745617 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 14}}
:::MLL 1560876263.745941 eval_accuracy: {"value": 0.52, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 14}}
:::MLL 1560876263.746280 eval_result: {"value": null, "metadata": {'lineno': 52, 'file': 'ml_perf/eval_models.py', 'iteration': 14, 'timestamp': 749.586}}
:::MLL 1560876263.746582 run_stop: {"value": null, "metadata": {'lineno': 53, 'file': 'ml_perf/eval_models.py', 'status': 'success'}}
Model 000015-000009 beat target after 749.586s
~/submission/benchmarks/minigo/clx-8260l-2s-x32
